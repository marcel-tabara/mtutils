{
  "service_name": "sagemaker-runtime",
  "service_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sagemaker-runtime/index.html",
  "service_commands": [
    {
      "command_name": "invoke-endpoint",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sagemaker-runtime/invoke-endpoint.html",
      "command_description": "Description\n\nAfter you deploy a model into production using Amazon SageMaker hosting services, your client applications use this API to get inferences from the model hosted at the specified endpoint.\n\nFor an overview of Amazon SageMaker, see How It Works .\n\nAmazon SageMaker strips all POST headers except those supported by the API. Amazon SageMaker might add additional headers. You should not rely on the behavior of headers outside those enumerated in the request syntax.\n\nCalls to InvokeEndpoint are authenticated by using AWS Signature Version 4. For information, see Authenticating Requests (AWS Signature Version 4) in the Amazon S3 API Reference .\n\nA customer’s model containers must respond to requests within 60 seconds. The model itself can have a maximum processing time of 60 seconds before responding to invocations. If your model is going to take 50-60 seconds of processing time, the SDK socket timeout should be set to be 70 seconds.\n\nNote\n\nEndpoints are scoped to an individual account, and are not public. The URL does not contain the account ID, but Amazon SageMaker determines the account ID from the authentication token that is supplied by the caller.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  invoke-endpoint\n--endpoint-name <value>\n--body <value>\n[--content-type <value>]\n[--accept <value>]\n[--custom-attributes <value>]\n[--target-model <value>]\n[--target-variant <value>]\n[--target-container-hostname <value>]\n[--inference-id <value>]\n<outfile>\n",
      "command_options": [
        "--endpoint-name <value>",
        "--body <value>",
        "[--content-type <value>]",
        "[--accept <value>]",
        "[--custom-attributes <value>]",
        "[--target-model <value>]",
        "[--target-variant <value>]",
        "[--target-container-hostname <value>]",
        "[--inference-id <value>]",
        "<outfile>"
      ],
      "command_options_description": "Options\n\n--endpoint-name (string)\n\nThe name of the endpoint that you specified when you created the endpoint using the CreateEndpoint API.\n\n--body (blob)\n\nProvides input data, in the format specified in the ContentType request header. Amazon SageMaker passes all of the data in the body to the model.\n\nFor information about the format of the request body, see Common Data Formats-Inference .\n\n--content-type (string)\n\nThe MIME type of the input data in the request body.\n\n--accept (string)\n\nThe desired MIME type of the inference in the response.\n\n--custom-attributes (string)\n\nProvides additional information about a request for an inference submitted to a model hosted at an Amazon SageMaker endpoint. The information is an opaque value that is forwarded verbatim. You could use this value, for example, to provide an ID that you can use to track a request or to provide other metadata that a service endpoint was programmed to process. The value must consist of no more than 1024 visible US-ASCII characters as specified in Section 3.3.6. Field Value Components of the Hypertext Transfer Protocol (HTTP/1.1).\n\nThe code in your model is responsible for setting or updating any custom attributes in the response. If your code does not set this value in the response, an empty value is returned. For example, if a custom attribute represents the trace ID, your model can prepend the custom attribute with Trace ID: in your post-processing function.\n\nThis feature is currently supported in the AWS SDKs but not in the Amazon SageMaker Python SDK.\n\n--target-model (string)\n\nThe model to request for inference when invoking a multi-model endpoint.\n\n--target-variant (string)\n\nSpecify the production variant to send the inference request to when invoking an endpoint that is running two or more variants. Note that this parameter overrides the default behavior for the endpoint, which is to distribute the invocation traffic based on the variant weights.\n\nFor information about how to use variant targeting to perform a/b testing, see Test models in production\n\n--target-container-hostname (string)\n\nIf the endpoint hosts multiple containers and is configured to use direct invocation, this parameter specifies the host name of the container to invoke.\n\n--inference-id (string)\n\nIf you provide a value, it is added to the captured data when you enable data capture on the endpoint. For information about data capture, see Capture Data .\n\noutfile (string) Filename where the content will be saved\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nBody -> (blob)\n\nIncludes the inference provided by the model.\n\nFor information about the format of the response body, see Common Data Formats-Inference .\n\nContentType -> (string)\n\nThe MIME type of the inference returned in the response body.\n\nInvokedProductionVariant -> (string)\n\nIdentifies the production variant that was invoked.\n\nCustomAttributes -> (string)\n\nProvides additional information in the response about the inference returned by a model hosted at an Amazon SageMaker endpoint. The information is an opaque value that is forwarded verbatim. You could use this value, for example, to return an ID received in the CustomAttributes header of a request or other metadata that a service endpoint was programmed to produce. The value must consist of no more than 1024 visible US-ASCII characters as specified in Section 3.3.6. Field Value Components of the Hypertext Transfer Protocol (HTTP/1.1). If the customer wants the custom attribute returned, the model must set the custom attribute to be included on the way back.\n\nThe code in your model is responsible for setting or updating any custom attributes in the response. If your code does not set this value in the response, an empty value is returned. For example, if a custom attribute represents the trace ID, your model can prepend the custom attribute with Trace ID: in your post-processing function.\n\nThis feature is currently supported in the AWS SDKs but not in the Amazon SageMaker Python SDK."
    },
    {
      "command_name": "invoke-endpoint-async",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sagemaker-runtime/invoke-endpoint-async.html",
      "command_description": "Description\n\nAfter you deploy a model into production using Amazon SageMaker hosting services, your client applications use this API to get inferences from the model hosted at the specified endpoint in an asynchronous manner.\n\nInference requests sent to this API are enqueued for asynchronous processing. The processing of the inference request may or may not complete before the you receive a response from this API. The response from this API will not contain the result of the inference request but contain information about where you can locate it.\n\nAmazon SageMaker strips all POST headers except those supported by the API. Amazon SageMaker might add additional headers. You should not rely on the behavior of headers outside those enumerated in the request syntax.\n\nCalls to InvokeEndpointAsync are authenticated by using AWS Signature Version 4. For information, see Authenticating Requests (AWS Signature Version 4) in the Amazon S3 API Reference .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  invoke-endpoint-async\n--endpoint-name <value>\n[--content-type <value>]\n[--accept <value>]\n[--custom-attributes <value>]\n[--inference-id <value>]\n--input-location <value>\n[--request-ttl-seconds <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--endpoint-name <value>",
        "[--content-type <value>]",
        "[--accept <value>]",
        "[--custom-attributes <value>]",
        "[--inference-id <value>]",
        "--input-location <value>",
        "[--request-ttl-seconds <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--endpoint-name (string)\n\nThe name of the endpoint that you specified when you created the endpoint using the ` CreateEndpoint https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEndpoint.html`__ API.\n\n--content-type (string)\n\nThe MIME type of the input data in the request body.\n\n--accept (string)\n\nThe desired MIME type of the inference in the response.\n\n--custom-attributes (string)\n\nProvides additional information about a request for an inference submitted to a model hosted at an Amazon SageMaker endpoint. The information is an opaque value that is forwarded verbatim. You could use this value, for example, to provide an ID that you can use to track a request or to provide other metadata that a service endpoint was programmed to process. The value must consist of no more than 1024 visible US-ASCII characters as specified in Section 3.3.6. Field Value Components of the Hypertext Transfer Protocol (HTTP/1.1).\n\nThe code in your model is responsible for setting or updating any custom attributes in the response. If your code does not set this value in the response, an empty value is returned. For example, if a custom attribute represents the trace ID, your model can prepend the custom attribute with Trace ID : in your post-processing function.\n\nThis feature is currently supported in the AWS SDKs but not in the Amazon SageMaker Python SDK.\n\n--inference-id (string)\n\nThe identifier for the inference request. Amazon SageMaker will generate an identifier for you if none is specified.\n\n--input-location (string)\n\nThe Amazon S3 URI where the inference request payload is stored.\n\n--request-ttl-seconds (integer)\n\nMaximum age in seconds a request can be in the queue before it is marked as expired.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nInferenceId -> (string)\n\nIdentifier for an inference request. This will be the same as the InferenceId specified in the input. Amazon SageMaker will generate an identifier for you if you do not specify one.\n\nOutputLocation -> (string)\n\nThe Amazon S3 URI where the inference response payload is stored."
    }
  ],
  "service_description": "Description\n\nThe Amazon SageMaker runtime API."
}