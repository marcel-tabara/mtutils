{
  "service_name": "medialive",
  "service_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/index.html",
  "service_commands": [
    {
      "command_name": "accept-input-device-transfer",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/accept-input-device-transfer.html",
      "command_description": "Description\n\nAccept an incoming input device transfer. The ownership of the device will transfer to your AWS account.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  accept-input-device-transfer\n--input-device-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-device-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-device-id (string) The unique ID of the input device to accept. For example, hd-123456789abcdef.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "batch-delete",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/batch-delete.html",
      "command_description": "Description\n\nStarts delete of resources.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  batch-delete\n[--channel-ids <value>]\n[--input-ids <value>]\n[--input-security-group-ids <value>]\n[--multiplex-ids <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--channel-ids <value>]",
        "[--input-ids <value>]",
        "[--input-security-group-ids <value>]",
        "[--multiplex-ids <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-ids (list) List of channel IDs(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--input-ids (list) List of input IDs(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--input-security-group-ids (list) List of input security group IDs(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--multiplex-ids (list) List of multiplex IDs(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nFailed -> (list)\n\nList of failed operations\n\n(structure)\n\nDetails from a failed operation\n\nArn -> (string)\n\nARN of the resource\n\nCode -> (string)\n\nError code for the failed operation\n\nId -> (string)\n\nID of the resource\n\nMessage -> (string)\n\nError message for the failed operation\n\nSuccessful -> (list)\n\nList of successful operations\n\n(structure)\n\nDetails from a successful operation\n\nArn -> (string)\n\nARN of the resource\n\nId -> (string)\n\nID of the resource\n\nState -> (string)\n\nCurrent state of the resource"
    },
    {
      "command_name": "batch-start",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/batch-start.html",
      "command_description": "Description\n\nStarts existing resources\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  batch-start\n[--channel-ids <value>]\n[--multiplex-ids <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--channel-ids <value>]",
        "[--multiplex-ids <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-ids (list) List of channel IDs(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--multiplex-ids (list) List of multiplex IDs(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nFailed -> (list)\n\nList of failed operations\n\n(structure)\n\nDetails from a failed operation\n\nArn -> (string)\n\nARN of the resource\n\nCode -> (string)\n\nError code for the failed operation\n\nId -> (string)\n\nID of the resource\n\nMessage -> (string)\n\nError message for the failed operation\n\nSuccessful -> (list)\n\nList of successful operations\n\n(structure)\n\nDetails from a successful operation\n\nArn -> (string)\n\nARN of the resource\n\nId -> (string)\n\nID of the resource\n\nState -> (string)\n\nCurrent state of the resource"
    },
    {
      "command_name": "batch-stop",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/batch-stop.html",
      "command_description": "Description\n\nStops running resources\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  batch-stop\n[--channel-ids <value>]\n[--multiplex-ids <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--channel-ids <value>]",
        "[--multiplex-ids <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-ids (list) List of channel IDs(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--multiplex-ids (list) List of multiplex IDs(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nFailed -> (list)\n\nList of failed operations\n\n(structure)\n\nDetails from a failed operation\n\nArn -> (string)\n\nARN of the resource\n\nCode -> (string)\n\nError code for the failed operation\n\nId -> (string)\n\nID of the resource\n\nMessage -> (string)\n\nError message for the failed operation\n\nSuccessful -> (list)\n\nList of successful operations\n\n(structure)\n\nDetails from a successful operation\n\nArn -> (string)\n\nARN of the resource\n\nId -> (string)\n\nID of the resource\n\nState -> (string)\n\nCurrent state of the resource"
    },
    {
      "command_name": "batch-update-schedule",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/batch-update-schedule.html",
      "command_description": "Description\n\nUpdate a channel schedule\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  batch-update-schedule\n--channel-id <value>\n[--creates <value>]\n[--deletes <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-id <value>",
        "[--creates <value>]",
        "[--deletes <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-id (string) Id of the channel whose schedule is being updated.\n\n--creates (structure) Schedule actions to create in the schedule.ScheduleActions -> (list)\n\nA list of schedule actions to create.\n\n(structure)\n\nContains information on a single schedule action.\n\nActionName -> (string)\n\nThe name of the action, must be unique within the schedule. This name provides the main reference to an action once it is added to the schedule. A name is unique if it is no longer in the schedule. The schedule is automatically cleaned up to remove actions with a start time of more than 1 hour ago (approximately) so at that point a name can be reused.\n\nScheduleActionSettings -> (structure)\n\nSettings for this schedule action.\n\nHlsId3SegmentTaggingSettings -> (structure)\n\nAction to insert HLS ID3 segment tagging\n\nTag -> (string)\n\nID3 tag to insert into each segment. Supports special keyword identifiers to substitute in segment-related values.nSupported keyword identifiers: https://docs.aws.amazon.com/medialive/latest/ug/variable-data-identifiers.html\n\nHlsTimedMetadataSettings -> (structure)\n\nAction to insert HLS metadata\n\nId3 -> (string)\n\nBase64 string formatted according to the ID3 specification: http://id3.org/id3v2.4.0-structure\n\nInputPrepareSettings -> (structure)\n\nAction to prepare an input for a future immediate input switch\n\nInputAttachmentNameReference -> (string)\n\nThe name of the input attachment that should be prepared by this action. If no name is provided, the action will stop the most recent prepare (if any) when activated.\n\nInputClippingSettings -> (structure)\n\nSettings to let you create a clip of the file input, in order to set up the input to ingest only a portion of the file.\n\nInputTimecodeSource -> (string)\n\nThe source of the timecodes in the source being clipped.\n\nStartTimecode -> (structure)\n\nSettings to identify the start of the clip.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to start the clip. Optional; if not specified, the clip starts at first frame in the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nStopTimecode -> (structure)\n\nSettings to identify the end of the clip.\n\nLastFrameClippingBehavior -> (string)\n\nIf you specify a StopTimecode in an input (in order to clip the file), you can specify if you want the clip to exclude (the default) or include the frame specified by the timecode.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to stop the clip. Optional; if not specified, the clip continues to the end of the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nUrlPath -> (list)\n\nThe value for the variable portion of the URL for the dynamic input, for this instance of the input. Each time you use the same dynamic input in an input switch action, you can provide a different value, in order to connect the input to a different content source.\n\n(string)\n\nPlaceholder documentation for __string\n\nInputSwitchSettings -> (structure)\n\nAction to switch the input\n\nInputAttachmentNameReference -> (string)\n\nThe name of the input attachment (not the name of the input!) to switch to. The name is specified in the channel configuration.\n\nInputClippingSettings -> (structure)\n\nSettings to let you create a clip of the file input, in order to set up the input to ingest only a portion of the file.\n\nInputTimecodeSource -> (string)\n\nThe source of the timecodes in the source being clipped.\n\nStartTimecode -> (structure)\n\nSettings to identify the start of the clip.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to start the clip. Optional; if not specified, the clip starts at first frame in the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nStopTimecode -> (structure)\n\nSettings to identify the end of the clip.\n\nLastFrameClippingBehavior -> (string)\n\nIf you specify a StopTimecode in an input (in order to clip the file), you can specify if you want the clip to exclude (the default) or include the frame specified by the timecode.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to stop the clip. Optional; if not specified, the clip continues to the end of the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nUrlPath -> (list)\n\nThe value for the variable portion of the URL for the dynamic input, for this instance of the input. Each time you use the same dynamic input in an input switch action, you can provide a different value, in order to connect the input to a different content source.\n\n(string)\n\nPlaceholder documentation for __string\n\nMotionGraphicsImageActivateSettings -> (structure)\n\nAction to activate a motion graphics image overlay\n\nDuration -> (long)\n\nDuration (in milliseconds) that motion graphics should render on to the video stream. Leaving out this property or setting to 0 will result in rendering continuing until a deactivate action is processed.\n\nPasswordParam -> (string)\n\nKey used to extract the password from EC2 Parameter store\n\nUrl -> (string)\n\nURI of the HTML5 content to be rendered into the live stream.\n\nUsername -> (string)\n\nDocumentation update needed\n\nMotionGraphicsImageDeactivateSettings -> (structure)\n\nAction to deactivate a motion graphics image overlay\n\nPauseStateSettings -> (structure)\n\nAction to pause or unpause one or both channel pipelines\n\nPipelines -> (list)\n\nPlaceholder documentation for __listOfPipelinePauseStateSettings\n\n(structure)\n\nSettings for pausing a pipeline.\n\nPipelineId -> (string)\n\nPipeline ID to pause (“PIPELINE_0” or “PIPELINE_1”).\n\nScte35ReturnToNetworkSettings -> (structure)\n\nAction to insert SCTE-35 return_to_network message\n\nSpliceEventId -> (long)\n\nThe splice_event_id for the SCTE-35 splice_insert, as defined in SCTE-35.\n\nScte35SpliceInsertSettings -> (structure)\n\nAction to insert SCTE-35 splice_insert message\n\nDuration -> (long)\n\nOptional, the duration for the splice_insert, in 90 KHz ticks. To convert seconds to ticks, multiple the seconds by 90,000. If you enter a duration, there is an expectation that the downstream system can read the duration and cue in at that time. If you do not enter a duration, the splice_insert will continue indefinitely and there is an expectation that you will enter a return_to_network to end the splice_insert at the appropriate time.\n\nSpliceEventId -> (long)\n\nThe splice_event_id for the SCTE-35 splice_insert, as defined in SCTE-35.\n\nScte35TimeSignalSettings -> (structure)\n\nAction to insert SCTE-35 time_signal message\n\nScte35Descriptors -> (list)\n\nThe list of SCTE-35 descriptors accompanying the SCTE-35 time_signal.\n\n(structure)\n\nHolds one set of SCTE-35 Descriptor Settings.\n\nScte35DescriptorSettings -> (structure)\n\nSCTE-35 Descriptor Settings.\n\nSegmentationDescriptorScte35DescriptorSettings -> (structure)\n\nSCTE-35 Segmentation Descriptor.\n\nDeliveryRestrictions -> (structure)\n\nHolds the four SCTE-35 delivery restriction parameters.\n\nArchiveAllowedFlag -> (string)\n\nCorresponds to SCTE-35 archive_allowed_flag.\n\nDeviceRestrictions -> (string)\n\nCorresponds to SCTE-35 device_restrictions parameter.\n\nNoRegionalBlackoutFlag -> (string)\n\nCorresponds to SCTE-35 no_regional_blackout_flag parameter.\n\nWebDeliveryAllowedFlag -> (string)\n\nCorresponds to SCTE-35 web_delivery_allowed_flag parameter.\n\nSegmentNum -> (integer)\n\nCorresponds to SCTE-35 segment_num. A value that is valid for the specified segmentation_type_id.\n\nSegmentationCancelIndicator -> (string)\n\nCorresponds to SCTE-35 segmentation_event_cancel_indicator.\n\nSegmentationDuration -> (long)\n\nCorresponds to SCTE-35 segmentation_duration. Optional. The duration for the time_signal, in 90 KHz ticks. To convert seconds to ticks, multiple the seconds by 90,000. Enter time in 90 KHz clock ticks. If you do not enter a duration, the time_signal will continue until you insert a cancellation message.\n\nSegmentationEventId -> (long)\n\nCorresponds to SCTE-35 segmentation_event_id.\n\nSegmentationTypeId -> (integer)\n\nCorresponds to SCTE-35 segmentation_type_id. One of the segmentation_type_id values listed in the SCTE-35 specification. On the console, enter the ID in decimal (for example, “52”). In the CLI, API, or an SDK, enter the ID in hex (for example, “0x34”) or decimal (for example, “52”).\n\nSegmentationUpid -> (string)\n\nCorresponds to SCTE-35 segmentation_upid. Enter a string containing the hexadecimal representation of the characters that make up the SCTE-35 segmentation_upid value. Must contain an even number of hex characters. Do not include spaces between each hex pair. For example, the ASCII “ADS Information” becomes hex “41445320496e666f726d6174696f6e.\n\nSegmentationUpidType -> (integer)\n\nCorresponds to SCTE-35 segmentation_upid_type. On the console, enter one of the types listed in the SCTE-35 specification, converted to a decimal. For example, “0x0C” hex from the specification is “12” in decimal. In the CLI, API, or an SDK, enter one of the types listed in the SCTE-35 specification, in either hex (for example, “0x0C” ) or in decimal (for example, “12”).\n\nSegmentsExpected -> (integer)\n\nCorresponds to SCTE-35 segments_expected. A value that is valid for the specified segmentation_type_id.\n\nSubSegmentNum -> (integer)\n\nCorresponds to SCTE-35 sub_segment_num. A value that is valid for the specified segmentation_type_id.\n\nSubSegmentsExpected -> (integer)\n\nCorresponds to SCTE-35 sub_segments_expected. A value that is valid for the specified segmentation_type_id.\n\nStaticImageActivateSettings -> (structure)\n\nAction to activate a static image overlay\n\nDuration -> (integer)\n\nThe duration in milliseconds for the image to remain on the video. If omitted or set to 0 the duration is unlimited and the image will remain until it is explicitly deactivated.\n\nFadeIn -> (integer)\n\nThe time in milliseconds for the image to fade in. The fade-in starts at the start time of the overlay. Default is 0 (no fade-in).\n\nFadeOut -> (integer)\n\nApplies only if a duration is specified. The time in milliseconds for the image to fade out. The fade-out starts when the duration time is hit, so it effectively extends the duration. Default is 0 (no fade-out).\n\nHeight -> (integer)\n\nThe height of the image when inserted into the video, in pixels. The overlay will be scaled up or down to the specified height. Leave blank to use the native height of the overlay.\n\nImage -> (structure)\n\nThe location and filename of the image file to overlay on the video. The file must be a 32-bit BMP, PNG, or TGA file, and must not be larger (in pixels) than the input video.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nImageX -> (integer)\n\nPlacement of the left edge of the overlay relative to the left edge of the video frame, in pixels. 0 (the default) is the left edge of the frame. If the placement causes the overlay to extend beyond the right edge of the underlying video, then the overlay is cropped on the right.\n\nImageY -> (integer)\n\nPlacement of the top edge of the overlay relative to the top edge of the video frame, in pixels. 0 (the default) is the top edge of the frame. If the placement causes the overlay to extend beyond the bottom edge of the underlying video, then the overlay is cropped on the bottom.\n\nLayer -> (integer)\n\nThe number of the layer, 0 to 7. There are 8 layers that can be overlaid on the video, each layer with a different image. The layers are in Z order, which means that overlays with higher values of layer are inserted on top of overlays with lower values of layer. Default is 0.\n\nOpacity -> (integer)\n\nOpacity of image where 0 is transparent and 100 is fully opaque. Default is 100.\n\nWidth -> (integer)\n\nThe width of the image when inserted into the video, in pixels. The overlay will be scaled up or down to the specified width. Leave blank to use the native width of the overlay.\n\nStaticImageDeactivateSettings -> (structure)\n\nAction to deactivate a static image overlay\n\nFadeOut -> (integer)\n\nThe time in milliseconds for the image to fade out. Default is 0 (no fade-out).\n\nLayer -> (integer)\n\nThe image overlay layer to deactivate, 0 to 7. Default is 0.\n\nScheduleActionStartSettings -> (structure)\n\nThe time for the action to start in the channel.\n\nFixedModeScheduleActionStartSettings -> (structure)\n\nOption for specifying the start time for an action.\n\nTime -> (string)\n\nStart time for the action to start in the channel. (Not the time for the action to be added to the schedule: actions are always added to the schedule immediately.) UTC format: yyyy-mm-ddThh:mm:ss.nnnZ. All the letters are digits (for example, mm might be 01) except for the two constants “T” for time and “Z” for “UTC format”.\n\nFollowModeScheduleActionStartSettings -> (structure)\n\nOption for specifying an action as relative to another action.\n\nFollowPoint -> (string)\n\nIdentifies whether this action starts relative to the start or relative to the end of the reference action.\n\nReferenceActionName -> (string)\n\nThe action name of another action that this one refers to.\n\nImmediateModeScheduleActionStartSettings -> (structure)\n\nOption for specifying an action that should be applied immediately.\n\nJSON Syntax:\n\n{\n  \"ScheduleActions\": [\n    {\n      \"ActionName\": \"string\",\n      \"ScheduleActionSettings\": {\n        \"HlsId3SegmentTaggingSettings\": {\n          \"Tag\": \"string\"\n        },\n        \"HlsTimedMetadataSettings\": {\n          \"Id3\": \"string\"\n        },\n        \"InputPrepareSettings\": {\n          \"InputAttachmentNameReference\": \"string\",\n          \"InputClippingSettings\": {\n            \"InputTimecodeSource\": \"ZEROBASED\"|\"EMBEDDED\",\n            \"StartTimecode\": {\n              \"Timecode\": \"string\"\n            },\n            \"StopTimecode\": {\n              \"LastFrameClippingBehavior\": \"EXCLUDE_LAST_FRAME\"|\"INCLUDE_LAST_FRAME\",\n              \"Timecode\": \"string\"\n            }\n          },\n          \"UrlPath\": [\"string\", ...]\n        },\n        \"InputSwitchSettings\": {\n          \"InputAttachmentNameReference\": \"string\",\n          \"InputClippingSettings\": {\n            \"InputTimecodeSource\": \"ZEROBASED\"|\"EMBEDDED\",\n            \"StartTimecode\": {\n              \"Timecode\": \"string\"\n            },\n            \"StopTimecode\": {\n              \"LastFrameClippingBehavior\": \"EXCLUDE_LAST_FRAME\"|\"INCLUDE_LAST_FRAME\",\n              \"Timecode\": \"string\"\n            }\n          },\n          \"UrlPath\": [\"string\", ...]\n        },\n        \"MotionGraphicsImageActivateSettings\": {\n          \"Duration\": long,\n          \"PasswordParam\": \"string\",\n          \"Url\": \"string\",\n          \"Username\": \"string\"\n        },\n        \"MotionGraphicsImageDeactivateSettings\": {\n\n        },\n        \"PauseStateSettings\": {\n          \"Pipelines\": [\n            {\n              \"PipelineId\": \"PIPELINE_0\"|\"PIPELINE_1\"\n            }\n            ...\n          ]\n        },\n        \"Scte35ReturnToNetworkSettings\": {\n          \"SpliceEventId\": long\n        },\n        \"Scte35SpliceInsertSettings\": {\n          \"Duration\": long,\n          \"SpliceEventId\": long\n        },\n        \"Scte35TimeSignalSettings\": {\n          \"Scte35Descriptors\": [\n            {\n              \"Scte35DescriptorSettings\": {\n                \"SegmentationDescriptorScte35DescriptorSettings\": {\n                  \"DeliveryRestrictions\": {\n                    \"ArchiveAllowedFlag\": \"ARCHIVE_NOT_ALLOWED\"|\"ARCHIVE_ALLOWED\",\n                    \"DeviceRestrictions\": \"NONE\"|\"RESTRICT_GROUP0\"|\"RESTRICT_GROUP1\"|\"RESTRICT_GROUP2\",\n                    \"NoRegionalBlackoutFlag\": \"REGIONAL_BLACKOUT\"|\"NO_REGIONAL_BLACKOUT\",\n                    \"WebDeliveryAllowedFlag\": \"WEB_DELIVERY_NOT_ALLOWED\"|\"WEB_DELIVERY_ALLOWED\"\n                  },\n                  \"SegmentNum\": integer,\n                  \"SegmentationCancelIndicator\": \"SEGMENTATION_EVENT_NOT_CANCELED\"|\"SEGMENTATION_EVENT_CANCELED\",\n                  \"SegmentationDuration\": long,\n                  \"SegmentationEventId\": long,\n                  \"SegmentationTypeId\": integer,\n                  \"SegmentationUpid\": \"string\",\n                  \"SegmentationUpidType\": integer,\n                  \"SegmentsExpected\": integer,\n                  \"SubSegmentNum\": integer,\n                  \"SubSegmentsExpected\": integer\n                }\n              }\n            }\n            ...\n          ]\n        },\n        \"StaticImageActivateSettings\": {\n          \"Duration\": integer,\n          \"FadeIn\": integer,\n          \"FadeOut\": integer,\n          \"Height\": integer,\n          \"Image\": {\n            \"PasswordParam\": \"string\",\n            \"Uri\": \"string\",\n            \"Username\": \"string\"\n          },\n          \"ImageX\": integer,\n          \"ImageY\": integer,\n          \"Layer\": integer,\n          \"Opacity\": integer,\n          \"Width\": integer\n        },\n        \"StaticImageDeactivateSettings\": {\n          \"FadeOut\": integer,\n          \"Layer\": integer\n        }\n      },\n      \"ScheduleActionStartSettings\": {\n        \"FixedModeScheduleActionStartSettings\": {\n          \"Time\": \"string\"\n        },\n        \"FollowModeScheduleActionStartSettings\": {\n          \"FollowPoint\": \"END\"|\"START\",\n          \"ReferenceActionName\": \"string\"\n        },\n        \"ImmediateModeScheduleActionStartSettings\": {\n\n        }\n      }\n    }\n    ...\n  ]\n}\n\n\n--deletes (structure) Schedule actions to delete from the schedule.ActionNames -> (list)\n\nA list of schedule actions to delete.\n\n(string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nActionNames=string,string\n\n\nJSON Syntax:\n\n{\n  \"ActionNames\": [\"string\", ...]\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nCreates -> (structure)\n\nSchedule actions created in the schedule.\n\nScheduleActions -> (list)\n\nList of actions that have been created in the schedule.\n\n(structure)\n\nContains information on a single schedule action.\n\nActionName -> (string)\n\nThe name of the action, must be unique within the schedule. This name provides the main reference to an action once it is added to the schedule. A name is unique if it is no longer in the schedule. The schedule is automatically cleaned up to remove actions with a start time of more than 1 hour ago (approximately) so at that point a name can be reused.\n\nScheduleActionSettings -> (structure)\n\nSettings for this schedule action.\n\nHlsId3SegmentTaggingSettings -> (structure)\n\nAction to insert HLS ID3 segment tagging\n\nTag -> (string)\n\nID3 tag to insert into each segment. Supports special keyword identifiers to substitute in segment-related values.nSupported keyword identifiers: https://docs.aws.amazon.com/medialive/latest/ug/variable-data-identifiers.html\n\nHlsTimedMetadataSettings -> (structure)\n\nAction to insert HLS metadata\n\nId3 -> (string)\n\nBase64 string formatted according to the ID3 specification: http://id3.org/id3v2.4.0-structure\n\nInputPrepareSettings -> (structure)\n\nAction to prepare an input for a future immediate input switch\n\nInputAttachmentNameReference -> (string)\n\nThe name of the input attachment that should be prepared by this action. If no name is provided, the action will stop the most recent prepare (if any) when activated.\n\nInputClippingSettings -> (structure)\n\nSettings to let you create a clip of the file input, in order to set up the input to ingest only a portion of the file.\n\nInputTimecodeSource -> (string)\n\nThe source of the timecodes in the source being clipped.\n\nStartTimecode -> (structure)\n\nSettings to identify the start of the clip.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to start the clip. Optional; if not specified, the clip starts at first frame in the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nStopTimecode -> (structure)\n\nSettings to identify the end of the clip.\n\nLastFrameClippingBehavior -> (string)\n\nIf you specify a StopTimecode in an input (in order to clip the file), you can specify if you want the clip to exclude (the default) or include the frame specified by the timecode.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to stop the clip. Optional; if not specified, the clip continues to the end of the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nUrlPath -> (list)\n\nThe value for the variable portion of the URL for the dynamic input, for this instance of the input. Each time you use the same dynamic input in an input switch action, you can provide a different value, in order to connect the input to a different content source.\n\n(string)\n\nPlaceholder documentation for __string\n\nInputSwitchSettings -> (structure)\n\nAction to switch the input\n\nInputAttachmentNameReference -> (string)\n\nThe name of the input attachment (not the name of the input!) to switch to. The name is specified in the channel configuration.\n\nInputClippingSettings -> (structure)\n\nSettings to let you create a clip of the file input, in order to set up the input to ingest only a portion of the file.\n\nInputTimecodeSource -> (string)\n\nThe source of the timecodes in the source being clipped.\n\nStartTimecode -> (structure)\n\nSettings to identify the start of the clip.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to start the clip. Optional; if not specified, the clip starts at first frame in the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nStopTimecode -> (structure)\n\nSettings to identify the end of the clip.\n\nLastFrameClippingBehavior -> (string)\n\nIf you specify a StopTimecode in an input (in order to clip the file), you can specify if you want the clip to exclude (the default) or include the frame specified by the timecode.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to stop the clip. Optional; if not specified, the clip continues to the end of the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nUrlPath -> (list)\n\nThe value for the variable portion of the URL for the dynamic input, for this instance of the input. Each time you use the same dynamic input in an input switch action, you can provide a different value, in order to connect the input to a different content source.\n\n(string)\n\nPlaceholder documentation for __string\n\nMotionGraphicsImageActivateSettings -> (structure)\n\nAction to activate a motion graphics image overlay\n\nDuration -> (long)\n\nDuration (in milliseconds) that motion graphics should render on to the video stream. Leaving out this property or setting to 0 will result in rendering continuing until a deactivate action is processed.\n\nPasswordParam -> (string)\n\nKey used to extract the password from EC2 Parameter store\n\nUrl -> (string)\n\nURI of the HTML5 content to be rendered into the live stream.\n\nUsername -> (string)\n\nDocumentation update needed\n\nMotionGraphicsImageDeactivateSettings -> (structure)\n\nAction to deactivate a motion graphics image overlay\n\nPauseStateSettings -> (structure)\n\nAction to pause or unpause one or both channel pipelines\n\nPipelines -> (list)\n\nPlaceholder documentation for __listOfPipelinePauseStateSettings\n\n(structure)\n\nSettings for pausing a pipeline.\n\nPipelineId -> (string)\n\nPipeline ID to pause (“PIPELINE_0” or “PIPELINE_1”).\n\nScte35ReturnToNetworkSettings -> (structure)\n\nAction to insert SCTE-35 return_to_network message\n\nSpliceEventId -> (long)\n\nThe splice_event_id for the SCTE-35 splice_insert, as defined in SCTE-35.\n\nScte35SpliceInsertSettings -> (structure)\n\nAction to insert SCTE-35 splice_insert message\n\nDuration -> (long)\n\nOptional, the duration for the splice_insert, in 90 KHz ticks. To convert seconds to ticks, multiple the seconds by 90,000. If you enter a duration, there is an expectation that the downstream system can read the duration and cue in at that time. If you do not enter a duration, the splice_insert will continue indefinitely and there is an expectation that you will enter a return_to_network to end the splice_insert at the appropriate time.\n\nSpliceEventId -> (long)\n\nThe splice_event_id for the SCTE-35 splice_insert, as defined in SCTE-35.\n\nScte35TimeSignalSettings -> (structure)\n\nAction to insert SCTE-35 time_signal message\n\nScte35Descriptors -> (list)\n\nThe list of SCTE-35 descriptors accompanying the SCTE-35 time_signal.\n\n(structure)\n\nHolds one set of SCTE-35 Descriptor Settings.\n\nScte35DescriptorSettings -> (structure)\n\nSCTE-35 Descriptor Settings.\n\nSegmentationDescriptorScte35DescriptorSettings -> (structure)\n\nSCTE-35 Segmentation Descriptor.\n\nDeliveryRestrictions -> (structure)\n\nHolds the four SCTE-35 delivery restriction parameters.\n\nArchiveAllowedFlag -> (string)\n\nCorresponds to SCTE-35 archive_allowed_flag.\n\nDeviceRestrictions -> (string)\n\nCorresponds to SCTE-35 device_restrictions parameter.\n\nNoRegionalBlackoutFlag -> (string)\n\nCorresponds to SCTE-35 no_regional_blackout_flag parameter.\n\nWebDeliveryAllowedFlag -> (string)\n\nCorresponds to SCTE-35 web_delivery_allowed_flag parameter.\n\nSegmentNum -> (integer)\n\nCorresponds to SCTE-35 segment_num. A value that is valid for the specified segmentation_type_id.\n\nSegmentationCancelIndicator -> (string)\n\nCorresponds to SCTE-35 segmentation_event_cancel_indicator.\n\nSegmentationDuration -> (long)\n\nCorresponds to SCTE-35 segmentation_duration. Optional. The duration for the time_signal, in 90 KHz ticks. To convert seconds to ticks, multiple the seconds by 90,000. Enter time in 90 KHz clock ticks. If you do not enter a duration, the time_signal will continue until you insert a cancellation message.\n\nSegmentationEventId -> (long)\n\nCorresponds to SCTE-35 segmentation_event_id.\n\nSegmentationTypeId -> (integer)\n\nCorresponds to SCTE-35 segmentation_type_id. One of the segmentation_type_id values listed in the SCTE-35 specification. On the console, enter the ID in decimal (for example, “52”). In the CLI, API, or an SDK, enter the ID in hex (for example, “0x34”) or decimal (for example, “52”).\n\nSegmentationUpid -> (string)\n\nCorresponds to SCTE-35 segmentation_upid. Enter a string containing the hexadecimal representation of the characters that make up the SCTE-35 segmentation_upid value. Must contain an even number of hex characters. Do not include spaces between each hex pair. For example, the ASCII “ADS Information” becomes hex “41445320496e666f726d6174696f6e.\n\nSegmentationUpidType -> (integer)\n\nCorresponds to SCTE-35 segmentation_upid_type. On the console, enter one of the types listed in the SCTE-35 specification, converted to a decimal. For example, “0x0C” hex from the specification is “12” in decimal. In the CLI, API, or an SDK, enter one of the types listed in the SCTE-35 specification, in either hex (for example, “0x0C” ) or in decimal (for example, “12”).\n\nSegmentsExpected -> (integer)\n\nCorresponds to SCTE-35 segments_expected. A value that is valid for the specified segmentation_type_id.\n\nSubSegmentNum -> (integer)\n\nCorresponds to SCTE-35 sub_segment_num. A value that is valid for the specified segmentation_type_id.\n\nSubSegmentsExpected -> (integer)\n\nCorresponds to SCTE-35 sub_segments_expected. A value that is valid for the specified segmentation_type_id.\n\nStaticImageActivateSettings -> (structure)\n\nAction to activate a static image overlay\n\nDuration -> (integer)\n\nThe duration in milliseconds for the image to remain on the video. If omitted or set to 0 the duration is unlimited and the image will remain until it is explicitly deactivated.\n\nFadeIn -> (integer)\n\nThe time in milliseconds for the image to fade in. The fade-in starts at the start time of the overlay. Default is 0 (no fade-in).\n\nFadeOut -> (integer)\n\nApplies only if a duration is specified. The time in milliseconds for the image to fade out. The fade-out starts when the duration time is hit, so it effectively extends the duration. Default is 0 (no fade-out).\n\nHeight -> (integer)\n\nThe height of the image when inserted into the video, in pixels. The overlay will be scaled up or down to the specified height. Leave blank to use the native height of the overlay.\n\nImage -> (structure)\n\nThe location and filename of the image file to overlay on the video. The file must be a 32-bit BMP, PNG, or TGA file, and must not be larger (in pixels) than the input video.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nImageX -> (integer)\n\nPlacement of the left edge of the overlay relative to the left edge of the video frame, in pixels. 0 (the default) is the left edge of the frame. If the placement causes the overlay to extend beyond the right edge of the underlying video, then the overlay is cropped on the right.\n\nImageY -> (integer)\n\nPlacement of the top edge of the overlay relative to the top edge of the video frame, in pixels. 0 (the default) is the top edge of the frame. If the placement causes the overlay to extend beyond the bottom edge of the underlying video, then the overlay is cropped on the bottom.\n\nLayer -> (integer)\n\nThe number of the layer, 0 to 7. There are 8 layers that can be overlaid on the video, each layer with a different image. The layers are in Z order, which means that overlays with higher values of layer are inserted on top of overlays with lower values of layer. Default is 0.\n\nOpacity -> (integer)\n\nOpacity of image where 0 is transparent and 100 is fully opaque. Default is 100.\n\nWidth -> (integer)\n\nThe width of the image when inserted into the video, in pixels. The overlay will be scaled up or down to the specified width. Leave blank to use the native width of the overlay.\n\nStaticImageDeactivateSettings -> (structure)\n\nAction to deactivate a static image overlay\n\nFadeOut -> (integer)\n\nThe time in milliseconds for the image to fade out. Default is 0 (no fade-out).\n\nLayer -> (integer)\n\nThe image overlay layer to deactivate, 0 to 7. Default is 0.\n\nScheduleActionStartSettings -> (structure)\n\nThe time for the action to start in the channel.\n\nFixedModeScheduleActionStartSettings -> (structure)\n\nOption for specifying the start time for an action.\n\nTime -> (string)\n\nStart time for the action to start in the channel. (Not the time for the action to be added to the schedule: actions are always added to the schedule immediately.) UTC format: yyyy-mm-ddThh:mm:ss.nnnZ. All the letters are digits (for example, mm might be 01) except for the two constants “T” for time and “Z” for “UTC format”.\n\nFollowModeScheduleActionStartSettings -> (structure)\n\nOption for specifying an action as relative to another action.\n\nFollowPoint -> (string)\n\nIdentifies whether this action starts relative to the start or relative to the end of the reference action.\n\nReferenceActionName -> (string)\n\nThe action name of another action that this one refers to.\n\nImmediateModeScheduleActionStartSettings -> (structure)\n\nOption for specifying an action that should be applied immediately.\n\nDeletes -> (structure)\n\nSchedule actions deleted from the schedule.\n\nScheduleActions -> (list)\n\nList of actions that have been deleted from the schedule.\n\n(structure)\n\nContains information on a single schedule action.\n\nActionName -> (string)\n\nThe name of the action, must be unique within the schedule. This name provides the main reference to an action once it is added to the schedule. A name is unique if it is no longer in the schedule. The schedule is automatically cleaned up to remove actions with a start time of more than 1 hour ago (approximately) so at that point a name can be reused.\n\nScheduleActionSettings -> (structure)\n\nSettings for this schedule action.\n\nHlsId3SegmentTaggingSettings -> (structure)\n\nAction to insert HLS ID3 segment tagging\n\nTag -> (string)\n\nID3 tag to insert into each segment. Supports special keyword identifiers to substitute in segment-related values.nSupported keyword identifiers: https://docs.aws.amazon.com/medialive/latest/ug/variable-data-identifiers.html\n\nHlsTimedMetadataSettings -> (structure)\n\nAction to insert HLS metadata\n\nId3 -> (string)\n\nBase64 string formatted according to the ID3 specification: http://id3.org/id3v2.4.0-structure\n\nInputPrepareSettings -> (structure)\n\nAction to prepare an input for a future immediate input switch\n\nInputAttachmentNameReference -> (string)\n\nThe name of the input attachment that should be prepared by this action. If no name is provided, the action will stop the most recent prepare (if any) when activated.\n\nInputClippingSettings -> (structure)\n\nSettings to let you create a clip of the file input, in order to set up the input to ingest only a portion of the file.\n\nInputTimecodeSource -> (string)\n\nThe source of the timecodes in the source being clipped.\n\nStartTimecode -> (structure)\n\nSettings to identify the start of the clip.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to start the clip. Optional; if not specified, the clip starts at first frame in the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nStopTimecode -> (structure)\n\nSettings to identify the end of the clip.\n\nLastFrameClippingBehavior -> (string)\n\nIf you specify a StopTimecode in an input (in order to clip the file), you can specify if you want the clip to exclude (the default) or include the frame specified by the timecode.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to stop the clip. Optional; if not specified, the clip continues to the end of the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nUrlPath -> (list)\n\nThe value for the variable portion of the URL for the dynamic input, for this instance of the input. Each time you use the same dynamic input in an input switch action, you can provide a different value, in order to connect the input to a different content source.\n\n(string)\n\nPlaceholder documentation for __string\n\nInputSwitchSettings -> (structure)\n\nAction to switch the input\n\nInputAttachmentNameReference -> (string)\n\nThe name of the input attachment (not the name of the input!) to switch to. The name is specified in the channel configuration.\n\nInputClippingSettings -> (structure)\n\nSettings to let you create a clip of the file input, in order to set up the input to ingest only a portion of the file.\n\nInputTimecodeSource -> (string)\n\nThe source of the timecodes in the source being clipped.\n\nStartTimecode -> (structure)\n\nSettings to identify the start of the clip.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to start the clip. Optional; if not specified, the clip starts at first frame in the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nStopTimecode -> (structure)\n\nSettings to identify the end of the clip.\n\nLastFrameClippingBehavior -> (string)\n\nIf you specify a StopTimecode in an input (in order to clip the file), you can specify if you want the clip to exclude (the default) or include the frame specified by the timecode.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to stop the clip. Optional; if not specified, the clip continues to the end of the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nUrlPath -> (list)\n\nThe value for the variable portion of the URL for the dynamic input, for this instance of the input. Each time you use the same dynamic input in an input switch action, you can provide a different value, in order to connect the input to a different content source.\n\n(string)\n\nPlaceholder documentation for __string\n\nMotionGraphicsImageActivateSettings -> (structure)\n\nAction to activate a motion graphics image overlay\n\nDuration -> (long)\n\nDuration (in milliseconds) that motion graphics should render on to the video stream. Leaving out this property or setting to 0 will result in rendering continuing until a deactivate action is processed.\n\nPasswordParam -> (string)\n\nKey used to extract the password from EC2 Parameter store\n\nUrl -> (string)\n\nURI of the HTML5 content to be rendered into the live stream.\n\nUsername -> (string)\n\nDocumentation update needed\n\nMotionGraphicsImageDeactivateSettings -> (structure)\n\nAction to deactivate a motion graphics image overlay\n\nPauseStateSettings -> (structure)\n\nAction to pause or unpause one or both channel pipelines\n\nPipelines -> (list)\n\nPlaceholder documentation for __listOfPipelinePauseStateSettings\n\n(structure)\n\nSettings for pausing a pipeline.\n\nPipelineId -> (string)\n\nPipeline ID to pause (“PIPELINE_0” or “PIPELINE_1”).\n\nScte35ReturnToNetworkSettings -> (structure)\n\nAction to insert SCTE-35 return_to_network message\n\nSpliceEventId -> (long)\n\nThe splice_event_id for the SCTE-35 splice_insert, as defined in SCTE-35.\n\nScte35SpliceInsertSettings -> (structure)\n\nAction to insert SCTE-35 splice_insert message\n\nDuration -> (long)\n\nOptional, the duration for the splice_insert, in 90 KHz ticks. To convert seconds to ticks, multiple the seconds by 90,000. If you enter a duration, there is an expectation that the downstream system can read the duration and cue in at that time. If you do not enter a duration, the splice_insert will continue indefinitely and there is an expectation that you will enter a return_to_network to end the splice_insert at the appropriate time.\n\nSpliceEventId -> (long)\n\nThe splice_event_id for the SCTE-35 splice_insert, as defined in SCTE-35.\n\nScte35TimeSignalSettings -> (structure)\n\nAction to insert SCTE-35 time_signal message\n\nScte35Descriptors -> (list)\n\nThe list of SCTE-35 descriptors accompanying the SCTE-35 time_signal.\n\n(structure)\n\nHolds one set of SCTE-35 Descriptor Settings.\n\nScte35DescriptorSettings -> (structure)\n\nSCTE-35 Descriptor Settings.\n\nSegmentationDescriptorScte35DescriptorSettings -> (structure)\n\nSCTE-35 Segmentation Descriptor.\n\nDeliveryRestrictions -> (structure)\n\nHolds the four SCTE-35 delivery restriction parameters.\n\nArchiveAllowedFlag -> (string)\n\nCorresponds to SCTE-35 archive_allowed_flag.\n\nDeviceRestrictions -> (string)\n\nCorresponds to SCTE-35 device_restrictions parameter.\n\nNoRegionalBlackoutFlag -> (string)\n\nCorresponds to SCTE-35 no_regional_blackout_flag parameter.\n\nWebDeliveryAllowedFlag -> (string)\n\nCorresponds to SCTE-35 web_delivery_allowed_flag parameter.\n\nSegmentNum -> (integer)\n\nCorresponds to SCTE-35 segment_num. A value that is valid for the specified segmentation_type_id.\n\nSegmentationCancelIndicator -> (string)\n\nCorresponds to SCTE-35 segmentation_event_cancel_indicator.\n\nSegmentationDuration -> (long)\n\nCorresponds to SCTE-35 segmentation_duration. Optional. The duration for the time_signal, in 90 KHz ticks. To convert seconds to ticks, multiple the seconds by 90,000. Enter time in 90 KHz clock ticks. If you do not enter a duration, the time_signal will continue until you insert a cancellation message.\n\nSegmentationEventId -> (long)\n\nCorresponds to SCTE-35 segmentation_event_id.\n\nSegmentationTypeId -> (integer)\n\nCorresponds to SCTE-35 segmentation_type_id. One of the segmentation_type_id values listed in the SCTE-35 specification. On the console, enter the ID in decimal (for example, “52”). In the CLI, API, or an SDK, enter the ID in hex (for example, “0x34”) or decimal (for example, “52”).\n\nSegmentationUpid -> (string)\n\nCorresponds to SCTE-35 segmentation_upid. Enter a string containing the hexadecimal representation of the characters that make up the SCTE-35 segmentation_upid value. Must contain an even number of hex characters. Do not include spaces between each hex pair. For example, the ASCII “ADS Information” becomes hex “41445320496e666f726d6174696f6e.\n\nSegmentationUpidType -> (integer)\n\nCorresponds to SCTE-35 segmentation_upid_type. On the console, enter one of the types listed in the SCTE-35 specification, converted to a decimal. For example, “0x0C” hex from the specification is “12” in decimal. In the CLI, API, or an SDK, enter one of the types listed in the SCTE-35 specification, in either hex (for example, “0x0C” ) or in decimal (for example, “12”).\n\nSegmentsExpected -> (integer)\n\nCorresponds to SCTE-35 segments_expected. A value that is valid for the specified segmentation_type_id.\n\nSubSegmentNum -> (integer)\n\nCorresponds to SCTE-35 sub_segment_num. A value that is valid for the specified segmentation_type_id.\n\nSubSegmentsExpected -> (integer)\n\nCorresponds to SCTE-35 sub_segments_expected. A value that is valid for the specified segmentation_type_id.\n\nStaticImageActivateSettings -> (structure)\n\nAction to activate a static image overlay\n\nDuration -> (integer)\n\nThe duration in milliseconds for the image to remain on the video. If omitted or set to 0 the duration is unlimited and the image will remain until it is explicitly deactivated.\n\nFadeIn -> (integer)\n\nThe time in milliseconds for the image to fade in. The fade-in starts at the start time of the overlay. Default is 0 (no fade-in).\n\nFadeOut -> (integer)\n\nApplies only if a duration is specified. The time in milliseconds for the image to fade out. The fade-out starts when the duration time is hit, so it effectively extends the duration. Default is 0 (no fade-out).\n\nHeight -> (integer)\n\nThe height of the image when inserted into the video, in pixels. The overlay will be scaled up or down to the specified height. Leave blank to use the native height of the overlay.\n\nImage -> (structure)\n\nThe location and filename of the image file to overlay on the video. The file must be a 32-bit BMP, PNG, or TGA file, and must not be larger (in pixels) than the input video.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nImageX -> (integer)\n\nPlacement of the left edge of the overlay relative to the left edge of the video frame, in pixels. 0 (the default) is the left edge of the frame. If the placement causes the overlay to extend beyond the right edge of the underlying video, then the overlay is cropped on the right.\n\nImageY -> (integer)\n\nPlacement of the top edge of the overlay relative to the top edge of the video frame, in pixels. 0 (the default) is the top edge of the frame. If the placement causes the overlay to extend beyond the bottom edge of the underlying video, then the overlay is cropped on the bottom.\n\nLayer -> (integer)\n\nThe number of the layer, 0 to 7. There are 8 layers that can be overlaid on the video, each layer with a different image. The layers are in Z order, which means that overlays with higher values of layer are inserted on top of overlays with lower values of layer. Default is 0.\n\nOpacity -> (integer)\n\nOpacity of image where 0 is transparent and 100 is fully opaque. Default is 100.\n\nWidth -> (integer)\n\nThe width of the image when inserted into the video, in pixels. The overlay will be scaled up or down to the specified width. Leave blank to use the native width of the overlay.\n\nStaticImageDeactivateSettings -> (structure)\n\nAction to deactivate a static image overlay\n\nFadeOut -> (integer)\n\nThe time in milliseconds for the image to fade out. Default is 0 (no fade-out).\n\nLayer -> (integer)\n\nThe image overlay layer to deactivate, 0 to 7. Default is 0.\n\nScheduleActionStartSettings -> (structure)\n\nThe time for the action to start in the channel.\n\nFixedModeScheduleActionStartSettings -> (structure)\n\nOption for specifying the start time for an action.\n\nTime -> (string)\n\nStart time for the action to start in the channel. (Not the time for the action to be added to the schedule: actions are always added to the schedule immediately.) UTC format: yyyy-mm-ddThh:mm:ss.nnnZ. All the letters are digits (for example, mm might be 01) except for the two constants “T” for time and “Z” for “UTC format”.\n\nFollowModeScheduleActionStartSettings -> (structure)\n\nOption for specifying an action as relative to another action.\n\nFollowPoint -> (string)\n\nIdentifies whether this action starts relative to the start or relative to the end of the reference action.\n\nReferenceActionName -> (string)\n\nThe action name of another action that this one refers to.\n\nImmediateModeScheduleActionStartSettings -> (structure)\n\nOption for specifying an action that should be applied immediately."
    },
    {
      "command_name": "cancel-input-device-transfer",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/cancel-input-device-transfer.html",
      "command_description": "Description\n\nCancel an input device transfer that you have requested.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  cancel-input-device-transfer\n--input-device-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-device-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-device-id (string) The unique ID of the input device to cancel. For example, hd-123456789abcdef.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "claim-device",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/claim-device.html",
      "command_description": "Description\n\nSend a request to claim an AWS Elemental device that you have purchased from a third-party vendor. After the request succeeds, you will own the device.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  claim-device\n[--id <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--id <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--id (string) The id of the device you want to claim.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "create-channel",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/create-channel.html",
      "command_description": "Description\n\nCreates a new channel\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-channel\n[--cdi-input-specification <value>]\n[--channel-class <value>]\n[--destinations <value>]\n[--encoder-settings <value>]\n[--input-attachments <value>]\n[--input-specification <value>]\n[--log-level <value>]\n[--name <value>]\n[--request-id <value>]\n[--reserved <value>]\n[--role-arn <value>]\n[--tags <value>]\n[--vpc <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cdi-input-specification <value>]",
        "[--channel-class <value>]",
        "[--destinations <value>]",
        "[--encoder-settings <value>]",
        "[--input-attachments <value>]",
        "[--input-specification <value>]",
        "[--log-level <value>]",
        "[--name <value>]",
        "[--request-id <value>]",
        "[--reserved <value>]",
        "[--role-arn <value>]",
        "[--tags <value>]",
        "[--vpc <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cdi-input-specification (structure) Specification of CDI inputs for this channelResolution -> (string)\n\nMaximum CDI input resolution\n\nShorthand Syntax:\n\nResolution=string\n\n\nJSON Syntax:\n\n{\n  \"Resolution\": \"SD\"|\"HD\"|\"FHD\"|\"UHD\"\n}\n\n\n--channel-class (string) The class for this channel. STANDARD for a channel with two pipelines or SINGLE_PIPELINE for a channel with one pipeline.\n\nPossible values:\n\nSTANDARD\n\nSINGLE_PIPELINE\n\n--destinations (list) Placeholder documentation for __listOfOutputDestination(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nShorthand Syntax:\n\nId=string,MediaPackageSettings=[{ChannelId=string},{ChannelId=string}],MultiplexSettings={MultiplexId=string,ProgramName=string},Settings=[{PasswordParam=string,StreamName=string,Url=string,Username=string},{PasswordParam=string,StreamName=string,Url=string,Username=string}] ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Id\": \"string\",\n    \"MediaPackageSettings\": [\n      {\n        \"ChannelId\": \"string\"\n      }\n      ...\n    ],\n    \"MultiplexSettings\": {\n      \"MultiplexId\": \"string\",\n      \"ProgramName\": \"string\"\n    },\n    \"Settings\": [\n      {\n        \"PasswordParam\": \"string\",\n        \"StreamName\": \"string\",\n        \"Url\": \"string\",\n        \"Username\": \"string\"\n      }\n      ...\n    ]\n  }\n  ...\n]\n\n\n--encoder-settings (structure) Encoder SettingsAudioDescriptions -> (list)\n\nPlaceholder documentation for __listOfAudioDescription\n\n(structure)\n\nAudio Description\n\nAudioNormalizationSettings -> (structure)\n\nAdvanced audio normalization settings.\n\nAlgorithm -> (string)\n\nAudio normalization algorithm to use. itu17701 conforms to the CALM Act specification, itu17702 conforms to the EBU R-128 specification.\n\nAlgorithmControl -> (string)\n\nWhen set to correctAudio the output audio is corrected using the chosen algorithm. If set to measureOnly, the audio will be measured but not adjusted.\n\nTargetLkfs -> (double)\n\nTarget LKFS(loudness) to adjust volume to. If no value is entered, a default value will be used according to the chosen algorithm. The CALM Act (1770-1) recommends a target of -24 LKFS. The EBU R-128 specification (1770-2) recommends a target of -23 LKFS.\n\nAudioSelectorName -> (string)\n\nThe name of the AudioSelector used as the source for this AudioDescription.\n\nAudioType -> (string)\n\nApplies only if audioTypeControl is useConfigured. The values for audioType are defined in ISO-IEC 13818-1.\n\nAudioTypeControl -> (string)\n\nDetermines how audio type is determined. followInput: If the input contains an ISO 639 audioType, then that value is passed through to the output. If the input contains no ISO 639 audioType, the value in Audio Type is included in the output. useConfigured: The value in Audio Type is included in the output. Note that this field and audioType are both ignored if inputType is broadcasterMixedAd.\n\nAudioWatermarkingSettings -> (structure)\n\nSettings to configure one or more solutions that insert audio watermarks in the audio encode\n\nNielsenWatermarksSettings -> (structure)\n\nSettings to configure Nielsen Watermarks in the audio encode\n\nNielsenCbetSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen CBET\n\nCbetCheckDigitString -> (string)\n\nEnter the CBET check digits to use in the watermark.\n\nCbetStepaside -> (string)\n\nDetermines the method of CBET insertion mode when prior encoding is detected on the same layer.\n\nCsid -> (string)\n\nEnter the CBET Source ID (CSID) to use in the watermark\n\nNielsenDistributionType -> (string)\n\nChoose the distribution types that you want to assign to the watermarks: - PROGRAM_CONTENT - FINAL_DISTRIBUTOR\n\nNielsenNaesIiNwSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen NAES II (N2) and Nielsen NAES VI (NW).\n\nCheckDigitString -> (string)\n\nEnter the check digit string for the watermark\n\nSid -> (double)\n\nEnter the Nielsen Source ID (SID) to include in the watermark\n\nCodecSettings -> (structure)\n\nAudio codec settings.\n\nAacSettings -> (structure)\n\nAac Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid values depend on rate control mode and profile.\n\nCodingMode -> (string)\n\nMono, Stereo, or 5.1 channel layout. Valid values depend on rate control mode and profile. The adReceiverMix setting receives a stereo description plus control track and emits a mono AAC encode of the description track, with control data emitted in the PES header as per ETSI TS 101 154 Annex E.\n\nInputType -> (string)\n\nSet to “broadcasterMixedAd” when input contains pre-mixed main audio + AD (narration) as a stereo pair. The Audio Type field (audioType) will be set to 3, which signals to downstream systems that this stream contains “broadcaster mixed AD”. Note that the input received by the encoder must contain pre-mixed audio; the encoder does not perform the mixing. The values in audioTypeControl and audioType (in AudioDescription) are ignored when set to broadcasterMixedAd. Leave set to “normal” when input does not contain pre-mixed audio + AD.\n\nProfile -> (string)\n\nAAC Profile.\n\nRateControlMode -> (string)\n\nRate Control Mode.\n\nRawFormat -> (string)\n\nSets LATM / LOAS AAC output for raw containers.\n\nSampleRate -> (double)\n\nSample rate in Hz. Valid values depend on rate control mode and profile.\n\nSpec -> (string)\n\nUse MPEG-2 AAC audio instead of MPEG-4 AAC audio for raw or MPEG-2 Transport Stream containers.\n\nVbrQuality -> (string)\n\nVBR Quality Level - Only used if rateControlMode is VBR.\n\nAc3Settings -> (structure)\n\nAc3 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted AC-3 stream. See ATSC A/52-2012 for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital coding mode. Determines number of channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If excluded and input audio is Dolby Digital, dialnorm will be passed through.\n\nDrcProfile -> (string)\n\nIf set to filmStandard, adds dynamic range compression signaling to the output bitstream as defined in the Dolby Digital specification.\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid in codingMode32Lfe mode.\n\nMetadataControl -> (string)\n\nWhen set to “followInput”, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nEac3Settings -> (structure)\n\nEac3 Settings\n\nAttenuationControl -> (string)\n\nWhen set to attenuate3Db, applies a 3 dB attenuation to the surround channels. Only used for 3/2 coding mode.\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted E-AC-3 stream. See ATSC A/52-2012 (Annex E) for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital Plus coding mode. Determines number of channels.\n\nDcFilter -> (string)\n\nWhen set to enabled, activates a DC highpass filter for all input channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If blank and input audio is Dolby Digital Plus, dialnorm will be passed through.\n\nDrcLine -> (string)\n\nSets the Dolby dynamic range compression profile.\n\nDrcRf -> (string)\n\nSets the profile for heavy Dolby dynamic range compression, ensures that the instantaneous signal peaks do not exceed specified levels.\n\nLfeControl -> (string)\n\nWhen encoding 3/2 audio, setting to lfe enables the LFE channel\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid with codingMode32 coding mode.\n\nLoRoCenterMixLevel -> (double)\n\nLeft only/Right only center mix level. Only used for 3/2 coding mode.\n\nLoRoSurroundMixLevel -> (double)\n\nLeft only/Right only surround mix level. Only used for 3/2 coding mode.\n\nLtRtCenterMixLevel -> (double)\n\nLeft total/Right total center mix level. Only used for 3/2 coding mode.\n\nLtRtSurroundMixLevel -> (double)\n\nLeft total/Right total surround mix level. Only used for 3/2 coding mode.\n\nMetadataControl -> (string)\n\nWhen set to followInput, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nPassthroughControl -> (string)\n\nWhen set to whenPossible, input DD+ audio will be passed through if it is present on the input. This detection is dynamic over the life of the transcode. Inputs that alternate between DD+ and non-DD+ content will have a consistent DD+ output as the system alternates between passthrough and encoding.\n\nPhaseControl -> (string)\n\nWhen set to shift90Degrees, applies a 90-degree phase shift to the surround channels. Only used for 3/2 coding mode.\n\nStereoDownmix -> (string)\n\nStereo downmix preference. Only used for 3/2 coding mode.\n\nSurroundExMode -> (string)\n\nWhen encoding 3/2 audio, sets whether an extra center back surround channel is matrix encoded into the left and right surround channels.\n\nSurroundMode -> (string)\n\nWhen encoding 2/0 audio, sets whether Dolby Surround is matrix encoded into the two channels.\n\nMp2Settings -> (structure)\n\nMp2 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second.\n\nCodingMode -> (string)\n\nThe MPEG2 Audio coding mode. Valid values are codingMode10 (for mono) or codingMode20 (for stereo).\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nPassThroughSettings -> (structure)\n\nPass Through Settings\n\nWavSettings -> (structure)\n\nWav Settings\n\nBitDepth -> (double)\n\nBits per sample.\n\nCodingMode -> (string)\n\nThe audio coding mode for the WAV audio. The mode determines the number of channels in the audio.\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nLanguageCode -> (string)\n\nRFC 5646 language code representing the language of the audio output track. Only used if languageControlMode is useConfigured, or there is no ISO 639 language code specified in the input.\n\nLanguageCodeControl -> (string)\n\nChoosing followInput will cause the ISO 639 language code of the output to follow the ISO 639 language code of the input. The languageCode will be used when useConfigured is set, or when followInput is selected but there is no ISO 639 language code specified by the input.\n\nName -> (string)\n\nThe name of this AudioDescription. Outputs will use this name to uniquely identify this AudioDescription. Description names should be unique within this Live Event.\n\nRemixSettings -> (structure)\n\nSettings that control how input audio channels are remixed into the output audio channels.\n\nChannelMappings -> (list)\n\nMapping of input channels to output channels, with appropriate gain adjustments.\n\n(structure)\n\nAudio Channel Mapping\n\nInputChannelLevels -> (list)\n\nIndices and gain values for each input channel that should be remixed into this output channel.\n\n(structure)\n\nInput Channel Level\n\nGain -> (integer)\n\nRemixing value. Units are in dB and acceptable values are within the range from -60 (mute) and 6 dB.\n\nInputChannel -> (integer)\n\nThe index of the input channel used as a source.\n\nOutputChannel -> (integer)\n\nThe index of the output channel being produced.\n\nChannelsIn -> (integer)\n\nNumber of input channels to be used.\n\nChannelsOut -> (integer)\n\nNumber of output channels to be produced. Valid values: 1, 2, 4, 6, 8\n\nStreamName -> (string)\n\nUsed for MS Smooth and Apple HLS outputs. Indicates the name displayed by the player (eg. English, or Director Commentary).\n\nAvailBlanking -> (structure)\n\nSettings for ad avail blanking.\n\nAvailBlankingImage -> (structure)\n\nBlanking image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when insertion metadata is added.\n\nAvailConfiguration -> (structure)\n\nEvent-wide configuration settings for ad avail insertion.\n\nAvailSettings -> (structure)\n\nAd avail settings.\n\nScte35SpliceInsert -> (structure)\n\nScte35 Splice Insert\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nScte35TimeSignalApos -> (structure)\n\nScte35 Time Signal Apos\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nBlackoutSlate -> (structure)\n\nSettings for blackout slate.\n\nBlackoutSlateImage -> (structure)\n\nBlackout slate image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkEndBlackout -> (string)\n\nSetting to enabled causes the encoder to blackout the video, audio, and captions, and raise the “Network Blackout Image” slate when an SCTE104/35 Network End Segmentation Descriptor is encountered. The blackout will be lifted when the Network Start Segmentation Descriptor is encountered. The Network End and Network Start descriptors must contain a network ID that matches the value entered in “Network ID”.\n\nNetworkEndBlackoutImage -> (structure)\n\nPath to local file to use as Network End Blackout image. Image will be scaled to fill the entire output raster.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkId -> (string)\n\nProvides Network ID that matches EIDR ID format (e.g., “10.XXXX/XXXX-XXXX-XXXX-XXXX-XXXX-C”).\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when indicated by program metadata.\n\nCaptionDescriptions -> (list)\n\nSettings for caption decriptions\n\n(structure)\n\nCaption Description\n\nCaptionSelectorName -> (string)\n\nSpecifies which input caption selector to use as a caption source when generating output captions. This field should match a captionSelector name.\n\nDestinationSettings -> (structure)\n\nAdditional settings for captions destination that depend on the destination type.\n\nAribDestinationSettings -> (structure)\n\nArib Destination Settings\n\nBurnInDestinationSettings -> (structure)\n\nBurn In Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to ‘auto’ fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. All burn-in and DVB-Sub font settings must match.\n\nDvbSubDestinationSettings -> (structure)\n\nDvb Sub Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. This option is not valid for source captions that are STL or 608/embedded. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to auto fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nEbuTtDDestinationSettings -> (structure)\n\nEbu Tt DDestination Settings\n\nCopyrightHolder -> (string)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. Complete this field if you want to include the name of the copyright holder in the copyright metadata tag in the TTML\n\nFillLineGap -> (string)\n\nSpecifies how to handle the gap between the lines (in multi-line captions). - enabled: Fill with the captions background color (as specified in the input captions). - disabled: Leave the gap unfilled.\n\nFontFamily -> (string)\n\nSpecifies the font family to include in the font data attached to the EBU-TT captions. Valid only if styleControl is set to include. If you leave this field empty, the font family is set to “monospaced”. (If styleControl is set to exclude, the font family is always set to “monospaced”.) You specify only the font family. All other style information (color, bold, position and so on) is copied from the input captions. The size is always set to 100% to allow the downstream player to choose the size. - Enter a list of font families, as a comma-separated list of font names, in order of preference. The name can be a font family (such as “Arial”), or a generic font family (such as “serif”), or “default” (to let the downstream player choose the font). - Leave blank to set the family to “monospace”.\n\nStyleControl -> (string)\n\nSpecifies the style information (font color, font position, and so on) to include in the font data that is attached to the EBU-TT captions. - include: Take the style information (font color, font position, and so on) from the source captions and include that information in the font data attached to the EBU-TT captions. This option is valid only if the source captions are Embedded or Teletext. - exclude: In the font data attached to the EBU-TT captions, set the font family to “monospaced”. Do not include any other style information.\n\nEmbeddedDestinationSettings -> (structure)\n\nEmbedded Destination Settings\n\nEmbeddedPlusScte20DestinationSettings -> (structure)\n\nEmbedded Plus Scte20 Destination Settings\n\nRtmpCaptionInfoDestinationSettings -> (structure)\n\nRtmp Caption Info Destination Settings\n\nScte20PlusEmbeddedDestinationSettings -> (structure)\n\nScte20 Plus Embedded Destination Settings\n\nScte27DestinationSettings -> (structure)\n\nScte27 Destination Settings\n\nSmpteTtDestinationSettings -> (structure)\n\nSmpte Tt Destination Settings\n\nTeletextDestinationSettings -> (structure)\n\nTeletext Destination Settings\n\nTtmlDestinationSettings -> (structure)\n\nTtml Destination Settings\n\nStyleControl -> (string)\n\nWhen set to passthrough, passes through style and position information from a TTML-like input source (TTML, SMPTE-TT, CFF-TT) to the CFF-TT output or TTML output.\n\nWebvttDestinationSettings -> (structure)\n\nWebvtt Destination Settings\n\nStyleControl -> (string)\n\nControls whether the color and position of the source captions is passed through to the WebVTT output captions. PASSTHROUGH - Valid only if the source captions are EMBEDDED or TELETEXT. NO_STYLE_DATA - Don’t pass through the style. The output captions will not contain any font styling information.\n\nLanguageCode -> (string)\n\nISO 639-2 three-digit code: http://www.loc.gov/standards/iso639-2/\n\nLanguageDescription -> (string)\n\nHuman readable information to indicate captions available for players (eg. English, or Spanish).\n\nName -> (string)\n\nName of the caption description. Used to associate a caption description with an output. Names must be unique within an event.\n\nFeatureActivations -> (structure)\n\nFeature Activations\n\nInputPrepareScheduleActions -> (string)\n\nEnables the Input Prepare feature. You can create Input Prepare actions in the schedule only if this feature is enabled. If you disable the feature on an existing schedule, make sure that you first delete all input prepare actions from the schedule.\n\nGlobalConfiguration -> (structure)\n\nConfiguration settings that apply to the event as a whole.\n\nInitialAudioGain -> (integer)\n\nValue to set the initial audio gain for the Live Event.\n\nInputEndAction -> (string)\n\nIndicates the action to take when the current input completes (e.g. end-of-file). When switchAndLoopInputs is configured the encoder will restart at the beginning of the first input. When “none” is configured the encoder will transcode either black, a solid color, or a user specified slate images per the “Input Loss Behavior” configuration until the next input switch occurs (which is controlled through the Channel Schedule API).\n\nInputLossBehavior -> (structure)\n\nSettings for system actions when input is lost.\n\nBlackFrameMsec -> (integer)\n\nDocumentation update needed\n\nInputLossImageColor -> (string)\n\nWhen input loss image type is “color” this field specifies the color to use. Value: 6 hex characters representing the values of RGB.\n\nInputLossImageSlate -> (structure)\n\nWhen input loss image type is “slate” these fields specify the parameters for accessing the slate.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nInputLossImageType -> (string)\n\nIndicates whether to substitute a solid color or a slate into the output after input loss exceeds blackFrameMsec.\n\nRepeatFrameMsec -> (integer)\n\nDocumentation update needed\n\nOutputLockingMode -> (string)\n\nIndicates how MediaLive pipelines are synchronized. PIPELINE_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the other. EPOCH_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the Unix epoch.\n\nOutputTimingSource -> (string)\n\nIndicates whether the rate of frames emitted by the Live encoder should be paced by its system clock (which optionally may be locked to another source via NTP) or should be locked to the clock of the source that is providing the input stream.\n\nSupportLowFramerateInputs -> (string)\n\nAdjusts video input buffer for streams with very low video framerates. This is commonly set to enabled for music channels with less than one video frame per second.\n\nMotionGraphicsConfiguration -> (structure)\n\nSettings for motion graphics.\n\nMotionGraphicsInsertion -> (string)\n\nMotion Graphics Insertion\n\nMotionGraphicsSettings -> (structure)\n\nMotion Graphics Settings\n\nHtmlMotionGraphicsSettings -> (structure)\n\nHtml Motion Graphics Settings\n\nNielsenConfiguration -> (structure)\n\nNielsen configuration settings.\n\nDistributorId -> (string)\n\nEnter the Distributor ID assigned to your organization by Nielsen.\n\nNielsenPcmToId3Tagging -> (string)\n\nEnables Nielsen PCM to ID3 tagging\n\nOutputGroups -> (list)\n\nPlaceholder documentation for __listOfOutputGroup\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nName -> (string)\n\nCustom output group name optionally defined by the user. Only letters, numbers, and the underscore character allowed; only 32 characters allowed.\n\nOutputGroupSettings -> (structure)\n\nSettings associated with the output group.\n\nArchiveGroupSettings -> (structure)\n\nArchive Group Settings\n\nArchiveCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nArchiveS3Settings -> (structure)\n\nArchive S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nDestination -> (structure)\n\nA directory and base filename where archive files should be written.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRolloverInterval -> (integer)\n\nNumber of seconds to write to archive file before closing and starting a new one.\n\nFrameCaptureGroupSettings -> (structure)\n\nFrame Capture Group Settings\n\nDestination -> (structure)\n\nThe destination for the frame capture files. Either the URI for an Amazon S3 bucket and object, plus a file name prefix (for example, s3ssl://sportsDelivery/highlights/20180820/curling-) or the URI for a MediaStore container, plus a file name prefix (for example, mediastoressl://sportsDelivery/20180820/curling-). The final file names consist of the prefix from the destination field (for example, “curling-“) + name modifier + the counter (5 digits, starting from 00001) + extension (which is always .jpg). For example, curling-low.00001.jpg\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFrameCaptureCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nFrameCaptureS3Settings -> (structure)\n\nFrame Capture S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsGroupSettings -> (structure)\n\nHls Group Settings\n\nAdMarkers -> (list)\n\nChoose one or more ad marker types to pass SCTE35 signals through to this group of Apple HLS outputs.\n\n(string)\n\nHls Ad Markers\n\nBaseUrlContent -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlContent1 -> (string)\n\nOptional. One value per output group. This field is required only if you are completing Base URL content A, and the downstream system has notified you that the media files for pipeline 1 of all outputs are in a location different from the media files for pipeline 0.\n\nBaseUrlManifest -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlManifest1 -> (string)\n\nOptional. One value per output group. Complete this field only if you are completing Base URL manifest A, and the downstream system has notified you that the child manifest files for pipeline 1 of all outputs are in a location different from the child manifest files for pipeline 0.\n\nCaptionLanguageMappings -> (list)\n\nMapping of up to 4 caption channels to caption languages. Is only meaningful if captionLanguageSetting is set to “insert”.\n\n(structure)\n\nMaps a caption channel to an ISO 693-2 language code (http://www.loc.gov/standards/iso639-2), with an optional description.\n\nCaptionChannel -> (integer)\n\nThe closed caption channel being described by this CaptionLanguageMapping. Each channel mapping must have a unique channel number (maximum of 4)\n\nLanguageCode -> (string)\n\nThree character ISO 639-2 language code (see http://www.loc.gov/standards/iso639-2)\n\nLanguageDescription -> (string)\n\nTextual description of language\n\nCaptionLanguageSetting -> (string)\n\nApplies only to 608 Embedded output captions. insert: Include CLOSED-CAPTIONS lines in the manifest. Specify at least one language in the CC1 Language Code field. One CLOSED-CAPTION line is added for each Language Code you specify. Make sure to specify the languages in the order in which they appear in the original source (if the source is embedded format) or the order of the caption selectors (if the source is other than embedded). Otherwise, languages in the manifest will not match up properly with the output captions. none: Include CLOSED-CAPTIONS=NONE line in the manifest. omit: Omit any CLOSED-CAPTIONS line from the manifest.\n\nClientCache -> (string)\n\nWhen set to “disabled”, sets the #EXT-X-ALLOW-CACHE:no tag in the manifest, which prevents clients from saving media segments for later replay.\n\nCodecSpecification -> (string)\n\nSpecification to use (RFC-6381 or the default RFC-4281) during m3u8 playlist generation.\n\nConstantIv -> (string)\n\nFor use with encryptionType. This is a 128-bit, 16-byte hex value represented by a 32-character text string. If ivSource is set to “explicit” then this parameter is required and is used as the IV for encryption.\n\nDestination -> (structure)\n\nA directory or HTTP destination for the HLS segments, manifest files, and encryption keys (if enabled).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nDirectoryStructure -> (string)\n\nPlace segments in subdirectories.\n\nDiscontinuityTags -> (string)\n\nSpecifies whether to insert EXT-X-DISCONTINUITY tags in the HLS child manifests for this output group. Typically, choose Insert because these tags are required in the manifest (according to the HLS specification) and serve an important purpose. Choose Never Insert only if the downstream system is doing real-time failover (without using the MediaLive automatic failover feature) and only if that downstream system has advised you to exclude the tags.\n\nEncryptionType -> (string)\n\nEncrypts the segments with the given encryption scheme. Exclude this parameter if no encryption is desired.\n\nHlsCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nHlsAkamaiSettings -> (structure)\n\nHls Akamai Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to Akamai. User should contact Akamai to enable this feature.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nSalt -> (string)\n\nSalt for authenticated Akamai.\n\nToken -> (string)\n\nToken parameter for authenticated akamai. If not specified, _gda_ is used.\n\nHlsBasicPutSettings -> (structure)\n\nHls Basic Put Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsMediaStoreSettings -> (structure)\n\nHls Media Store Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nMediaStoreStorageClass -> (string)\n\nWhen set to temporal, output files are stored in non-persistent memory for faster reading and writing.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsS3Settings -> (structure)\n\nHls S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsWebdavSettings -> (structure)\n\nHls Webdav Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to WebDAV.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsId3SegmentTagging -> (string)\n\nState of HLS ID3 Segment Tagging\n\nIFrameOnlyPlaylists -> (string)\n\nDISABLED: Do not create an I-frame-only manifest, but do create the master and media manifests (according to the Output Selection field). STANDARD: Create an I-frame-only manifest for each output that contains video, as well as the other manifests (according to the Output Selection field). The I-frame manifest contains a #EXT-X-I-FRAMES-ONLY tag to indicate it is I-frame only, and one or more #EXT-X-BYTERANGE entries identifying the I-frame position. For example, #EXT-X-BYTERANGE:160364@1461888”\n\nIncompleteSegmentBehavior -> (string)\n\nSpecifies whether to include the final (incomplete) segment in the media output when the pipeline stops producing output because of a channel stop, a channel pause or a loss of input to the pipeline. Auto means that MediaLive decides whether to include the final segment, depending on the channel class and the types of output groups. Suppress means to never include the incomplete segment. We recommend you choose Auto and let MediaLive control the behavior.\n\nIndexNSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the maximum number of segments in the media manifest file. After this maximum, older segments are removed from the media manifest. This number must be smaller than the number in the Keep Segments field.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nIvInManifest -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If set to “include”, IV is listed in the manifest, otherwise the IV is not in the manifest.\n\nIvSource -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If this setting is “followsSegmentNumber”, it will cause the IV to change every segment (to match the segment number). If this is set to “explicit”, you must enter a constantIv value.\n\nKeepSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the number of media segments to retain in the destination directory. This number should be bigger than indexNSegments (Num segments). We recommend (value = (2 x indexNsegments) + 1). If this “keep segments” number is too low, the following might happen: the player is still reading a media manifest file that lists this segment, but that segment has been removed from the destination directory (as directed by indexNSegments). This situation would result in a 404 HTTP error on the player.\n\nKeyFormat -> (string)\n\nThe value specifies how the key is represented in the resource identified by the URI. If parameter is absent, an implicit value of “identity” is used. A reverse DNS string can also be given.\n\nKeyFormatVersions -> (string)\n\nEither a single positive integer version value or a slash delimited list of version values (1/2/3).\n\nKeyProviderSettings -> (structure)\n\nThe key provider settings.\n\nStaticKeySettings -> (structure)\n\nStatic Key Settings\n\nKeyProviderServer -> (structure)\n\nThe URL of the license server used for protecting content.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nStaticKeyValue -> (string)\n\nStatic key value as a 32 character hexadecimal string.\n\nManifestCompression -> (string)\n\nWhen set to gzip, compresses HLS playlist.\n\nManifestDurationFormat -> (string)\n\nIndicates whether the output manifest should use floating point or integer values for segment duration.\n\nMinSegmentLength -> (integer)\n\nWhen set, minimumSegmentLength is enforced by looking ahead and back within the specified range for a nearby avail and extending the segment size if needed.\n\nMode -> (string)\n\nIf “vod”, all segments are indexed and kept permanently in the destination and manifest. If “live”, only the number segments specified in keepSegments and indexNSegments are kept; newer segments replace older segments, which may prevent players from rewinding all the way to the beginning of the event. VOD mode uses HLS EXT-X-PLAYLIST-TYPE of EVENT while the channel is running, converting it to a “VOD” type manifest on completion of the stream.\n\nOutputSelection -> (string)\n\nMANIFESTS_AND_SEGMENTS: Generates manifests (master manifest, if applicable, and media manifests) for this output group. VARIANT_MANIFESTS_AND_SEGMENTS: Generates media manifests for this output group, but not a master manifest. SEGMENTS_ONLY: Does not generate any manifests for this output group.\n\nProgramDateTime -> (string)\n\nIncludes or excludes EXT-X-PROGRAM-DATE-TIME tag in .m3u8 manifest files. The value is calculated as follows: either the program date and time are initialized using the input timecode source, or the time is initialized using the input timecode source and the date is initialized using the timestampOffset.\n\nProgramDateTimePeriod -> (integer)\n\nPeriod of insertion of EXT-X-PROGRAM-DATE-TIME entry, in seconds.\n\nRedundantManifest -> (string)\n\nENABLED: The master manifest (.m3u8 file) for each pipeline includes information about both pipelines: first its own media files, then the media files of the other pipeline. This feature allows playout device that support stale manifest detection to switch from one manifest to the other, when the current manifest seems to be stale. There are still two destinations and two master manifests, but both master manifests reference the media files from both pipelines. DISABLED: The master manifest (.m3u8 file) for each pipeline includes information about its own pipeline only. For an HLS output group with MediaPackage as the destination, the DISABLED behavior is always followed. MediaPackage regenerates the manifests it serves to players so a redundant manifest from MediaLive is irrelevant.\n\nSegmentLength -> (integer)\n\nLength of MPEG-2 Transport Stream segments to create (in seconds). Note that segments will end on the next keyframe after this number of seconds, so actual segment length may be longer.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSegmentsPerSubdirectory -> (integer)\n\nNumber of segments to write to a subdirectory before starting a new one. directoryStructure must be subdirectoryPerStream for this setting to have an effect.\n\nStreamInfResolution -> (string)\n\nInclude or exclude RESOLUTION attribute for video in EXT-X-STREAM-INF tag of variant manifest.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nTimestampDeltaMilliseconds -> (integer)\n\nProvides an extra millisecond delta offset to fine tune the timestamps.\n\nTsFileMode -> (string)\n\nSEGMENTED_FILES: Emit the program as segments - multiple .ts media files. SINGLE_FILE: Applies only if Mode field is VOD. Emit the program as a single .ts media file. The media manifest includes #EXT-X-BYTERANGE tags to index segments for playback. A typical use for this value is when sending the output to AWS Elemental MediaConvert, which can accept only a single media file. Playback while the channel is running is not guaranteed due to HTTP server caching.\n\nMediaPackageGroupSettings -> (structure)\n\nMedia Package Group Settings\n\nDestination -> (structure)\n\nMediaPackage channel destination.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nMsSmoothGroupSettings -> (structure)\n\nMs Smooth Group Settings\n\nAcquisitionPointId -> (string)\n\nThe ID to include in each message in the sparse track. Ignored if sparseTrackType is NONE.\n\nAudioOnlyTimecodeControl -> (string)\n\nIf set to passthrough for an audio-only MS Smooth output, the fragment absolute time will be set to the current timecode. This option does not write timecodes to the audio elementary stream.\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the https certificate chain to a trusted Certificate Authority (CA). This will cause https outputs to self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the IIS server if the connection is lost. Content will be cached during this time and the cache will be be delivered to the IIS server once the connection is re-established.\n\nDestination -> (structure)\n\nSmooth Streaming publish point on an IIS server. Elemental Live acts as a “Push” encoder to IIS.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nEventId -> (string)\n\nMS Smooth event ID to be sent to the IIS server. Should only be specified if eventIdMode is set to useConfigured.\n\nEventIdMode -> (string)\n\nSpecifies whether or not to send an event ID to the IIS server. If no event ID is sent and the same Live Event is used without changing the publishing point, clients might see cached video from the previous run. Options: - “useConfigured” - use the value provided in eventId - “useTimestamp” - generate and send an event ID based on the current timestamp - “noEventId” - do not send an event ID to the IIS server.\n\nEventStopBehavior -> (string)\n\nWhen set to sendEos, send EOS signal to IIS server when stopping the event\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nFragmentLength -> (integer)\n\nLength of mp4 fragments to generate (in seconds). Fragment length must be compatible with GOP size and framerate.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nRestartDelay -> (integer)\n\nNumber of seconds before initiating a restart due to output failure, due to exhausting the numRetries on one segment, or exceeding filecacheDuration.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSendDelayMs -> (integer)\n\nNumber of milliseconds to delay the output from the second pipeline.\n\nSparseTrackType -> (string)\n\nIdentifies the type of data to place in the sparse track: - SCTE35: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame to start a new segment. - SCTE35_WITHOUT_SEGMENTATION: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame but don’t start a new segment. - NONE: Don’t generate a sparse track for any outputs in this output group.\n\nStreamManifestBehavior -> (string)\n\nWhen set to send, send stream manifest so publishing point doesn’t start until all streams start.\n\nTimestampOffset -> (string)\n\nTimestamp offset for the event. Only used if timestampOffsetMode is set to useConfiguredOffset.\n\nTimestampOffsetMode -> (string)\n\nType of timestamp date offset to use. - useEventStartDate: Use the date the event was started as the offset - useConfiguredOffset: Use an explicitly configured date as the offset\n\nMultiplexGroupSettings -> (structure)\n\nMultiplex Group Settings\n\nRtmpGroupSettings -> (structure)\n\nRtmp Group Settings\n\nAdMarkers -> (list)\n\nChoose the ad marker type for this output group. MediaLive will create a message based on the content of each SCTE-35 message, format it for that marker type, and insert it in the datastream.\n\n(string)\n\nRtmp Ad Markers\n\nAuthenticationScheme -> (string)\n\nAuthentication scheme to use when connecting with CDN\n\nCacheFullBehavior -> (string)\n\nControls behavior when content cache fills up. If remote origin server stalls the RTMP connection and does not accept content fast enough the ‘Media Cache’ will fill up. When the cache reaches the duration specified by cacheLength the cache will stop accepting new content. If set to disconnectImmediately, the RTMP output will force a disconnect. Clear the media cache, and reconnect after restartDelay seconds. If set to waitForServer, the RTMP output will wait up to 5 minutes to allow the origin server to begin accepting data again.\n\nCacheLength -> (integer)\n\nCache length, in seconds, is used to calculate buffer size.\n\nCaptionData -> (string)\n\nControls the types of data that passes to onCaptionInfo outputs. If set to ‘all’ then 608 and 708 carried DTVCC data will be passed. If set to ‘field1AndField2608’ then DTVCC data will be stripped out, but 608 data from both fields will be passed. If set to ‘field1608’ then only the data carried in 608 from field 1 video will be passed.\n\nInputLossAction -> (string)\n\nControls the behavior of this RTMP group if input becomes unavailable. - emitOutput: Emit a slate until input returns. - pauseOutput: Stop transmitting data until input returns. This does not close the underlying RTMP connection.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nUdpGroupSettings -> (structure)\n\nUdp Group Settings\n\nInputLossAction -> (string)\n\nSpecifies behavior of last resort when input video is lost, and no more backup inputs are available. When dropTs is selected the entire transport stream will stop being emitted. When dropProgram is selected the program can be dropped from the transport stream (and replaced with null packets to meet the TS bitrate requirement). Or, when emitProgram is chosen the transport stream will continue to be produced normally with repeat frames, black frames, or slate frames substituted for the absent input video.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nOutputs -> (list)\n\nPlaceholder documentation for __listOfOutput\n\n(structure)\n\nOutput settings. There can be multiple outputs within a group.\n\nAudioDescriptionNames -> (list)\n\nThe names of the AudioDescriptions used as audio sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nCaptionDescriptionNames -> (list)\n\nThe names of the CaptionDescriptions used as caption sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nOutputName -> (string)\n\nThe name used to identify an output.\n\nOutputSettings -> (structure)\n\nOutput type-specific settings.\n\nArchiveOutputSettings -> (structure)\n\nArchive Output Settings\n\nContainerSettings -> (structure)\n\nSettings specific to the container type of the file.\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nRawSettings -> (structure)\n\nRaw Settings\n\nExtension -> (string)\n\nOutput file extension. If excluded, this will be auto-selected from the container type.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nFrameCaptureOutputSettings -> (structure)\n\nFrame Capture Output Settings\n\nNameModifier -> (string)\n\nRequired if the output group contains more than one output. This modifier forms part of the output file name.\n\nHlsOutputSettings -> (structure)\n\nHls Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nHlsSettings -> (structure)\n\nSettings regarding the underlying stream. These settings are different for audio-only outputs.\n\nAudioOnlyHlsSettings -> (structure)\n\nAudio Only Hls Settings\n\nAudioGroupId -> (string)\n\nSpecifies the group to which the audio Rendition belongs.\n\nAudioOnlyImage -> (structure)\n\nOptional. Specifies the .jpg or .png image to use as the cover art for an audio-only output. We recommend a low bit-size file because the image increases the output audio bandwidth. The image is attached to the audio as an ID3 tag, frame type APIC, picture type 0x10, as per the “ID3 tag version 2.4.0 - Native Frames” standard.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nAudioTrackType -> (string)\n\nFour types of audio-only tracks are supported: Audio-Only Variant Stream The client can play back this audio-only stream instead of video in low-bandwidth scenarios. Represented as an EXT-X-STREAM-INF in the HLS manifest. Alternate Audio, Auto Select, Default Alternate rendition that the client should try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=YES, AUTOSELECT=YES Alternate Audio, Auto Select, Not Default Alternate rendition that the client may try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=YES Alternate Audio, not Auto Select Alternate rendition that the client will not try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=NO\n\nSegmentType -> (string)\n\nSpecifies the segment type.\n\nFmp4HlsSettings -> (structure)\n\nFmp4 Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nFrameCaptureHlsSettings -> (structure)\n\nFrame Capture Hls Settings\n\nStandardHlsSettings -> (structure)\n\nStandard Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nM3u8Settings -> (structure)\n\nSettings information for the .m3u8 container\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values.\n\nEcmPid -> (string)\n\nThis parameter is unused and deprecated.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock References (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value.\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nScte35Behavior -> (string)\n\nIf set to passthrough, passes any SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Accepts “Format Identifiers”:#formatIdentifierParameters.\n\nSegmentModifier -> (string)\n\nString concatenated to end of segment filenames.\n\nMediaPackageOutputSettings -> (structure)\n\nMedia Package Output Settings\n\nMsSmoothOutputSettings -> (structure)\n\nMs Smooth Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nMultiplexOutputSettings -> (structure)\n\nMultiplex Output Settings\n\nDestination -> (structure)\n\nDestination is a Multiplex.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRtmpOutputSettings -> (structure)\n\nRtmp Output Settings\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the tls certificate chain to a trusted Certificate Authority (CA). This will cause rtmps outputs with self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying a connection to the Flash Media server if the connection is lost.\n\nDestination -> (structure)\n\nThe RTMP endpoint excluding the stream name (eg. rtmp://host/appname). For connection to Akamai, a username and password must be supplied. URI fields accept format identifiers.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nUdpOutputSettings -> (structure)\n\nUdp Output Settings\n\nBufferMsec -> (integer)\n\nUDP output buffering in milliseconds. Larger values increase latency through the transcoder but simultaneously assist the transcoder in maintaining a constant, low-jitter UDP/RTP output while accommodating clock recovery, input switching, input disruptions, picture reordering, etc.\n\nContainerSettings -> (structure)\n\nUdp Container Settings\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nDestination -> (structure)\n\nDestination address and port number for RTP or UDP packets. Can be unicast or multicast RTP or UDP (eg. rtp://239.10.10.10:5001 or udp://10.100.100.100:5002).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFecOutputSettings -> (structure)\n\nSettings for enabling and adjusting Forward Error Correction on UDP outputs.\n\nColumnDepth -> (integer)\n\nParameter D from SMPTE 2022-1. The height of the FEC protection matrix. The number of transport stream packets per column error correction packet. Must be between 4 and 20, inclusive.\n\nIncludeFec -> (string)\n\nEnables column only or column and row based FEC\n\nRowLength -> (integer)\n\nParameter L from SMPTE 2022-1. The width of the FEC protection matrix. Must be between 1 and 20, inclusive. If only Column FEC is used, then larger values increase robustness. If Row FEC is used, then this is the number of transport stream packets per row error correction packet, and the value must be between 4 and 20, inclusive, if includeFec is columnAndRow. If includeFec is column, this value must be 1 to 20, inclusive.\n\nVideoDescriptionName -> (string)\n\nThe name of the VideoDescription used as the source for this output.\n\nTimecodeConfig -> (structure)\n\nContains settings used to acquire and adjust timecode information from inputs.\n\nSource -> (string)\n\nIdentifies the source for the timecode that will be associated with the events outputs. -Embedded (embedded): Initialize the output timecode with timecode from the the source. If no embedded timecode is detected in the source, the system falls back to using “Start at 0” (zerobased). -System Clock (systemclock): Use the UTC time. -Start at 0 (zerobased): The time of the first frame of the event will be 00:00:00:00.\n\nSyncThreshold -> (integer)\n\nThreshold in frames beyond which output timecode is resynchronized to the input timecode. Discrepancies below this threshold are permitted to avoid unnecessary discontinuities in the output timecode. No timecode sync when this is not specified.\n\nVideoDescriptions -> (list)\n\nPlaceholder documentation for __listOfVideoDescription\n\n(structure)\n\nVideo settings for this stream.\n\nCodecSettings -> (structure)\n\nVideo codec settings.\n\nFrameCaptureSettings -> (structure)\n\nFrame Capture Settings\n\nCaptureInterval -> (integer)\n\nThe frequency at which to capture frames for inclusion in the output. May be specified in either seconds or milliseconds, as specified by captureIntervalUnits.\n\nCaptureIntervalUnits -> (string)\n\nUnit for the frame capture interval.\n\nH264Settings -> (structure)\n\nH264 Settings\n\nAdaptiveQuantization -> (string)\n\nEnables or disables adaptive quantization, which is a technique MediaLive can apply to video on a frame-by-frame basis to produce more compression without losing quality. There are three types of adaptive quantization: flicker, spatial, and temporal. Set the field in one of these ways: Set to Auto. Recommended. For each type of AQ, MediaLive will determine if AQ is needed, and if so, the appropriate strength. Set a strength (a value other than Auto or Disable). This strength will apply to any of the AQ fields that you choose to enable. Set to Disabled to disable all types of adaptive quantization.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufFillPct -> (integer)\n\nPercentage of the buffer that should initially be filled (HRD buffer model).\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nEntropyEncoding -> (string)\n\nEntropy encoding mode. Use cabac (must be in Main or High profile) or cavlc.\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nFlicker AQ makes adjustments within each frame to reduce flicker or ‘pop’ on I-frames. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if flicker AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply flicker AQ using the specified strength. Disabled: MediaLive won’t apply flicker AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply flicker AQ.\n\nForceFieldPictures -> (string)\n\nThis setting applies only when scan type is “interlaced.” It controls whether coding is performed on a field basis or on a frame basis. (When the video is progressive, the coding is always performed on a frame basis.) enabled: Force MediaLive to code on a field basis, so that odd and even sets of fields are coded separately. disabled: Code the two sets of fields separately (on a field basis) or together (on a frame basis using PAFF), depending on what is most appropriate for the content.\n\nFramerateControl -> (string)\n\nThis field indicates how the output video frame rate is specified. If “specified” is selected then the output video frame rate is determined by framerateNumerator and framerateDenominator, else if “initializeFromSource” is selected then the output video frame rate will be set equal to the input video frame rate of the first input.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopBReference -> (string)\n\nDocumentation update needed\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopNumBFrames -> (integer)\n\nNumber of B-frames between reference frames.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.264 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level For VBR: Set the maximum bitrate in order to accommodate expected spikes in the complexity of the video.\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nNumRefFrames -> (integer)\n\nNumber of reference frames to use. The encoder may use more than requested if using B-frames and/or interlaced encoding.\n\nParControl -> (string)\n\nThis field indicates how the output pixel aspect ratio is specified. If “specified” is selected then the output video pixel aspect ratio is determined by parNumerator and parDenominator, else if “initializeFromSource” is selected then the output pixsel aspect ratio will be set equal to the input video pixel aspect ratio of the first input.\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.264 Profile.\n\nQualityLevel -> (string)\n\nLeave as STANDARD_QUALITY or choose a different value (which might result in additional costs to run the channel). - ENHANCED_QUALITY: Produces a slightly better video quality without an increase in the bitrate. Has an effect only when the Rate control mode is QVBR or CBR. If this channel is in a MediaLive multiplex, the value must be ENHANCED_QUALITY. - STANDARD_QUALITY: Valid for any Rate control mode.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. You can set a target quality or you can let MediaLive determine the best quality. To set a target quality, enter values in the QVBR quality level field and the Max bitrate field. Enter values that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M To let MediaLive decide, leave the QVBR quality level field empty, and in Max bitrate enter the maximum rate you want in the video. For more information, see the section called “Video - rate control mode” in the MediaLive user guide\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. VBR: Quality and bitrate vary, depending on the video complexity. Recommended instead of QVBR if you want to maintain a specific average bitrate over the duration of the channel. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection. - On: inserts I-frames when scene change is detected. - Off: does not force an I-frame when scene change is detected.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nSoftness -> (integer)\n\nSoftness. Selects quantizer matrix, larger values reduce high-frequency content in the encoded image. If not set to zero, must be greater than 15.\n\nSpatialAq -> (string)\n\nSpatial AQ makes adjustments within each frame based on spatial variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if spatial AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply spatial AQ using the specified strength. Disabled: MediaLive won’t apply spatial AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply spatial AQ.\n\nSubgopLength -> (string)\n\nIf set to fixed, use gopNumBFrames B-frames per sub-GOP. If set to dynamic, optimize the number of B-frames used for each sub-GOP to improve visual quality.\n\nSyntax -> (string)\n\nProduces a bitstream compliant with SMPTE RP-2027.\n\nTemporalAq -> (string)\n\nTemporal makes adjustments within each frame based on temporal variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if temporal AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply temporal AQ using the specified strength. Disabled: MediaLive won’t apply temporal AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply temporal AQ.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nH265Settings -> (structure)\n\nH265 Settings\n\nAdaptiveQuantization -> (string)\n\nAdaptive quantization. Allows intra-frame quantizers to vary to improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nAlternativeTransferFunction -> (string)\n\nWhether or not EML should insert an Alternative Transfer Function SEI message to support backwards compatibility with non-HDR decoders and displays.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nIf set to enabled, adjust quantization within each frame to reduce flicker or ‘pop’ on I-frames.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.265 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.265 Profile.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. Set values for the QVBR quality level field and Max bitrate field that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nTier -> (string)\n\nH.265 Tier.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nMpeg2Settings -> (structure)\n\nMpeg2 Settings\n\nAdaptiveQuantization -> (string)\n\nChoose Off to disable adaptive quantization. Or choose another value to enable the quantizer and set its strength. The strengths are: Auto, Off, Low, Medium, High. When you enable this field, MediaLive allows intra-frame quantizers to vary, which might improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates the AFD values that MediaLive will write into the video encode. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose AUTO. AUTO: MediaLive will try to preserve the input AFD value (in cases where multiple AFD values are valid). FIXED: MediaLive will use the value you specify in fixedAFD.\n\nColorMetadata -> (string)\n\nSpecifies whether to include the color space metadata. The metadata describes the color space that applies to the video (the colorSpace field). We recommend that you insert the metadata.\n\nColorSpace -> (string)\n\nChoose the type of color space conversion to apply to the output. For detailed information on setting up both the input and the output to obtain the desired color space in the output, see the section on “MediaLive Features - Video - color space” in the MediaLive User Guide. PASSTHROUGH: Keep the color space of the input content - do not convert it. AUTO:Convert all content that is SD to rec 601, and convert all content that is HD to rec 709.\n\nDisplayAspectRatio -> (string)\n\nSets the pixel aspect ratio for the encode.\n\nFilterSettings -> (structure)\n\nOptionally specify a noise reduction filter, which can improve quality of compressed content. If you do not choose a filter, no filter will be applied. TEMPORAL: This filter is useful for both source content that is noisy (when it has excessive digital artifacts) and source content that is clean. When the content is noisy, the filter cleans up the source content before the encoding phase, with these two effects: First, it improves the output video quality because the content has been cleaned up. Secondly, it decreases the bandwidth because MediaLive does not waste bits on encoding noise. When the content is reasonably clean, the filter tends to decrease the bitrate.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nComplete this field only when afdSignaling is set to FIXED. Enter the AFD value (4 bits) to write on all frames of the video encode.\n\nFramerateDenominator -> (integer)\n\ndescription”: “The framerate denominator. For example, 1001. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nFramerateNumerator -> (integer)\n\nThe framerate numerator. For example, 24000. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nGopClosedCadence -> (integer)\n\nMPEG2: default is open GOP.\n\nGopNumBFrames -> (integer)\n\nRelates to the GOP structure. The number of B-frames between reference frames. If you do not know what a B-frame is, use the default.\n\nGopSize -> (double)\n\nRelates to the GOP structure. The GOP size (keyframe interval) in the units specified in gopSizeUnits. If you do not know what GOP is, use the default. If gopSizeUnits is frames, then the gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, the gopSize must be greater than 0, but does not need to be an integer.\n\nGopSizeUnits -> (string)\n\nRelates to the GOP structure. Specifies whether the gopSize is specified in frames or seconds. If you do not plan to change the default gopSize, leave the default. If you specify SECONDS, MediaLive will internally convert the gop size to a frame count.\n\nScanType -> (string)\n\nSet the scan type of the output to PROGRESSIVE or INTERLACED (top field first).\n\nSubgopLength -> (string)\n\nRelates to the GOP structure. If you do not know what GOP is, use the default. FIXED: Set the number of B-frames in each sub-GOP to the value in gopNumBFrames. DYNAMIC: Let MediaLive optimize the number of B-frames in each sub-GOP, to improve visual quality.\n\nTimecodeInsertion -> (string)\n\nDetermines how MediaLive inserts timecodes in the output video. For detailed information about setting up the input and the output for a timecode, see the section on “MediaLive Features - Timecode configuration” in the MediaLive User Guide. DISABLED: do not include timecodes. GOP_TIMECODE: Include timecode metadata in the GOP header.\n\nHeight -> (integer)\n\nOutput video height, in pixels. Must be an even number. For most codecs, you can leave this field and width blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nName -> (string)\n\nThe name of this VideoDescription. Outputs will use this name to uniquely identify this Description. Description names should be unique within this Live Event.\n\nRespondToAfd -> (string)\n\nIndicates how MediaLive will respond to the AFD values that might be in the input video. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose PASSTHROUGH. RESPOND: MediaLive clips the input video using a formula that uses the AFD values (configured in afdSignaling ), the input display aspect ratio, and the output display aspect ratio. MediaLive also includes the AFD values in the output, unless the codec for this encode is FRAME_CAPTURE. PASSTHROUGH: MediaLive ignores the AFD values and does not clip the video. But MediaLive does include the values in the output. NONE: MediaLive does not clip the input video and does not include the AFD values in the output\n\nScalingBehavior -> (string)\n\nSTRETCH_TO_OUTPUT configures the output position to stretch the video to the specified output resolution (height and width). This option will override any position value. DEFAULT may insert black boxes (pillar boxes or letter boxes) around the video to provide the specified output resolution.\n\nSharpness -> (integer)\n\nChanges the strength of the anti-alias filter used for scaling. 0 is the softest setting, 100 is the sharpest. A setting of 50 is recommended for most content.\n\nWidth -> (integer)\n\nOutput video width, in pixels. Must be an even number. For most codecs, you can leave this field and height blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nJSON Syntax:\n\n{\n  \"AudioDescriptions\": [\n    {\n      \"AudioNormalizationSettings\": {\n        \"Algorithm\": \"ITU_1770_1\"|\"ITU_1770_2\",\n        \"AlgorithmControl\": \"CORRECT_AUDIO\",\n        \"TargetLkfs\": double\n      },\n      \"AudioSelectorName\": \"string\",\n      \"AudioType\": \"CLEAN_EFFECTS\"|\"HEARING_IMPAIRED\"|\"UNDEFINED\"|\"VISUAL_IMPAIRED_COMMENTARY\",\n      \"AudioTypeControl\": \"FOLLOW_INPUT\"|\"USE_CONFIGURED\",\n      \"AudioWatermarkingSettings\": {\n        \"NielsenWatermarksSettings\": {\n          \"NielsenCbetSettings\": {\n            \"CbetCheckDigitString\": \"string\",\n            \"CbetStepaside\": \"DISABLED\"|\"ENABLED\",\n            \"Csid\": \"string\"\n          },\n          \"NielsenDistributionType\": \"FINAL_DISTRIBUTOR\"|\"PROGRAM_CONTENT\",\n          \"NielsenNaesIiNwSettings\": {\n            \"CheckDigitString\": \"string\",\n            \"Sid\": double\n          }\n        }\n      },\n      \"CodecSettings\": {\n        \"AacSettings\": {\n          \"Bitrate\": double,\n          \"CodingMode\": \"AD_RECEIVER_MIX\"|\"CODING_MODE_1_0\"|\"CODING_MODE_1_1\"|\"CODING_MODE_2_0\"|\"CODING_MODE_5_1\",\n          \"InputType\": \"BROADCASTER_MIXED_AD\"|\"NORMAL\",\n          \"Profile\": \"HEV1\"|\"HEV2\"|\"LC\",\n          \"RateControlMode\": \"CBR\"|\"VBR\",\n          \"RawFormat\": \"LATM_LOAS\"|\"NONE\",\n          \"SampleRate\": double,\n          \"Spec\": \"MPEG2\"|\"MPEG4\",\n          \"VbrQuality\": \"HIGH\"|\"LOW\"|\"MEDIUM_HIGH\"|\"MEDIUM_LOW\"\n        },\n        \"Ac3Settings\": {\n          \"Bitrate\": double,\n          \"BitstreamMode\": \"COMMENTARY\"|\"COMPLETE_MAIN\"|\"DIALOGUE\"|\"EMERGENCY\"|\"HEARING_IMPAIRED\"|\"MUSIC_AND_EFFECTS\"|\"VISUALLY_IMPAIRED\"|\"VOICE_OVER\",\n          \"CodingMode\": \"CODING_MODE_1_0\"|\"CODING_MODE_1_1\"|\"CODING_MODE_2_0\"|\"CODING_MODE_3_2_LFE\",\n          \"Dialnorm\": integer,\n          \"DrcProfile\": \"FILM_STANDARD\"|\"NONE\",\n          \"LfeFilter\": \"DISABLED\"|\"ENABLED\",\n          \"MetadataControl\": \"FOLLOW_INPUT\"|\"USE_CONFIGURED\"\n        },\n        \"Eac3Settings\": {\n          \"AttenuationControl\": \"ATTENUATE_3_DB\"|\"NONE\",\n          \"Bitrate\": double,\n          \"BitstreamMode\": \"COMMENTARY\"|\"COMPLETE_MAIN\"|\"EMERGENCY\"|\"HEARING_IMPAIRED\"|\"VISUALLY_IMPAIRED\",\n          \"CodingMode\": \"CODING_MODE_1_0\"|\"CODING_MODE_2_0\"|\"CODING_MODE_3_2\",\n          \"DcFilter\": \"DISABLED\"|\"ENABLED\",\n          \"Dialnorm\": integer,\n          \"DrcLine\": \"FILM_LIGHT\"|\"FILM_STANDARD\"|\"MUSIC_LIGHT\"|\"MUSIC_STANDARD\"|\"NONE\"|\"SPEECH\",\n          \"DrcRf\": \"FILM_LIGHT\"|\"FILM_STANDARD\"|\"MUSIC_LIGHT\"|\"MUSIC_STANDARD\"|\"NONE\"|\"SPEECH\",\n          \"LfeControl\": \"LFE\"|\"NO_LFE\",\n          \"LfeFilter\": \"DISABLED\"|\"ENABLED\",\n          \"LoRoCenterMixLevel\": double,\n          \"LoRoSurroundMixLevel\": double,\n          \"LtRtCenterMixLevel\": double,\n          \"LtRtSurroundMixLevel\": double,\n          \"MetadataControl\": \"FOLLOW_INPUT\"|\"USE_CONFIGURED\",\n          \"PassthroughControl\": \"NO_PASSTHROUGH\"|\"WHEN_POSSIBLE\",\n          \"PhaseControl\": \"NO_SHIFT\"|\"SHIFT_90_DEGREES\",\n          \"StereoDownmix\": \"DPL2\"|\"LO_RO\"|\"LT_RT\"|\"NOT_INDICATED\",\n          \"SurroundExMode\": \"DISABLED\"|\"ENABLED\"|\"NOT_INDICATED\",\n          \"SurroundMode\": \"DISABLED\"|\"ENABLED\"|\"NOT_INDICATED\"\n        },\n        \"Mp2Settings\": {\n          \"Bitrate\": double,\n          \"CodingMode\": \"CODING_MODE_1_0\"|\"CODING_MODE_2_0\",\n          \"SampleRate\": double\n        },\n        \"PassThroughSettings\": {\n\n        },\n        \"WavSettings\": {\n          \"BitDepth\": double,\n          \"CodingMode\": \"CODING_MODE_1_0\"|\"CODING_MODE_2_0\"|\"CODING_MODE_4_0\"|\"CODING_MODE_8_0\",\n          \"SampleRate\": double\n        }\n      },\n      \"LanguageCode\": \"string\",\n      \"LanguageCodeControl\": \"FOLLOW_INPUT\"|\"USE_CONFIGURED\",\n      \"Name\": \"string\",\n      \"RemixSettings\": {\n        \"ChannelMappings\": [\n          {\n            \"InputChannelLevels\": [\n              {\n                \"Gain\": integer,\n                \"InputChannel\": integer\n              }\n              ...\n            ],\n            \"OutputChannel\": integer\n          }\n          ...\n        ],\n        \"ChannelsIn\": integer,\n        \"ChannelsOut\": integer\n      },\n      \"StreamName\": \"string\"\n    }\n    ...\n  ],\n  \"AvailBlanking\": {\n    \"AvailBlankingImage\": {\n      \"PasswordParam\": \"string\",\n      \"Uri\": \"string\",\n      \"Username\": \"string\"\n    },\n    \"State\": \"DISABLED\"|\"ENABLED\"\n  },\n  \"AvailConfiguration\": {\n    \"AvailSettings\": {\n      \"Scte35SpliceInsert\": {\n        \"AdAvailOffset\": integer,\n        \"NoRegionalBlackoutFlag\": \"FOLLOW\"|\"IGNORE\",\n        \"WebDeliveryAllowedFlag\": \"FOLLOW\"|\"IGNORE\"\n      },\n      \"Scte35TimeSignalApos\": {\n        \"AdAvailOffset\": integer,\n        \"NoRegionalBlackoutFlag\": \"FOLLOW\"|\"IGNORE\",\n        \"WebDeliveryAllowedFlag\": \"FOLLOW\"|\"IGNORE\"\n      }\n    }\n  },\n  \"BlackoutSlate\": {\n    \"BlackoutSlateImage\": {\n      \"PasswordParam\": \"string\",\n      \"Uri\": \"string\",\n      \"Username\": \"string\"\n    },\n    \"NetworkEndBlackout\": \"DISABLED\"|\"ENABLED\",\n    \"NetworkEndBlackoutImage\": {\n      \"PasswordParam\": \"string\",\n      \"Uri\": \"string\",\n      \"Username\": \"string\"\n    },\n    \"NetworkId\": \"string\",\n    \"State\": \"DISABLED\"|\"ENABLED\"\n  },\n  \"CaptionDescriptions\": [\n    {\n      \"CaptionSelectorName\": \"string\",\n      \"DestinationSettings\": {\n        \"AribDestinationSettings\": {\n\n        },\n        \"BurnInDestinationSettings\": {\n          \"Alignment\": \"CENTERED\"|\"LEFT\"|\"SMART\",\n          \"BackgroundColor\": \"BLACK\"|\"NONE\"|\"WHITE\",\n          \"BackgroundOpacity\": integer,\n          \"Font\": {\n            \"PasswordParam\": \"string\",\n            \"Uri\": \"string\",\n            \"Username\": \"string\"\n          },\n          \"FontColor\": \"BLACK\"|\"BLUE\"|\"GREEN\"|\"RED\"|\"WHITE\"|\"YELLOW\",\n          \"FontOpacity\": integer,\n          \"FontResolution\": integer,\n          \"FontSize\": \"string\",\n          \"OutlineColor\": \"BLACK\"|\"BLUE\"|\"GREEN\"|\"RED\"|\"WHITE\"|\"YELLOW\",\n          \"OutlineSize\": integer,\n          \"ShadowColor\": \"BLACK\"|\"NONE\"|\"WHITE\",\n          \"ShadowOpacity\": integer,\n          \"ShadowXOffset\": integer,\n          \"ShadowYOffset\": integer,\n          \"TeletextGridControl\": \"FIXED\"|\"SCALED\",\n          \"XPosition\": integer,\n          \"YPosition\": integer\n        },\n        \"DvbSubDestinationSettings\": {\n          \"Alignment\": \"CENTERED\"|\"LEFT\"|\"SMART\",\n          \"BackgroundColor\": \"BLACK\"|\"NONE\"|\"WHITE\",\n          \"BackgroundOpacity\": integer,\n          \"Font\": {\n            \"PasswordParam\": \"string\",\n            \"Uri\": \"string\",\n            \"Username\": \"string\"\n          },\n          \"FontColor\": \"BLACK\"|\"BLUE\"|\"GREEN\"|\"RED\"|\"WHITE\"|\"YELLOW\",\n          \"FontOpacity\": integer,\n          \"FontResolution\": integer,\n          \"FontSize\": \"string\",\n          \"OutlineColor\": \"BLACK\"|\"BLUE\"|\"GREEN\"|\"RED\"|\"WHITE\"|\"YELLOW\",\n          \"OutlineSize\": integer,\n          \"ShadowColor\": \"BLACK\"|\"NONE\"|\"WHITE\",\n          \"ShadowOpacity\": integer,\n          \"ShadowXOffset\": integer,\n          \"ShadowYOffset\": integer,\n          \"TeletextGridControl\": \"FIXED\"|\"SCALED\",\n          \"XPosition\": integer,\n          \"YPosition\": integer\n        },\n        \"EbuTtDDestinationSettings\": {\n          \"CopyrightHolder\": \"string\",\n          \"FillLineGap\": \"DISABLED\"|\"ENABLED\",\n          \"FontFamily\": \"string\",\n          \"StyleControl\": \"EXCLUDE\"|\"INCLUDE\"\n        },\n        \"EmbeddedDestinationSettings\": {\n\n        },\n        \"EmbeddedPlusScte20DestinationSettings\": {\n\n        },\n        \"RtmpCaptionInfoDestinationSettings\": {\n\n        },\n        \"Scte20PlusEmbeddedDestinationSettings\": {\n\n        },\n        \"Scte27DestinationSettings\": {\n\n        },\n        \"SmpteTtDestinationSettings\": {\n\n        },\n        \"TeletextDestinationSettings\": {\n\n        },\n        \"TtmlDestinationSettings\": {\n          \"StyleControl\": \"PASSTHROUGH\"|\"USE_CONFIGURED\"\n        },\n        \"WebvttDestinationSettings\": {\n          \"StyleControl\": \"NO_STYLE_DATA\"|\"PASSTHROUGH\"\n        }\n      },\n      \"LanguageCode\": \"string\",\n      \"LanguageDescription\": \"string\",\n      \"Name\": \"string\"\n    }\n    ...\n  ],\n  \"FeatureActivations\": {\n    \"InputPrepareScheduleActions\": \"DISABLED\"|\"ENABLED\"\n  },\n  \"GlobalConfiguration\": {\n    \"InitialAudioGain\": integer,\n    \"InputEndAction\": \"NONE\"|\"SWITCH_AND_LOOP_INPUTS\",\n    \"InputLossBehavior\": {\n      \"BlackFrameMsec\": integer,\n      \"InputLossImageColor\": \"string\",\n      \"InputLossImageSlate\": {\n        \"PasswordParam\": \"string\",\n        \"Uri\": \"string\",\n        \"Username\": \"string\"\n      },\n      \"InputLossImageType\": \"COLOR\"|\"SLATE\",\n      \"RepeatFrameMsec\": integer\n    },\n    \"OutputLockingMode\": \"EPOCH_LOCKING\"|\"PIPELINE_LOCKING\",\n    \"OutputTimingSource\": \"INPUT_CLOCK\"|\"SYSTEM_CLOCK\",\n    \"SupportLowFramerateInputs\": \"DISABLED\"|\"ENABLED\"\n  },\n  \"MotionGraphicsConfiguration\": {\n    \"MotionGraphicsInsertion\": \"DISABLED\"|\"ENABLED\",\n    \"MotionGraphicsSettings\": {\n      \"HtmlMotionGraphicsSettings\": {\n\n      }\n    }\n  },\n  \"NielsenConfiguration\": {\n    \"DistributorId\": \"string\",\n    \"NielsenPcmToId3Tagging\": \"DISABLED\"|\"ENABLED\"\n  },\n  \"OutputGroups\": [\n    {\n      \"Name\": \"string\",\n      \"OutputGroupSettings\": {\n        \"ArchiveGroupSettings\": {\n          \"ArchiveCdnSettings\": {\n            \"ArchiveS3Settings\": {\n              \"CannedAcl\": \"AUTHENTICATED_READ\"|\"BUCKET_OWNER_FULL_CONTROL\"|\"BUCKET_OWNER_READ\"|\"PUBLIC_READ\"\n            }\n          },\n          \"Destination\": {\n            \"DestinationRefId\": \"string\"\n          },\n          \"RolloverInterval\": integer\n        },\n        \"FrameCaptureGroupSettings\": {\n          \"Destination\": {\n            \"DestinationRefId\": \"string\"\n          },\n          \"FrameCaptureCdnSettings\": {\n            \"FrameCaptureS3Settings\": {\n              \"CannedAcl\": \"AUTHENTICATED_READ\"|\"BUCKET_OWNER_FULL_CONTROL\"|\"BUCKET_OWNER_READ\"|\"PUBLIC_READ\"\n            }\n          }\n        },\n        \"HlsGroupSettings\": {\n          \"AdMarkers\": [\"ADOBE\"|\"ELEMENTAL\"|\"ELEMENTAL_SCTE35\", ...],\n          \"BaseUrlContent\": \"string\",\n          \"BaseUrlContent1\": \"string\",\n          \"BaseUrlManifest\": \"string\",\n          \"BaseUrlManifest1\": \"string\",\n          \"CaptionLanguageMappings\": [\n            {\n              \"CaptionChannel\": integer,\n              \"LanguageCode\": \"string\",\n              \"LanguageDescription\": \"string\"\n            }\n            ...\n          ],\n          \"CaptionLanguageSetting\": \"INSERT\"|\"NONE\"|\"OMIT\",\n          \"ClientCache\": \"DISABLED\"|\"ENABLED\",\n          \"CodecSpecification\": \"RFC_4281\"|\"RFC_6381\",\n          \"ConstantIv\": \"string\",\n          \"Destination\": {\n            \"DestinationRefId\": \"string\"\n          },\n          \"DirectoryStructure\": \"SINGLE_DIRECTORY\"|\"SUBDIRECTORY_PER_STREAM\",\n          \"DiscontinuityTags\": \"INSERT\"|\"NEVER_INSERT\",\n          \"EncryptionType\": \"AES128\"|\"SAMPLE_AES\",\n          \"HlsCdnSettings\": {\n            \"HlsAkamaiSettings\": {\n              \"ConnectionRetryInterval\": integer,\n              \"FilecacheDuration\": integer,\n              \"HttpTransferMode\": \"CHUNKED\"|\"NON_CHUNKED\",\n              \"NumRetries\": integer,\n              \"RestartDelay\": integer,\n              \"Salt\": \"string\",\n              \"Token\": \"string\"\n            },\n            \"HlsBasicPutSettings\": {\n              \"ConnectionRetryInterval\": integer,\n              \"FilecacheDuration\": integer,\n              \"NumRetries\": integer,\n              \"RestartDelay\": integer\n            },\n            \"HlsMediaStoreSettings\": {\n              \"ConnectionRetryInterval\": integer,\n              \"FilecacheDuration\": integer,\n              \"MediaStoreStorageClass\": \"TEMPORAL\",\n              \"NumRetries\": integer,\n              \"RestartDelay\": integer\n            },\n            \"HlsS3Settings\": {\n              \"CannedAcl\": \"AUTHENTICATED_READ\"|\"BUCKET_OWNER_FULL_CONTROL\"|\"BUCKET_OWNER_READ\"|\"PUBLIC_READ\"\n            },\n            \"HlsWebdavSettings\": {\n              \"ConnectionRetryInterval\": integer,\n              \"FilecacheDuration\": integer,\n              \"HttpTransferMode\": \"CHUNKED\"|\"NON_CHUNKED\",\n              \"NumRetries\": integer,\n              \"RestartDelay\": integer\n            }\n          },\n          \"HlsId3SegmentTagging\": \"DISABLED\"|\"ENABLED\",\n          \"IFrameOnlyPlaylists\": \"DISABLED\"|\"STANDARD\",\n          \"IncompleteSegmentBehavior\": \"AUTO\"|\"SUPPRESS\",\n          \"IndexNSegments\": integer,\n          \"InputLossAction\": \"EMIT_OUTPUT\"|\"PAUSE_OUTPUT\",\n          \"IvInManifest\": \"EXCLUDE\"|\"INCLUDE\",\n          \"IvSource\": \"EXPLICIT\"|\"FOLLOWS_SEGMENT_NUMBER\",\n          \"KeepSegments\": integer,\n          \"KeyFormat\": \"string\",\n          \"KeyFormatVersions\": \"string\",\n          \"KeyProviderSettings\": {\n            \"StaticKeySettings\": {\n              \"KeyProviderServer\": {\n                \"PasswordParam\": \"string\",\n                \"Uri\": \"string\",\n                \"Username\": \"string\"\n              },\n              \"StaticKeyValue\": \"string\"\n            }\n          },\n          \"ManifestCompression\": \"GZIP\"|\"NONE\",\n          \"ManifestDurationFormat\": \"FLOATING_POINT\"|\"INTEGER\",\n          \"MinSegmentLength\": integer,\n          \"Mode\": \"LIVE\"|\"VOD\",\n          \"OutputSelection\": \"MANIFESTS_AND_SEGMENTS\"|\"SEGMENTS_ONLY\"|\"VARIANT_MANIFESTS_AND_SEGMENTS\",\n          \"ProgramDateTime\": \"EXCLUDE\"|\"INCLUDE\",\n          \"ProgramDateTimePeriod\": integer,\n          \"RedundantManifest\": \"DISABLED\"|\"ENABLED\",\n          \"SegmentLength\": integer,\n          \"SegmentationMode\": \"USE_INPUT_SEGMENTATION\"|\"USE_SEGMENT_DURATION\",\n          \"SegmentsPerSubdirectory\": integer,\n          \"StreamInfResolution\": \"EXCLUDE\"|\"INCLUDE\",\n          \"TimedMetadataId3Frame\": \"NONE\"|\"PRIV\"|\"TDRL\",\n          \"TimedMetadataId3Period\": integer,\n          \"TimestampDeltaMilliseconds\": integer,\n          \"TsFileMode\": \"SEGMENTED_FILES\"|\"SINGLE_FILE\"\n        },\n        \"MediaPackageGroupSettings\": {\n          \"Destination\": {\n            \"DestinationRefId\": \"string\"\n          }\n        },\n        \"MsSmoothGroupSettings\": {\n          \"AcquisitionPointId\": \"string\",\n          \"AudioOnlyTimecodeControl\": \"PASSTHROUGH\"|\"USE_CONFIGURED_CLOCK\",\n          \"CertificateMode\": \"SELF_SIGNED\"|\"VERIFY_AUTHENTICITY\",\n          \"ConnectionRetryInterval\": integer,\n          \"Destination\": {\n            \"DestinationRefId\": \"string\"\n          },\n          \"EventId\": \"string\",\n          \"EventIdMode\": \"NO_EVENT_ID\"|\"USE_CONFIGURED\"|\"USE_TIMESTAMP\",\n          \"EventStopBehavior\": \"NONE\"|\"SEND_EOS\",\n          \"FilecacheDuration\": integer,\n          \"FragmentLength\": integer,\n          \"InputLossAction\": \"EMIT_OUTPUT\"|\"PAUSE_OUTPUT\",\n          \"NumRetries\": integer,\n          \"RestartDelay\": integer,\n          \"SegmentationMode\": \"USE_INPUT_SEGMENTATION\"|\"USE_SEGMENT_DURATION\",\n          \"SendDelayMs\": integer,\n          \"SparseTrackType\": \"NONE\"|\"SCTE_35\"|\"SCTE_35_WITHOUT_SEGMENTATION\",\n          \"StreamManifestBehavior\": \"DO_NOT_SEND\"|\"SEND\",\n          \"TimestampOffset\": \"string\",\n          \"TimestampOffsetMode\": \"USE_CONFIGURED_OFFSET\"|\"USE_EVENT_START_DATE\"\n        },\n        \"MultiplexGroupSettings\": {\n\n        },\n        \"RtmpGroupSettings\": {\n          \"AdMarkers\": [\"ON_CUE_POINT_SCTE35\", ...],\n          \"AuthenticationScheme\": \"AKAMAI\"|\"COMMON\",\n          \"CacheFullBehavior\": \"DISCONNECT_IMMEDIATELY\"|\"WAIT_FOR_SERVER\",\n          \"CacheLength\": integer,\n          \"CaptionData\": \"ALL\"|\"FIELD1_608\"|\"FIELD1_AND_FIELD2_608\",\n          \"InputLossAction\": \"EMIT_OUTPUT\"|\"PAUSE_OUTPUT\",\n          \"RestartDelay\": integer\n        },\n        \"UdpGroupSettings\": {\n          \"InputLossAction\": \"DROP_PROGRAM\"|\"DROP_TS\"|\"EMIT_PROGRAM\",\n          \"TimedMetadataId3Frame\": \"NONE\"|\"PRIV\"|\"TDRL\",\n          \"TimedMetadataId3Period\": integer\n        }\n      },\n      \"Outputs\": [\n        {\n          \"AudioDescriptionNames\": [\"string\", ...],\n          \"CaptionDescriptionNames\": [\"string\", ...],\n          \"OutputName\": \"string\",\n          \"OutputSettings\": {\n            \"ArchiveOutputSettings\": {\n              \"ContainerSettings\": {\n                \"M2tsSettings\": {\n                  \"AbsentInputAudioBehavior\": \"DROP\"|\"ENCODE_SILENCE\",\n                  \"Arib\": \"DISABLED\"|\"ENABLED\",\n                  \"AribCaptionsPid\": \"string\",\n                  \"AribCaptionsPidControl\": \"AUTO\"|\"USE_CONFIGURED\",\n                  \"AudioBufferModel\": \"ATSC\"|\"DVB\",\n                  \"AudioFramesPerPes\": integer,\n                  \"AudioPids\": \"string\",\n                  \"AudioStreamType\": \"ATSC\"|\"DVB\",\n                  \"Bitrate\": integer,\n                  \"BufferModel\": \"MULTIPLEX\"|\"NONE\",\n                  \"CcDescriptor\": \"DISABLED\"|\"ENABLED\",\n                  \"DvbNitSettings\": {\n                    \"NetworkId\": integer,\n                    \"NetworkName\": \"string\",\n                    \"RepInterval\": integer\n                  },\n                  \"DvbSdtSettings\": {\n                    \"OutputSdt\": \"SDT_FOLLOW\"|\"SDT_FOLLOW_IF_PRESENT\"|\"SDT_MANUAL\"|\"SDT_NONE\",\n                    \"RepInterval\": integer,\n                    \"ServiceName\": \"string\",\n                    \"ServiceProviderName\": \"string\"\n                  },\n                  \"DvbSubPids\": \"string\",\n                  \"DvbTdtSettings\": {\n                    \"RepInterval\": integer\n                  },\n                  \"DvbTeletextPid\": \"string\",\n                  \"Ebif\": \"NONE\"|\"PASSTHROUGH\",\n                  \"EbpAudioInterval\": \"VIDEO_AND_FIXED_INTERVALS\"|\"VIDEO_INTERVAL\",\n                  \"EbpLookaheadMs\": integer,\n                  \"EbpPlacement\": \"VIDEO_AND_AUDIO_PIDS\"|\"VIDEO_PID\",\n                  \"EcmPid\": \"string\",\n                  \"EsRateInPes\": \"EXCLUDE\"|\"INCLUDE\",\n                  \"EtvPlatformPid\": \"string\",\n                  \"EtvSignalPid\": \"string\",\n                  \"FragmentTime\": double,\n                  \"Klv\": \"NONE\"|\"PASSTHROUGH\",\n                  \"KlvDataPids\": \"string\",\n                  \"NielsenId3Behavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                  \"NullPacketBitrate\": double,\n                  \"PatInterval\": integer,\n                  \"PcrControl\": \"CONFIGURED_PCR_PERIOD\"|\"PCR_EVERY_PES_PACKET\",\n                  \"PcrPeriod\": integer,\n                  \"PcrPid\": \"string\",\n                  \"PmtInterval\": integer,\n                  \"PmtPid\": \"string\",\n                  \"ProgramNum\": integer,\n                  \"RateMode\": \"CBR\"|\"VBR\",\n                  \"Scte27Pids\": \"string\",\n                  \"Scte35Control\": \"NONE\"|\"PASSTHROUGH\",\n                  \"Scte35Pid\": \"string\",\n                  \"SegmentationMarkers\": \"EBP\"|\"EBP_LEGACY\"|\"NONE\"|\"PSI_SEGSTART\"|\"RAI_ADAPT\"|\"RAI_SEGSTART\",\n                  \"SegmentationStyle\": \"MAINTAIN_CADENCE\"|\"RESET_CADENCE\",\n                  \"SegmentationTime\": double,\n                  \"TimedMetadataBehavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                  \"TimedMetadataPid\": \"string\",\n                  \"TransportStreamId\": integer,\n                  \"VideoPid\": \"string\"\n                },\n                \"RawSettings\": {\n\n                }\n              },\n              \"Extension\": \"string\",\n              \"NameModifier\": \"string\"\n            },\n            \"FrameCaptureOutputSettings\": {\n              \"NameModifier\": \"string\"\n            },\n            \"HlsOutputSettings\": {\n              \"H265PackagingType\": \"HEV1\"|\"HVC1\",\n              \"HlsSettings\": {\n                \"AudioOnlyHlsSettings\": {\n                  \"AudioGroupId\": \"string\",\n                  \"AudioOnlyImage\": {\n                    \"PasswordParam\": \"string\",\n                    \"Uri\": \"string\",\n                    \"Username\": \"string\"\n                  },\n                  \"AudioTrackType\": \"ALTERNATE_AUDIO_AUTO_SELECT\"|\"ALTERNATE_AUDIO_AUTO_SELECT_DEFAULT\"|\"ALTERNATE_AUDIO_NOT_AUTO_SELECT\"|\"AUDIO_ONLY_VARIANT_STREAM\",\n                  \"SegmentType\": \"AAC\"|\"FMP4\"\n                },\n                \"Fmp4HlsSettings\": {\n                  \"AudioRenditionSets\": \"string\",\n                  \"NielsenId3Behavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                  \"TimedMetadataBehavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\"\n                },\n                \"FrameCaptureHlsSettings\": {\n\n                },\n                \"StandardHlsSettings\": {\n                  \"AudioRenditionSets\": \"string\",\n                  \"M3u8Settings\": {\n                    \"AudioFramesPerPes\": integer,\n                    \"AudioPids\": \"string\",\n                    \"EcmPid\": \"string\",\n                    \"NielsenId3Behavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                    \"PatInterval\": integer,\n                    \"PcrControl\": \"CONFIGURED_PCR_PERIOD\"|\"PCR_EVERY_PES_PACKET\",\n                    \"PcrPeriod\": integer,\n                    \"PcrPid\": \"string\",\n                    \"PmtInterval\": integer,\n                    \"PmtPid\": \"string\",\n                    \"ProgramNum\": integer,\n                    \"Scte35Behavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                    \"Scte35Pid\": \"string\",\n                    \"TimedMetadataBehavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                    \"TimedMetadataPid\": \"string\",\n                    \"TransportStreamId\": integer,\n                    \"VideoPid\": \"string\"\n                  }\n                }\n              },\n              \"NameModifier\": \"string\",\n              \"SegmentModifier\": \"string\"\n            },\n            \"MediaPackageOutputSettings\": {\n\n            },\n            \"MsSmoothOutputSettings\": {\n              \"H265PackagingType\": \"HEV1\"|\"HVC1\",\n              \"NameModifier\": \"string\"\n            },\n            \"MultiplexOutputSettings\": {\n              \"Destination\": {\n                \"DestinationRefId\": \"string\"\n              }\n            },\n            \"RtmpOutputSettings\": {\n              \"CertificateMode\": \"SELF_SIGNED\"|\"VERIFY_AUTHENTICITY\",\n              \"ConnectionRetryInterval\": integer,\n              \"Destination\": {\n                \"DestinationRefId\": \"string\"\n              },\n              \"NumRetries\": integer\n            },\n            \"UdpOutputSettings\": {\n              \"BufferMsec\": integer,\n              \"ContainerSettings\": {\n                \"M2tsSettings\": {\n                  \"AbsentInputAudioBehavior\": \"DROP\"|\"ENCODE_SILENCE\",\n                  \"Arib\": \"DISABLED\"|\"ENABLED\",\n                  \"AribCaptionsPid\": \"string\",\n                  \"AribCaptionsPidControl\": \"AUTO\"|\"USE_CONFIGURED\",\n                  \"AudioBufferModel\": \"ATSC\"|\"DVB\",\n                  \"AudioFramesPerPes\": integer,\n                  \"AudioPids\": \"string\",\n                  \"AudioStreamType\": \"ATSC\"|\"DVB\",\n                  \"Bitrate\": integer,\n                  \"BufferModel\": \"MULTIPLEX\"|\"NONE\",\n                  \"CcDescriptor\": \"DISABLED\"|\"ENABLED\",\n                  \"DvbNitSettings\": {\n                    \"NetworkId\": integer,\n                    \"NetworkName\": \"string\",\n                    \"RepInterval\": integer\n                  },\n                  \"DvbSdtSettings\": {\n                    \"OutputSdt\": \"SDT_FOLLOW\"|\"SDT_FOLLOW_IF_PRESENT\"|\"SDT_MANUAL\"|\"SDT_NONE\",\n                    \"RepInterval\": integer,\n                    \"ServiceName\": \"string\",\n                    \"ServiceProviderName\": \"string\"\n                  },\n                  \"DvbSubPids\": \"string\",\n                  \"DvbTdtSettings\": {\n                    \"RepInterval\": integer\n                  },\n                  \"DvbTeletextPid\": \"string\",\n                  \"Ebif\": \"NONE\"|\"PASSTHROUGH\",\n                  \"EbpAudioInterval\": \"VIDEO_AND_FIXED_INTERVALS\"|\"VIDEO_INTERVAL\",\n                  \"EbpLookaheadMs\": integer,\n                  \"EbpPlacement\": \"VIDEO_AND_AUDIO_PIDS\"|\"VIDEO_PID\",\n                  \"EcmPid\": \"string\",\n                  \"EsRateInPes\": \"EXCLUDE\"|\"INCLUDE\",\n                  \"EtvPlatformPid\": \"string\",\n                  \"EtvSignalPid\": \"string\",\n                  \"FragmentTime\": double,\n                  \"Klv\": \"NONE\"|\"PASSTHROUGH\",\n                  \"KlvDataPids\": \"string\",\n                  \"NielsenId3Behavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                  \"NullPacketBitrate\": double,\n                  \"PatInterval\": integer,\n                  \"PcrControl\": \"CONFIGURED_PCR_PERIOD\"|\"PCR_EVERY_PES_PACKET\",\n                  \"PcrPeriod\": integer,\n                  \"PcrPid\": \"string\",\n                  \"PmtInterval\": integer,\n                  \"PmtPid\": \"string\",\n                  \"ProgramNum\": integer,\n                  \"RateMode\": \"CBR\"|\"VBR\",\n                  \"Scte27Pids\": \"string\",\n                  \"Scte35Control\": \"NONE\"|\"PASSTHROUGH\",\n                  \"Scte35Pid\": \"string\",\n                  \"SegmentationMarkers\": \"EBP\"|\"EBP_LEGACY\"|\"NONE\"|\"PSI_SEGSTART\"|\"RAI_ADAPT\"|\"RAI_SEGSTART\",\n                  \"SegmentationStyle\": \"MAINTAIN_CADENCE\"|\"RESET_CADENCE\",\n                  \"SegmentationTime\": double,\n                  \"TimedMetadataBehavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                  \"TimedMetadataPid\": \"string\",\n                  \"TransportStreamId\": integer,\n                  \"VideoPid\": \"string\"\n                }\n              },\n              \"Destination\": {\n                \"DestinationRefId\": \"string\"\n              },\n              \"FecOutputSettings\": {\n                \"ColumnDepth\": integer,\n                \"IncludeFec\": \"COLUMN\"|\"COLUMN_AND_ROW\",\n                \"RowLength\": integer\n              }\n            }\n          },\n          \"VideoDescriptionName\": \"string\"\n        }\n        ...\n      ]\n    }\n    ...\n  ],\n  \"TimecodeConfig\": {\n    \"Source\": \"EMBEDDED\"|\"SYSTEMCLOCK\"|\"ZEROBASED\",\n    \"SyncThreshold\": integer\n  },\n  \"VideoDescriptions\": [\n    {\n      \"CodecSettings\": {\n        \"FrameCaptureSettings\": {\n          \"CaptureInterval\": integer,\n          \"CaptureIntervalUnits\": \"MILLISECONDS\"|\"SECONDS\"\n        },\n        \"H264Settings\": {\n          \"AdaptiveQuantization\": \"AUTO\"|\"HIGH\"|\"HIGHER\"|\"LOW\"|\"MAX\"|\"MEDIUM\"|\"OFF\",\n          \"AfdSignaling\": \"AUTO\"|\"FIXED\"|\"NONE\",\n          \"Bitrate\": integer,\n          \"BufFillPct\": integer,\n          \"BufSize\": integer,\n          \"ColorMetadata\": \"IGNORE\"|\"INSERT\",\n          \"ColorSpaceSettings\": {\n            \"ColorSpacePassthroughSettings\": {\n\n            },\n            \"Rec601Settings\": {\n\n            },\n            \"Rec709Settings\": {\n\n            }\n          },\n          \"EntropyEncoding\": \"CABAC\"|\"CAVLC\",\n          \"FilterSettings\": {\n            \"TemporalFilterSettings\": {\n              \"PostFilterSharpening\": \"AUTO\"|\"DISABLED\"|\"ENABLED\",\n              \"Strength\": \"AUTO\"|\"STRENGTH_1\"|\"STRENGTH_2\"|\"STRENGTH_3\"|\"STRENGTH_4\"|\"STRENGTH_5\"|\"STRENGTH_6\"|\"STRENGTH_7\"|\"STRENGTH_8\"|\"STRENGTH_9\"|\"STRENGTH_10\"|\"STRENGTH_11\"|\"STRENGTH_12\"|\"STRENGTH_13\"|\"STRENGTH_14\"|\"STRENGTH_15\"|\"STRENGTH_16\"\n            }\n          },\n          \"FixedAfd\": \"AFD_0000\"|\"AFD_0010\"|\"AFD_0011\"|\"AFD_0100\"|\"AFD_1000\"|\"AFD_1001\"|\"AFD_1010\"|\"AFD_1011\"|\"AFD_1101\"|\"AFD_1110\"|\"AFD_1111\",\n          \"FlickerAq\": \"DISABLED\"|\"ENABLED\",\n          \"ForceFieldPictures\": \"DISABLED\"|\"ENABLED\",\n          \"FramerateControl\": \"INITIALIZE_FROM_SOURCE\"|\"SPECIFIED\",\n          \"FramerateDenominator\": integer,\n          \"FramerateNumerator\": integer,\n          \"GopBReference\": \"DISABLED\"|\"ENABLED\",\n          \"GopClosedCadence\": integer,\n          \"GopNumBFrames\": integer,\n          \"GopSize\": double,\n          \"GopSizeUnits\": \"FRAMES\"|\"SECONDS\",\n          \"Level\": \"H264_LEVEL_1\"|\"H264_LEVEL_1_1\"|\"H264_LEVEL_1_2\"|\"H264_LEVEL_1_3\"|\"H264_LEVEL_2\"|\"H264_LEVEL_2_1\"|\"H264_LEVEL_2_2\"|\"H264_LEVEL_3\"|\"H264_LEVEL_3_1\"|\"H264_LEVEL_3_2\"|\"H264_LEVEL_4\"|\"H264_LEVEL_4_1\"|\"H264_LEVEL_4_2\"|\"H264_LEVEL_5\"|\"H264_LEVEL_5_1\"|\"H264_LEVEL_5_2\"|\"H264_LEVEL_AUTO\",\n          \"LookAheadRateControl\": \"HIGH\"|\"LOW\"|\"MEDIUM\",\n          \"MaxBitrate\": integer,\n          \"MinIInterval\": integer,\n          \"NumRefFrames\": integer,\n          \"ParControl\": \"INITIALIZE_FROM_SOURCE\"|\"SPECIFIED\",\n          \"ParDenominator\": integer,\n          \"ParNumerator\": integer,\n          \"Profile\": \"BASELINE\"|\"HIGH\"|\"HIGH_10BIT\"|\"HIGH_422\"|\"HIGH_422_10BIT\"|\"MAIN\",\n          \"QualityLevel\": \"ENHANCED_QUALITY\"|\"STANDARD_QUALITY\",\n          \"QvbrQualityLevel\": integer,\n          \"RateControlMode\": \"CBR\"|\"MULTIPLEX\"|\"QVBR\"|\"VBR\",\n          \"ScanType\": \"INTERLACED\"|\"PROGRESSIVE\",\n          \"SceneChangeDetect\": \"DISABLED\"|\"ENABLED\",\n          \"Slices\": integer,\n          \"Softness\": integer,\n          \"SpatialAq\": \"DISABLED\"|\"ENABLED\",\n          \"SubgopLength\": \"DYNAMIC\"|\"FIXED\",\n          \"Syntax\": \"DEFAULT\"|\"RP2027\",\n          \"TemporalAq\": \"DISABLED\"|\"ENABLED\",\n          \"TimecodeInsertion\": \"DISABLED\"|\"PIC_TIMING_SEI\"\n        },\n        \"H265Settings\": {\n          \"AdaptiveQuantization\": \"AUTO\"|\"HIGH\"|\"HIGHER\"|\"LOW\"|\"MAX\"|\"MEDIUM\"|\"OFF\",\n          \"AfdSignaling\": \"AUTO\"|\"FIXED\"|\"NONE\",\n          \"AlternativeTransferFunction\": \"INSERT\"|\"OMIT\",\n          \"Bitrate\": integer,\n          \"BufSize\": integer,\n          \"ColorMetadata\": \"IGNORE\"|\"INSERT\",\n          \"ColorSpaceSettings\": {\n            \"ColorSpacePassthroughSettings\": {\n\n            },\n            \"Hdr10Settings\": {\n              \"MaxCll\": integer,\n              \"MaxFall\": integer\n            },\n            \"Rec601Settings\": {\n\n            },\n            \"Rec709Settings\": {\n\n            }\n          },\n          \"FilterSettings\": {\n            \"TemporalFilterSettings\": {\n              \"PostFilterSharpening\": \"AUTO\"|\"DISABLED\"|\"ENABLED\",\n              \"Strength\": \"AUTO\"|\"STRENGTH_1\"|\"STRENGTH_2\"|\"STRENGTH_3\"|\"STRENGTH_4\"|\"STRENGTH_5\"|\"STRENGTH_6\"|\"STRENGTH_7\"|\"STRENGTH_8\"|\"STRENGTH_9\"|\"STRENGTH_10\"|\"STRENGTH_11\"|\"STRENGTH_12\"|\"STRENGTH_13\"|\"STRENGTH_14\"|\"STRENGTH_15\"|\"STRENGTH_16\"\n            }\n          },\n          \"FixedAfd\": \"AFD_0000\"|\"AFD_0010\"|\"AFD_0011\"|\"AFD_0100\"|\"AFD_1000\"|\"AFD_1001\"|\"AFD_1010\"|\"AFD_1011\"|\"AFD_1101\"|\"AFD_1110\"|\"AFD_1111\",\n          \"FlickerAq\": \"DISABLED\"|\"ENABLED\",\n          \"FramerateDenominator\": integer,\n          \"FramerateNumerator\": integer,\n          \"GopClosedCadence\": integer,\n          \"GopSize\": double,\n          \"GopSizeUnits\": \"FRAMES\"|\"SECONDS\",\n          \"Level\": \"H265_LEVEL_1\"|\"H265_LEVEL_2\"|\"H265_LEVEL_2_1\"|\"H265_LEVEL_3\"|\"H265_LEVEL_3_1\"|\"H265_LEVEL_4\"|\"H265_LEVEL_4_1\"|\"H265_LEVEL_5\"|\"H265_LEVEL_5_1\"|\"H265_LEVEL_5_2\"|\"H265_LEVEL_6\"|\"H265_LEVEL_6_1\"|\"H265_LEVEL_6_2\"|\"H265_LEVEL_AUTO\",\n          \"LookAheadRateControl\": \"HIGH\"|\"LOW\"|\"MEDIUM\",\n          \"MaxBitrate\": integer,\n          \"MinIInterval\": integer,\n          \"ParDenominator\": integer,\n          \"ParNumerator\": integer,\n          \"Profile\": \"MAIN\"|\"MAIN_10BIT\",\n          \"QvbrQualityLevel\": integer,\n          \"RateControlMode\": \"CBR\"|\"MULTIPLEX\"|\"QVBR\",\n          \"ScanType\": \"INTERLACED\"|\"PROGRESSIVE\",\n          \"SceneChangeDetect\": \"DISABLED\"|\"ENABLED\",\n          \"Slices\": integer,\n          \"Tier\": \"HIGH\"|\"MAIN\",\n          \"TimecodeInsertion\": \"DISABLED\"|\"PIC_TIMING_SEI\"\n        },\n        \"Mpeg2Settings\": {\n          \"AdaptiveQuantization\": \"AUTO\"|\"HIGH\"|\"LOW\"|\"MEDIUM\"|\"OFF\",\n          \"AfdSignaling\": \"AUTO\"|\"FIXED\"|\"NONE\",\n          \"ColorMetadata\": \"IGNORE\"|\"INSERT\",\n          \"ColorSpace\": \"AUTO\"|\"PASSTHROUGH\",\n          \"DisplayAspectRatio\": \"DISPLAYRATIO16X9\"|\"DISPLAYRATIO4X3\",\n          \"FilterSettings\": {\n            \"TemporalFilterSettings\": {\n              \"PostFilterSharpening\": \"AUTO\"|\"DISABLED\"|\"ENABLED\",\n              \"Strength\": \"AUTO\"|\"STRENGTH_1\"|\"STRENGTH_2\"|\"STRENGTH_3\"|\"STRENGTH_4\"|\"STRENGTH_5\"|\"STRENGTH_6\"|\"STRENGTH_7\"|\"STRENGTH_8\"|\"STRENGTH_9\"|\"STRENGTH_10\"|\"STRENGTH_11\"|\"STRENGTH_12\"|\"STRENGTH_13\"|\"STRENGTH_14\"|\"STRENGTH_15\"|\"STRENGTH_16\"\n            }\n          },\n          \"FixedAfd\": \"AFD_0000\"|\"AFD_0010\"|\"AFD_0011\"|\"AFD_0100\"|\"AFD_1000\"|\"AFD_1001\"|\"AFD_1010\"|\"AFD_1011\"|\"AFD_1101\"|\"AFD_1110\"|\"AFD_1111\",\n          \"FramerateDenominator\": integer,\n          \"FramerateNumerator\": integer,\n          \"GopClosedCadence\": integer,\n          \"GopNumBFrames\": integer,\n          \"GopSize\": double,\n          \"GopSizeUnits\": \"FRAMES\"|\"SECONDS\",\n          \"ScanType\": \"INTERLACED\"|\"PROGRESSIVE\",\n          \"SubgopLength\": \"DYNAMIC\"|\"FIXED\",\n          \"TimecodeInsertion\": \"DISABLED\"|\"GOP_TIMECODE\"\n        }\n      },\n      \"Height\": integer,\n      \"Name\": \"string\",\n      \"RespondToAfd\": \"NONE\"|\"PASSTHROUGH\"|\"RESPOND\",\n      \"ScalingBehavior\": \"DEFAULT\"|\"STRETCH_TO_OUTPUT\",\n      \"Sharpness\": integer,\n      \"Width\": integer\n    }\n    ...\n  ]\n}\n\n\n--input-attachments (list) List of input attachments for channel.(structure)\n\nPlaceholder documentation for InputAttachment\n\nAutomaticInputFailoverSettings -> (structure)\n\nUser-specified settings for defining what the conditions are for declaring the input unhealthy and failing over to a different input.\n\nErrorClearTimeMsec -> (integer)\n\nThis clear time defines the requirement a recovered input must meet to be considered healthy. The input must have no failover conditions for this length of time. Enter a time in milliseconds. This value is particularly important if the input_preference for the failover pair is set to PRIMARY_INPUT_PREFERRED, because after this time, MediaLive will switch back to the primary input.\n\nFailoverConditions -> (list)\n\nA list of failover conditions. If any of these conditions occur, MediaLive will perform a failover to the other input.\n\n(structure)\n\nFailover Condition settings. There can be multiple failover conditions inside AutomaticInputFailoverSettings.\n\nFailoverConditionSettings -> (structure)\n\nFailover condition type-specific settings.\n\nAudioSilenceSettings -> (structure)\n\nMediaLive will perform a failover if the specified audio selector is silent for the specified period.\n\nAudioSelectorName -> (string)\n\nThe name of the audio selector in the input that MediaLive should monitor to detect silence. Select your most important rendition. If you didn’t create an audio selector in this input, leave blank.\n\nAudioSilenceThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be silent before automatic input failover occurs. Silence is defined as audio loss or audio quieter than -50 dBFS.\n\nInputLossSettings -> (structure)\n\nMediaLive will perform a failover if content is not detected in this input for the specified period.\n\nInputLossThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that no input is detected. After that time, an input failover will occur.\n\nVideoBlackSettings -> (structure)\n\nMediaLive will perform a failover if content is considered black for the specified period.\n\nBlackDetectThreshold -> (double)\n\nA value used in calculating the threshold below which MediaLive considers a pixel to be ‘black’. For the input to be considered black, every pixel in a frame must be below this threshold. The threshold is calculated as a percentage (expressed as a decimal) of white. Therefore .1 means 10% white (or 90% black). Note how the formula works for any color depth. For example, if you set this field to 0.1 in 10-bit color depth: (1023*0.1=102.3), which means a pixel value of 102 or less is ‘black’. If you set this field to .1 in an 8-bit color depth: (255*0.1=25.5), which means a pixel value of 25 or less is ‘black’. The range is 0.0 to 1.0, with any number of decimal places.\n\nVideoBlackThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be black before automatic input failover occurs.\n\nInputPreference -> (string)\n\nInput preference when deciding which input to make active when a previously failed input has recovered.\n\nSecondaryInputId -> (string)\n\nThe input ID of the secondary input in the automatic input failover pair.\n\nInputAttachmentName -> (string)\n\nUser-specified name for the attachment. This is required if the user wants to use this input in an input switch action.\n\nInputId -> (string)\n\nThe ID of the input\n\nInputSettings -> (structure)\n\nSettings of an input (caption selector, etc.)\n\nAudioSelectors -> (list)\n\nUsed to select the audio stream to decode for inputs that have multiple available.\n\n(structure)\n\nAudio Selector\n\nName -> (string)\n\nThe name of this AudioSelector. AudioDescriptions will use this name to uniquely identify this Selector. Selector names should be unique per input.\n\nSelectorSettings -> (structure)\n\nThe audio selector settings.\n\nAudioHlsRenditionSelection -> (structure)\n\nAudio Hls Rendition Selection\n\nGroupId -> (string)\n\nSpecifies the GROUP-ID in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nName -> (string)\n\nSpecifies the NAME in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nAudioLanguageSelection -> (structure)\n\nAudio Language Selection\n\nLanguageCode -> (string)\n\nSelects a specific three-letter language code from within an audio source.\n\nLanguageSelectionPolicy -> (string)\n\nWhen set to “strict”, the transport stream demux strictly identifies audio streams by their language descriptor. If a PMT update occurs such that an audio stream matching the initially selected language is no longer present then mute will be encoded until the language returns. If “loose”, then on a PMT update the demux will choose another audio stream in the program with the same stream type if it can’t find one with the same language.\n\nAudioPidSelection -> (structure)\n\nAudio Pid Selection\n\nPid -> (integer)\n\nSelects a specific PID from within a source.\n\nAudioTrackSelection -> (structure)\n\nAudio Track Selection\n\nTracks -> (list)\n\nSelects one or more unique audio tracks from within a source.\n\n(structure)\n\nAudio Track\n\nTrack -> (integer)\n\n1-based integer value that maps to a specific audio track\n\nCaptionSelectors -> (list)\n\nUsed to select the caption input to use for inputs that have multiple available.\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nLanguageCode -> (string)\n\nWhen specified this field indicates the three letter language code of the caption track to extract from the source.\n\nName -> (string)\n\nName identifier for a caption selector. This name is used to associate this caption selector with one or more caption descriptions. Names must be unique within an event.\n\nSelectorSettings -> (structure)\n\nCaption selector settings.\n\nAncillarySourceSettings -> (structure)\n\nAncillary Source Settings\n\nSourceAncillaryChannelNumber -> (integer)\n\nSpecifies the number (1 to 4) of the captions channel you want to extract from the ancillary captions. If you plan to convert the ancillary captions to another format, complete this field. If you plan to choose Embedded as the captions destination in the output (to pass through all the channels in the ancillary captions), leave this field blank because MediaLive ignores the field.\n\nAribSourceSettings -> (structure)\n\nArib Source Settings\n\nDvbSubSourceSettings -> (structure)\n\nDvb Sub Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nWhen using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through, regardless of selectors.\n\nEmbeddedSourceSettings -> (structure)\n\nEmbedded Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nScte20Detection -> (string)\n\nSet to “auto” to handle streams with intermittent and/or non-aligned SCTE-20 and Embedded captions.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nSource608TrackNumber -> (integer)\n\nThis field is unused and deprecated.\n\nScte20SourceSettings -> (structure)\n\nScte20 Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nScte27SourceSettings -> (structure)\n\nScte27 Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nThe pid field is used in conjunction with the caption selector languageCode field as follows: - Specify PID and Language: Extracts captions from that PID; the language is “informational”. - Specify PID and omit Language: Extracts the specified PID. - Omit PID and specify Language: Extracts the specified language, whichever PID that happens to be. - Omit PID and omit Language: Valid only if source is DVB-Sub that is being passed through; all languages will be passed through.\n\nTeletextSourceSettings -> (structure)\n\nTeletext Source Settings\n\nOutputRectangle -> (structure)\n\nOptionally defines a region where TTML style captions will be displayed\n\nHeight -> (double)\n\nSee the description in leftOffset. For height, specify the entire height of the rectangle as a percentage of the underlying frame height. For example, “80” means the rectangle height is 80% of the underlying frame height. The topOffset and rectangleHeight must add up to 100% or less. This field corresponds to tts:extent - Y in the TTML standard.\n\nLeftOffset -> (double)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. (Make sure to leave the default if you don’t have either of these formats in the output.) You can define a display rectangle for the captions that is smaller than the underlying video frame. You define the rectangle by specifying the position of the left edge, top edge, bottom edge, and right edge of the rectangle, all within the underlying video frame. The units for the measurements are percentages. If you specify a value for one of these fields, you must specify a value for all of them. For leftOffset, specify the position of the left edge of the rectangle, as a percentage of the underlying frame width, and relative to the left edge of the frame. For example, “10” means the measurement is 10% of the underlying frame width. The rectangle left edge starts at that position from the left edge of the frame. This field corresponds to tts:origin - X in the TTML standard.\n\nTopOffset -> (double)\n\nSee the description in leftOffset. For topOffset, specify the position of the top edge of the rectangle, as a percentage of the underlying frame height, and relative to the top edge of the frame. For example, “10” means the measurement is 10% of the underlying frame height. The rectangle top edge starts at that position from the top edge of the frame. This field corresponds to tts:origin - Y in the TTML standard.\n\nWidth -> (double)\n\nSee the description in leftOffset. For width, specify the entire width of the rectangle as a percentage of the underlying frame width. For example, “80” means the rectangle width is 80% of the underlying frame width. The leftOffset and rectangleWidth must add up to 100% or less. This field corresponds to tts:extent - X in the TTML standard.\n\nPageNumber -> (string)\n\nSpecifies the teletext page number within the data stream from which to extract captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should be specified as a hexadecimal string with no “0x” prefix.\n\nDeblockFilter -> (string)\n\nEnable or disable the deblock filter when filtering.\n\nDenoiseFilter -> (string)\n\nEnable or disable the denoise filter when filtering.\n\nFilterStrength -> (integer)\n\nAdjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).\n\nInputFilter -> (string)\n\nTurns on the filter for this input. MPEG-2 inputs have the deblocking filter enabled by default. 1) auto - filtering will be applied depending on input type/quality 2) disabled - no filtering will be applied to the input 3) forced - filtering will be applied regardless of input type\n\nNetworkInputSettings -> (structure)\n\nInput settings.\n\nHlsInputSettings -> (structure)\n\nSpecifies HLS input settings when the uri is for a HLS manifest.\n\nBandwidth -> (integer)\n\nWhen specified the HLS stream with the m3u8 BANDWIDTH that most closely matches this value will be chosen, otherwise the highest bandwidth stream in the m3u8 will be chosen. The bitrate is specified in bits per second, as in an HLS manifest.\n\nBufferSegments -> (integer)\n\nWhen specified, reading of the HLS input will begin this many buffer segments from the end (most recently written segment). When not specified, the HLS input will begin with the first segment specified in the m3u8.\n\nRetries -> (integer)\n\nThe number of consecutive times that attempts to read a manifest or segment must fail before the input is considered unavailable.\n\nRetryInterval -> (integer)\n\nThe number of seconds between retries when an attempt to read a manifest or segment fails.\n\nScte35Source -> (string)\n\nIdentifies the source for the SCTE-35 messages that MediaLive will ingest. Messages can be ingested from the content segments (in the stream) or from tags in the playlist (the HLS manifest). MediaLive ignores SCTE-35 information in the source that is not selected.\n\nServerValidation -> (string)\n\nCheck HTTPS server certificates. When set to checkCryptographyOnly, cryptography in the certificate will be checked, but not the server’s name. Certain subdomains (notably S3 buckets that use dots in the bucket name) do not strictly match the corresponding certificate’s wildcard pattern and would otherwise cause the event to error. This setting is ignored for protocols that do not use https.\n\nSmpte2038DataPreference -> (string)\n\nSpecifies whether to extract applicable ancillary data from a SMPTE-2038 source in this input. Applicable data types are captions, timecode, AFD, and SCTE-104 messages. - PREFER: Extract from SMPTE-2038 if present in this input, otherwise extract from another source (if any). - IGNORE: Never extract any ancillary data from SMPTE-2038.\n\nSourceEndBehavior -> (string)\n\nLoop input if it is a file. This allows a file input to be streamed indefinitely.\n\nVideoSelector -> (structure)\n\nInforms which video elementary stream to decode for input types that have multiple available.\n\nColorSpace -> (string)\n\nSpecifies the color space of an input. This setting works in tandem with colorSpaceUsage and a video description’s colorSpaceSettingsChoice to determine if any conversion will be performed.\n\nColorSpaceSettings -> (structure)\n\nColor space settings\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nColorSpaceUsage -> (string)\n\nApplies only if colorSpace is a value other than follow. This field controls how the value in the colorSpace field will be used. fallback means that when the input does include color space data, that data will be used, but when the input has no color space data, the value in colorSpace will be used. Choose fallback if your input is sometimes missing color space data, but when it does have color space data, that data is correct. force means to always use the value in colorSpace. Choose force if your input usually has no color space data or might have unreliable color space data.\n\nSelectorSettings -> (structure)\n\nThe video selector settings.\n\nVideoSelectorPid -> (structure)\n\nVideo Selector Pid\n\nPid -> (integer)\n\nSelects a specific PID from within a video source.\n\nVideoSelectorProgramId -> (structure)\n\nVideo Selector Program Id\n\nProgramId -> (integer)\n\nSelects a specific program from within a multi-program transport stream. If the program doesn’t exist, the first program within the transport stream will be selected by default.\n\nJSON Syntax:\n\n[\n  {\n    \"AutomaticInputFailoverSettings\": {\n      \"ErrorClearTimeMsec\": integer,\n      \"FailoverConditions\": [\n        {\n          \"FailoverConditionSettings\": {\n            \"AudioSilenceSettings\": {\n              \"AudioSelectorName\": \"string\",\n              \"AudioSilenceThresholdMsec\": integer\n            },\n            \"InputLossSettings\": {\n              \"InputLossThresholdMsec\": integer\n            },\n            \"VideoBlackSettings\": {\n              \"BlackDetectThreshold\": double,\n              \"VideoBlackThresholdMsec\": integer\n            }\n          }\n        }\n        ...\n      ],\n      \"InputPreference\": \"EQUAL_INPUT_PREFERENCE\"|\"PRIMARY_INPUT_PREFERRED\",\n      \"SecondaryInputId\": \"string\"\n    },\n    \"InputAttachmentName\": \"string\",\n    \"InputId\": \"string\",\n    \"InputSettings\": {\n      \"AudioSelectors\": [\n        {\n          \"Name\": \"string\",\n          \"SelectorSettings\": {\n            \"AudioHlsRenditionSelection\": {\n              \"GroupId\": \"string\",\n              \"Name\": \"string\"\n            },\n            \"AudioLanguageSelection\": {\n              \"LanguageCode\": \"string\",\n              \"LanguageSelectionPolicy\": \"LOOSE\"|\"STRICT\"\n            },\n            \"AudioPidSelection\": {\n              \"Pid\": integer\n            },\n            \"AudioTrackSelection\": {\n              \"Tracks\": [\n                {\n                  \"Track\": integer\n                }\n                ...\n              ]\n            }\n          }\n        }\n        ...\n      ],\n      \"CaptionSelectors\": [\n        {\n          \"LanguageCode\": \"string\",\n          \"Name\": \"string\",\n          \"SelectorSettings\": {\n            \"AncillarySourceSettings\": {\n              \"SourceAncillaryChannelNumber\": integer\n            },\n            \"AribSourceSettings\": {\n\n            },\n            \"DvbSubSourceSettings\": {\n              \"OcrLanguage\": \"DEU\"|\"ENG\"|\"FRA\"|\"NLD\"|\"POR\"|\"SPA\",\n              \"Pid\": integer\n            },\n            \"EmbeddedSourceSettings\": {\n              \"Convert608To708\": \"DISABLED\"|\"UPCONVERT\",\n              \"Scte20Detection\": \"AUTO\"|\"OFF\",\n              \"Source608ChannelNumber\": integer,\n              \"Source608TrackNumber\": integer\n            },\n            \"Scte20SourceSettings\": {\n              \"Convert608To708\": \"DISABLED\"|\"UPCONVERT\",\n              \"Source608ChannelNumber\": integer\n            },\n            \"Scte27SourceSettings\": {\n              \"OcrLanguage\": \"DEU\"|\"ENG\"|\"FRA\"|\"NLD\"|\"POR\"|\"SPA\",\n              \"Pid\": integer\n            },\n            \"TeletextSourceSettings\": {\n              \"OutputRectangle\": {\n                \"Height\": double,\n                \"LeftOffset\": double,\n                \"TopOffset\": double,\n                \"Width\": double\n              },\n              \"PageNumber\": \"string\"\n            }\n          }\n        }\n        ...\n      ],\n      \"DeblockFilter\": \"DISABLED\"|\"ENABLED\",\n      \"DenoiseFilter\": \"DISABLED\"|\"ENABLED\",\n      \"FilterStrength\": integer,\n      \"InputFilter\": \"AUTO\"|\"DISABLED\"|\"FORCED\",\n      \"NetworkInputSettings\": {\n        \"HlsInputSettings\": {\n          \"Bandwidth\": integer,\n          \"BufferSegments\": integer,\n          \"Retries\": integer,\n          \"RetryInterval\": integer,\n          \"Scte35Source\": \"MANIFEST\"|\"SEGMENTS\"\n        },\n        \"ServerValidation\": \"CHECK_CRYPTOGRAPHY_AND_VALIDATE_NAME\"|\"CHECK_CRYPTOGRAPHY_ONLY\"\n      },\n      \"Smpte2038DataPreference\": \"IGNORE\"|\"PREFER\",\n      \"SourceEndBehavior\": \"CONTINUE\"|\"LOOP\",\n      \"VideoSelector\": {\n        \"ColorSpace\": \"FOLLOW\"|\"HDR10\"|\"HLG_2020\"|\"REC_601\"|\"REC_709\",\n        \"ColorSpaceSettings\": {\n          \"Hdr10Settings\": {\n            \"MaxCll\": integer,\n            \"MaxFall\": integer\n          }\n        },\n        \"ColorSpaceUsage\": \"FALLBACK\"|\"FORCE\",\n        \"SelectorSettings\": {\n          \"VideoSelectorPid\": {\n            \"Pid\": integer\n          },\n          \"VideoSelectorProgramId\": {\n            \"ProgramId\": integer\n          }\n        }\n      }\n    }\n  }\n  ...\n]\n\n\n--input-specification (structure) Specification of network and file inputs for this channelCodec -> (string)\n\nInput codec\n\nMaximumBitrate -> (string)\n\nMaximum input bitrate, categorized coarsely\n\nResolution -> (string)\n\nInput resolution, categorized coarsely\n\nShorthand Syntax:\n\nCodec=string,MaximumBitrate=string,Resolution=string\n\n\nJSON Syntax:\n\n{\n  \"Codec\": \"MPEG2\"|\"AVC\"|\"HEVC\",\n  \"MaximumBitrate\": \"MAX_10_MBPS\"|\"MAX_20_MBPS\"|\"MAX_50_MBPS\",\n  \"Resolution\": \"SD\"|\"HD\"|\"UHD\"\n}\n\n\n--log-level (string) The log level to write to CloudWatch Logs.\n\nPossible values:\n\nERROR\n\nWARNING\n\nINFO\n\nDEBUG\n\nDISABLED\n\n--name (string) Name of channel.\n\n--request-id (string) Unique request ID to be specified. This is needed to prevent retries from creating multiple resources.\n\n--reserved (string) Deprecated field that’s only usable by whitelisted customers.\n\n--role-arn (string) An optional Amazon Resource Name (ARN) of the role to assume when running the Channel.\n\n--tags (map) A collection of key-value pairs.key -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--vpc (structure) Settings for the VPC outputsPublicAddressAllocationIds -> (list)\n\nList of public address allocation ids to associate with ENIs that will be created in Output VPC. Must specify one for SINGLE_PIPELINE, two for STANDARD channels\n\n(string)\n\nPlaceholder documentation for __string\n\nSecurityGroupIds -> (list)\n\nA list of up to 5 EC2 VPC security group IDs to attach to the Output VPC network interfaces. If none are specified then the VPC default security group will be used\n\n(string)\n\nPlaceholder documentation for __string\n\nSubnetIds -> (list)\n\nA list of VPC subnet IDs from the same VPC. If STANDARD channel, subnet IDs must be mapped to two unique availability zones (AZ).\n\n(string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nPublicAddressAllocationIds=string,string,SecurityGroupIds=string,string,SubnetIds=string,string\n\n\nJSON Syntax:\n\n{\n  \"PublicAddressAllocationIds\": [\"string\", ...],\n  \"SecurityGroupIds\": [\"string\", ...],\n  \"SubnetIds\": [\"string\", ...]\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nChannel -> (structure)\n\nPlaceholder documentation for Channel\n\nArn -> (string)\n\nThe unique arn of the channel.\n\nCdiInputSpecification -> (structure)\n\nSpecification of CDI inputs for this channel\n\nResolution -> (string)\n\nMaximum CDI input resolution\n\nChannelClass -> (string)\n\nThe class for this channel. STANDARD for a channel with two pipelines or SINGLE_PIPELINE for a channel with one pipeline.\n\nDestinations -> (list)\n\nA list of destinations of the channel. For UDP outputs, there is one destination per output. For other types (HLS, for example), there is one destination per packager.\n\n(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nEgressEndpoints -> (list)\n\nThe endpoints where outgoing connections initiate from\n\n(structure)\n\nPlaceholder documentation for ChannelEgressEndpoint\n\nSourceIp -> (string)\n\nPublic IP of where a channel’s output comes from\n\nEncoderSettings -> (structure)\n\nEncoder Settings\n\nAudioDescriptions -> (list)\n\nPlaceholder documentation for __listOfAudioDescription\n\n(structure)\n\nAudio Description\n\nAudioNormalizationSettings -> (structure)\n\nAdvanced audio normalization settings.\n\nAlgorithm -> (string)\n\nAudio normalization algorithm to use. itu17701 conforms to the CALM Act specification, itu17702 conforms to the EBU R-128 specification.\n\nAlgorithmControl -> (string)\n\nWhen set to correctAudio the output audio is corrected using the chosen algorithm. If set to measureOnly, the audio will be measured but not adjusted.\n\nTargetLkfs -> (double)\n\nTarget LKFS(loudness) to adjust volume to. If no value is entered, a default value will be used according to the chosen algorithm. The CALM Act (1770-1) recommends a target of -24 LKFS. The EBU R-128 specification (1770-2) recommends a target of -23 LKFS.\n\nAudioSelectorName -> (string)\n\nThe name of the AudioSelector used as the source for this AudioDescription.\n\nAudioType -> (string)\n\nApplies only if audioTypeControl is useConfigured. The values for audioType are defined in ISO-IEC 13818-1.\n\nAudioTypeControl -> (string)\n\nDetermines how audio type is determined. followInput: If the input contains an ISO 639 audioType, then that value is passed through to the output. If the input contains no ISO 639 audioType, the value in Audio Type is included in the output. useConfigured: The value in Audio Type is included in the output. Note that this field and audioType are both ignored if inputType is broadcasterMixedAd.\n\nAudioWatermarkingSettings -> (structure)\n\nSettings to configure one or more solutions that insert audio watermarks in the audio encode\n\nNielsenWatermarksSettings -> (structure)\n\nSettings to configure Nielsen Watermarks in the audio encode\n\nNielsenCbetSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen CBET\n\nCbetCheckDigitString -> (string)\n\nEnter the CBET check digits to use in the watermark.\n\nCbetStepaside -> (string)\n\nDetermines the method of CBET insertion mode when prior encoding is detected on the same layer.\n\nCsid -> (string)\n\nEnter the CBET Source ID (CSID) to use in the watermark\n\nNielsenDistributionType -> (string)\n\nChoose the distribution types that you want to assign to the watermarks: - PROGRAM_CONTENT - FINAL_DISTRIBUTOR\n\nNielsenNaesIiNwSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen NAES II (N2) and Nielsen NAES VI (NW).\n\nCheckDigitString -> (string)\n\nEnter the check digit string for the watermark\n\nSid -> (double)\n\nEnter the Nielsen Source ID (SID) to include in the watermark\n\nCodecSettings -> (structure)\n\nAudio codec settings.\n\nAacSettings -> (structure)\n\nAac Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid values depend on rate control mode and profile.\n\nCodingMode -> (string)\n\nMono, Stereo, or 5.1 channel layout. Valid values depend on rate control mode and profile. The adReceiverMix setting receives a stereo description plus control track and emits a mono AAC encode of the description track, with control data emitted in the PES header as per ETSI TS 101 154 Annex E.\n\nInputType -> (string)\n\nSet to “broadcasterMixedAd” when input contains pre-mixed main audio + AD (narration) as a stereo pair. The Audio Type field (audioType) will be set to 3, which signals to downstream systems that this stream contains “broadcaster mixed AD”. Note that the input received by the encoder must contain pre-mixed audio; the encoder does not perform the mixing. The values in audioTypeControl and audioType (in AudioDescription) are ignored when set to broadcasterMixedAd. Leave set to “normal” when input does not contain pre-mixed audio + AD.\n\nProfile -> (string)\n\nAAC Profile.\n\nRateControlMode -> (string)\n\nRate Control Mode.\n\nRawFormat -> (string)\n\nSets LATM / LOAS AAC output for raw containers.\n\nSampleRate -> (double)\n\nSample rate in Hz. Valid values depend on rate control mode and profile.\n\nSpec -> (string)\n\nUse MPEG-2 AAC audio instead of MPEG-4 AAC audio for raw or MPEG-2 Transport Stream containers.\n\nVbrQuality -> (string)\n\nVBR Quality Level - Only used if rateControlMode is VBR.\n\nAc3Settings -> (structure)\n\nAc3 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted AC-3 stream. See ATSC A/52-2012 for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital coding mode. Determines number of channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If excluded and input audio is Dolby Digital, dialnorm will be passed through.\n\nDrcProfile -> (string)\n\nIf set to filmStandard, adds dynamic range compression signaling to the output bitstream as defined in the Dolby Digital specification.\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid in codingMode32Lfe mode.\n\nMetadataControl -> (string)\n\nWhen set to “followInput”, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nEac3Settings -> (structure)\n\nEac3 Settings\n\nAttenuationControl -> (string)\n\nWhen set to attenuate3Db, applies a 3 dB attenuation to the surround channels. Only used for 3/2 coding mode.\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted E-AC-3 stream. See ATSC A/52-2012 (Annex E) for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital Plus coding mode. Determines number of channels.\n\nDcFilter -> (string)\n\nWhen set to enabled, activates a DC highpass filter for all input channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If blank and input audio is Dolby Digital Plus, dialnorm will be passed through.\n\nDrcLine -> (string)\n\nSets the Dolby dynamic range compression profile.\n\nDrcRf -> (string)\n\nSets the profile for heavy Dolby dynamic range compression, ensures that the instantaneous signal peaks do not exceed specified levels.\n\nLfeControl -> (string)\n\nWhen encoding 3/2 audio, setting to lfe enables the LFE channel\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid with codingMode32 coding mode.\n\nLoRoCenterMixLevel -> (double)\n\nLeft only/Right only center mix level. Only used for 3/2 coding mode.\n\nLoRoSurroundMixLevel -> (double)\n\nLeft only/Right only surround mix level. Only used for 3/2 coding mode.\n\nLtRtCenterMixLevel -> (double)\n\nLeft total/Right total center mix level. Only used for 3/2 coding mode.\n\nLtRtSurroundMixLevel -> (double)\n\nLeft total/Right total surround mix level. Only used for 3/2 coding mode.\n\nMetadataControl -> (string)\n\nWhen set to followInput, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nPassthroughControl -> (string)\n\nWhen set to whenPossible, input DD+ audio will be passed through if it is present on the input. This detection is dynamic over the life of the transcode. Inputs that alternate between DD+ and non-DD+ content will have a consistent DD+ output as the system alternates between passthrough and encoding.\n\nPhaseControl -> (string)\n\nWhen set to shift90Degrees, applies a 90-degree phase shift to the surround channels. Only used for 3/2 coding mode.\n\nStereoDownmix -> (string)\n\nStereo downmix preference. Only used for 3/2 coding mode.\n\nSurroundExMode -> (string)\n\nWhen encoding 3/2 audio, sets whether an extra center back surround channel is matrix encoded into the left and right surround channels.\n\nSurroundMode -> (string)\n\nWhen encoding 2/0 audio, sets whether Dolby Surround is matrix encoded into the two channels.\n\nMp2Settings -> (structure)\n\nMp2 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second.\n\nCodingMode -> (string)\n\nThe MPEG2 Audio coding mode. Valid values are codingMode10 (for mono) or codingMode20 (for stereo).\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nPassThroughSettings -> (structure)\n\nPass Through Settings\n\nWavSettings -> (structure)\n\nWav Settings\n\nBitDepth -> (double)\n\nBits per sample.\n\nCodingMode -> (string)\n\nThe audio coding mode for the WAV audio. The mode determines the number of channels in the audio.\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nLanguageCode -> (string)\n\nRFC 5646 language code representing the language of the audio output track. Only used if languageControlMode is useConfigured, or there is no ISO 639 language code specified in the input.\n\nLanguageCodeControl -> (string)\n\nChoosing followInput will cause the ISO 639 language code of the output to follow the ISO 639 language code of the input. The languageCode will be used when useConfigured is set, or when followInput is selected but there is no ISO 639 language code specified by the input.\n\nName -> (string)\n\nThe name of this AudioDescription. Outputs will use this name to uniquely identify this AudioDescription. Description names should be unique within this Live Event.\n\nRemixSettings -> (structure)\n\nSettings that control how input audio channels are remixed into the output audio channels.\n\nChannelMappings -> (list)\n\nMapping of input channels to output channels, with appropriate gain adjustments.\n\n(structure)\n\nAudio Channel Mapping\n\nInputChannelLevels -> (list)\n\nIndices and gain values for each input channel that should be remixed into this output channel.\n\n(structure)\n\nInput Channel Level\n\nGain -> (integer)\n\nRemixing value. Units are in dB and acceptable values are within the range from -60 (mute) and 6 dB.\n\nInputChannel -> (integer)\n\nThe index of the input channel used as a source.\n\nOutputChannel -> (integer)\n\nThe index of the output channel being produced.\n\nChannelsIn -> (integer)\n\nNumber of input channels to be used.\n\nChannelsOut -> (integer)\n\nNumber of output channels to be produced. Valid values: 1, 2, 4, 6, 8\n\nStreamName -> (string)\n\nUsed for MS Smooth and Apple HLS outputs. Indicates the name displayed by the player (eg. English, or Director Commentary).\n\nAvailBlanking -> (structure)\n\nSettings for ad avail blanking.\n\nAvailBlankingImage -> (structure)\n\nBlanking image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when insertion metadata is added.\n\nAvailConfiguration -> (structure)\n\nEvent-wide configuration settings for ad avail insertion.\n\nAvailSettings -> (structure)\n\nAd avail settings.\n\nScte35SpliceInsert -> (structure)\n\nScte35 Splice Insert\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nScte35TimeSignalApos -> (structure)\n\nScte35 Time Signal Apos\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nBlackoutSlate -> (structure)\n\nSettings for blackout slate.\n\nBlackoutSlateImage -> (structure)\n\nBlackout slate image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkEndBlackout -> (string)\n\nSetting to enabled causes the encoder to blackout the video, audio, and captions, and raise the “Network Blackout Image” slate when an SCTE104/35 Network End Segmentation Descriptor is encountered. The blackout will be lifted when the Network Start Segmentation Descriptor is encountered. The Network End and Network Start descriptors must contain a network ID that matches the value entered in “Network ID”.\n\nNetworkEndBlackoutImage -> (structure)\n\nPath to local file to use as Network End Blackout image. Image will be scaled to fill the entire output raster.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkId -> (string)\n\nProvides Network ID that matches EIDR ID format (e.g., “10.XXXX/XXXX-XXXX-XXXX-XXXX-XXXX-C”).\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when indicated by program metadata.\n\nCaptionDescriptions -> (list)\n\nSettings for caption decriptions\n\n(structure)\n\nCaption Description\n\nCaptionSelectorName -> (string)\n\nSpecifies which input caption selector to use as a caption source when generating output captions. This field should match a captionSelector name.\n\nDestinationSettings -> (structure)\n\nAdditional settings for captions destination that depend on the destination type.\n\nAribDestinationSettings -> (structure)\n\nArib Destination Settings\n\nBurnInDestinationSettings -> (structure)\n\nBurn In Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to ‘auto’ fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. All burn-in and DVB-Sub font settings must match.\n\nDvbSubDestinationSettings -> (structure)\n\nDvb Sub Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. This option is not valid for source captions that are STL or 608/embedded. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to auto fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nEbuTtDDestinationSettings -> (structure)\n\nEbu Tt DDestination Settings\n\nCopyrightHolder -> (string)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. Complete this field if you want to include the name of the copyright holder in the copyright metadata tag in the TTML\n\nFillLineGap -> (string)\n\nSpecifies how to handle the gap between the lines (in multi-line captions). - enabled: Fill with the captions background color (as specified in the input captions). - disabled: Leave the gap unfilled.\n\nFontFamily -> (string)\n\nSpecifies the font family to include in the font data attached to the EBU-TT captions. Valid only if styleControl is set to include. If you leave this field empty, the font family is set to “monospaced”. (If styleControl is set to exclude, the font family is always set to “monospaced”.) You specify only the font family. All other style information (color, bold, position and so on) is copied from the input captions. The size is always set to 100% to allow the downstream player to choose the size. - Enter a list of font families, as a comma-separated list of font names, in order of preference. The name can be a font family (such as “Arial”), or a generic font family (such as “serif”), or “default” (to let the downstream player choose the font). - Leave blank to set the family to “monospace”.\n\nStyleControl -> (string)\n\nSpecifies the style information (font color, font position, and so on) to include in the font data that is attached to the EBU-TT captions. - include: Take the style information (font color, font position, and so on) from the source captions and include that information in the font data attached to the EBU-TT captions. This option is valid only if the source captions are Embedded or Teletext. - exclude: In the font data attached to the EBU-TT captions, set the font family to “monospaced”. Do not include any other style information.\n\nEmbeddedDestinationSettings -> (structure)\n\nEmbedded Destination Settings\n\nEmbeddedPlusScte20DestinationSettings -> (structure)\n\nEmbedded Plus Scte20 Destination Settings\n\nRtmpCaptionInfoDestinationSettings -> (structure)\n\nRtmp Caption Info Destination Settings\n\nScte20PlusEmbeddedDestinationSettings -> (structure)\n\nScte20 Plus Embedded Destination Settings\n\nScte27DestinationSettings -> (structure)\n\nScte27 Destination Settings\n\nSmpteTtDestinationSettings -> (structure)\n\nSmpte Tt Destination Settings\n\nTeletextDestinationSettings -> (structure)\n\nTeletext Destination Settings\n\nTtmlDestinationSettings -> (structure)\n\nTtml Destination Settings\n\nStyleControl -> (string)\n\nWhen set to passthrough, passes through style and position information from a TTML-like input source (TTML, SMPTE-TT, CFF-TT) to the CFF-TT output or TTML output.\n\nWebvttDestinationSettings -> (structure)\n\nWebvtt Destination Settings\n\nStyleControl -> (string)\n\nControls whether the color and position of the source captions is passed through to the WebVTT output captions. PASSTHROUGH - Valid only if the source captions are EMBEDDED or TELETEXT. NO_STYLE_DATA - Don’t pass through the style. The output captions will not contain any font styling information.\n\nLanguageCode -> (string)\n\nISO 639-2 three-digit code: http://www.loc.gov/standards/iso639-2/\n\nLanguageDescription -> (string)\n\nHuman readable information to indicate captions available for players (eg. English, or Spanish).\n\nName -> (string)\n\nName of the caption description. Used to associate a caption description with an output. Names must be unique within an event.\n\nFeatureActivations -> (structure)\n\nFeature Activations\n\nInputPrepareScheduleActions -> (string)\n\nEnables the Input Prepare feature. You can create Input Prepare actions in the schedule only if this feature is enabled. If you disable the feature on an existing schedule, make sure that you first delete all input prepare actions from the schedule.\n\nGlobalConfiguration -> (structure)\n\nConfiguration settings that apply to the event as a whole.\n\nInitialAudioGain -> (integer)\n\nValue to set the initial audio gain for the Live Event.\n\nInputEndAction -> (string)\n\nIndicates the action to take when the current input completes (e.g. end-of-file). When switchAndLoopInputs is configured the encoder will restart at the beginning of the first input. When “none” is configured the encoder will transcode either black, a solid color, or a user specified slate images per the “Input Loss Behavior” configuration until the next input switch occurs (which is controlled through the Channel Schedule API).\n\nInputLossBehavior -> (structure)\n\nSettings for system actions when input is lost.\n\nBlackFrameMsec -> (integer)\n\nDocumentation update needed\n\nInputLossImageColor -> (string)\n\nWhen input loss image type is “color” this field specifies the color to use. Value: 6 hex characters representing the values of RGB.\n\nInputLossImageSlate -> (structure)\n\nWhen input loss image type is “slate” these fields specify the parameters for accessing the slate.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nInputLossImageType -> (string)\n\nIndicates whether to substitute a solid color or a slate into the output after input loss exceeds blackFrameMsec.\n\nRepeatFrameMsec -> (integer)\n\nDocumentation update needed\n\nOutputLockingMode -> (string)\n\nIndicates how MediaLive pipelines are synchronized. PIPELINE_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the other. EPOCH_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the Unix epoch.\n\nOutputTimingSource -> (string)\n\nIndicates whether the rate of frames emitted by the Live encoder should be paced by its system clock (which optionally may be locked to another source via NTP) or should be locked to the clock of the source that is providing the input stream.\n\nSupportLowFramerateInputs -> (string)\n\nAdjusts video input buffer for streams with very low video framerates. This is commonly set to enabled for music channels with less than one video frame per second.\n\nMotionGraphicsConfiguration -> (structure)\n\nSettings for motion graphics.\n\nMotionGraphicsInsertion -> (string)\n\nMotion Graphics Insertion\n\nMotionGraphicsSettings -> (structure)\n\nMotion Graphics Settings\n\nHtmlMotionGraphicsSettings -> (structure)\n\nHtml Motion Graphics Settings\n\nNielsenConfiguration -> (structure)\n\nNielsen configuration settings.\n\nDistributorId -> (string)\n\nEnter the Distributor ID assigned to your organization by Nielsen.\n\nNielsenPcmToId3Tagging -> (string)\n\nEnables Nielsen PCM to ID3 tagging\n\nOutputGroups -> (list)\n\nPlaceholder documentation for __listOfOutputGroup\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nName -> (string)\n\nCustom output group name optionally defined by the user. Only letters, numbers, and the underscore character allowed; only 32 characters allowed.\n\nOutputGroupSettings -> (structure)\n\nSettings associated with the output group.\n\nArchiveGroupSettings -> (structure)\n\nArchive Group Settings\n\nArchiveCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nArchiveS3Settings -> (structure)\n\nArchive S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nDestination -> (structure)\n\nA directory and base filename where archive files should be written.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRolloverInterval -> (integer)\n\nNumber of seconds to write to archive file before closing and starting a new one.\n\nFrameCaptureGroupSettings -> (structure)\n\nFrame Capture Group Settings\n\nDestination -> (structure)\n\nThe destination for the frame capture files. Either the URI for an Amazon S3 bucket and object, plus a file name prefix (for example, s3ssl://sportsDelivery/highlights/20180820/curling-) or the URI for a MediaStore container, plus a file name prefix (for example, mediastoressl://sportsDelivery/20180820/curling-). The final file names consist of the prefix from the destination field (for example, “curling-“) + name modifier + the counter (5 digits, starting from 00001) + extension (which is always .jpg). For example, curling-low.00001.jpg\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFrameCaptureCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nFrameCaptureS3Settings -> (structure)\n\nFrame Capture S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsGroupSettings -> (structure)\n\nHls Group Settings\n\nAdMarkers -> (list)\n\nChoose one or more ad marker types to pass SCTE35 signals through to this group of Apple HLS outputs.\n\n(string)\n\nHls Ad Markers\n\nBaseUrlContent -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlContent1 -> (string)\n\nOptional. One value per output group. This field is required only if you are completing Base URL content A, and the downstream system has notified you that the media files for pipeline 1 of all outputs are in a location different from the media files for pipeline 0.\n\nBaseUrlManifest -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlManifest1 -> (string)\n\nOptional. One value per output group. Complete this field only if you are completing Base URL manifest A, and the downstream system has notified you that the child manifest files for pipeline 1 of all outputs are in a location different from the child manifest files for pipeline 0.\n\nCaptionLanguageMappings -> (list)\n\nMapping of up to 4 caption channels to caption languages. Is only meaningful if captionLanguageSetting is set to “insert”.\n\n(structure)\n\nMaps a caption channel to an ISO 693-2 language code (http://www.loc.gov/standards/iso639-2), with an optional description.\n\nCaptionChannel -> (integer)\n\nThe closed caption channel being described by this CaptionLanguageMapping. Each channel mapping must have a unique channel number (maximum of 4)\n\nLanguageCode -> (string)\n\nThree character ISO 639-2 language code (see http://www.loc.gov/standards/iso639-2)\n\nLanguageDescription -> (string)\n\nTextual description of language\n\nCaptionLanguageSetting -> (string)\n\nApplies only to 608 Embedded output captions. insert: Include CLOSED-CAPTIONS lines in the manifest. Specify at least one language in the CC1 Language Code field. One CLOSED-CAPTION line is added for each Language Code you specify. Make sure to specify the languages in the order in which they appear in the original source (if the source is embedded format) or the order of the caption selectors (if the source is other than embedded). Otherwise, languages in the manifest will not match up properly with the output captions. none: Include CLOSED-CAPTIONS=NONE line in the manifest. omit: Omit any CLOSED-CAPTIONS line from the manifest.\n\nClientCache -> (string)\n\nWhen set to “disabled”, sets the #EXT-X-ALLOW-CACHE:no tag in the manifest, which prevents clients from saving media segments for later replay.\n\nCodecSpecification -> (string)\n\nSpecification to use (RFC-6381 or the default RFC-4281) during m3u8 playlist generation.\n\nConstantIv -> (string)\n\nFor use with encryptionType. This is a 128-bit, 16-byte hex value represented by a 32-character text string. If ivSource is set to “explicit” then this parameter is required and is used as the IV for encryption.\n\nDestination -> (structure)\n\nA directory or HTTP destination for the HLS segments, manifest files, and encryption keys (if enabled).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nDirectoryStructure -> (string)\n\nPlace segments in subdirectories.\n\nDiscontinuityTags -> (string)\n\nSpecifies whether to insert EXT-X-DISCONTINUITY tags in the HLS child manifests for this output group. Typically, choose Insert because these tags are required in the manifest (according to the HLS specification) and serve an important purpose. Choose Never Insert only if the downstream system is doing real-time failover (without using the MediaLive automatic failover feature) and only if that downstream system has advised you to exclude the tags.\n\nEncryptionType -> (string)\n\nEncrypts the segments with the given encryption scheme. Exclude this parameter if no encryption is desired.\n\nHlsCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nHlsAkamaiSettings -> (structure)\n\nHls Akamai Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to Akamai. User should contact Akamai to enable this feature.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nSalt -> (string)\n\nSalt for authenticated Akamai.\n\nToken -> (string)\n\nToken parameter for authenticated akamai. If not specified, _gda_ is used.\n\nHlsBasicPutSettings -> (structure)\n\nHls Basic Put Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsMediaStoreSettings -> (structure)\n\nHls Media Store Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nMediaStoreStorageClass -> (string)\n\nWhen set to temporal, output files are stored in non-persistent memory for faster reading and writing.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsS3Settings -> (structure)\n\nHls S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsWebdavSettings -> (structure)\n\nHls Webdav Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to WebDAV.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsId3SegmentTagging -> (string)\n\nState of HLS ID3 Segment Tagging\n\nIFrameOnlyPlaylists -> (string)\n\nDISABLED: Do not create an I-frame-only manifest, but do create the master and media manifests (according to the Output Selection field). STANDARD: Create an I-frame-only manifest for each output that contains video, as well as the other manifests (according to the Output Selection field). The I-frame manifest contains a #EXT-X-I-FRAMES-ONLY tag to indicate it is I-frame only, and one or more #EXT-X-BYTERANGE entries identifying the I-frame position. For example, #EXT-X-BYTERANGE:160364@1461888”\n\nIncompleteSegmentBehavior -> (string)\n\nSpecifies whether to include the final (incomplete) segment in the media output when the pipeline stops producing output because of a channel stop, a channel pause or a loss of input to the pipeline. Auto means that MediaLive decides whether to include the final segment, depending on the channel class and the types of output groups. Suppress means to never include the incomplete segment. We recommend you choose Auto and let MediaLive control the behavior.\n\nIndexNSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the maximum number of segments in the media manifest file. After this maximum, older segments are removed from the media manifest. This number must be smaller than the number in the Keep Segments field.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nIvInManifest -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If set to “include”, IV is listed in the manifest, otherwise the IV is not in the manifest.\n\nIvSource -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If this setting is “followsSegmentNumber”, it will cause the IV to change every segment (to match the segment number). If this is set to “explicit”, you must enter a constantIv value.\n\nKeepSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the number of media segments to retain in the destination directory. This number should be bigger than indexNSegments (Num segments). We recommend (value = (2 x indexNsegments) + 1). If this “keep segments” number is too low, the following might happen: the player is still reading a media manifest file that lists this segment, but that segment has been removed from the destination directory (as directed by indexNSegments). This situation would result in a 404 HTTP error on the player.\n\nKeyFormat -> (string)\n\nThe value specifies how the key is represented in the resource identified by the URI. If parameter is absent, an implicit value of “identity” is used. A reverse DNS string can also be given.\n\nKeyFormatVersions -> (string)\n\nEither a single positive integer version value or a slash delimited list of version values (1/2/3).\n\nKeyProviderSettings -> (structure)\n\nThe key provider settings.\n\nStaticKeySettings -> (structure)\n\nStatic Key Settings\n\nKeyProviderServer -> (structure)\n\nThe URL of the license server used for protecting content.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nStaticKeyValue -> (string)\n\nStatic key value as a 32 character hexadecimal string.\n\nManifestCompression -> (string)\n\nWhen set to gzip, compresses HLS playlist.\n\nManifestDurationFormat -> (string)\n\nIndicates whether the output manifest should use floating point or integer values for segment duration.\n\nMinSegmentLength -> (integer)\n\nWhen set, minimumSegmentLength is enforced by looking ahead and back within the specified range for a nearby avail and extending the segment size if needed.\n\nMode -> (string)\n\nIf “vod”, all segments are indexed and kept permanently in the destination and manifest. If “live”, only the number segments specified in keepSegments and indexNSegments are kept; newer segments replace older segments, which may prevent players from rewinding all the way to the beginning of the event. VOD mode uses HLS EXT-X-PLAYLIST-TYPE of EVENT while the channel is running, converting it to a “VOD” type manifest on completion of the stream.\n\nOutputSelection -> (string)\n\nMANIFESTS_AND_SEGMENTS: Generates manifests (master manifest, if applicable, and media manifests) for this output group. VARIANT_MANIFESTS_AND_SEGMENTS: Generates media manifests for this output group, but not a master manifest. SEGMENTS_ONLY: Does not generate any manifests for this output group.\n\nProgramDateTime -> (string)\n\nIncludes or excludes EXT-X-PROGRAM-DATE-TIME tag in .m3u8 manifest files. The value is calculated as follows: either the program date and time are initialized using the input timecode source, or the time is initialized using the input timecode source and the date is initialized using the timestampOffset.\n\nProgramDateTimePeriod -> (integer)\n\nPeriod of insertion of EXT-X-PROGRAM-DATE-TIME entry, in seconds.\n\nRedundantManifest -> (string)\n\nENABLED: The master manifest (.m3u8 file) for each pipeline includes information about both pipelines: first its own media files, then the media files of the other pipeline. This feature allows playout device that support stale manifest detection to switch from one manifest to the other, when the current manifest seems to be stale. There are still two destinations and two master manifests, but both master manifests reference the media files from both pipelines. DISABLED: The master manifest (.m3u8 file) for each pipeline includes information about its own pipeline only. For an HLS output group with MediaPackage as the destination, the DISABLED behavior is always followed. MediaPackage regenerates the manifests it serves to players so a redundant manifest from MediaLive is irrelevant.\n\nSegmentLength -> (integer)\n\nLength of MPEG-2 Transport Stream segments to create (in seconds). Note that segments will end on the next keyframe after this number of seconds, so actual segment length may be longer.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSegmentsPerSubdirectory -> (integer)\n\nNumber of segments to write to a subdirectory before starting a new one. directoryStructure must be subdirectoryPerStream for this setting to have an effect.\n\nStreamInfResolution -> (string)\n\nInclude or exclude RESOLUTION attribute for video in EXT-X-STREAM-INF tag of variant manifest.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nTimestampDeltaMilliseconds -> (integer)\n\nProvides an extra millisecond delta offset to fine tune the timestamps.\n\nTsFileMode -> (string)\n\nSEGMENTED_FILES: Emit the program as segments - multiple .ts media files. SINGLE_FILE: Applies only if Mode field is VOD. Emit the program as a single .ts media file. The media manifest includes #EXT-X-BYTERANGE tags to index segments for playback. A typical use for this value is when sending the output to AWS Elemental MediaConvert, which can accept only a single media file. Playback while the channel is running is not guaranteed due to HTTP server caching.\n\nMediaPackageGroupSettings -> (structure)\n\nMedia Package Group Settings\n\nDestination -> (structure)\n\nMediaPackage channel destination.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nMsSmoothGroupSettings -> (structure)\n\nMs Smooth Group Settings\n\nAcquisitionPointId -> (string)\n\nThe ID to include in each message in the sparse track. Ignored if sparseTrackType is NONE.\n\nAudioOnlyTimecodeControl -> (string)\n\nIf set to passthrough for an audio-only MS Smooth output, the fragment absolute time will be set to the current timecode. This option does not write timecodes to the audio elementary stream.\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the https certificate chain to a trusted Certificate Authority (CA). This will cause https outputs to self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the IIS server if the connection is lost. Content will be cached during this time and the cache will be be delivered to the IIS server once the connection is re-established.\n\nDestination -> (structure)\n\nSmooth Streaming publish point on an IIS server. Elemental Live acts as a “Push” encoder to IIS.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nEventId -> (string)\n\nMS Smooth event ID to be sent to the IIS server. Should only be specified if eventIdMode is set to useConfigured.\n\nEventIdMode -> (string)\n\nSpecifies whether or not to send an event ID to the IIS server. If no event ID is sent and the same Live Event is used without changing the publishing point, clients might see cached video from the previous run. Options: - “useConfigured” - use the value provided in eventId - “useTimestamp” - generate and send an event ID based on the current timestamp - “noEventId” - do not send an event ID to the IIS server.\n\nEventStopBehavior -> (string)\n\nWhen set to sendEos, send EOS signal to IIS server when stopping the event\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nFragmentLength -> (integer)\n\nLength of mp4 fragments to generate (in seconds). Fragment length must be compatible with GOP size and framerate.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nRestartDelay -> (integer)\n\nNumber of seconds before initiating a restart due to output failure, due to exhausting the numRetries on one segment, or exceeding filecacheDuration.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSendDelayMs -> (integer)\n\nNumber of milliseconds to delay the output from the second pipeline.\n\nSparseTrackType -> (string)\n\nIdentifies the type of data to place in the sparse track: - SCTE35: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame to start a new segment. - SCTE35_WITHOUT_SEGMENTATION: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame but don’t start a new segment. - NONE: Don’t generate a sparse track for any outputs in this output group.\n\nStreamManifestBehavior -> (string)\n\nWhen set to send, send stream manifest so publishing point doesn’t start until all streams start.\n\nTimestampOffset -> (string)\n\nTimestamp offset for the event. Only used if timestampOffsetMode is set to useConfiguredOffset.\n\nTimestampOffsetMode -> (string)\n\nType of timestamp date offset to use. - useEventStartDate: Use the date the event was started as the offset - useConfiguredOffset: Use an explicitly configured date as the offset\n\nMultiplexGroupSettings -> (structure)\n\nMultiplex Group Settings\n\nRtmpGroupSettings -> (structure)\n\nRtmp Group Settings\n\nAdMarkers -> (list)\n\nChoose the ad marker type for this output group. MediaLive will create a message based on the content of each SCTE-35 message, format it for that marker type, and insert it in the datastream.\n\n(string)\n\nRtmp Ad Markers\n\nAuthenticationScheme -> (string)\n\nAuthentication scheme to use when connecting with CDN\n\nCacheFullBehavior -> (string)\n\nControls behavior when content cache fills up. If remote origin server stalls the RTMP connection and does not accept content fast enough the ‘Media Cache’ will fill up. When the cache reaches the duration specified by cacheLength the cache will stop accepting new content. If set to disconnectImmediately, the RTMP output will force a disconnect. Clear the media cache, and reconnect after restartDelay seconds. If set to waitForServer, the RTMP output will wait up to 5 minutes to allow the origin server to begin accepting data again.\n\nCacheLength -> (integer)\n\nCache length, in seconds, is used to calculate buffer size.\n\nCaptionData -> (string)\n\nControls the types of data that passes to onCaptionInfo outputs. If set to ‘all’ then 608 and 708 carried DTVCC data will be passed. If set to ‘field1AndField2608’ then DTVCC data will be stripped out, but 608 data from both fields will be passed. If set to ‘field1608’ then only the data carried in 608 from field 1 video will be passed.\n\nInputLossAction -> (string)\n\nControls the behavior of this RTMP group if input becomes unavailable. - emitOutput: Emit a slate until input returns. - pauseOutput: Stop transmitting data until input returns. This does not close the underlying RTMP connection.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nUdpGroupSettings -> (structure)\n\nUdp Group Settings\n\nInputLossAction -> (string)\n\nSpecifies behavior of last resort when input video is lost, and no more backup inputs are available. When dropTs is selected the entire transport stream will stop being emitted. When dropProgram is selected the program can be dropped from the transport stream (and replaced with null packets to meet the TS bitrate requirement). Or, when emitProgram is chosen the transport stream will continue to be produced normally with repeat frames, black frames, or slate frames substituted for the absent input video.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nOutputs -> (list)\n\nPlaceholder documentation for __listOfOutput\n\n(structure)\n\nOutput settings. There can be multiple outputs within a group.\n\nAudioDescriptionNames -> (list)\n\nThe names of the AudioDescriptions used as audio sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nCaptionDescriptionNames -> (list)\n\nThe names of the CaptionDescriptions used as caption sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nOutputName -> (string)\n\nThe name used to identify an output.\n\nOutputSettings -> (structure)\n\nOutput type-specific settings.\n\nArchiveOutputSettings -> (structure)\n\nArchive Output Settings\n\nContainerSettings -> (structure)\n\nSettings specific to the container type of the file.\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nRawSettings -> (structure)\n\nRaw Settings\n\nExtension -> (string)\n\nOutput file extension. If excluded, this will be auto-selected from the container type.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nFrameCaptureOutputSettings -> (structure)\n\nFrame Capture Output Settings\n\nNameModifier -> (string)\n\nRequired if the output group contains more than one output. This modifier forms part of the output file name.\n\nHlsOutputSettings -> (structure)\n\nHls Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nHlsSettings -> (structure)\n\nSettings regarding the underlying stream. These settings are different for audio-only outputs.\n\nAudioOnlyHlsSettings -> (structure)\n\nAudio Only Hls Settings\n\nAudioGroupId -> (string)\n\nSpecifies the group to which the audio Rendition belongs.\n\nAudioOnlyImage -> (structure)\n\nOptional. Specifies the .jpg or .png image to use as the cover art for an audio-only output. We recommend a low bit-size file because the image increases the output audio bandwidth. The image is attached to the audio as an ID3 tag, frame type APIC, picture type 0x10, as per the “ID3 tag version 2.4.0 - Native Frames” standard.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nAudioTrackType -> (string)\n\nFour types of audio-only tracks are supported: Audio-Only Variant Stream The client can play back this audio-only stream instead of video in low-bandwidth scenarios. Represented as an EXT-X-STREAM-INF in the HLS manifest. Alternate Audio, Auto Select, Default Alternate rendition that the client should try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=YES, AUTOSELECT=YES Alternate Audio, Auto Select, Not Default Alternate rendition that the client may try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=YES Alternate Audio, not Auto Select Alternate rendition that the client will not try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=NO\n\nSegmentType -> (string)\n\nSpecifies the segment type.\n\nFmp4HlsSettings -> (structure)\n\nFmp4 Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nFrameCaptureHlsSettings -> (structure)\n\nFrame Capture Hls Settings\n\nStandardHlsSettings -> (structure)\n\nStandard Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nM3u8Settings -> (structure)\n\nSettings information for the .m3u8 container\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values.\n\nEcmPid -> (string)\n\nThis parameter is unused and deprecated.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock References (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value.\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nScte35Behavior -> (string)\n\nIf set to passthrough, passes any SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Accepts “Format Identifiers”:#formatIdentifierParameters.\n\nSegmentModifier -> (string)\n\nString concatenated to end of segment filenames.\n\nMediaPackageOutputSettings -> (structure)\n\nMedia Package Output Settings\n\nMsSmoothOutputSettings -> (structure)\n\nMs Smooth Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nMultiplexOutputSettings -> (structure)\n\nMultiplex Output Settings\n\nDestination -> (structure)\n\nDestination is a Multiplex.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRtmpOutputSettings -> (structure)\n\nRtmp Output Settings\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the tls certificate chain to a trusted Certificate Authority (CA). This will cause rtmps outputs with self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying a connection to the Flash Media server if the connection is lost.\n\nDestination -> (structure)\n\nThe RTMP endpoint excluding the stream name (eg. rtmp://host/appname). For connection to Akamai, a username and password must be supplied. URI fields accept format identifiers.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nUdpOutputSettings -> (structure)\n\nUdp Output Settings\n\nBufferMsec -> (integer)\n\nUDP output buffering in milliseconds. Larger values increase latency through the transcoder but simultaneously assist the transcoder in maintaining a constant, low-jitter UDP/RTP output while accommodating clock recovery, input switching, input disruptions, picture reordering, etc.\n\nContainerSettings -> (structure)\n\nUdp Container Settings\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nDestination -> (structure)\n\nDestination address and port number for RTP or UDP packets. Can be unicast or multicast RTP or UDP (eg. rtp://239.10.10.10:5001 or udp://10.100.100.100:5002).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFecOutputSettings -> (structure)\n\nSettings for enabling and adjusting Forward Error Correction on UDP outputs.\n\nColumnDepth -> (integer)\n\nParameter D from SMPTE 2022-1. The height of the FEC protection matrix. The number of transport stream packets per column error correction packet. Must be between 4 and 20, inclusive.\n\nIncludeFec -> (string)\n\nEnables column only or column and row based FEC\n\nRowLength -> (integer)\n\nParameter L from SMPTE 2022-1. The width of the FEC protection matrix. Must be between 1 and 20, inclusive. If only Column FEC is used, then larger values increase robustness. If Row FEC is used, then this is the number of transport stream packets per row error correction packet, and the value must be between 4 and 20, inclusive, if includeFec is columnAndRow. If includeFec is column, this value must be 1 to 20, inclusive.\n\nVideoDescriptionName -> (string)\n\nThe name of the VideoDescription used as the source for this output.\n\nTimecodeConfig -> (structure)\n\nContains settings used to acquire and adjust timecode information from inputs.\n\nSource -> (string)\n\nIdentifies the source for the timecode that will be associated with the events outputs. -Embedded (embedded): Initialize the output timecode with timecode from the the source. If no embedded timecode is detected in the source, the system falls back to using “Start at 0” (zerobased). -System Clock (systemclock): Use the UTC time. -Start at 0 (zerobased): The time of the first frame of the event will be 00:00:00:00.\n\nSyncThreshold -> (integer)\n\nThreshold in frames beyond which output timecode is resynchronized to the input timecode. Discrepancies below this threshold are permitted to avoid unnecessary discontinuities in the output timecode. No timecode sync when this is not specified.\n\nVideoDescriptions -> (list)\n\nPlaceholder documentation for __listOfVideoDescription\n\n(structure)\n\nVideo settings for this stream.\n\nCodecSettings -> (structure)\n\nVideo codec settings.\n\nFrameCaptureSettings -> (structure)\n\nFrame Capture Settings\n\nCaptureInterval -> (integer)\n\nThe frequency at which to capture frames for inclusion in the output. May be specified in either seconds or milliseconds, as specified by captureIntervalUnits.\n\nCaptureIntervalUnits -> (string)\n\nUnit for the frame capture interval.\n\nH264Settings -> (structure)\n\nH264 Settings\n\nAdaptiveQuantization -> (string)\n\nEnables or disables adaptive quantization, which is a technique MediaLive can apply to video on a frame-by-frame basis to produce more compression without losing quality. There are three types of adaptive quantization: flicker, spatial, and temporal. Set the field in one of these ways: Set to Auto. Recommended. For each type of AQ, MediaLive will determine if AQ is needed, and if so, the appropriate strength. Set a strength (a value other than Auto or Disable). This strength will apply to any of the AQ fields that you choose to enable. Set to Disabled to disable all types of adaptive quantization.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufFillPct -> (integer)\n\nPercentage of the buffer that should initially be filled (HRD buffer model).\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nEntropyEncoding -> (string)\n\nEntropy encoding mode. Use cabac (must be in Main or High profile) or cavlc.\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nFlicker AQ makes adjustments within each frame to reduce flicker or ‘pop’ on I-frames. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if flicker AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply flicker AQ using the specified strength. Disabled: MediaLive won’t apply flicker AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply flicker AQ.\n\nForceFieldPictures -> (string)\n\nThis setting applies only when scan type is “interlaced.” It controls whether coding is performed on a field basis or on a frame basis. (When the video is progressive, the coding is always performed on a frame basis.) enabled: Force MediaLive to code on a field basis, so that odd and even sets of fields are coded separately. disabled: Code the two sets of fields separately (on a field basis) or together (on a frame basis using PAFF), depending on what is most appropriate for the content.\n\nFramerateControl -> (string)\n\nThis field indicates how the output video frame rate is specified. If “specified” is selected then the output video frame rate is determined by framerateNumerator and framerateDenominator, else if “initializeFromSource” is selected then the output video frame rate will be set equal to the input video frame rate of the first input.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopBReference -> (string)\n\nDocumentation update needed\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopNumBFrames -> (integer)\n\nNumber of B-frames between reference frames.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.264 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level For VBR: Set the maximum bitrate in order to accommodate expected spikes in the complexity of the video.\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nNumRefFrames -> (integer)\n\nNumber of reference frames to use. The encoder may use more than requested if using B-frames and/or interlaced encoding.\n\nParControl -> (string)\n\nThis field indicates how the output pixel aspect ratio is specified. If “specified” is selected then the output video pixel aspect ratio is determined by parNumerator and parDenominator, else if “initializeFromSource” is selected then the output pixsel aspect ratio will be set equal to the input video pixel aspect ratio of the first input.\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.264 Profile.\n\nQualityLevel -> (string)\n\nLeave as STANDARD_QUALITY or choose a different value (which might result in additional costs to run the channel). - ENHANCED_QUALITY: Produces a slightly better video quality without an increase in the bitrate. Has an effect only when the Rate control mode is QVBR or CBR. If this channel is in a MediaLive multiplex, the value must be ENHANCED_QUALITY. - STANDARD_QUALITY: Valid for any Rate control mode.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. You can set a target quality or you can let MediaLive determine the best quality. To set a target quality, enter values in the QVBR quality level field and the Max bitrate field. Enter values that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M To let MediaLive decide, leave the QVBR quality level field empty, and in Max bitrate enter the maximum rate you want in the video. For more information, see the section called “Video - rate control mode” in the MediaLive user guide\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. VBR: Quality and bitrate vary, depending on the video complexity. Recommended instead of QVBR if you want to maintain a specific average bitrate over the duration of the channel. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection. - On: inserts I-frames when scene change is detected. - Off: does not force an I-frame when scene change is detected.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nSoftness -> (integer)\n\nSoftness. Selects quantizer matrix, larger values reduce high-frequency content in the encoded image. If not set to zero, must be greater than 15.\n\nSpatialAq -> (string)\n\nSpatial AQ makes adjustments within each frame based on spatial variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if spatial AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply spatial AQ using the specified strength. Disabled: MediaLive won’t apply spatial AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply spatial AQ.\n\nSubgopLength -> (string)\n\nIf set to fixed, use gopNumBFrames B-frames per sub-GOP. If set to dynamic, optimize the number of B-frames used for each sub-GOP to improve visual quality.\n\nSyntax -> (string)\n\nProduces a bitstream compliant with SMPTE RP-2027.\n\nTemporalAq -> (string)\n\nTemporal makes adjustments within each frame based on temporal variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if temporal AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply temporal AQ using the specified strength. Disabled: MediaLive won’t apply temporal AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply temporal AQ.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nH265Settings -> (structure)\n\nH265 Settings\n\nAdaptiveQuantization -> (string)\n\nAdaptive quantization. Allows intra-frame quantizers to vary to improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nAlternativeTransferFunction -> (string)\n\nWhether or not EML should insert an Alternative Transfer Function SEI message to support backwards compatibility with non-HDR decoders and displays.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nIf set to enabled, adjust quantization within each frame to reduce flicker or ‘pop’ on I-frames.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.265 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.265 Profile.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. Set values for the QVBR quality level field and Max bitrate field that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nTier -> (string)\n\nH.265 Tier.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nMpeg2Settings -> (structure)\n\nMpeg2 Settings\n\nAdaptiveQuantization -> (string)\n\nChoose Off to disable adaptive quantization. Or choose another value to enable the quantizer and set its strength. The strengths are: Auto, Off, Low, Medium, High. When you enable this field, MediaLive allows intra-frame quantizers to vary, which might improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates the AFD values that MediaLive will write into the video encode. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose AUTO. AUTO: MediaLive will try to preserve the input AFD value (in cases where multiple AFD values are valid). FIXED: MediaLive will use the value you specify in fixedAFD.\n\nColorMetadata -> (string)\n\nSpecifies whether to include the color space metadata. The metadata describes the color space that applies to the video (the colorSpace field). We recommend that you insert the metadata.\n\nColorSpace -> (string)\n\nChoose the type of color space conversion to apply to the output. For detailed information on setting up both the input and the output to obtain the desired color space in the output, see the section on “MediaLive Features - Video - color space” in the MediaLive User Guide. PASSTHROUGH: Keep the color space of the input content - do not convert it. AUTO:Convert all content that is SD to rec 601, and convert all content that is HD to rec 709.\n\nDisplayAspectRatio -> (string)\n\nSets the pixel aspect ratio for the encode.\n\nFilterSettings -> (structure)\n\nOptionally specify a noise reduction filter, which can improve quality of compressed content. If you do not choose a filter, no filter will be applied. TEMPORAL: This filter is useful for both source content that is noisy (when it has excessive digital artifacts) and source content that is clean. When the content is noisy, the filter cleans up the source content before the encoding phase, with these two effects: First, it improves the output video quality because the content has been cleaned up. Secondly, it decreases the bandwidth because MediaLive does not waste bits on encoding noise. When the content is reasonably clean, the filter tends to decrease the bitrate.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nComplete this field only when afdSignaling is set to FIXED. Enter the AFD value (4 bits) to write on all frames of the video encode.\n\nFramerateDenominator -> (integer)\n\ndescription”: “The framerate denominator. For example, 1001. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nFramerateNumerator -> (integer)\n\nThe framerate numerator. For example, 24000. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nGopClosedCadence -> (integer)\n\nMPEG2: default is open GOP.\n\nGopNumBFrames -> (integer)\n\nRelates to the GOP structure. The number of B-frames between reference frames. If you do not know what a B-frame is, use the default.\n\nGopSize -> (double)\n\nRelates to the GOP structure. The GOP size (keyframe interval) in the units specified in gopSizeUnits. If you do not know what GOP is, use the default. If gopSizeUnits is frames, then the gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, the gopSize must be greater than 0, but does not need to be an integer.\n\nGopSizeUnits -> (string)\n\nRelates to the GOP structure. Specifies whether the gopSize is specified in frames or seconds. If you do not plan to change the default gopSize, leave the default. If you specify SECONDS, MediaLive will internally convert the gop size to a frame count.\n\nScanType -> (string)\n\nSet the scan type of the output to PROGRESSIVE or INTERLACED (top field first).\n\nSubgopLength -> (string)\n\nRelates to the GOP structure. If you do not know what GOP is, use the default. FIXED: Set the number of B-frames in each sub-GOP to the value in gopNumBFrames. DYNAMIC: Let MediaLive optimize the number of B-frames in each sub-GOP, to improve visual quality.\n\nTimecodeInsertion -> (string)\n\nDetermines how MediaLive inserts timecodes in the output video. For detailed information about setting up the input and the output for a timecode, see the section on “MediaLive Features - Timecode configuration” in the MediaLive User Guide. DISABLED: do not include timecodes. GOP_TIMECODE: Include timecode metadata in the GOP header.\n\nHeight -> (integer)\n\nOutput video height, in pixels. Must be an even number. For most codecs, you can leave this field and width blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nName -> (string)\n\nThe name of this VideoDescription. Outputs will use this name to uniquely identify this Description. Description names should be unique within this Live Event.\n\nRespondToAfd -> (string)\n\nIndicates how MediaLive will respond to the AFD values that might be in the input video. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose PASSTHROUGH. RESPOND: MediaLive clips the input video using a formula that uses the AFD values (configured in afdSignaling ), the input display aspect ratio, and the output display aspect ratio. MediaLive also includes the AFD values in the output, unless the codec for this encode is FRAME_CAPTURE. PASSTHROUGH: MediaLive ignores the AFD values and does not clip the video. But MediaLive does include the values in the output. NONE: MediaLive does not clip the input video and does not include the AFD values in the output\n\nScalingBehavior -> (string)\n\nSTRETCH_TO_OUTPUT configures the output position to stretch the video to the specified output resolution (height and width). This option will override any position value. DEFAULT may insert black boxes (pillar boxes or letter boxes) around the video to provide the specified output resolution.\n\nSharpness -> (integer)\n\nChanges the strength of the anti-alias filter used for scaling. 0 is the softest setting, 100 is the sharpest. A setting of 50 is recommended for most content.\n\nWidth -> (integer)\n\nOutput video width, in pixels. Must be an even number. For most codecs, you can leave this field and height blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nId -> (string)\n\nThe unique id of the channel.\n\nInputAttachments -> (list)\n\nList of input attachments for channel.\n\n(structure)\n\nPlaceholder documentation for InputAttachment\n\nAutomaticInputFailoverSettings -> (structure)\n\nUser-specified settings for defining what the conditions are for declaring the input unhealthy and failing over to a different input.\n\nErrorClearTimeMsec -> (integer)\n\nThis clear time defines the requirement a recovered input must meet to be considered healthy. The input must have no failover conditions for this length of time. Enter a time in milliseconds. This value is particularly important if the input_preference for the failover pair is set to PRIMARY_INPUT_PREFERRED, because after this time, MediaLive will switch back to the primary input.\n\nFailoverConditions -> (list)\n\nA list of failover conditions. If any of these conditions occur, MediaLive will perform a failover to the other input.\n\n(structure)\n\nFailover Condition settings. There can be multiple failover conditions inside AutomaticInputFailoverSettings.\n\nFailoverConditionSettings -> (structure)\n\nFailover condition type-specific settings.\n\nAudioSilenceSettings -> (structure)\n\nMediaLive will perform a failover if the specified audio selector is silent for the specified period.\n\nAudioSelectorName -> (string)\n\nThe name of the audio selector in the input that MediaLive should monitor to detect silence. Select your most important rendition. If you didn’t create an audio selector in this input, leave blank.\n\nAudioSilenceThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be silent before automatic input failover occurs. Silence is defined as audio loss or audio quieter than -50 dBFS.\n\nInputLossSettings -> (structure)\n\nMediaLive will perform a failover if content is not detected in this input for the specified period.\n\nInputLossThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that no input is detected. After that time, an input failover will occur.\n\nVideoBlackSettings -> (structure)\n\nMediaLive will perform a failover if content is considered black for the specified period.\n\nBlackDetectThreshold -> (double)\n\nA value used in calculating the threshold below which MediaLive considers a pixel to be ‘black’. For the input to be considered black, every pixel in a frame must be below this threshold. The threshold is calculated as a percentage (expressed as a decimal) of white. Therefore .1 means 10% white (or 90% black). Note how the formula works for any color depth. For example, if you set this field to 0.1 in 10-bit color depth: (1023*0.1=102.3), which means a pixel value of 102 or less is ‘black’. If you set this field to .1 in an 8-bit color depth: (255*0.1=25.5), which means a pixel value of 25 or less is ‘black’. The range is 0.0 to 1.0, with any number of decimal places.\n\nVideoBlackThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be black before automatic input failover occurs.\n\nInputPreference -> (string)\n\nInput preference when deciding which input to make active when a previously failed input has recovered.\n\nSecondaryInputId -> (string)\n\nThe input ID of the secondary input in the automatic input failover pair.\n\nInputAttachmentName -> (string)\n\nUser-specified name for the attachment. This is required if the user wants to use this input in an input switch action.\n\nInputId -> (string)\n\nThe ID of the input\n\nInputSettings -> (structure)\n\nSettings of an input (caption selector, etc.)\n\nAudioSelectors -> (list)\n\nUsed to select the audio stream to decode for inputs that have multiple available.\n\n(structure)\n\nAudio Selector\n\nName -> (string)\n\nThe name of this AudioSelector. AudioDescriptions will use this name to uniquely identify this Selector. Selector names should be unique per input.\n\nSelectorSettings -> (structure)\n\nThe audio selector settings.\n\nAudioHlsRenditionSelection -> (structure)\n\nAudio Hls Rendition Selection\n\nGroupId -> (string)\n\nSpecifies the GROUP-ID in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nName -> (string)\n\nSpecifies the NAME in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nAudioLanguageSelection -> (structure)\n\nAudio Language Selection\n\nLanguageCode -> (string)\n\nSelects a specific three-letter language code from within an audio source.\n\nLanguageSelectionPolicy -> (string)\n\nWhen set to “strict”, the transport stream demux strictly identifies audio streams by their language descriptor. If a PMT update occurs such that an audio stream matching the initially selected language is no longer present then mute will be encoded until the language returns. If “loose”, then on a PMT update the demux will choose another audio stream in the program with the same stream type if it can’t find one with the same language.\n\nAudioPidSelection -> (structure)\n\nAudio Pid Selection\n\nPid -> (integer)\n\nSelects a specific PID from within a source.\n\nAudioTrackSelection -> (structure)\n\nAudio Track Selection\n\nTracks -> (list)\n\nSelects one or more unique audio tracks from within a source.\n\n(structure)\n\nAudio Track\n\nTrack -> (integer)\n\n1-based integer value that maps to a specific audio track\n\nCaptionSelectors -> (list)\n\nUsed to select the caption input to use for inputs that have multiple available.\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nLanguageCode -> (string)\n\nWhen specified this field indicates the three letter language code of the caption track to extract from the source.\n\nName -> (string)\n\nName identifier for a caption selector. This name is used to associate this caption selector with one or more caption descriptions. Names must be unique within an event.\n\nSelectorSettings -> (structure)\n\nCaption selector settings.\n\nAncillarySourceSettings -> (structure)\n\nAncillary Source Settings\n\nSourceAncillaryChannelNumber -> (integer)\n\nSpecifies the number (1 to 4) of the captions channel you want to extract from the ancillary captions. If you plan to convert the ancillary captions to another format, complete this field. If you plan to choose Embedded as the captions destination in the output (to pass through all the channels in the ancillary captions), leave this field blank because MediaLive ignores the field.\n\nAribSourceSettings -> (structure)\n\nArib Source Settings\n\nDvbSubSourceSettings -> (structure)\n\nDvb Sub Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nWhen using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through, regardless of selectors.\n\nEmbeddedSourceSettings -> (structure)\n\nEmbedded Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nScte20Detection -> (string)\n\nSet to “auto” to handle streams with intermittent and/or non-aligned SCTE-20 and Embedded captions.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nSource608TrackNumber -> (integer)\n\nThis field is unused and deprecated.\n\nScte20SourceSettings -> (structure)\n\nScte20 Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nScte27SourceSettings -> (structure)\n\nScte27 Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nThe pid field is used in conjunction with the caption selector languageCode field as follows: - Specify PID and Language: Extracts captions from that PID; the language is “informational”. - Specify PID and omit Language: Extracts the specified PID. - Omit PID and specify Language: Extracts the specified language, whichever PID that happens to be. - Omit PID and omit Language: Valid only if source is DVB-Sub that is being passed through; all languages will be passed through.\n\nTeletextSourceSettings -> (structure)\n\nTeletext Source Settings\n\nOutputRectangle -> (structure)\n\nOptionally defines a region where TTML style captions will be displayed\n\nHeight -> (double)\n\nSee the description in leftOffset. For height, specify the entire height of the rectangle as a percentage of the underlying frame height. For example, “80” means the rectangle height is 80% of the underlying frame height. The topOffset and rectangleHeight must add up to 100% or less. This field corresponds to tts:extent - Y in the TTML standard.\n\nLeftOffset -> (double)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. (Make sure to leave the default if you don’t have either of these formats in the output.) You can define a display rectangle for the captions that is smaller than the underlying video frame. You define the rectangle by specifying the position of the left edge, top edge, bottom edge, and right edge of the rectangle, all within the underlying video frame. The units for the measurements are percentages. If you specify a value for one of these fields, you must specify a value for all of them. For leftOffset, specify the position of the left edge of the rectangle, as a percentage of the underlying frame width, and relative to the left edge of the frame. For example, “10” means the measurement is 10% of the underlying frame width. The rectangle left edge starts at that position from the left edge of the frame. This field corresponds to tts:origin - X in the TTML standard.\n\nTopOffset -> (double)\n\nSee the description in leftOffset. For topOffset, specify the position of the top edge of the rectangle, as a percentage of the underlying frame height, and relative to the top edge of the frame. For example, “10” means the measurement is 10% of the underlying frame height. The rectangle top edge starts at that position from the top edge of the frame. This field corresponds to tts:origin - Y in the TTML standard.\n\nWidth -> (double)\n\nSee the description in leftOffset. For width, specify the entire width of the rectangle as a percentage of the underlying frame width. For example, “80” means the rectangle width is 80% of the underlying frame width. The leftOffset and rectangleWidth must add up to 100% or less. This field corresponds to tts:extent - X in the TTML standard.\n\nPageNumber -> (string)\n\nSpecifies the teletext page number within the data stream from which to extract captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should be specified as a hexadecimal string with no “0x” prefix.\n\nDeblockFilter -> (string)\n\nEnable or disable the deblock filter when filtering.\n\nDenoiseFilter -> (string)\n\nEnable or disable the denoise filter when filtering.\n\nFilterStrength -> (integer)\n\nAdjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).\n\nInputFilter -> (string)\n\nTurns on the filter for this input. MPEG-2 inputs have the deblocking filter enabled by default. 1) auto - filtering will be applied depending on input type/quality 2) disabled - no filtering will be applied to the input 3) forced - filtering will be applied regardless of input type\n\nNetworkInputSettings -> (structure)\n\nInput settings.\n\nHlsInputSettings -> (structure)\n\nSpecifies HLS input settings when the uri is for a HLS manifest.\n\nBandwidth -> (integer)\n\nWhen specified the HLS stream with the m3u8 BANDWIDTH that most closely matches this value will be chosen, otherwise the highest bandwidth stream in the m3u8 will be chosen. The bitrate is specified in bits per second, as in an HLS manifest.\n\nBufferSegments -> (integer)\n\nWhen specified, reading of the HLS input will begin this many buffer segments from the end (most recently written segment). When not specified, the HLS input will begin with the first segment specified in the m3u8.\n\nRetries -> (integer)\n\nThe number of consecutive times that attempts to read a manifest or segment must fail before the input is considered unavailable.\n\nRetryInterval -> (integer)\n\nThe number of seconds between retries when an attempt to read a manifest or segment fails.\n\nScte35Source -> (string)\n\nIdentifies the source for the SCTE-35 messages that MediaLive will ingest. Messages can be ingested from the content segments (in the stream) or from tags in the playlist (the HLS manifest). MediaLive ignores SCTE-35 information in the source that is not selected.\n\nServerValidation -> (string)\n\nCheck HTTPS server certificates. When set to checkCryptographyOnly, cryptography in the certificate will be checked, but not the server’s name. Certain subdomains (notably S3 buckets that use dots in the bucket name) do not strictly match the corresponding certificate’s wildcard pattern and would otherwise cause the event to error. This setting is ignored for protocols that do not use https.\n\nSmpte2038DataPreference -> (string)\n\nSpecifies whether to extract applicable ancillary data from a SMPTE-2038 source in this input. Applicable data types are captions, timecode, AFD, and SCTE-104 messages. - PREFER: Extract from SMPTE-2038 if present in this input, otherwise extract from another source (if any). - IGNORE: Never extract any ancillary data from SMPTE-2038.\n\nSourceEndBehavior -> (string)\n\nLoop input if it is a file. This allows a file input to be streamed indefinitely.\n\nVideoSelector -> (structure)\n\nInforms which video elementary stream to decode for input types that have multiple available.\n\nColorSpace -> (string)\n\nSpecifies the color space of an input. This setting works in tandem with colorSpaceUsage and a video description’s colorSpaceSettingsChoice to determine if any conversion will be performed.\n\nColorSpaceSettings -> (structure)\n\nColor space settings\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nColorSpaceUsage -> (string)\n\nApplies only if colorSpace is a value other than follow. This field controls how the value in the colorSpace field will be used. fallback means that when the input does include color space data, that data will be used, but when the input has no color space data, the value in colorSpace will be used. Choose fallback if your input is sometimes missing color space data, but when it does have color space data, that data is correct. force means to always use the value in colorSpace. Choose force if your input usually has no color space data or might have unreliable color space data.\n\nSelectorSettings -> (structure)\n\nThe video selector settings.\n\nVideoSelectorPid -> (structure)\n\nVideo Selector Pid\n\nPid -> (integer)\n\nSelects a specific PID from within a video source.\n\nVideoSelectorProgramId -> (structure)\n\nVideo Selector Program Id\n\nProgramId -> (integer)\n\nSelects a specific program from within a multi-program transport stream. If the program doesn’t exist, the first program within the transport stream will be selected by default.\n\nInputSpecification -> (structure)\n\nSpecification of network and file inputs for this channel\n\nCodec -> (string)\n\nInput codec\n\nMaximumBitrate -> (string)\n\nMaximum input bitrate, categorized coarsely\n\nResolution -> (string)\n\nInput resolution, categorized coarsely\n\nLogLevel -> (string)\n\nThe log level being written to CloudWatch Logs.\n\nName -> (string)\n\nThe name of the channel. (user-mutable)\n\nPipelineDetails -> (list)\n\nRuntime details for the pipelines of a running channel.\n\n(structure)\n\nRuntime details of a pipeline when a channel is running.\n\nActiveInputAttachmentName -> (string)\n\nThe name of the active input attachment currently being ingested by this pipeline.\n\nActiveInputSwitchActionName -> (string)\n\nThe name of the input switch schedule action that occurred most recently and that resulted in the switch to the current input attachment for this pipeline.\n\nActiveMotionGraphicsActionName -> (string)\n\nThe name of the motion graphics activate action that occurred most recently and that resulted in the current graphics URI for this pipeline.\n\nActiveMotionGraphicsUri -> (string)\n\nThe current URI being used for HTML5 motion graphics for this pipeline.\n\nPipelineId -> (string)\n\nPipeline ID\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role assumed when running the Channel.\n\nState -> (string)\n\nPlaceholder documentation for ChannelState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nVpc -> (structure)\n\nSettings for VPC output\n\nAvailabilityZones -> (list)\n\nThe Availability Zones where the vpc subnets are located. The first Availability Zone applies to the first subnet in the list of subnets. The second Availability Zone applies to the second subnet.\n\n(string)\n\nPlaceholder documentation for __string\n\nNetworkInterfaceIds -> (list)\n\nA list of Elastic Network Interfaces created by MediaLive in the customer’s VPC\n\n(string)\n\nPlaceholder documentation for __string\n\nSecurityGroupIds -> (list)\n\nA list of up EC2 VPC security group IDs attached to the Output VPC network interfaces.\n\n(string)\n\nPlaceholder documentation for __string\n\nSubnetIds -> (list)\n\nA list of VPC subnet IDs from the same VPC. If STANDARD channel, subnet IDs must be mapped to two unique availability zones (AZ).\n\n(string)\n\nPlaceholder documentation for __string",
      "command_examples": "Examples\n\nTo create a channel\n\nThe following create-channel example creates a channel by passing in a JSON file that contains the parameters that you want to specify.\n\nThe channel in this example ingests an HLS PULL input that connects to a source that contains video, audio, and embedded captions. The channel creates one HLS output group with an Akamai server as the destination. The output group contains two outputs: one for the H.265 video and AAC audio, and one for the Web-VTT captions, in English only.\n\nThe JSON for this example channel includes the minimum required parameters for a channel that uses an HLS PULL input and that produces an HLS output group with Akamai as the destination. The JSON contains these main sections:\n\nInputAttachments, which specifies one source for the audio, and one source for the captions. It does not specify a video selector, which means that MediaLive extracts the first video it finds in the source.\n\nDestinations, which contains the two IP addresses (URLs) for the single output group in this channel. These addresses require passwords.\n\nEncoderSettings, which contains subsections.\n\nAudioDescriptions, which specifies that the channel contains one audio output asset, which uses the source from InputAttachments, and produces audio in AAC format.\n\nCaptionDescriptions, which specifies that the channel contains one captions output asset, which uses the source from InputAttachments, and produces captions in Web-VTT format.\n\nVideoDescriptions, which specifies that the channel contains one video output asset, with the specified resolution.\n\nOutputGroups, which specifies the output groups. In this example there is one group named Akamai. The connection is made using HLS PUT. The output group contains two outputs. One output is for the video asset (named Video_high) and the audio asset (named Audio_EN). One output is for the captions asset (named WebVTT_EN).\n\nIn this example, some of the parameters contain no value or contain nested empty parameters. For example, OutputSettings for the Video_and_audio output contains several nested parameters that end at an empty parameter M3u8Settings. This parameter must be included, but you can omit one, several, or all its children, which means that the child will take its default value or be null.\n\nAll the parameters that apply to this example channel but that aren’t specified in this file will either take the default value, be set to null, or take a unique value generated by MediaLive.\n\naws medialive create-channel \\\n    --cli-input-json file://channel-in-hls-out-hls-akamai.json\n\n\nContents of channel-in-hls-out-hls-akamai.json:\n\n{\n    \"Name\": \"News_West\",\n    \"RoleArn\": \"arn:aws:iam::111122223333:role/MediaLiveAccessRole\",\n    \"InputAttachments\": [\n        {\n            \"InputAttachmentName\": \"local_news\",\n            \"InputId\": \"1234567\",\n            \"InputSettings\": {\n                \"AudioSelectors\": [\n                    {\n                        \"Name\": \"English-Audio\",\n                        \"SelectorSettings\": {\n                            \"AudioLanguageSelection\": {\n                                \"LanguageCode\": \"EN\"\n                            }\n                        }\n                    }\n                ],\n                \"CaptionSelectors\": [\n                    {\n                        \"LanguageCode\": \"ENE\",\n                        \"Name\": \"English_embedded\"\n                    }\n                ]\n            }\n        }\n    ],\n    \"Destinations\": [\n        {\n            \"Id\": \"akamai-server-west\",\n            \"Settings\": [\n                {\n                    \"PasswordParam\": \"/medialive/examplecorp1\",\n                    \"Url\": \"http://203.0.113.55/news/news_west\",\n                    \"Username\": \"examplecorp\"\n                },\n                {\n                    \"PasswordParam\": \"/medialive/examplecorp2\",\n                    \"Url\": \"http://203.0.113.82/news/news_west\",\n                    \"Username\": \"examplecorp\"\n                }\n            ]\n        }\n    ],\n    \"EncoderSettings\": {\n        \"AudioDescriptions\": [\n            {\n                \"AudioSelectorName\": \"English-Audio\",\n                \"CodecSettings\": {\n                    \"AacSettings\": {}\n                },\n                \"Name\": \"Audio_EN\"\n            }\n        ],\n        \"CaptionDescriptions\": [\n            {\n                \"CaptionSelectorName\": \"English_embedded\",\n                \"DestinationSettings\": {\n                    \"WebvttDestinationSettings\": {}\n                },\n                \"Name\": \"WebVTT_EN\"\n            }\n        ],\n        \"VideoDescriptions\": [\n            {\n                \"Height\": 720,\n                \"Name\": \"Video_high\",\n                \"Width\": 1280\n            }\n        ],\n        \"OutputGroups\": [\n            {\n                \"Name\": \"Akamai\",\n                \"OutputGroupSettings\": {\n                    \"HlsGroupSettings\": {\n                        \"Destination\": {\n                            \"DestinationRefId\": \"akamai-server-west\"\n                        },\n                        \"HlsCdnSettings\": {\n                            \"HlsBasicPutSettings\": {}\n                        }\n                    }\n                },\n                \"Outputs\": [\n                    {\n                        \"AudioDescriptionNames\": [\n                            \"Audio_EN\"\n                        ],\n                        \"OutputName\": \"Video_and_audio\",\n                        \"OutputSettings\": {\n                            \"HlsOutputSettings\": {\n                                \"HlsSettings\": {\n                                    \"StandardHlsSettings\": {\n                                        \"M3u8Settings\": {}\n                                    }\n                                },\n                                \"NameModifier\": \"_1\"\n                            }\n                        },\n                        \"VideoDescriptionName\": \"Video_high\"\n                    },\n                    {\n                        \"CaptionDescriptionNames\": [\n                            \"WebVTT_EN\"\n                        ],\n                        \"OutputName\": \"Captions-WebVTT\",\n                        \"OutputSettings\": {\n                            \"HlsOutputSettings\": {\n                                \"HlsSettings\": {\n                                    \"StandardHlsSettings\": {\n                                        \"M3u8Settings\": {}\n                                    }\n                                },\n                                \"NameModifier\": \"_2\"\n                            }\n                        }\n                    }\n                ]\n            }\n        ],\n        \"TimecodeConfig\": {\n            \"Source\": \"EMBEDDED\"\n        }\n    }\n}\n\n\nOutput:\n\nThe output repeats back the contents of the JSON file, plus the following values. All parameters are ordered alphabetically.\n\nARN for the channel. The last part of the ARN is the unique channel ID.\n\nEgressEndpoints is blank in this example channel because it used only for PUSH inputs. When it applies it shows the addresses on MediaLive that content is pushed to.\n\nOutputGroups, Outputs. These show all the parameters for the output group and outputs, including those that you didn’t include but that are relevant to this channel. The parameters might be empty (perhaps indicating the parameter or feature is disabled in this channel configuration) or might show the default value that will apply.\n\nLogLevel is set to the default (DISABLED).\n\nTags is set to the default (null).\n\nPipelinesRunningCount and State show the current status of the channel.\n\nFor more information, see `Creating a Channel from Scratch<http://docs.aws.amazon.com/medialive/latest/ug/creating-channel-scratch.html>`__ in the AWS Elemental MediaLive User Guide."
    },
    {
      "command_name": "create-input",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/create-input.html",
      "command_description": "Description\n\nCreate an input\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-input\n[--destinations <value>]\n[--input-devices <value>]\n[--input-security-groups <value>]\n[--media-connect-flows <value>]\n[--name <value>]\n[--request-id <value>]\n[--role-arn <value>]\n[--sources <value>]\n[--tags <value>]\n[--type <value>]\n[--vpc <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--destinations <value>]",
        "[--input-devices <value>]",
        "[--input-security-groups <value>]",
        "[--media-connect-flows <value>]",
        "[--name <value>]",
        "[--request-id <value>]",
        "[--role-arn <value>]",
        "[--sources <value>]",
        "[--tags <value>]",
        "[--type <value>]",
        "[--vpc <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--destinations (list) Destination settings for PUSH type inputs.(structure)\n\nEndpoint settings for a PUSH type input.\n\nStreamName -> (string)\n\nA unique name for the location the RTMP stream is being pushed to.\n\nShorthand Syntax:\n\nStreamName=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"StreamName\": \"string\"\n  }\n  ...\n]\n\n\n--input-devices (list) Settings for the devices.(structure)\n\nSettings for an input device.\n\nId -> (string)\n\nThe unique ID for the device.\n\nShorthand Syntax:\n\nId=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Id\": \"string\"\n  }\n  ...\n]\n\n\n--input-security-groups (list) A list of security groups referenced by IDs to attach to the input.(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--media-connect-flows (list) A list of the MediaConnect Flows that you want to use in this input. You can specify as few as one Flow and presently, as many as two. The only requirement is when you have more than one is that each Flow is in a separate Availability Zone as this ensures your EML input is redundant to AZ issues. (structure)\n\nThe settings for a MediaConnect Flow.\n\nFlowArn -> (string)\n\nThe ARN of the MediaConnect Flow that you want to use as a source.\n\nShorthand Syntax:\n\nFlowArn=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"FlowArn\": \"string\"\n  }\n  ...\n]\n\n\n--name (string) Name of the input.\n\n--request-id (string) Unique identifier of the request to ensure the request is handled exactly once in case of retries.\n\n--role-arn (string) The Amazon Resource Name (ARN) of the role this input assumes during and after creation.\n\n--sources (list) The source URLs for a PULL-type input. Every PULL type input needs exactly two source URLs for redundancy. Only specify sources for PULL type Inputs. Leave Destinations empty. (structure)\n\nSettings for for a PULL type input.\n\nPasswordParam -> (string)\n\nThe key used to extract the password from EC2 Parameter store.\n\nUrl -> (string)\n\nThis represents the customer’s source URL where stream is pulled from.\n\nUsername -> (string)\n\nThe username for the input source.\n\nShorthand Syntax:\n\nPasswordParam=string,Url=string,Username=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"PasswordParam\": \"string\",\n    \"Url\": \"string\",\n    \"Username\": \"string\"\n  }\n  ...\n]\n\n\n--tags (map) A collection of key-value pairs.key -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--type (string) The different types of inputs that AWS Elemental MediaLive supports.\n\nPossible values:\n\nUDP_PUSH\n\nRTP_PUSH\n\nRTMP_PUSH\n\nRTMP_PULL\n\nURL_PULL\n\nMP4_FILE\n\nMEDIACONNECT\n\nINPUT_DEVICE\n\nAWS_CDI\n\nTS_FILE\n\n--vpc (structure) Settings for a private VPC Input. When this property is specified, the input destination addresses will be created in a VPC rather than with public Internet addresses. This property requires setting the roleArn property on Input creation. Not compatible with the inputSecurityGroups property. SecurityGroupIds -> (list)\n\nA list of up to 5 EC2 VPC security group IDs to attach to the Input VPC network interfaces. Requires subnetIds. If none are specified then the VPC default security group will be used.\n\n(string)\n\nPlaceholder documentation for __string\n\nSubnetIds -> (list)\n\nA list of 2 VPC subnet IDs from the same VPC. Subnet IDs must be mapped to two unique availability zones (AZ).\n\n(string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nSecurityGroupIds=string,string,SubnetIds=string,string\n\n\nJSON Syntax:\n\n{\n  \"SecurityGroupIds\": [\"string\", ...],\n  \"SubnetIds\": [\"string\", ...]\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nInput -> (structure)\n\nPlaceholder documentation for Input\n\nArn -> (string)\n\nThe Unique ARN of the input (generated, immutable).\n\nAttachedChannels -> (list)\n\nA list of channel IDs that that input is attached to (currently an input can only be attached to one channel).\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the destinations of the input (PUSH-type).\n\n(structure)\n\nThe settings for a PUSH type input.\n\nIp -> (string)\n\nThe system-generated static IP address of endpoint. It remains fixed for the lifetime of the input.\n\nPort -> (string)\n\nThe port number for the input.\n\nUrl -> (string)\n\nThis represents the endpoint that the customer stream will be pushed to.\n\nVpc -> (structure)\n\nThe properties for a VPC type input destination.\n\nAvailabilityZone -> (string)\n\nThe availability zone of the Input destination.\n\nNetworkInterfaceId -> (string)\n\nThe network interface ID of the Input destination in the VPC.\n\nId -> (string)\n\nThe generated ID of the input (unique for user account, immutable).\n\nInputClass -> (string)\n\nSTANDARD - MediaLive expects two sources to be connected to this input. If the channel is also STANDARD, both sources will be ingested. If the channel is SINGLE_PIPELINE, only the first source will be ingested; the second source will always be ignored, even if the first source fails. SINGLE_PIPELINE - You can connect only one source to this input. If the ChannelClass is also SINGLE_PIPELINE, this value is valid. If the ChannelClass is STANDARD, this value is not valid because the channel requires two sources in the input.\n\nInputDevices -> (list)\n\nSettings for the input devices.\n\n(structure)\n\nSettings for an input device.\n\nId -> (string)\n\nThe unique ID for the device.\n\nInputPartnerIds -> (list)\n\nA list of IDs for all Inputs which are partners of this one.\n\n(string)\n\nPlaceholder documentation for __string\n\nInputSourceType -> (string)\n\nCertain pull input sources can be dynamic, meaning that they can have their URL’s dynamically changes during input switch actions. Presently, this functionality only works with MP4_FILE and TS_FILE inputs.\n\nMediaConnectFlows -> (list)\n\nA list of MediaConnect Flows for this input.\n\n(structure)\n\nThe settings for a MediaConnect Flow.\n\nFlowArn -> (string)\n\nThe unique ARN of the MediaConnect Flow being used as a source.\n\nName -> (string)\n\nThe user-assigned name (This is a mutable value).\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role this input assumes during and after creation.\n\nSecurityGroups -> (list)\n\nA list of IDs for all the Input Security Groups attached to the input.\n\n(string)\n\nPlaceholder documentation for __string\n\nSources -> (list)\n\nA list of the sources of the input (PULL-type).\n\n(structure)\n\nThe settings for a PULL type input.\n\nPasswordParam -> (string)\n\nThe key used to extract the password from EC2 Parameter store.\n\nUrl -> (string)\n\nThis represents the customer’s source URL where stream is pulled from.\n\nUsername -> (string)\n\nThe username for the input source.\n\nState -> (string)\n\nPlaceholder documentation for InputState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nType -> (string)\n\nThe different types of inputs that AWS Elemental MediaLive supports.",
      "command_examples": "Examples\n\nTo create an input\n\nThe following create-input example creates an HLS PULL input by passing in a JSON file that contains the parameters that apply to this type of input. The JSON for this example input specifies two sources (addresses) to the input, in order to support redundancy in the ingest. These addresses require passwords.\n\naws medialive create-input \\\n    --cli-input-json file://input-hls-pull-news.json\n\n\nContents of input-hls-pull-news.json:\n\n{\n    \"Name\": \"local_news\",\n    \"RequestId\": \"cli000059\",\n    \"Sources\": [\n            {\n                    \"Url\": \"https://203.0.113.13/newschannel/anytownusa.m3u8\",\n                    \"Username\": \"examplecorp\",\n                    \"PasswordParam\": \"/medialive/examplecorp1\"\n            },\n       {\n                    \"Url\": \"https://198.51.100.54/fillervideos/oceanwaves.mp4\",\n                    \"Username\": \"examplecorp\",\n                    \"PasswordParam\": \"examplecorp2\"\n            }\n    ],\n    \"Type\": \"URL_PULL\"\n}\n\n\nOutput:\n\nThe output repeats back the contents of the JSON file, plus the following values. All parameters are ordered alphabetically.\n\nArn for the input. The last part of the ARN is the unique input ID.\n\nAttached Channels, which is always empty for a newly created input.\n\nDestinations, which is empty in this example because it is used only with a PUSH input.\n\nId for the input, the same as the ID in the ARN.\n\nMediaConnectFlows, which is empty in this example because it is used only with an input of type MediaConnect.\n\nSecurityGroups, which is empty in this example because it is used only with a PUSH input.\n\nState of this input.\n\nTags, which is empty (the default for this parameter).\n\nFor more information, see Creating an Input in the AWS Elemental MediaLive User Guide."
    },
    {
      "command_name": "create-input-security-group",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/create-input-security-group.html",
      "command_description": "Description\n\nCreates a Input Security Group\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-input-security-group\n[--tags <value>]\n[--whitelist-rules <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--tags <value>]",
        "[--whitelist-rules <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--tags (map) A collection of key-value pairs.key -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--whitelist-rules (list) List of IPv4 CIDR addresses to whitelist(structure)\n\nAn IPv4 CIDR to whitelist.\n\nCidr -> (string)\n\nThe IPv4 CIDR to whitelist.\n\nShorthand Syntax:\n\nCidr=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Cidr\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nSecurityGroup -> (structure)\n\nAn Input Security Group\n\nArn -> (string)\n\nUnique ARN of Input Security Group\n\nId -> (string)\n\nThe Id of the Input Security Group\n\nInputs -> (list)\n\nThe list of inputs currently using this Input Security Group.\n\n(string)\n\nPlaceholder documentation for __string\n\nState -> (string)\n\nThe current state of the Input Security Group.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nWhitelistRules -> (list)\n\nWhitelist rules and their sync status\n\n(structure)\n\nWhitelist rule\n\nCidr -> (string)\n\nThe IPv4 CIDR that’s whitelisted."
    },
    {
      "command_name": "create-multiplex",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/create-multiplex.html",
      "command_description": "Description\n\nCreate a new multiplex.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-multiplex\n--availability-zones <value>\n--multiplex-settings <value>\n--name <value>\n[--request-id <value>]\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--availability-zones <value>",
        "--multiplex-settings <value>",
        "--name <value>",
        "[--request-id <value>]",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--availability-zones (list) A list of availability zones for the multiplex. You must specify exactly two.(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--multiplex-settings (structure) Configuration for a multiplex event.MaximumVideoBufferDelayMilliseconds -> (integer)\n\nMaximum video buffer delay in milliseconds.\n\nTransportStreamBitrate -> (integer)\n\nTransport stream bit rate.\n\nTransportStreamId -> (integer)\n\nTransport stream ID.\n\nTransportStreamReservedBitrate -> (integer)\n\nTransport stream reserved bit rate.\n\nShorthand Syntax:\n\nMaximumVideoBufferDelayMilliseconds=integer,TransportStreamBitrate=integer,TransportStreamId=integer,TransportStreamReservedBitrate=integer\n\n\nJSON Syntax:\n\n{\n  \"MaximumVideoBufferDelayMilliseconds\": integer,\n  \"TransportStreamBitrate\": integer,\n  \"TransportStreamId\": integer,\n  \"TransportStreamReservedBitrate\": integer\n}\n\n\n--name (string) Name of multiplex.\n\n--request-id (string) Unique request ID. This prevents retries from creating multiple resources.\n\n--tags (map) A collection of key-value pairs.key -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nMultiplex -> (structure)\n\nThe newly created multiplex.\n\nArn -> (string)\n\nThe unique arn of the multiplex.\n\nAvailabilityZones -> (list)\n\nA list of availability zones for the multiplex.\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the multiplex output destinations.\n\n(structure)\n\nMultiplex output destination settings\n\nMediaConnectSettings -> (structure)\n\nMultiplex MediaConnect output destination settings.\n\nEntitlementArn -> (string)\n\nThe MediaConnect entitlement ARN available as a Flow source.\n\nId -> (string)\n\nThe unique id of the multiplex.\n\nMultiplexSettings -> (structure)\n\nConfiguration for a multiplex event.\n\nMaximumVideoBufferDelayMilliseconds -> (integer)\n\nMaximum video buffer delay in milliseconds.\n\nTransportStreamBitrate -> (integer)\n\nTransport stream bit rate.\n\nTransportStreamId -> (integer)\n\nTransport stream ID.\n\nTransportStreamReservedBitrate -> (integer)\n\nTransport stream reserved bit rate.\n\nName -> (string)\n\nThe name of the multiplex.\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nProgramCount -> (integer)\n\nThe number of programs in the multiplex.\n\nState -> (string)\n\nThe current state of the multiplex.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "create-multiplex-program",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/create-multiplex-program.html",
      "command_description": "Description\n\nCreate a new program in the multiplex.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-multiplex-program\n--multiplex-id <value>\n--multiplex-program-settings <value>\n--program-name <value>\n[--request-id <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--multiplex-id <value>",
        "--multiplex-program-settings <value>",
        "--program-name <value>",
        "[--request-id <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--multiplex-id (string) ID of the multiplex where the program is to be created.\n\n--multiplex-program-settings (structure) The settings for this multiplex program.PreferredChannelPipeline -> (string)\n\nIndicates which pipeline is preferred by the multiplex for program ingest.\n\nProgramNumber -> (integer)\n\nUnique program number.\n\nServiceDescriptor -> (structure)\n\nTransport stream service descriptor configuration for the Multiplex program.\n\nProviderName -> (string)\n\nName of the provider.\n\nServiceName -> (string)\n\nName of the service.\n\nVideoSettings -> (structure)\n\nProgram video settings configuration.\n\nConstantBitrate -> (integer)\n\nThe constant bitrate configuration for the video encode. When this field is defined, StatmuxSettings must be undefined.\n\nStatmuxSettings -> (structure)\n\nStatmux rate control settings. When this field is defined, ConstantBitrate must be undefined.\n\nMaximumBitrate -> (integer)\n\nMaximum statmux bitrate.\n\nMinimumBitrate -> (integer)\n\nMinimum statmux bitrate.\n\nPriority -> (integer)\n\nThe purpose of the priority is to use a combination of thenmultiplex rate control algorithm and the QVBR capability of thenencoder to prioritize the video quality of some channels in anmultiplex over others. Channels that have a higher priority willnget higher video quality at the expense of the video quality ofnother channels in the multiplex with lower priority.\n\nShorthand Syntax:\n\nPreferredChannelPipeline=string,ProgramNumber=integer,ServiceDescriptor={ProviderName=string,ServiceName=string},VideoSettings={ConstantBitrate=integer,StatmuxSettings={MaximumBitrate=integer,MinimumBitrate=integer,Priority=integer}}\n\n\nJSON Syntax:\n\n{\n  \"PreferredChannelPipeline\": \"CURRENTLY_ACTIVE\"|\"PIPELINE_0\"|\"PIPELINE_1\",\n  \"ProgramNumber\": integer,\n  \"ServiceDescriptor\": {\n    \"ProviderName\": \"string\",\n    \"ServiceName\": \"string\"\n  },\n  \"VideoSettings\": {\n    \"ConstantBitrate\": integer,\n    \"StatmuxSettings\": {\n      \"MaximumBitrate\": integer,\n      \"MinimumBitrate\": integer,\n      \"Priority\": integer\n    }\n  }\n}\n\n\n--program-name (string) Name of multiplex program.\n\n--request-id (string) Unique request ID. This prevents retries from creating multiple resources.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nMultiplexProgram -> (structure)\n\nThe newly created multiplex program.\n\nChannelId -> (string)\n\nThe MediaLive channel associated with the program.\n\nMultiplexProgramSettings -> (structure)\n\nThe settings for this multiplex program.\n\nPreferredChannelPipeline -> (string)\n\nIndicates which pipeline is preferred by the multiplex for program ingest.\n\nProgramNumber -> (integer)\n\nUnique program number.\n\nServiceDescriptor -> (structure)\n\nTransport stream service descriptor configuration for the Multiplex program.\n\nProviderName -> (string)\n\nName of the provider.\n\nServiceName -> (string)\n\nName of the service.\n\nVideoSettings -> (structure)\n\nProgram video settings configuration.\n\nConstantBitrate -> (integer)\n\nThe constant bitrate configuration for the video encode. When this field is defined, StatmuxSettings must be undefined.\n\nStatmuxSettings -> (structure)\n\nStatmux rate control settings. When this field is defined, ConstantBitrate must be undefined.\n\nMaximumBitrate -> (integer)\n\nMaximum statmux bitrate.\n\nMinimumBitrate -> (integer)\n\nMinimum statmux bitrate.\n\nPriority -> (integer)\n\nThe purpose of the priority is to use a combination of thenmultiplex rate control algorithm and the QVBR capability of thenencoder to prioritize the video quality of some channels in anmultiplex over others. Channels that have a higher priority willnget higher video quality at the expense of the video quality ofnother channels in the multiplex with lower priority.\n\nPacketIdentifiersMap -> (structure)\n\nThe packet identifier map for this multiplex program.\n\nAudioPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nDvbSubPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nDvbTeletextPid -> (integer)\n\nPlaceholder documentation for __integer\n\nEtvPlatformPid -> (integer)\n\nPlaceholder documentation for __integer\n\nEtvSignalPid -> (integer)\n\nPlaceholder documentation for __integer\n\nKlvDataPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nPcrPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPmtPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPrivateMetadataPid -> (integer)\n\nPlaceholder documentation for __integer\n\nScte27Pids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nScte35Pid -> (integer)\n\nPlaceholder documentation for __integer\n\nTimedMetadataPid -> (integer)\n\nPlaceholder documentation for __integer\n\nVideoPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPipelineDetails -> (list)\n\nContains information about the current sources for the specified program in the specified multiplex. Keep in mind that each multiplex pipeline connects to both pipelines in a given source channel (the channel identified by the program). But only one of those channel pipelines is ever active at one time.\n\n(structure)\n\nThe current source for one of the pipelines in the multiplex.\n\nActiveChannelPipeline -> (string)\n\nIdentifies the channel pipeline that is currently active for the pipeline (identified by PipelineId) in the multiplex.\n\nPipelineId -> (string)\n\nIdentifies a specific pipeline in the multiplex.\n\nProgramName -> (string)\n\nThe name of the multiplex program."
    },
    {
      "command_name": "create-partner-input",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/create-partner-input.html",
      "command_description": "Description\n\nCreate a partner input\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-partner-input\n--input-id <value>\n[--request-id <value>]\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-id <value>",
        "[--request-id <value>]",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-id (string) Unique ID of the input.\n\n--request-id (string) Unique identifier of the request to ensure the request is handled exactly once in case of retries.\n\n--tags (map) A collection of key-value pairs.key -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nInput -> (structure)\n\nPlaceholder documentation for Input\n\nArn -> (string)\n\nThe Unique ARN of the input (generated, immutable).\n\nAttachedChannels -> (list)\n\nA list of channel IDs that that input is attached to (currently an input can only be attached to one channel).\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the destinations of the input (PUSH-type).\n\n(structure)\n\nThe settings for a PUSH type input.\n\nIp -> (string)\n\nThe system-generated static IP address of endpoint. It remains fixed for the lifetime of the input.\n\nPort -> (string)\n\nThe port number for the input.\n\nUrl -> (string)\n\nThis represents the endpoint that the customer stream will be pushed to.\n\nVpc -> (structure)\n\nThe properties for a VPC type input destination.\n\nAvailabilityZone -> (string)\n\nThe availability zone of the Input destination.\n\nNetworkInterfaceId -> (string)\n\nThe network interface ID of the Input destination in the VPC.\n\nId -> (string)\n\nThe generated ID of the input (unique for user account, immutable).\n\nInputClass -> (string)\n\nSTANDARD - MediaLive expects two sources to be connected to this input. If the channel is also STANDARD, both sources will be ingested. If the channel is SINGLE_PIPELINE, only the first source will be ingested; the second source will always be ignored, even if the first source fails. SINGLE_PIPELINE - You can connect only one source to this input. If the ChannelClass is also SINGLE_PIPELINE, this value is valid. If the ChannelClass is STANDARD, this value is not valid because the channel requires two sources in the input.\n\nInputDevices -> (list)\n\nSettings for the input devices.\n\n(structure)\n\nSettings for an input device.\n\nId -> (string)\n\nThe unique ID for the device.\n\nInputPartnerIds -> (list)\n\nA list of IDs for all Inputs which are partners of this one.\n\n(string)\n\nPlaceholder documentation for __string\n\nInputSourceType -> (string)\n\nCertain pull input sources can be dynamic, meaning that they can have their URL’s dynamically changes during input switch actions. Presently, this functionality only works with MP4_FILE and TS_FILE inputs.\n\nMediaConnectFlows -> (list)\n\nA list of MediaConnect Flows for this input.\n\n(structure)\n\nThe settings for a MediaConnect Flow.\n\nFlowArn -> (string)\n\nThe unique ARN of the MediaConnect Flow being used as a source.\n\nName -> (string)\n\nThe user-assigned name (This is a mutable value).\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role this input assumes during and after creation.\n\nSecurityGroups -> (list)\n\nA list of IDs for all the Input Security Groups attached to the input.\n\n(string)\n\nPlaceholder documentation for __string\n\nSources -> (list)\n\nA list of the sources of the input (PULL-type).\n\n(structure)\n\nThe settings for a PULL type input.\n\nPasswordParam -> (string)\n\nThe key used to extract the password from EC2 Parameter store.\n\nUrl -> (string)\n\nThis represents the customer’s source URL where stream is pulled from.\n\nUsername -> (string)\n\nThe username for the input source.\n\nState -> (string)\n\nPlaceholder documentation for InputState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nType -> (string)\n\nThe different types of inputs that AWS Elemental MediaLive supports."
    },
    {
      "command_name": "create-tags",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/create-tags.html",
      "command_description": "Description\n\nCreate tags for a resource\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-tags\n--resource-arn <value>\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string) Placeholder documentation for __string\n\n--tags (map) Placeholder documentation for Tagskey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "delete-channel",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/delete-channel.html",
      "command_description": "Description\n\nStarts deletion of channel. The associated outputs are also deleted.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-channel\n--channel-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-id (string) Unique ID of the channel.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe unique arn of the channel.\n\nCdiInputSpecification -> (structure)\n\nSpecification of CDI inputs for this channel\n\nResolution -> (string)\n\nMaximum CDI input resolution\n\nChannelClass -> (string)\n\nThe class for this channel. STANDARD for a channel with two pipelines or SINGLE_PIPELINE for a channel with one pipeline.\n\nDestinations -> (list)\n\nA list of destinations of the channel. For UDP outputs, there is one destination per output. For other types (HLS, for example), there is one destination per packager.\n\n(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nEgressEndpoints -> (list)\n\nThe endpoints where outgoing connections initiate from\n\n(structure)\n\nPlaceholder documentation for ChannelEgressEndpoint\n\nSourceIp -> (string)\n\nPublic IP of where a channel’s output comes from\n\nEncoderSettings -> (structure)\n\nEncoder Settings\n\nAudioDescriptions -> (list)\n\nPlaceholder documentation for __listOfAudioDescription\n\n(structure)\n\nAudio Description\n\nAudioNormalizationSettings -> (structure)\n\nAdvanced audio normalization settings.\n\nAlgorithm -> (string)\n\nAudio normalization algorithm to use. itu17701 conforms to the CALM Act specification, itu17702 conforms to the EBU R-128 specification.\n\nAlgorithmControl -> (string)\n\nWhen set to correctAudio the output audio is corrected using the chosen algorithm. If set to measureOnly, the audio will be measured but not adjusted.\n\nTargetLkfs -> (double)\n\nTarget LKFS(loudness) to adjust volume to. If no value is entered, a default value will be used according to the chosen algorithm. The CALM Act (1770-1) recommends a target of -24 LKFS. The EBU R-128 specification (1770-2) recommends a target of -23 LKFS.\n\nAudioSelectorName -> (string)\n\nThe name of the AudioSelector used as the source for this AudioDescription.\n\nAudioType -> (string)\n\nApplies only if audioTypeControl is useConfigured. The values for audioType are defined in ISO-IEC 13818-1.\n\nAudioTypeControl -> (string)\n\nDetermines how audio type is determined. followInput: If the input contains an ISO 639 audioType, then that value is passed through to the output. If the input contains no ISO 639 audioType, the value in Audio Type is included in the output. useConfigured: The value in Audio Type is included in the output. Note that this field and audioType are both ignored if inputType is broadcasterMixedAd.\n\nAudioWatermarkingSettings -> (structure)\n\nSettings to configure one or more solutions that insert audio watermarks in the audio encode\n\nNielsenWatermarksSettings -> (structure)\n\nSettings to configure Nielsen Watermarks in the audio encode\n\nNielsenCbetSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen CBET\n\nCbetCheckDigitString -> (string)\n\nEnter the CBET check digits to use in the watermark.\n\nCbetStepaside -> (string)\n\nDetermines the method of CBET insertion mode when prior encoding is detected on the same layer.\n\nCsid -> (string)\n\nEnter the CBET Source ID (CSID) to use in the watermark\n\nNielsenDistributionType -> (string)\n\nChoose the distribution types that you want to assign to the watermarks: - PROGRAM_CONTENT - FINAL_DISTRIBUTOR\n\nNielsenNaesIiNwSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen NAES II (N2) and Nielsen NAES VI (NW).\n\nCheckDigitString -> (string)\n\nEnter the check digit string for the watermark\n\nSid -> (double)\n\nEnter the Nielsen Source ID (SID) to include in the watermark\n\nCodecSettings -> (structure)\n\nAudio codec settings.\n\nAacSettings -> (structure)\n\nAac Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid values depend on rate control mode and profile.\n\nCodingMode -> (string)\n\nMono, Stereo, or 5.1 channel layout. Valid values depend on rate control mode and profile. The adReceiverMix setting receives a stereo description plus control track and emits a mono AAC encode of the description track, with control data emitted in the PES header as per ETSI TS 101 154 Annex E.\n\nInputType -> (string)\n\nSet to “broadcasterMixedAd” when input contains pre-mixed main audio + AD (narration) as a stereo pair. The Audio Type field (audioType) will be set to 3, which signals to downstream systems that this stream contains “broadcaster mixed AD”. Note that the input received by the encoder must contain pre-mixed audio; the encoder does not perform the mixing. The values in audioTypeControl and audioType (in AudioDescription) are ignored when set to broadcasterMixedAd. Leave set to “normal” when input does not contain pre-mixed audio + AD.\n\nProfile -> (string)\n\nAAC Profile.\n\nRateControlMode -> (string)\n\nRate Control Mode.\n\nRawFormat -> (string)\n\nSets LATM / LOAS AAC output for raw containers.\n\nSampleRate -> (double)\n\nSample rate in Hz. Valid values depend on rate control mode and profile.\n\nSpec -> (string)\n\nUse MPEG-2 AAC audio instead of MPEG-4 AAC audio for raw or MPEG-2 Transport Stream containers.\n\nVbrQuality -> (string)\n\nVBR Quality Level - Only used if rateControlMode is VBR.\n\nAc3Settings -> (structure)\n\nAc3 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted AC-3 stream. See ATSC A/52-2012 for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital coding mode. Determines number of channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If excluded and input audio is Dolby Digital, dialnorm will be passed through.\n\nDrcProfile -> (string)\n\nIf set to filmStandard, adds dynamic range compression signaling to the output bitstream as defined in the Dolby Digital specification.\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid in codingMode32Lfe mode.\n\nMetadataControl -> (string)\n\nWhen set to “followInput”, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nEac3Settings -> (structure)\n\nEac3 Settings\n\nAttenuationControl -> (string)\n\nWhen set to attenuate3Db, applies a 3 dB attenuation to the surround channels. Only used for 3/2 coding mode.\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted E-AC-3 stream. See ATSC A/52-2012 (Annex E) for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital Plus coding mode. Determines number of channels.\n\nDcFilter -> (string)\n\nWhen set to enabled, activates a DC highpass filter for all input channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If blank and input audio is Dolby Digital Plus, dialnorm will be passed through.\n\nDrcLine -> (string)\n\nSets the Dolby dynamic range compression profile.\n\nDrcRf -> (string)\n\nSets the profile for heavy Dolby dynamic range compression, ensures that the instantaneous signal peaks do not exceed specified levels.\n\nLfeControl -> (string)\n\nWhen encoding 3/2 audio, setting to lfe enables the LFE channel\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid with codingMode32 coding mode.\n\nLoRoCenterMixLevel -> (double)\n\nLeft only/Right only center mix level. Only used for 3/2 coding mode.\n\nLoRoSurroundMixLevel -> (double)\n\nLeft only/Right only surround mix level. Only used for 3/2 coding mode.\n\nLtRtCenterMixLevel -> (double)\n\nLeft total/Right total center mix level. Only used for 3/2 coding mode.\n\nLtRtSurroundMixLevel -> (double)\n\nLeft total/Right total surround mix level. Only used for 3/2 coding mode.\n\nMetadataControl -> (string)\n\nWhen set to followInput, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nPassthroughControl -> (string)\n\nWhen set to whenPossible, input DD+ audio will be passed through if it is present on the input. This detection is dynamic over the life of the transcode. Inputs that alternate between DD+ and non-DD+ content will have a consistent DD+ output as the system alternates between passthrough and encoding.\n\nPhaseControl -> (string)\n\nWhen set to shift90Degrees, applies a 90-degree phase shift to the surround channels. Only used for 3/2 coding mode.\n\nStereoDownmix -> (string)\n\nStereo downmix preference. Only used for 3/2 coding mode.\n\nSurroundExMode -> (string)\n\nWhen encoding 3/2 audio, sets whether an extra center back surround channel is matrix encoded into the left and right surround channels.\n\nSurroundMode -> (string)\n\nWhen encoding 2/0 audio, sets whether Dolby Surround is matrix encoded into the two channels.\n\nMp2Settings -> (structure)\n\nMp2 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second.\n\nCodingMode -> (string)\n\nThe MPEG2 Audio coding mode. Valid values are codingMode10 (for mono) or codingMode20 (for stereo).\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nPassThroughSettings -> (structure)\n\nPass Through Settings\n\nWavSettings -> (structure)\n\nWav Settings\n\nBitDepth -> (double)\n\nBits per sample.\n\nCodingMode -> (string)\n\nThe audio coding mode for the WAV audio. The mode determines the number of channels in the audio.\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nLanguageCode -> (string)\n\nRFC 5646 language code representing the language of the audio output track. Only used if languageControlMode is useConfigured, or there is no ISO 639 language code specified in the input.\n\nLanguageCodeControl -> (string)\n\nChoosing followInput will cause the ISO 639 language code of the output to follow the ISO 639 language code of the input. The languageCode will be used when useConfigured is set, or when followInput is selected but there is no ISO 639 language code specified by the input.\n\nName -> (string)\n\nThe name of this AudioDescription. Outputs will use this name to uniquely identify this AudioDescription. Description names should be unique within this Live Event.\n\nRemixSettings -> (structure)\n\nSettings that control how input audio channels are remixed into the output audio channels.\n\nChannelMappings -> (list)\n\nMapping of input channels to output channels, with appropriate gain adjustments.\n\n(structure)\n\nAudio Channel Mapping\n\nInputChannelLevels -> (list)\n\nIndices and gain values for each input channel that should be remixed into this output channel.\n\n(structure)\n\nInput Channel Level\n\nGain -> (integer)\n\nRemixing value. Units are in dB and acceptable values are within the range from -60 (mute) and 6 dB.\n\nInputChannel -> (integer)\n\nThe index of the input channel used as a source.\n\nOutputChannel -> (integer)\n\nThe index of the output channel being produced.\n\nChannelsIn -> (integer)\n\nNumber of input channels to be used.\n\nChannelsOut -> (integer)\n\nNumber of output channels to be produced. Valid values: 1, 2, 4, 6, 8\n\nStreamName -> (string)\n\nUsed for MS Smooth and Apple HLS outputs. Indicates the name displayed by the player (eg. English, or Director Commentary).\n\nAvailBlanking -> (structure)\n\nSettings for ad avail blanking.\n\nAvailBlankingImage -> (structure)\n\nBlanking image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when insertion metadata is added.\n\nAvailConfiguration -> (structure)\n\nEvent-wide configuration settings for ad avail insertion.\n\nAvailSettings -> (structure)\n\nAd avail settings.\n\nScte35SpliceInsert -> (structure)\n\nScte35 Splice Insert\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nScte35TimeSignalApos -> (structure)\n\nScte35 Time Signal Apos\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nBlackoutSlate -> (structure)\n\nSettings for blackout slate.\n\nBlackoutSlateImage -> (structure)\n\nBlackout slate image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkEndBlackout -> (string)\n\nSetting to enabled causes the encoder to blackout the video, audio, and captions, and raise the “Network Blackout Image” slate when an SCTE104/35 Network End Segmentation Descriptor is encountered. The blackout will be lifted when the Network Start Segmentation Descriptor is encountered. The Network End and Network Start descriptors must contain a network ID that matches the value entered in “Network ID”.\n\nNetworkEndBlackoutImage -> (structure)\n\nPath to local file to use as Network End Blackout image. Image will be scaled to fill the entire output raster.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkId -> (string)\n\nProvides Network ID that matches EIDR ID format (e.g., “10.XXXX/XXXX-XXXX-XXXX-XXXX-XXXX-C”).\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when indicated by program metadata.\n\nCaptionDescriptions -> (list)\n\nSettings for caption decriptions\n\n(structure)\n\nCaption Description\n\nCaptionSelectorName -> (string)\n\nSpecifies which input caption selector to use as a caption source when generating output captions. This field should match a captionSelector name.\n\nDestinationSettings -> (structure)\n\nAdditional settings for captions destination that depend on the destination type.\n\nAribDestinationSettings -> (structure)\n\nArib Destination Settings\n\nBurnInDestinationSettings -> (structure)\n\nBurn In Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to ‘auto’ fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. All burn-in and DVB-Sub font settings must match.\n\nDvbSubDestinationSettings -> (structure)\n\nDvb Sub Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. This option is not valid for source captions that are STL or 608/embedded. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to auto fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nEbuTtDDestinationSettings -> (structure)\n\nEbu Tt DDestination Settings\n\nCopyrightHolder -> (string)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. Complete this field if you want to include the name of the copyright holder in the copyright metadata tag in the TTML\n\nFillLineGap -> (string)\n\nSpecifies how to handle the gap between the lines (in multi-line captions). - enabled: Fill with the captions background color (as specified in the input captions). - disabled: Leave the gap unfilled.\n\nFontFamily -> (string)\n\nSpecifies the font family to include in the font data attached to the EBU-TT captions. Valid only if styleControl is set to include. If you leave this field empty, the font family is set to “monospaced”. (If styleControl is set to exclude, the font family is always set to “monospaced”.) You specify only the font family. All other style information (color, bold, position and so on) is copied from the input captions. The size is always set to 100% to allow the downstream player to choose the size. - Enter a list of font families, as a comma-separated list of font names, in order of preference. The name can be a font family (such as “Arial”), or a generic font family (such as “serif”), or “default” (to let the downstream player choose the font). - Leave blank to set the family to “monospace”.\n\nStyleControl -> (string)\n\nSpecifies the style information (font color, font position, and so on) to include in the font data that is attached to the EBU-TT captions. - include: Take the style information (font color, font position, and so on) from the source captions and include that information in the font data attached to the EBU-TT captions. This option is valid only if the source captions are Embedded or Teletext. - exclude: In the font data attached to the EBU-TT captions, set the font family to “monospaced”. Do not include any other style information.\n\nEmbeddedDestinationSettings -> (structure)\n\nEmbedded Destination Settings\n\nEmbeddedPlusScte20DestinationSettings -> (structure)\n\nEmbedded Plus Scte20 Destination Settings\n\nRtmpCaptionInfoDestinationSettings -> (structure)\n\nRtmp Caption Info Destination Settings\n\nScte20PlusEmbeddedDestinationSettings -> (structure)\n\nScte20 Plus Embedded Destination Settings\n\nScte27DestinationSettings -> (structure)\n\nScte27 Destination Settings\n\nSmpteTtDestinationSettings -> (structure)\n\nSmpte Tt Destination Settings\n\nTeletextDestinationSettings -> (structure)\n\nTeletext Destination Settings\n\nTtmlDestinationSettings -> (structure)\n\nTtml Destination Settings\n\nStyleControl -> (string)\n\nWhen set to passthrough, passes through style and position information from a TTML-like input source (TTML, SMPTE-TT, CFF-TT) to the CFF-TT output or TTML output.\n\nWebvttDestinationSettings -> (structure)\n\nWebvtt Destination Settings\n\nStyleControl -> (string)\n\nControls whether the color and position of the source captions is passed through to the WebVTT output captions. PASSTHROUGH - Valid only if the source captions are EMBEDDED or TELETEXT. NO_STYLE_DATA - Don’t pass through the style. The output captions will not contain any font styling information.\n\nLanguageCode -> (string)\n\nISO 639-2 three-digit code: http://www.loc.gov/standards/iso639-2/\n\nLanguageDescription -> (string)\n\nHuman readable information to indicate captions available for players (eg. English, or Spanish).\n\nName -> (string)\n\nName of the caption description. Used to associate a caption description with an output. Names must be unique within an event.\n\nFeatureActivations -> (structure)\n\nFeature Activations\n\nInputPrepareScheduleActions -> (string)\n\nEnables the Input Prepare feature. You can create Input Prepare actions in the schedule only if this feature is enabled. If you disable the feature on an existing schedule, make sure that you first delete all input prepare actions from the schedule.\n\nGlobalConfiguration -> (structure)\n\nConfiguration settings that apply to the event as a whole.\n\nInitialAudioGain -> (integer)\n\nValue to set the initial audio gain for the Live Event.\n\nInputEndAction -> (string)\n\nIndicates the action to take when the current input completes (e.g. end-of-file). When switchAndLoopInputs is configured the encoder will restart at the beginning of the first input. When “none” is configured the encoder will transcode either black, a solid color, or a user specified slate images per the “Input Loss Behavior” configuration until the next input switch occurs (which is controlled through the Channel Schedule API).\n\nInputLossBehavior -> (structure)\n\nSettings for system actions when input is lost.\n\nBlackFrameMsec -> (integer)\n\nDocumentation update needed\n\nInputLossImageColor -> (string)\n\nWhen input loss image type is “color” this field specifies the color to use. Value: 6 hex characters representing the values of RGB.\n\nInputLossImageSlate -> (structure)\n\nWhen input loss image type is “slate” these fields specify the parameters for accessing the slate.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nInputLossImageType -> (string)\n\nIndicates whether to substitute a solid color or a slate into the output after input loss exceeds blackFrameMsec.\n\nRepeatFrameMsec -> (integer)\n\nDocumentation update needed\n\nOutputLockingMode -> (string)\n\nIndicates how MediaLive pipelines are synchronized. PIPELINE_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the other. EPOCH_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the Unix epoch.\n\nOutputTimingSource -> (string)\n\nIndicates whether the rate of frames emitted by the Live encoder should be paced by its system clock (which optionally may be locked to another source via NTP) or should be locked to the clock of the source that is providing the input stream.\n\nSupportLowFramerateInputs -> (string)\n\nAdjusts video input buffer for streams with very low video framerates. This is commonly set to enabled for music channels with less than one video frame per second.\n\nMotionGraphicsConfiguration -> (structure)\n\nSettings for motion graphics.\n\nMotionGraphicsInsertion -> (string)\n\nMotion Graphics Insertion\n\nMotionGraphicsSettings -> (structure)\n\nMotion Graphics Settings\n\nHtmlMotionGraphicsSettings -> (structure)\n\nHtml Motion Graphics Settings\n\nNielsenConfiguration -> (structure)\n\nNielsen configuration settings.\n\nDistributorId -> (string)\n\nEnter the Distributor ID assigned to your organization by Nielsen.\n\nNielsenPcmToId3Tagging -> (string)\n\nEnables Nielsen PCM to ID3 tagging\n\nOutputGroups -> (list)\n\nPlaceholder documentation for __listOfOutputGroup\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nName -> (string)\n\nCustom output group name optionally defined by the user. Only letters, numbers, and the underscore character allowed; only 32 characters allowed.\n\nOutputGroupSettings -> (structure)\n\nSettings associated with the output group.\n\nArchiveGroupSettings -> (structure)\n\nArchive Group Settings\n\nArchiveCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nArchiveS3Settings -> (structure)\n\nArchive S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nDestination -> (structure)\n\nA directory and base filename where archive files should be written.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRolloverInterval -> (integer)\n\nNumber of seconds to write to archive file before closing and starting a new one.\n\nFrameCaptureGroupSettings -> (structure)\n\nFrame Capture Group Settings\n\nDestination -> (structure)\n\nThe destination for the frame capture files. Either the URI for an Amazon S3 bucket and object, plus a file name prefix (for example, s3ssl://sportsDelivery/highlights/20180820/curling-) or the URI for a MediaStore container, plus a file name prefix (for example, mediastoressl://sportsDelivery/20180820/curling-). The final file names consist of the prefix from the destination field (for example, “curling-“) + name modifier + the counter (5 digits, starting from 00001) + extension (which is always .jpg). For example, curling-low.00001.jpg\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFrameCaptureCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nFrameCaptureS3Settings -> (structure)\n\nFrame Capture S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsGroupSettings -> (structure)\n\nHls Group Settings\n\nAdMarkers -> (list)\n\nChoose one or more ad marker types to pass SCTE35 signals through to this group of Apple HLS outputs.\n\n(string)\n\nHls Ad Markers\n\nBaseUrlContent -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlContent1 -> (string)\n\nOptional. One value per output group. This field is required only if you are completing Base URL content A, and the downstream system has notified you that the media files for pipeline 1 of all outputs are in a location different from the media files for pipeline 0.\n\nBaseUrlManifest -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlManifest1 -> (string)\n\nOptional. One value per output group. Complete this field only if you are completing Base URL manifest A, and the downstream system has notified you that the child manifest files for pipeline 1 of all outputs are in a location different from the child manifest files for pipeline 0.\n\nCaptionLanguageMappings -> (list)\n\nMapping of up to 4 caption channels to caption languages. Is only meaningful if captionLanguageSetting is set to “insert”.\n\n(structure)\n\nMaps a caption channel to an ISO 693-2 language code (http://www.loc.gov/standards/iso639-2), with an optional description.\n\nCaptionChannel -> (integer)\n\nThe closed caption channel being described by this CaptionLanguageMapping. Each channel mapping must have a unique channel number (maximum of 4)\n\nLanguageCode -> (string)\n\nThree character ISO 639-2 language code (see http://www.loc.gov/standards/iso639-2)\n\nLanguageDescription -> (string)\n\nTextual description of language\n\nCaptionLanguageSetting -> (string)\n\nApplies only to 608 Embedded output captions. insert: Include CLOSED-CAPTIONS lines in the manifest. Specify at least one language in the CC1 Language Code field. One CLOSED-CAPTION line is added for each Language Code you specify. Make sure to specify the languages in the order in which they appear in the original source (if the source is embedded format) or the order of the caption selectors (if the source is other than embedded). Otherwise, languages in the manifest will not match up properly with the output captions. none: Include CLOSED-CAPTIONS=NONE line in the manifest. omit: Omit any CLOSED-CAPTIONS line from the manifest.\n\nClientCache -> (string)\n\nWhen set to “disabled”, sets the #EXT-X-ALLOW-CACHE:no tag in the manifest, which prevents clients from saving media segments for later replay.\n\nCodecSpecification -> (string)\n\nSpecification to use (RFC-6381 or the default RFC-4281) during m3u8 playlist generation.\n\nConstantIv -> (string)\n\nFor use with encryptionType. This is a 128-bit, 16-byte hex value represented by a 32-character text string. If ivSource is set to “explicit” then this parameter is required and is used as the IV for encryption.\n\nDestination -> (structure)\n\nA directory or HTTP destination for the HLS segments, manifest files, and encryption keys (if enabled).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nDirectoryStructure -> (string)\n\nPlace segments in subdirectories.\n\nDiscontinuityTags -> (string)\n\nSpecifies whether to insert EXT-X-DISCONTINUITY tags in the HLS child manifests for this output group. Typically, choose Insert because these tags are required in the manifest (according to the HLS specification) and serve an important purpose. Choose Never Insert only if the downstream system is doing real-time failover (without using the MediaLive automatic failover feature) and only if that downstream system has advised you to exclude the tags.\n\nEncryptionType -> (string)\n\nEncrypts the segments with the given encryption scheme. Exclude this parameter if no encryption is desired.\n\nHlsCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nHlsAkamaiSettings -> (structure)\n\nHls Akamai Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to Akamai. User should contact Akamai to enable this feature.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nSalt -> (string)\n\nSalt for authenticated Akamai.\n\nToken -> (string)\n\nToken parameter for authenticated akamai. If not specified, _gda_ is used.\n\nHlsBasicPutSettings -> (structure)\n\nHls Basic Put Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsMediaStoreSettings -> (structure)\n\nHls Media Store Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nMediaStoreStorageClass -> (string)\n\nWhen set to temporal, output files are stored in non-persistent memory for faster reading and writing.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsS3Settings -> (structure)\n\nHls S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsWebdavSettings -> (structure)\n\nHls Webdav Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to WebDAV.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsId3SegmentTagging -> (string)\n\nState of HLS ID3 Segment Tagging\n\nIFrameOnlyPlaylists -> (string)\n\nDISABLED: Do not create an I-frame-only manifest, but do create the master and media manifests (according to the Output Selection field). STANDARD: Create an I-frame-only manifest for each output that contains video, as well as the other manifests (according to the Output Selection field). The I-frame manifest contains a #EXT-X-I-FRAMES-ONLY tag to indicate it is I-frame only, and one or more #EXT-X-BYTERANGE entries identifying the I-frame position. For example, #EXT-X-BYTERANGE:160364@1461888”\n\nIncompleteSegmentBehavior -> (string)\n\nSpecifies whether to include the final (incomplete) segment in the media output when the pipeline stops producing output because of a channel stop, a channel pause or a loss of input to the pipeline. Auto means that MediaLive decides whether to include the final segment, depending on the channel class and the types of output groups. Suppress means to never include the incomplete segment. We recommend you choose Auto and let MediaLive control the behavior.\n\nIndexNSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the maximum number of segments in the media manifest file. After this maximum, older segments are removed from the media manifest. This number must be smaller than the number in the Keep Segments field.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nIvInManifest -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If set to “include”, IV is listed in the manifest, otherwise the IV is not in the manifest.\n\nIvSource -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If this setting is “followsSegmentNumber”, it will cause the IV to change every segment (to match the segment number). If this is set to “explicit”, you must enter a constantIv value.\n\nKeepSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the number of media segments to retain in the destination directory. This number should be bigger than indexNSegments (Num segments). We recommend (value = (2 x indexNsegments) + 1). If this “keep segments” number is too low, the following might happen: the player is still reading a media manifest file that lists this segment, but that segment has been removed from the destination directory (as directed by indexNSegments). This situation would result in a 404 HTTP error on the player.\n\nKeyFormat -> (string)\n\nThe value specifies how the key is represented in the resource identified by the URI. If parameter is absent, an implicit value of “identity” is used. A reverse DNS string can also be given.\n\nKeyFormatVersions -> (string)\n\nEither a single positive integer version value or a slash delimited list of version values (1/2/3).\n\nKeyProviderSettings -> (structure)\n\nThe key provider settings.\n\nStaticKeySettings -> (structure)\n\nStatic Key Settings\n\nKeyProviderServer -> (structure)\n\nThe URL of the license server used for protecting content.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nStaticKeyValue -> (string)\n\nStatic key value as a 32 character hexadecimal string.\n\nManifestCompression -> (string)\n\nWhen set to gzip, compresses HLS playlist.\n\nManifestDurationFormat -> (string)\n\nIndicates whether the output manifest should use floating point or integer values for segment duration.\n\nMinSegmentLength -> (integer)\n\nWhen set, minimumSegmentLength is enforced by looking ahead and back within the specified range for a nearby avail and extending the segment size if needed.\n\nMode -> (string)\n\nIf “vod”, all segments are indexed and kept permanently in the destination and manifest. If “live”, only the number segments specified in keepSegments and indexNSegments are kept; newer segments replace older segments, which may prevent players from rewinding all the way to the beginning of the event. VOD mode uses HLS EXT-X-PLAYLIST-TYPE of EVENT while the channel is running, converting it to a “VOD” type manifest on completion of the stream.\n\nOutputSelection -> (string)\n\nMANIFESTS_AND_SEGMENTS: Generates manifests (master manifest, if applicable, and media manifests) for this output group. VARIANT_MANIFESTS_AND_SEGMENTS: Generates media manifests for this output group, but not a master manifest. SEGMENTS_ONLY: Does not generate any manifests for this output group.\n\nProgramDateTime -> (string)\n\nIncludes or excludes EXT-X-PROGRAM-DATE-TIME tag in .m3u8 manifest files. The value is calculated as follows: either the program date and time are initialized using the input timecode source, or the time is initialized using the input timecode source and the date is initialized using the timestampOffset.\n\nProgramDateTimePeriod -> (integer)\n\nPeriod of insertion of EXT-X-PROGRAM-DATE-TIME entry, in seconds.\n\nRedundantManifest -> (string)\n\nENABLED: The master manifest (.m3u8 file) for each pipeline includes information about both pipelines: first its own media files, then the media files of the other pipeline. This feature allows playout device that support stale manifest detection to switch from one manifest to the other, when the current manifest seems to be stale. There are still two destinations and two master manifests, but both master manifests reference the media files from both pipelines. DISABLED: The master manifest (.m3u8 file) for each pipeline includes information about its own pipeline only. For an HLS output group with MediaPackage as the destination, the DISABLED behavior is always followed. MediaPackage regenerates the manifests it serves to players so a redundant manifest from MediaLive is irrelevant.\n\nSegmentLength -> (integer)\n\nLength of MPEG-2 Transport Stream segments to create (in seconds). Note that segments will end on the next keyframe after this number of seconds, so actual segment length may be longer.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSegmentsPerSubdirectory -> (integer)\n\nNumber of segments to write to a subdirectory before starting a new one. directoryStructure must be subdirectoryPerStream for this setting to have an effect.\n\nStreamInfResolution -> (string)\n\nInclude or exclude RESOLUTION attribute for video in EXT-X-STREAM-INF tag of variant manifest.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nTimestampDeltaMilliseconds -> (integer)\n\nProvides an extra millisecond delta offset to fine tune the timestamps.\n\nTsFileMode -> (string)\n\nSEGMENTED_FILES: Emit the program as segments - multiple .ts media files. SINGLE_FILE: Applies only if Mode field is VOD. Emit the program as a single .ts media file. The media manifest includes #EXT-X-BYTERANGE tags to index segments for playback. A typical use for this value is when sending the output to AWS Elemental MediaConvert, which can accept only a single media file. Playback while the channel is running is not guaranteed due to HTTP server caching.\n\nMediaPackageGroupSettings -> (structure)\n\nMedia Package Group Settings\n\nDestination -> (structure)\n\nMediaPackage channel destination.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nMsSmoothGroupSettings -> (structure)\n\nMs Smooth Group Settings\n\nAcquisitionPointId -> (string)\n\nThe ID to include in each message in the sparse track. Ignored if sparseTrackType is NONE.\n\nAudioOnlyTimecodeControl -> (string)\n\nIf set to passthrough for an audio-only MS Smooth output, the fragment absolute time will be set to the current timecode. This option does not write timecodes to the audio elementary stream.\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the https certificate chain to a trusted Certificate Authority (CA). This will cause https outputs to self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the IIS server if the connection is lost. Content will be cached during this time and the cache will be be delivered to the IIS server once the connection is re-established.\n\nDestination -> (structure)\n\nSmooth Streaming publish point on an IIS server. Elemental Live acts as a “Push” encoder to IIS.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nEventId -> (string)\n\nMS Smooth event ID to be sent to the IIS server. Should only be specified if eventIdMode is set to useConfigured.\n\nEventIdMode -> (string)\n\nSpecifies whether or not to send an event ID to the IIS server. If no event ID is sent and the same Live Event is used without changing the publishing point, clients might see cached video from the previous run. Options: - “useConfigured” - use the value provided in eventId - “useTimestamp” - generate and send an event ID based on the current timestamp - “noEventId” - do not send an event ID to the IIS server.\n\nEventStopBehavior -> (string)\n\nWhen set to sendEos, send EOS signal to IIS server when stopping the event\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nFragmentLength -> (integer)\n\nLength of mp4 fragments to generate (in seconds). Fragment length must be compatible with GOP size and framerate.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nRestartDelay -> (integer)\n\nNumber of seconds before initiating a restart due to output failure, due to exhausting the numRetries on one segment, or exceeding filecacheDuration.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSendDelayMs -> (integer)\n\nNumber of milliseconds to delay the output from the second pipeline.\n\nSparseTrackType -> (string)\n\nIdentifies the type of data to place in the sparse track: - SCTE35: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame to start a new segment. - SCTE35_WITHOUT_SEGMENTATION: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame but don’t start a new segment. - NONE: Don’t generate a sparse track for any outputs in this output group.\n\nStreamManifestBehavior -> (string)\n\nWhen set to send, send stream manifest so publishing point doesn’t start until all streams start.\n\nTimestampOffset -> (string)\n\nTimestamp offset for the event. Only used if timestampOffsetMode is set to useConfiguredOffset.\n\nTimestampOffsetMode -> (string)\n\nType of timestamp date offset to use. - useEventStartDate: Use the date the event was started as the offset - useConfiguredOffset: Use an explicitly configured date as the offset\n\nMultiplexGroupSettings -> (structure)\n\nMultiplex Group Settings\n\nRtmpGroupSettings -> (structure)\n\nRtmp Group Settings\n\nAdMarkers -> (list)\n\nChoose the ad marker type for this output group. MediaLive will create a message based on the content of each SCTE-35 message, format it for that marker type, and insert it in the datastream.\n\n(string)\n\nRtmp Ad Markers\n\nAuthenticationScheme -> (string)\n\nAuthentication scheme to use when connecting with CDN\n\nCacheFullBehavior -> (string)\n\nControls behavior when content cache fills up. If remote origin server stalls the RTMP connection and does not accept content fast enough the ‘Media Cache’ will fill up. When the cache reaches the duration specified by cacheLength the cache will stop accepting new content. If set to disconnectImmediately, the RTMP output will force a disconnect. Clear the media cache, and reconnect after restartDelay seconds. If set to waitForServer, the RTMP output will wait up to 5 minutes to allow the origin server to begin accepting data again.\n\nCacheLength -> (integer)\n\nCache length, in seconds, is used to calculate buffer size.\n\nCaptionData -> (string)\n\nControls the types of data that passes to onCaptionInfo outputs. If set to ‘all’ then 608 and 708 carried DTVCC data will be passed. If set to ‘field1AndField2608’ then DTVCC data will be stripped out, but 608 data from both fields will be passed. If set to ‘field1608’ then only the data carried in 608 from field 1 video will be passed.\n\nInputLossAction -> (string)\n\nControls the behavior of this RTMP group if input becomes unavailable. - emitOutput: Emit a slate until input returns. - pauseOutput: Stop transmitting data until input returns. This does not close the underlying RTMP connection.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nUdpGroupSettings -> (structure)\n\nUdp Group Settings\n\nInputLossAction -> (string)\n\nSpecifies behavior of last resort when input video is lost, and no more backup inputs are available. When dropTs is selected the entire transport stream will stop being emitted. When dropProgram is selected the program can be dropped from the transport stream (and replaced with null packets to meet the TS bitrate requirement). Or, when emitProgram is chosen the transport stream will continue to be produced normally with repeat frames, black frames, or slate frames substituted for the absent input video.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nOutputs -> (list)\n\nPlaceholder documentation for __listOfOutput\n\n(structure)\n\nOutput settings. There can be multiple outputs within a group.\n\nAudioDescriptionNames -> (list)\n\nThe names of the AudioDescriptions used as audio sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nCaptionDescriptionNames -> (list)\n\nThe names of the CaptionDescriptions used as caption sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nOutputName -> (string)\n\nThe name used to identify an output.\n\nOutputSettings -> (structure)\n\nOutput type-specific settings.\n\nArchiveOutputSettings -> (structure)\n\nArchive Output Settings\n\nContainerSettings -> (structure)\n\nSettings specific to the container type of the file.\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nRawSettings -> (structure)\n\nRaw Settings\n\nExtension -> (string)\n\nOutput file extension. If excluded, this will be auto-selected from the container type.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nFrameCaptureOutputSettings -> (structure)\n\nFrame Capture Output Settings\n\nNameModifier -> (string)\n\nRequired if the output group contains more than one output. This modifier forms part of the output file name.\n\nHlsOutputSettings -> (structure)\n\nHls Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nHlsSettings -> (structure)\n\nSettings regarding the underlying stream. These settings are different for audio-only outputs.\n\nAudioOnlyHlsSettings -> (structure)\n\nAudio Only Hls Settings\n\nAudioGroupId -> (string)\n\nSpecifies the group to which the audio Rendition belongs.\n\nAudioOnlyImage -> (structure)\n\nOptional. Specifies the .jpg or .png image to use as the cover art for an audio-only output. We recommend a low bit-size file because the image increases the output audio bandwidth. The image is attached to the audio as an ID3 tag, frame type APIC, picture type 0x10, as per the “ID3 tag version 2.4.0 - Native Frames” standard.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nAudioTrackType -> (string)\n\nFour types of audio-only tracks are supported: Audio-Only Variant Stream The client can play back this audio-only stream instead of video in low-bandwidth scenarios. Represented as an EXT-X-STREAM-INF in the HLS manifest. Alternate Audio, Auto Select, Default Alternate rendition that the client should try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=YES, AUTOSELECT=YES Alternate Audio, Auto Select, Not Default Alternate rendition that the client may try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=YES Alternate Audio, not Auto Select Alternate rendition that the client will not try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=NO\n\nSegmentType -> (string)\n\nSpecifies the segment type.\n\nFmp4HlsSettings -> (structure)\n\nFmp4 Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nFrameCaptureHlsSettings -> (structure)\n\nFrame Capture Hls Settings\n\nStandardHlsSettings -> (structure)\n\nStandard Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nM3u8Settings -> (structure)\n\nSettings information for the .m3u8 container\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values.\n\nEcmPid -> (string)\n\nThis parameter is unused and deprecated.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock References (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value.\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nScte35Behavior -> (string)\n\nIf set to passthrough, passes any SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Accepts “Format Identifiers”:#formatIdentifierParameters.\n\nSegmentModifier -> (string)\n\nString concatenated to end of segment filenames.\n\nMediaPackageOutputSettings -> (structure)\n\nMedia Package Output Settings\n\nMsSmoothOutputSettings -> (structure)\n\nMs Smooth Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nMultiplexOutputSettings -> (structure)\n\nMultiplex Output Settings\n\nDestination -> (structure)\n\nDestination is a Multiplex.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRtmpOutputSettings -> (structure)\n\nRtmp Output Settings\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the tls certificate chain to a trusted Certificate Authority (CA). This will cause rtmps outputs with self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying a connection to the Flash Media server if the connection is lost.\n\nDestination -> (structure)\n\nThe RTMP endpoint excluding the stream name (eg. rtmp://host/appname). For connection to Akamai, a username and password must be supplied. URI fields accept format identifiers.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nUdpOutputSettings -> (structure)\n\nUdp Output Settings\n\nBufferMsec -> (integer)\n\nUDP output buffering in milliseconds. Larger values increase latency through the transcoder but simultaneously assist the transcoder in maintaining a constant, low-jitter UDP/RTP output while accommodating clock recovery, input switching, input disruptions, picture reordering, etc.\n\nContainerSettings -> (structure)\n\nUdp Container Settings\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nDestination -> (structure)\n\nDestination address and port number for RTP or UDP packets. Can be unicast or multicast RTP or UDP (eg. rtp://239.10.10.10:5001 or udp://10.100.100.100:5002).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFecOutputSettings -> (structure)\n\nSettings for enabling and adjusting Forward Error Correction on UDP outputs.\n\nColumnDepth -> (integer)\n\nParameter D from SMPTE 2022-1. The height of the FEC protection matrix. The number of transport stream packets per column error correction packet. Must be between 4 and 20, inclusive.\n\nIncludeFec -> (string)\n\nEnables column only or column and row based FEC\n\nRowLength -> (integer)\n\nParameter L from SMPTE 2022-1. The width of the FEC protection matrix. Must be between 1 and 20, inclusive. If only Column FEC is used, then larger values increase robustness. If Row FEC is used, then this is the number of transport stream packets per row error correction packet, and the value must be between 4 and 20, inclusive, if includeFec is columnAndRow. If includeFec is column, this value must be 1 to 20, inclusive.\n\nVideoDescriptionName -> (string)\n\nThe name of the VideoDescription used as the source for this output.\n\nTimecodeConfig -> (structure)\n\nContains settings used to acquire and adjust timecode information from inputs.\n\nSource -> (string)\n\nIdentifies the source for the timecode that will be associated with the events outputs. -Embedded (embedded): Initialize the output timecode with timecode from the the source. If no embedded timecode is detected in the source, the system falls back to using “Start at 0” (zerobased). -System Clock (systemclock): Use the UTC time. -Start at 0 (zerobased): The time of the first frame of the event will be 00:00:00:00.\n\nSyncThreshold -> (integer)\n\nThreshold in frames beyond which output timecode is resynchronized to the input timecode. Discrepancies below this threshold are permitted to avoid unnecessary discontinuities in the output timecode. No timecode sync when this is not specified.\n\nVideoDescriptions -> (list)\n\nPlaceholder documentation for __listOfVideoDescription\n\n(structure)\n\nVideo settings for this stream.\n\nCodecSettings -> (structure)\n\nVideo codec settings.\n\nFrameCaptureSettings -> (structure)\n\nFrame Capture Settings\n\nCaptureInterval -> (integer)\n\nThe frequency at which to capture frames for inclusion in the output. May be specified in either seconds or milliseconds, as specified by captureIntervalUnits.\n\nCaptureIntervalUnits -> (string)\n\nUnit for the frame capture interval.\n\nH264Settings -> (structure)\n\nH264 Settings\n\nAdaptiveQuantization -> (string)\n\nEnables or disables adaptive quantization, which is a technique MediaLive can apply to video on a frame-by-frame basis to produce more compression without losing quality. There are three types of adaptive quantization: flicker, spatial, and temporal. Set the field in one of these ways: Set to Auto. Recommended. For each type of AQ, MediaLive will determine if AQ is needed, and if so, the appropriate strength. Set a strength (a value other than Auto or Disable). This strength will apply to any of the AQ fields that you choose to enable. Set to Disabled to disable all types of adaptive quantization.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufFillPct -> (integer)\n\nPercentage of the buffer that should initially be filled (HRD buffer model).\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nEntropyEncoding -> (string)\n\nEntropy encoding mode. Use cabac (must be in Main or High profile) or cavlc.\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nFlicker AQ makes adjustments within each frame to reduce flicker or ‘pop’ on I-frames. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if flicker AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply flicker AQ using the specified strength. Disabled: MediaLive won’t apply flicker AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply flicker AQ.\n\nForceFieldPictures -> (string)\n\nThis setting applies only when scan type is “interlaced.” It controls whether coding is performed on a field basis or on a frame basis. (When the video is progressive, the coding is always performed on a frame basis.) enabled: Force MediaLive to code on a field basis, so that odd and even sets of fields are coded separately. disabled: Code the two sets of fields separately (on a field basis) or together (on a frame basis using PAFF), depending on what is most appropriate for the content.\n\nFramerateControl -> (string)\n\nThis field indicates how the output video frame rate is specified. If “specified” is selected then the output video frame rate is determined by framerateNumerator and framerateDenominator, else if “initializeFromSource” is selected then the output video frame rate will be set equal to the input video frame rate of the first input.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopBReference -> (string)\n\nDocumentation update needed\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopNumBFrames -> (integer)\n\nNumber of B-frames between reference frames.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.264 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level For VBR: Set the maximum bitrate in order to accommodate expected spikes in the complexity of the video.\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nNumRefFrames -> (integer)\n\nNumber of reference frames to use. The encoder may use more than requested if using B-frames and/or interlaced encoding.\n\nParControl -> (string)\n\nThis field indicates how the output pixel aspect ratio is specified. If “specified” is selected then the output video pixel aspect ratio is determined by parNumerator and parDenominator, else if “initializeFromSource” is selected then the output pixsel aspect ratio will be set equal to the input video pixel aspect ratio of the first input.\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.264 Profile.\n\nQualityLevel -> (string)\n\nLeave as STANDARD_QUALITY or choose a different value (which might result in additional costs to run the channel). - ENHANCED_QUALITY: Produces a slightly better video quality without an increase in the bitrate. Has an effect only when the Rate control mode is QVBR or CBR. If this channel is in a MediaLive multiplex, the value must be ENHANCED_QUALITY. - STANDARD_QUALITY: Valid for any Rate control mode.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. You can set a target quality or you can let MediaLive determine the best quality. To set a target quality, enter values in the QVBR quality level field and the Max bitrate field. Enter values that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M To let MediaLive decide, leave the QVBR quality level field empty, and in Max bitrate enter the maximum rate you want in the video. For more information, see the section called “Video - rate control mode” in the MediaLive user guide\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. VBR: Quality and bitrate vary, depending on the video complexity. Recommended instead of QVBR if you want to maintain a specific average bitrate over the duration of the channel. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection. - On: inserts I-frames when scene change is detected. - Off: does not force an I-frame when scene change is detected.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nSoftness -> (integer)\n\nSoftness. Selects quantizer matrix, larger values reduce high-frequency content in the encoded image. If not set to zero, must be greater than 15.\n\nSpatialAq -> (string)\n\nSpatial AQ makes adjustments within each frame based on spatial variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if spatial AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply spatial AQ using the specified strength. Disabled: MediaLive won’t apply spatial AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply spatial AQ.\n\nSubgopLength -> (string)\n\nIf set to fixed, use gopNumBFrames B-frames per sub-GOP. If set to dynamic, optimize the number of B-frames used for each sub-GOP to improve visual quality.\n\nSyntax -> (string)\n\nProduces a bitstream compliant with SMPTE RP-2027.\n\nTemporalAq -> (string)\n\nTemporal makes adjustments within each frame based on temporal variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if temporal AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply temporal AQ using the specified strength. Disabled: MediaLive won’t apply temporal AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply temporal AQ.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nH265Settings -> (structure)\n\nH265 Settings\n\nAdaptiveQuantization -> (string)\n\nAdaptive quantization. Allows intra-frame quantizers to vary to improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nAlternativeTransferFunction -> (string)\n\nWhether or not EML should insert an Alternative Transfer Function SEI message to support backwards compatibility with non-HDR decoders and displays.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nIf set to enabled, adjust quantization within each frame to reduce flicker or ‘pop’ on I-frames.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.265 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.265 Profile.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. Set values for the QVBR quality level field and Max bitrate field that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nTier -> (string)\n\nH.265 Tier.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nMpeg2Settings -> (structure)\n\nMpeg2 Settings\n\nAdaptiveQuantization -> (string)\n\nChoose Off to disable adaptive quantization. Or choose another value to enable the quantizer and set its strength. The strengths are: Auto, Off, Low, Medium, High. When you enable this field, MediaLive allows intra-frame quantizers to vary, which might improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates the AFD values that MediaLive will write into the video encode. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose AUTO. AUTO: MediaLive will try to preserve the input AFD value (in cases where multiple AFD values are valid). FIXED: MediaLive will use the value you specify in fixedAFD.\n\nColorMetadata -> (string)\n\nSpecifies whether to include the color space metadata. The metadata describes the color space that applies to the video (the colorSpace field). We recommend that you insert the metadata.\n\nColorSpace -> (string)\n\nChoose the type of color space conversion to apply to the output. For detailed information on setting up both the input and the output to obtain the desired color space in the output, see the section on “MediaLive Features - Video - color space” in the MediaLive User Guide. PASSTHROUGH: Keep the color space of the input content - do not convert it. AUTO:Convert all content that is SD to rec 601, and convert all content that is HD to rec 709.\n\nDisplayAspectRatio -> (string)\n\nSets the pixel aspect ratio for the encode.\n\nFilterSettings -> (structure)\n\nOptionally specify a noise reduction filter, which can improve quality of compressed content. If you do not choose a filter, no filter will be applied. TEMPORAL: This filter is useful for both source content that is noisy (when it has excessive digital artifacts) and source content that is clean. When the content is noisy, the filter cleans up the source content before the encoding phase, with these two effects: First, it improves the output video quality because the content has been cleaned up. Secondly, it decreases the bandwidth because MediaLive does not waste bits on encoding noise. When the content is reasonably clean, the filter tends to decrease the bitrate.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nComplete this field only when afdSignaling is set to FIXED. Enter the AFD value (4 bits) to write on all frames of the video encode.\n\nFramerateDenominator -> (integer)\n\ndescription”: “The framerate denominator. For example, 1001. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nFramerateNumerator -> (integer)\n\nThe framerate numerator. For example, 24000. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nGopClosedCadence -> (integer)\n\nMPEG2: default is open GOP.\n\nGopNumBFrames -> (integer)\n\nRelates to the GOP structure. The number of B-frames between reference frames. If you do not know what a B-frame is, use the default.\n\nGopSize -> (double)\n\nRelates to the GOP structure. The GOP size (keyframe interval) in the units specified in gopSizeUnits. If you do not know what GOP is, use the default. If gopSizeUnits is frames, then the gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, the gopSize must be greater than 0, but does not need to be an integer.\n\nGopSizeUnits -> (string)\n\nRelates to the GOP structure. Specifies whether the gopSize is specified in frames or seconds. If you do not plan to change the default gopSize, leave the default. If you specify SECONDS, MediaLive will internally convert the gop size to a frame count.\n\nScanType -> (string)\n\nSet the scan type of the output to PROGRESSIVE or INTERLACED (top field first).\n\nSubgopLength -> (string)\n\nRelates to the GOP structure. If you do not know what GOP is, use the default. FIXED: Set the number of B-frames in each sub-GOP to the value in gopNumBFrames. DYNAMIC: Let MediaLive optimize the number of B-frames in each sub-GOP, to improve visual quality.\n\nTimecodeInsertion -> (string)\n\nDetermines how MediaLive inserts timecodes in the output video. For detailed information about setting up the input and the output for a timecode, see the section on “MediaLive Features - Timecode configuration” in the MediaLive User Guide. DISABLED: do not include timecodes. GOP_TIMECODE: Include timecode metadata in the GOP header.\n\nHeight -> (integer)\n\nOutput video height, in pixels. Must be an even number. For most codecs, you can leave this field and width blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nName -> (string)\n\nThe name of this VideoDescription. Outputs will use this name to uniquely identify this Description. Description names should be unique within this Live Event.\n\nRespondToAfd -> (string)\n\nIndicates how MediaLive will respond to the AFD values that might be in the input video. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose PASSTHROUGH. RESPOND: MediaLive clips the input video using a formula that uses the AFD values (configured in afdSignaling ), the input display aspect ratio, and the output display aspect ratio. MediaLive also includes the AFD values in the output, unless the codec for this encode is FRAME_CAPTURE. PASSTHROUGH: MediaLive ignores the AFD values and does not clip the video. But MediaLive does include the values in the output. NONE: MediaLive does not clip the input video and does not include the AFD values in the output\n\nScalingBehavior -> (string)\n\nSTRETCH_TO_OUTPUT configures the output position to stretch the video to the specified output resolution (height and width). This option will override any position value. DEFAULT may insert black boxes (pillar boxes or letter boxes) around the video to provide the specified output resolution.\n\nSharpness -> (integer)\n\nChanges the strength of the anti-alias filter used for scaling. 0 is the softest setting, 100 is the sharpest. A setting of 50 is recommended for most content.\n\nWidth -> (integer)\n\nOutput video width, in pixels. Must be an even number. For most codecs, you can leave this field and height blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nId -> (string)\n\nThe unique id of the channel.\n\nInputAttachments -> (list)\n\nList of input attachments for channel.\n\n(structure)\n\nPlaceholder documentation for InputAttachment\n\nAutomaticInputFailoverSettings -> (structure)\n\nUser-specified settings for defining what the conditions are for declaring the input unhealthy and failing over to a different input.\n\nErrorClearTimeMsec -> (integer)\n\nThis clear time defines the requirement a recovered input must meet to be considered healthy. The input must have no failover conditions for this length of time. Enter a time in milliseconds. This value is particularly important if the input_preference for the failover pair is set to PRIMARY_INPUT_PREFERRED, because after this time, MediaLive will switch back to the primary input.\n\nFailoverConditions -> (list)\n\nA list of failover conditions. If any of these conditions occur, MediaLive will perform a failover to the other input.\n\n(structure)\n\nFailover Condition settings. There can be multiple failover conditions inside AutomaticInputFailoverSettings.\n\nFailoverConditionSettings -> (structure)\n\nFailover condition type-specific settings.\n\nAudioSilenceSettings -> (structure)\n\nMediaLive will perform a failover if the specified audio selector is silent for the specified period.\n\nAudioSelectorName -> (string)\n\nThe name of the audio selector in the input that MediaLive should monitor to detect silence. Select your most important rendition. If you didn’t create an audio selector in this input, leave blank.\n\nAudioSilenceThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be silent before automatic input failover occurs. Silence is defined as audio loss or audio quieter than -50 dBFS.\n\nInputLossSettings -> (structure)\n\nMediaLive will perform a failover if content is not detected in this input for the specified period.\n\nInputLossThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that no input is detected. After that time, an input failover will occur.\n\nVideoBlackSettings -> (structure)\n\nMediaLive will perform a failover if content is considered black for the specified period.\n\nBlackDetectThreshold -> (double)\n\nA value used in calculating the threshold below which MediaLive considers a pixel to be ‘black’. For the input to be considered black, every pixel in a frame must be below this threshold. The threshold is calculated as a percentage (expressed as a decimal) of white. Therefore .1 means 10% white (or 90% black). Note how the formula works for any color depth. For example, if you set this field to 0.1 in 10-bit color depth: (1023*0.1=102.3), which means a pixel value of 102 or less is ‘black’. If you set this field to .1 in an 8-bit color depth: (255*0.1=25.5), which means a pixel value of 25 or less is ‘black’. The range is 0.0 to 1.0, with any number of decimal places.\n\nVideoBlackThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be black before automatic input failover occurs.\n\nInputPreference -> (string)\n\nInput preference when deciding which input to make active when a previously failed input has recovered.\n\nSecondaryInputId -> (string)\n\nThe input ID of the secondary input in the automatic input failover pair.\n\nInputAttachmentName -> (string)\n\nUser-specified name for the attachment. This is required if the user wants to use this input in an input switch action.\n\nInputId -> (string)\n\nThe ID of the input\n\nInputSettings -> (structure)\n\nSettings of an input (caption selector, etc.)\n\nAudioSelectors -> (list)\n\nUsed to select the audio stream to decode for inputs that have multiple available.\n\n(structure)\n\nAudio Selector\n\nName -> (string)\n\nThe name of this AudioSelector. AudioDescriptions will use this name to uniquely identify this Selector. Selector names should be unique per input.\n\nSelectorSettings -> (structure)\n\nThe audio selector settings.\n\nAudioHlsRenditionSelection -> (structure)\n\nAudio Hls Rendition Selection\n\nGroupId -> (string)\n\nSpecifies the GROUP-ID in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nName -> (string)\n\nSpecifies the NAME in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nAudioLanguageSelection -> (structure)\n\nAudio Language Selection\n\nLanguageCode -> (string)\n\nSelects a specific three-letter language code from within an audio source.\n\nLanguageSelectionPolicy -> (string)\n\nWhen set to “strict”, the transport stream demux strictly identifies audio streams by their language descriptor. If a PMT update occurs such that an audio stream matching the initially selected language is no longer present then mute will be encoded until the language returns. If “loose”, then on a PMT update the demux will choose another audio stream in the program with the same stream type if it can’t find one with the same language.\n\nAudioPidSelection -> (structure)\n\nAudio Pid Selection\n\nPid -> (integer)\n\nSelects a specific PID from within a source.\n\nAudioTrackSelection -> (structure)\n\nAudio Track Selection\n\nTracks -> (list)\n\nSelects one or more unique audio tracks from within a source.\n\n(structure)\n\nAudio Track\n\nTrack -> (integer)\n\n1-based integer value that maps to a specific audio track\n\nCaptionSelectors -> (list)\n\nUsed to select the caption input to use for inputs that have multiple available.\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nLanguageCode -> (string)\n\nWhen specified this field indicates the three letter language code of the caption track to extract from the source.\n\nName -> (string)\n\nName identifier for a caption selector. This name is used to associate this caption selector with one or more caption descriptions. Names must be unique within an event.\n\nSelectorSettings -> (structure)\n\nCaption selector settings.\n\nAncillarySourceSettings -> (structure)\n\nAncillary Source Settings\n\nSourceAncillaryChannelNumber -> (integer)\n\nSpecifies the number (1 to 4) of the captions channel you want to extract from the ancillary captions. If you plan to convert the ancillary captions to another format, complete this field. If you plan to choose Embedded as the captions destination in the output (to pass through all the channels in the ancillary captions), leave this field blank because MediaLive ignores the field.\n\nAribSourceSettings -> (structure)\n\nArib Source Settings\n\nDvbSubSourceSettings -> (structure)\n\nDvb Sub Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nWhen using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through, regardless of selectors.\n\nEmbeddedSourceSettings -> (structure)\n\nEmbedded Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nScte20Detection -> (string)\n\nSet to “auto” to handle streams with intermittent and/or non-aligned SCTE-20 and Embedded captions.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nSource608TrackNumber -> (integer)\n\nThis field is unused and deprecated.\n\nScte20SourceSettings -> (structure)\n\nScte20 Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nScte27SourceSettings -> (structure)\n\nScte27 Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nThe pid field is used in conjunction with the caption selector languageCode field as follows: - Specify PID and Language: Extracts captions from that PID; the language is “informational”. - Specify PID and omit Language: Extracts the specified PID. - Omit PID and specify Language: Extracts the specified language, whichever PID that happens to be. - Omit PID and omit Language: Valid only if source is DVB-Sub that is being passed through; all languages will be passed through.\n\nTeletextSourceSettings -> (structure)\n\nTeletext Source Settings\n\nOutputRectangle -> (structure)\n\nOptionally defines a region where TTML style captions will be displayed\n\nHeight -> (double)\n\nSee the description in leftOffset. For height, specify the entire height of the rectangle as a percentage of the underlying frame height. For example, “80” means the rectangle height is 80% of the underlying frame height. The topOffset and rectangleHeight must add up to 100% or less. This field corresponds to tts:extent - Y in the TTML standard.\n\nLeftOffset -> (double)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. (Make sure to leave the default if you don’t have either of these formats in the output.) You can define a display rectangle for the captions that is smaller than the underlying video frame. You define the rectangle by specifying the position of the left edge, top edge, bottom edge, and right edge of the rectangle, all within the underlying video frame. The units for the measurements are percentages. If you specify a value for one of these fields, you must specify a value for all of them. For leftOffset, specify the position of the left edge of the rectangle, as a percentage of the underlying frame width, and relative to the left edge of the frame. For example, “10” means the measurement is 10% of the underlying frame width. The rectangle left edge starts at that position from the left edge of the frame. This field corresponds to tts:origin - X in the TTML standard.\n\nTopOffset -> (double)\n\nSee the description in leftOffset. For topOffset, specify the position of the top edge of the rectangle, as a percentage of the underlying frame height, and relative to the top edge of the frame. For example, “10” means the measurement is 10% of the underlying frame height. The rectangle top edge starts at that position from the top edge of the frame. This field corresponds to tts:origin - Y in the TTML standard.\n\nWidth -> (double)\n\nSee the description in leftOffset. For width, specify the entire width of the rectangle as a percentage of the underlying frame width. For example, “80” means the rectangle width is 80% of the underlying frame width. The leftOffset and rectangleWidth must add up to 100% or less. This field corresponds to tts:extent - X in the TTML standard.\n\nPageNumber -> (string)\n\nSpecifies the teletext page number within the data stream from which to extract captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should be specified as a hexadecimal string with no “0x” prefix.\n\nDeblockFilter -> (string)\n\nEnable or disable the deblock filter when filtering.\n\nDenoiseFilter -> (string)\n\nEnable or disable the denoise filter when filtering.\n\nFilterStrength -> (integer)\n\nAdjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).\n\nInputFilter -> (string)\n\nTurns on the filter for this input. MPEG-2 inputs have the deblocking filter enabled by default. 1) auto - filtering will be applied depending on input type/quality 2) disabled - no filtering will be applied to the input 3) forced - filtering will be applied regardless of input type\n\nNetworkInputSettings -> (structure)\n\nInput settings.\n\nHlsInputSettings -> (structure)\n\nSpecifies HLS input settings when the uri is for a HLS manifest.\n\nBandwidth -> (integer)\n\nWhen specified the HLS stream with the m3u8 BANDWIDTH that most closely matches this value will be chosen, otherwise the highest bandwidth stream in the m3u8 will be chosen. The bitrate is specified in bits per second, as in an HLS manifest.\n\nBufferSegments -> (integer)\n\nWhen specified, reading of the HLS input will begin this many buffer segments from the end (most recently written segment). When not specified, the HLS input will begin with the first segment specified in the m3u8.\n\nRetries -> (integer)\n\nThe number of consecutive times that attempts to read a manifest or segment must fail before the input is considered unavailable.\n\nRetryInterval -> (integer)\n\nThe number of seconds between retries when an attempt to read a manifest or segment fails.\n\nScte35Source -> (string)\n\nIdentifies the source for the SCTE-35 messages that MediaLive will ingest. Messages can be ingested from the content segments (in the stream) or from tags in the playlist (the HLS manifest). MediaLive ignores SCTE-35 information in the source that is not selected.\n\nServerValidation -> (string)\n\nCheck HTTPS server certificates. When set to checkCryptographyOnly, cryptography in the certificate will be checked, but not the server’s name. Certain subdomains (notably S3 buckets that use dots in the bucket name) do not strictly match the corresponding certificate’s wildcard pattern and would otherwise cause the event to error. This setting is ignored for protocols that do not use https.\n\nSmpte2038DataPreference -> (string)\n\nSpecifies whether to extract applicable ancillary data from a SMPTE-2038 source in this input. Applicable data types are captions, timecode, AFD, and SCTE-104 messages. - PREFER: Extract from SMPTE-2038 if present in this input, otherwise extract from another source (if any). - IGNORE: Never extract any ancillary data from SMPTE-2038.\n\nSourceEndBehavior -> (string)\n\nLoop input if it is a file. This allows a file input to be streamed indefinitely.\n\nVideoSelector -> (structure)\n\nInforms which video elementary stream to decode for input types that have multiple available.\n\nColorSpace -> (string)\n\nSpecifies the color space of an input. This setting works in tandem with colorSpaceUsage and a video description’s colorSpaceSettingsChoice to determine if any conversion will be performed.\n\nColorSpaceSettings -> (structure)\n\nColor space settings\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nColorSpaceUsage -> (string)\n\nApplies only if colorSpace is a value other than follow. This field controls how the value in the colorSpace field will be used. fallback means that when the input does include color space data, that data will be used, but when the input has no color space data, the value in colorSpace will be used. Choose fallback if your input is sometimes missing color space data, but when it does have color space data, that data is correct. force means to always use the value in colorSpace. Choose force if your input usually has no color space data or might have unreliable color space data.\n\nSelectorSettings -> (structure)\n\nThe video selector settings.\n\nVideoSelectorPid -> (structure)\n\nVideo Selector Pid\n\nPid -> (integer)\n\nSelects a specific PID from within a video source.\n\nVideoSelectorProgramId -> (structure)\n\nVideo Selector Program Id\n\nProgramId -> (integer)\n\nSelects a specific program from within a multi-program transport stream. If the program doesn’t exist, the first program within the transport stream will be selected by default.\n\nInputSpecification -> (structure)\n\nSpecification of network and file inputs for this channel\n\nCodec -> (string)\n\nInput codec\n\nMaximumBitrate -> (string)\n\nMaximum input bitrate, categorized coarsely\n\nResolution -> (string)\n\nInput resolution, categorized coarsely\n\nLogLevel -> (string)\n\nThe log level being written to CloudWatch Logs.\n\nName -> (string)\n\nThe name of the channel. (user-mutable)\n\nPipelineDetails -> (list)\n\nRuntime details for the pipelines of a running channel.\n\n(structure)\n\nRuntime details of a pipeline when a channel is running.\n\nActiveInputAttachmentName -> (string)\n\nThe name of the active input attachment currently being ingested by this pipeline.\n\nActiveInputSwitchActionName -> (string)\n\nThe name of the input switch schedule action that occurred most recently and that resulted in the switch to the current input attachment for this pipeline.\n\nActiveMotionGraphicsActionName -> (string)\n\nThe name of the motion graphics activate action that occurred most recently and that resulted in the current graphics URI for this pipeline.\n\nActiveMotionGraphicsUri -> (string)\n\nThe current URI being used for HTML5 motion graphics for this pipeline.\n\nPipelineId -> (string)\n\nPipeline ID\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role assumed when running the Channel.\n\nState -> (string)\n\nPlaceholder documentation for ChannelState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nVpc -> (structure)\n\nSettings for VPC output\n\nAvailabilityZones -> (list)\n\nThe Availability Zones where the vpc subnets are located. The first Availability Zone applies to the first subnet in the list of subnets. The second Availability Zone applies to the second subnet.\n\n(string)\n\nPlaceholder documentation for __string\n\nNetworkInterfaceIds -> (list)\n\nA list of Elastic Network Interfaces created by MediaLive in the customer’s VPC\n\n(string)\n\nPlaceholder documentation for __string\n\nSecurityGroupIds -> (list)\n\nA list of up EC2 VPC security group IDs attached to the Output VPC network interfaces.\n\n(string)\n\nPlaceholder documentation for __string\n\nSubnetIds -> (list)\n\nA list of VPC subnet IDs from the same VPC. If STANDARD channel, subnet IDs must be mapped to two unique availability zones (AZ).\n\n(string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "delete-input",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/delete-input.html",
      "command_description": "Description\n\nDeletes the input end point\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-input\n--input-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-id (string) Unique ID of the input\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "delete-input-security-group",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/delete-input-security-group.html",
      "command_description": "Description\n\nDeletes an Input Security Group\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-input-security-group\n--input-security-group-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-security-group-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-security-group-id (string) The Input Security Group to delete\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "delete-multiplex",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/delete-multiplex.html",
      "command_description": "Description\n\nDelete a multiplex. The multiplex must be idle.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-multiplex\n--multiplex-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--multiplex-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--multiplex-id (string) The ID of the multiplex.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe unique arn of the multiplex.\n\nAvailabilityZones -> (list)\n\nA list of availability zones for the multiplex.\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the multiplex output destinations.\n\n(structure)\n\nMultiplex output destination settings\n\nMediaConnectSettings -> (structure)\n\nMultiplex MediaConnect output destination settings.\n\nEntitlementArn -> (string)\n\nThe MediaConnect entitlement ARN available as a Flow source.\n\nId -> (string)\n\nThe unique id of the multiplex.\n\nMultiplexSettings -> (structure)\n\nConfiguration for a multiplex event.\n\nMaximumVideoBufferDelayMilliseconds -> (integer)\n\nMaximum video buffer delay in milliseconds.\n\nTransportStreamBitrate -> (integer)\n\nTransport stream bit rate.\n\nTransportStreamId -> (integer)\n\nTransport stream ID.\n\nTransportStreamReservedBitrate -> (integer)\n\nTransport stream reserved bit rate.\n\nName -> (string)\n\nThe name of the multiplex.\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nProgramCount -> (integer)\n\nThe number of programs in the multiplex.\n\nState -> (string)\n\nThe current state of the multiplex.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "delete-multiplex-program",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/delete-multiplex-program.html",
      "command_description": "Description\n\nDelete a program from a multiplex.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-multiplex-program\n--multiplex-id <value>\n--program-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--multiplex-id <value>",
        "--program-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--multiplex-id (string) The ID of the multiplex that the program belongs to.\n\n--program-name (string) The multiplex program name.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nChannelId -> (string)\n\nThe MediaLive channel associated with the program.\n\nMultiplexProgramSettings -> (structure)\n\nThe settings for this multiplex program.\n\nPreferredChannelPipeline -> (string)\n\nIndicates which pipeline is preferred by the multiplex for program ingest.\n\nProgramNumber -> (integer)\n\nUnique program number.\n\nServiceDescriptor -> (structure)\n\nTransport stream service descriptor configuration for the Multiplex program.\n\nProviderName -> (string)\n\nName of the provider.\n\nServiceName -> (string)\n\nName of the service.\n\nVideoSettings -> (structure)\n\nProgram video settings configuration.\n\nConstantBitrate -> (integer)\n\nThe constant bitrate configuration for the video encode. When this field is defined, StatmuxSettings must be undefined.\n\nStatmuxSettings -> (structure)\n\nStatmux rate control settings. When this field is defined, ConstantBitrate must be undefined.\n\nMaximumBitrate -> (integer)\n\nMaximum statmux bitrate.\n\nMinimumBitrate -> (integer)\n\nMinimum statmux bitrate.\n\nPriority -> (integer)\n\nThe purpose of the priority is to use a combination of thenmultiplex rate control algorithm and the QVBR capability of thenencoder to prioritize the video quality of some channels in anmultiplex over others. Channels that have a higher priority willnget higher video quality at the expense of the video quality ofnother channels in the multiplex with lower priority.\n\nPacketIdentifiersMap -> (structure)\n\nThe packet identifier map for this multiplex program.\n\nAudioPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nDvbSubPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nDvbTeletextPid -> (integer)\n\nPlaceholder documentation for __integer\n\nEtvPlatformPid -> (integer)\n\nPlaceholder documentation for __integer\n\nEtvSignalPid -> (integer)\n\nPlaceholder documentation for __integer\n\nKlvDataPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nPcrPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPmtPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPrivateMetadataPid -> (integer)\n\nPlaceholder documentation for __integer\n\nScte27Pids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nScte35Pid -> (integer)\n\nPlaceholder documentation for __integer\n\nTimedMetadataPid -> (integer)\n\nPlaceholder documentation for __integer\n\nVideoPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPipelineDetails -> (list)\n\nContains information about the current sources for the specified program in the specified multiplex. Keep in mind that each multiplex pipeline connects to both pipelines in a given source channel (the channel identified by the program). But only one of those channel pipelines is ever active at one time.\n\n(structure)\n\nThe current source for one of the pipelines in the multiplex.\n\nActiveChannelPipeline -> (string)\n\nIdentifies the channel pipeline that is currently active for the pipeline (identified by PipelineId) in the multiplex.\n\nPipelineId -> (string)\n\nIdentifies a specific pipeline in the multiplex.\n\nProgramName -> (string)\n\nThe name of the multiplex program."
    },
    {
      "command_name": "delete-reservation",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/delete-reservation.html",
      "command_description": "Description\n\nDelete an expired reservation.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-reservation\n--reservation-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--reservation-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--reservation-id (string) Unique reservation ID, e.g. ‘1234567’\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nUnique reservation ARN, e.g. ‘arn:aws:medialive:us-west-2:123456789012:reservation:1234567’\n\nCount -> (integer)\n\nNumber of reserved resources\n\nCurrencyCode -> (string)\n\nCurrency code for usagePrice and fixedPrice in ISO-4217 format, e.g. ‘USD’\n\nDuration -> (integer)\n\nLease duration, e.g. ‘12’\n\nDurationUnits -> (string)\n\nUnits for duration, e.g. ‘MONTHS’\n\nEnd -> (string)\n\nReservation UTC end date and time in ISO-8601 format, e.g. ‘2019-03-01T00:00:00’\n\nFixedPrice -> (double)\n\nOne-time charge for each reserved resource, e.g. ‘0.0’ for a NO_UPFRONT offering\n\nName -> (string)\n\nUser specified reservation name\n\nOfferingDescription -> (string)\n\nOffering description, e.g. ‘HD AVC output at 10-20 Mbps, 30 fps, and standard VQ in US West (Oregon)’\n\nOfferingId -> (string)\n\nUnique offering ID, e.g. ‘87654321’\n\nOfferingType -> (string)\n\nOffering type, e.g. ‘NO_UPFRONT’\n\nRegion -> (string)\n\nAWS region, e.g. ‘us-west-2’\n\nReservationId -> (string)\n\nUnique reservation ID, e.g. ‘1234567’\n\nResourceSpecification -> (structure)\n\nResource configuration details\n\nChannelClass -> (string)\n\nChannel class, e.g. ‘STANDARD’\n\nCodec -> (string)\n\nCodec, e.g. ‘AVC’\n\nMaximumBitrate -> (string)\n\nMaximum bitrate, e.g. ‘MAX_20_MBPS’\n\nMaximumFramerate -> (string)\n\nMaximum framerate, e.g. ‘MAX_30_FPS’ (Outputs only)\n\nResolution -> (string)\n\nResolution, e.g. ‘HD’\n\nResourceType -> (string)\n\nResource type, ‘INPUT’, ‘OUTPUT’, ‘MULTIPLEX’, or ‘CHANNEL’\n\nSpecialFeature -> (string)\n\nSpecial feature, e.g. ‘AUDIO_NORMALIZATION’ (Channels only)\n\nVideoQuality -> (string)\n\nVideo quality, e.g. ‘STANDARD’ (Outputs only)\n\nStart -> (string)\n\nReservation UTC start date and time in ISO-8601 format, e.g. ‘2018-03-01T00:00:00’\n\nState -> (string)\n\nCurrent state of reservation, e.g. ‘ACTIVE’\n\nTags -> (map)\n\nA collection of key-value pairs\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nUsagePrice -> (double)\n\nRecurring usage charge for each reserved resource, e.g. ‘157.0’"
    },
    {
      "command_name": "delete-schedule",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/delete-schedule.html",
      "command_description": "Description\n\nDelete all schedule actions on a channel.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-schedule\n--channel-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-id (string) Id of the channel whose schedule is being deleted.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "delete-tags",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/delete-tags.html",
      "command_description": "Description\n\nRemoves tags for a resource\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-tags\n--resource-arn <value>\n--tag-keys <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "--tag-keys <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string) Placeholder documentation for __string\n\n--tag-keys (list) An array of tag keys to delete(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "describe-channel",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/describe-channel.html",
      "command_description": "Description\n\nGets details about a channel\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-channel\n--channel-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-id (string) channel ID\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe unique arn of the channel.\n\nCdiInputSpecification -> (structure)\n\nSpecification of CDI inputs for this channel\n\nResolution -> (string)\n\nMaximum CDI input resolution\n\nChannelClass -> (string)\n\nThe class for this channel. STANDARD for a channel with two pipelines or SINGLE_PIPELINE for a channel with one pipeline.\n\nDestinations -> (list)\n\nA list of destinations of the channel. For UDP outputs, there is one destination per output. For other types (HLS, for example), there is one destination per packager.\n\n(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nEgressEndpoints -> (list)\n\nThe endpoints where outgoing connections initiate from\n\n(structure)\n\nPlaceholder documentation for ChannelEgressEndpoint\n\nSourceIp -> (string)\n\nPublic IP of where a channel’s output comes from\n\nEncoderSettings -> (structure)\n\nEncoder Settings\n\nAudioDescriptions -> (list)\n\nPlaceholder documentation for __listOfAudioDescription\n\n(structure)\n\nAudio Description\n\nAudioNormalizationSettings -> (structure)\n\nAdvanced audio normalization settings.\n\nAlgorithm -> (string)\n\nAudio normalization algorithm to use. itu17701 conforms to the CALM Act specification, itu17702 conforms to the EBU R-128 specification.\n\nAlgorithmControl -> (string)\n\nWhen set to correctAudio the output audio is corrected using the chosen algorithm. If set to measureOnly, the audio will be measured but not adjusted.\n\nTargetLkfs -> (double)\n\nTarget LKFS(loudness) to adjust volume to. If no value is entered, a default value will be used according to the chosen algorithm. The CALM Act (1770-1) recommends a target of -24 LKFS. The EBU R-128 specification (1770-2) recommends a target of -23 LKFS.\n\nAudioSelectorName -> (string)\n\nThe name of the AudioSelector used as the source for this AudioDescription.\n\nAudioType -> (string)\n\nApplies only if audioTypeControl is useConfigured. The values for audioType are defined in ISO-IEC 13818-1.\n\nAudioTypeControl -> (string)\n\nDetermines how audio type is determined. followInput: If the input contains an ISO 639 audioType, then that value is passed through to the output. If the input contains no ISO 639 audioType, the value in Audio Type is included in the output. useConfigured: The value in Audio Type is included in the output. Note that this field and audioType are both ignored if inputType is broadcasterMixedAd.\n\nAudioWatermarkingSettings -> (structure)\n\nSettings to configure one or more solutions that insert audio watermarks in the audio encode\n\nNielsenWatermarksSettings -> (structure)\n\nSettings to configure Nielsen Watermarks in the audio encode\n\nNielsenCbetSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen CBET\n\nCbetCheckDigitString -> (string)\n\nEnter the CBET check digits to use in the watermark.\n\nCbetStepaside -> (string)\n\nDetermines the method of CBET insertion mode when prior encoding is detected on the same layer.\n\nCsid -> (string)\n\nEnter the CBET Source ID (CSID) to use in the watermark\n\nNielsenDistributionType -> (string)\n\nChoose the distribution types that you want to assign to the watermarks: - PROGRAM_CONTENT - FINAL_DISTRIBUTOR\n\nNielsenNaesIiNwSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen NAES II (N2) and Nielsen NAES VI (NW).\n\nCheckDigitString -> (string)\n\nEnter the check digit string for the watermark\n\nSid -> (double)\n\nEnter the Nielsen Source ID (SID) to include in the watermark\n\nCodecSettings -> (structure)\n\nAudio codec settings.\n\nAacSettings -> (structure)\n\nAac Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid values depend on rate control mode and profile.\n\nCodingMode -> (string)\n\nMono, Stereo, or 5.1 channel layout. Valid values depend on rate control mode and profile. The adReceiverMix setting receives a stereo description plus control track and emits a mono AAC encode of the description track, with control data emitted in the PES header as per ETSI TS 101 154 Annex E.\n\nInputType -> (string)\n\nSet to “broadcasterMixedAd” when input contains pre-mixed main audio + AD (narration) as a stereo pair. The Audio Type field (audioType) will be set to 3, which signals to downstream systems that this stream contains “broadcaster mixed AD”. Note that the input received by the encoder must contain pre-mixed audio; the encoder does not perform the mixing. The values in audioTypeControl and audioType (in AudioDescription) are ignored when set to broadcasterMixedAd. Leave set to “normal” when input does not contain pre-mixed audio + AD.\n\nProfile -> (string)\n\nAAC Profile.\n\nRateControlMode -> (string)\n\nRate Control Mode.\n\nRawFormat -> (string)\n\nSets LATM / LOAS AAC output for raw containers.\n\nSampleRate -> (double)\n\nSample rate in Hz. Valid values depend on rate control mode and profile.\n\nSpec -> (string)\n\nUse MPEG-2 AAC audio instead of MPEG-4 AAC audio for raw or MPEG-2 Transport Stream containers.\n\nVbrQuality -> (string)\n\nVBR Quality Level - Only used if rateControlMode is VBR.\n\nAc3Settings -> (structure)\n\nAc3 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted AC-3 stream. See ATSC A/52-2012 for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital coding mode. Determines number of channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If excluded and input audio is Dolby Digital, dialnorm will be passed through.\n\nDrcProfile -> (string)\n\nIf set to filmStandard, adds dynamic range compression signaling to the output bitstream as defined in the Dolby Digital specification.\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid in codingMode32Lfe mode.\n\nMetadataControl -> (string)\n\nWhen set to “followInput”, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nEac3Settings -> (structure)\n\nEac3 Settings\n\nAttenuationControl -> (string)\n\nWhen set to attenuate3Db, applies a 3 dB attenuation to the surround channels. Only used for 3/2 coding mode.\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted E-AC-3 stream. See ATSC A/52-2012 (Annex E) for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital Plus coding mode. Determines number of channels.\n\nDcFilter -> (string)\n\nWhen set to enabled, activates a DC highpass filter for all input channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If blank and input audio is Dolby Digital Plus, dialnorm will be passed through.\n\nDrcLine -> (string)\n\nSets the Dolby dynamic range compression profile.\n\nDrcRf -> (string)\n\nSets the profile for heavy Dolby dynamic range compression, ensures that the instantaneous signal peaks do not exceed specified levels.\n\nLfeControl -> (string)\n\nWhen encoding 3/2 audio, setting to lfe enables the LFE channel\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid with codingMode32 coding mode.\n\nLoRoCenterMixLevel -> (double)\n\nLeft only/Right only center mix level. Only used for 3/2 coding mode.\n\nLoRoSurroundMixLevel -> (double)\n\nLeft only/Right only surround mix level. Only used for 3/2 coding mode.\n\nLtRtCenterMixLevel -> (double)\n\nLeft total/Right total center mix level. Only used for 3/2 coding mode.\n\nLtRtSurroundMixLevel -> (double)\n\nLeft total/Right total surround mix level. Only used for 3/2 coding mode.\n\nMetadataControl -> (string)\n\nWhen set to followInput, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nPassthroughControl -> (string)\n\nWhen set to whenPossible, input DD+ audio will be passed through if it is present on the input. This detection is dynamic over the life of the transcode. Inputs that alternate between DD+ and non-DD+ content will have a consistent DD+ output as the system alternates between passthrough and encoding.\n\nPhaseControl -> (string)\n\nWhen set to shift90Degrees, applies a 90-degree phase shift to the surround channels. Only used for 3/2 coding mode.\n\nStereoDownmix -> (string)\n\nStereo downmix preference. Only used for 3/2 coding mode.\n\nSurroundExMode -> (string)\n\nWhen encoding 3/2 audio, sets whether an extra center back surround channel is matrix encoded into the left and right surround channels.\n\nSurroundMode -> (string)\n\nWhen encoding 2/0 audio, sets whether Dolby Surround is matrix encoded into the two channels.\n\nMp2Settings -> (structure)\n\nMp2 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second.\n\nCodingMode -> (string)\n\nThe MPEG2 Audio coding mode. Valid values are codingMode10 (for mono) or codingMode20 (for stereo).\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nPassThroughSettings -> (structure)\n\nPass Through Settings\n\nWavSettings -> (structure)\n\nWav Settings\n\nBitDepth -> (double)\n\nBits per sample.\n\nCodingMode -> (string)\n\nThe audio coding mode for the WAV audio. The mode determines the number of channels in the audio.\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nLanguageCode -> (string)\n\nRFC 5646 language code representing the language of the audio output track. Only used if languageControlMode is useConfigured, or there is no ISO 639 language code specified in the input.\n\nLanguageCodeControl -> (string)\n\nChoosing followInput will cause the ISO 639 language code of the output to follow the ISO 639 language code of the input. The languageCode will be used when useConfigured is set, or when followInput is selected but there is no ISO 639 language code specified by the input.\n\nName -> (string)\n\nThe name of this AudioDescription. Outputs will use this name to uniquely identify this AudioDescription. Description names should be unique within this Live Event.\n\nRemixSettings -> (structure)\n\nSettings that control how input audio channels are remixed into the output audio channels.\n\nChannelMappings -> (list)\n\nMapping of input channels to output channels, with appropriate gain adjustments.\n\n(structure)\n\nAudio Channel Mapping\n\nInputChannelLevels -> (list)\n\nIndices and gain values for each input channel that should be remixed into this output channel.\n\n(structure)\n\nInput Channel Level\n\nGain -> (integer)\n\nRemixing value. Units are in dB and acceptable values are within the range from -60 (mute) and 6 dB.\n\nInputChannel -> (integer)\n\nThe index of the input channel used as a source.\n\nOutputChannel -> (integer)\n\nThe index of the output channel being produced.\n\nChannelsIn -> (integer)\n\nNumber of input channels to be used.\n\nChannelsOut -> (integer)\n\nNumber of output channels to be produced. Valid values: 1, 2, 4, 6, 8\n\nStreamName -> (string)\n\nUsed for MS Smooth and Apple HLS outputs. Indicates the name displayed by the player (eg. English, or Director Commentary).\n\nAvailBlanking -> (structure)\n\nSettings for ad avail blanking.\n\nAvailBlankingImage -> (structure)\n\nBlanking image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when insertion metadata is added.\n\nAvailConfiguration -> (structure)\n\nEvent-wide configuration settings for ad avail insertion.\n\nAvailSettings -> (structure)\n\nAd avail settings.\n\nScte35SpliceInsert -> (structure)\n\nScte35 Splice Insert\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nScte35TimeSignalApos -> (structure)\n\nScte35 Time Signal Apos\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nBlackoutSlate -> (structure)\n\nSettings for blackout slate.\n\nBlackoutSlateImage -> (structure)\n\nBlackout slate image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkEndBlackout -> (string)\n\nSetting to enabled causes the encoder to blackout the video, audio, and captions, and raise the “Network Blackout Image” slate when an SCTE104/35 Network End Segmentation Descriptor is encountered. The blackout will be lifted when the Network Start Segmentation Descriptor is encountered. The Network End and Network Start descriptors must contain a network ID that matches the value entered in “Network ID”.\n\nNetworkEndBlackoutImage -> (structure)\n\nPath to local file to use as Network End Blackout image. Image will be scaled to fill the entire output raster.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkId -> (string)\n\nProvides Network ID that matches EIDR ID format (e.g., “10.XXXX/XXXX-XXXX-XXXX-XXXX-XXXX-C”).\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when indicated by program metadata.\n\nCaptionDescriptions -> (list)\n\nSettings for caption decriptions\n\n(structure)\n\nCaption Description\n\nCaptionSelectorName -> (string)\n\nSpecifies which input caption selector to use as a caption source when generating output captions. This field should match a captionSelector name.\n\nDestinationSettings -> (structure)\n\nAdditional settings for captions destination that depend on the destination type.\n\nAribDestinationSettings -> (structure)\n\nArib Destination Settings\n\nBurnInDestinationSettings -> (structure)\n\nBurn In Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to ‘auto’ fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. All burn-in and DVB-Sub font settings must match.\n\nDvbSubDestinationSettings -> (structure)\n\nDvb Sub Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. This option is not valid for source captions that are STL or 608/embedded. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to auto fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nEbuTtDDestinationSettings -> (structure)\n\nEbu Tt DDestination Settings\n\nCopyrightHolder -> (string)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. Complete this field if you want to include the name of the copyright holder in the copyright metadata tag in the TTML\n\nFillLineGap -> (string)\n\nSpecifies how to handle the gap between the lines (in multi-line captions). - enabled: Fill with the captions background color (as specified in the input captions). - disabled: Leave the gap unfilled.\n\nFontFamily -> (string)\n\nSpecifies the font family to include in the font data attached to the EBU-TT captions. Valid only if styleControl is set to include. If you leave this field empty, the font family is set to “monospaced”. (If styleControl is set to exclude, the font family is always set to “monospaced”.) You specify only the font family. All other style information (color, bold, position and so on) is copied from the input captions. The size is always set to 100% to allow the downstream player to choose the size. - Enter a list of font families, as a comma-separated list of font names, in order of preference. The name can be a font family (such as “Arial”), or a generic font family (such as “serif”), or “default” (to let the downstream player choose the font). - Leave blank to set the family to “monospace”.\n\nStyleControl -> (string)\n\nSpecifies the style information (font color, font position, and so on) to include in the font data that is attached to the EBU-TT captions. - include: Take the style information (font color, font position, and so on) from the source captions and include that information in the font data attached to the EBU-TT captions. This option is valid only if the source captions are Embedded or Teletext. - exclude: In the font data attached to the EBU-TT captions, set the font family to “monospaced”. Do not include any other style information.\n\nEmbeddedDestinationSettings -> (structure)\n\nEmbedded Destination Settings\n\nEmbeddedPlusScte20DestinationSettings -> (structure)\n\nEmbedded Plus Scte20 Destination Settings\n\nRtmpCaptionInfoDestinationSettings -> (structure)\n\nRtmp Caption Info Destination Settings\n\nScte20PlusEmbeddedDestinationSettings -> (structure)\n\nScte20 Plus Embedded Destination Settings\n\nScte27DestinationSettings -> (structure)\n\nScte27 Destination Settings\n\nSmpteTtDestinationSettings -> (structure)\n\nSmpte Tt Destination Settings\n\nTeletextDestinationSettings -> (structure)\n\nTeletext Destination Settings\n\nTtmlDestinationSettings -> (structure)\n\nTtml Destination Settings\n\nStyleControl -> (string)\n\nWhen set to passthrough, passes through style and position information from a TTML-like input source (TTML, SMPTE-TT, CFF-TT) to the CFF-TT output or TTML output.\n\nWebvttDestinationSettings -> (structure)\n\nWebvtt Destination Settings\n\nStyleControl -> (string)\n\nControls whether the color and position of the source captions is passed through to the WebVTT output captions. PASSTHROUGH - Valid only if the source captions are EMBEDDED or TELETEXT. NO_STYLE_DATA - Don’t pass through the style. The output captions will not contain any font styling information.\n\nLanguageCode -> (string)\n\nISO 639-2 three-digit code: http://www.loc.gov/standards/iso639-2/\n\nLanguageDescription -> (string)\n\nHuman readable information to indicate captions available for players (eg. English, or Spanish).\n\nName -> (string)\n\nName of the caption description. Used to associate a caption description with an output. Names must be unique within an event.\n\nFeatureActivations -> (structure)\n\nFeature Activations\n\nInputPrepareScheduleActions -> (string)\n\nEnables the Input Prepare feature. You can create Input Prepare actions in the schedule only if this feature is enabled. If you disable the feature on an existing schedule, make sure that you first delete all input prepare actions from the schedule.\n\nGlobalConfiguration -> (structure)\n\nConfiguration settings that apply to the event as a whole.\n\nInitialAudioGain -> (integer)\n\nValue to set the initial audio gain for the Live Event.\n\nInputEndAction -> (string)\n\nIndicates the action to take when the current input completes (e.g. end-of-file). When switchAndLoopInputs is configured the encoder will restart at the beginning of the first input. When “none” is configured the encoder will transcode either black, a solid color, or a user specified slate images per the “Input Loss Behavior” configuration until the next input switch occurs (which is controlled through the Channel Schedule API).\n\nInputLossBehavior -> (structure)\n\nSettings for system actions when input is lost.\n\nBlackFrameMsec -> (integer)\n\nDocumentation update needed\n\nInputLossImageColor -> (string)\n\nWhen input loss image type is “color” this field specifies the color to use. Value: 6 hex characters representing the values of RGB.\n\nInputLossImageSlate -> (structure)\n\nWhen input loss image type is “slate” these fields specify the parameters for accessing the slate.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nInputLossImageType -> (string)\n\nIndicates whether to substitute a solid color or a slate into the output after input loss exceeds blackFrameMsec.\n\nRepeatFrameMsec -> (integer)\n\nDocumentation update needed\n\nOutputLockingMode -> (string)\n\nIndicates how MediaLive pipelines are synchronized. PIPELINE_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the other. EPOCH_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the Unix epoch.\n\nOutputTimingSource -> (string)\n\nIndicates whether the rate of frames emitted by the Live encoder should be paced by its system clock (which optionally may be locked to another source via NTP) or should be locked to the clock of the source that is providing the input stream.\n\nSupportLowFramerateInputs -> (string)\n\nAdjusts video input buffer for streams with very low video framerates. This is commonly set to enabled for music channels with less than one video frame per second.\n\nMotionGraphicsConfiguration -> (structure)\n\nSettings for motion graphics.\n\nMotionGraphicsInsertion -> (string)\n\nMotion Graphics Insertion\n\nMotionGraphicsSettings -> (structure)\n\nMotion Graphics Settings\n\nHtmlMotionGraphicsSettings -> (structure)\n\nHtml Motion Graphics Settings\n\nNielsenConfiguration -> (structure)\n\nNielsen configuration settings.\n\nDistributorId -> (string)\n\nEnter the Distributor ID assigned to your organization by Nielsen.\n\nNielsenPcmToId3Tagging -> (string)\n\nEnables Nielsen PCM to ID3 tagging\n\nOutputGroups -> (list)\n\nPlaceholder documentation for __listOfOutputGroup\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nName -> (string)\n\nCustom output group name optionally defined by the user. Only letters, numbers, and the underscore character allowed; only 32 characters allowed.\n\nOutputGroupSettings -> (structure)\n\nSettings associated with the output group.\n\nArchiveGroupSettings -> (structure)\n\nArchive Group Settings\n\nArchiveCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nArchiveS3Settings -> (structure)\n\nArchive S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nDestination -> (structure)\n\nA directory and base filename where archive files should be written.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRolloverInterval -> (integer)\n\nNumber of seconds to write to archive file before closing and starting a new one.\n\nFrameCaptureGroupSettings -> (structure)\n\nFrame Capture Group Settings\n\nDestination -> (structure)\n\nThe destination for the frame capture files. Either the URI for an Amazon S3 bucket and object, plus a file name prefix (for example, s3ssl://sportsDelivery/highlights/20180820/curling-) or the URI for a MediaStore container, plus a file name prefix (for example, mediastoressl://sportsDelivery/20180820/curling-). The final file names consist of the prefix from the destination field (for example, “curling-“) + name modifier + the counter (5 digits, starting from 00001) + extension (which is always .jpg). For example, curling-low.00001.jpg\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFrameCaptureCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nFrameCaptureS3Settings -> (structure)\n\nFrame Capture S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsGroupSettings -> (structure)\n\nHls Group Settings\n\nAdMarkers -> (list)\n\nChoose one or more ad marker types to pass SCTE35 signals through to this group of Apple HLS outputs.\n\n(string)\n\nHls Ad Markers\n\nBaseUrlContent -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlContent1 -> (string)\n\nOptional. One value per output group. This field is required only if you are completing Base URL content A, and the downstream system has notified you that the media files for pipeline 1 of all outputs are in a location different from the media files for pipeline 0.\n\nBaseUrlManifest -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlManifest1 -> (string)\n\nOptional. One value per output group. Complete this field only if you are completing Base URL manifest A, and the downstream system has notified you that the child manifest files for pipeline 1 of all outputs are in a location different from the child manifest files for pipeline 0.\n\nCaptionLanguageMappings -> (list)\n\nMapping of up to 4 caption channels to caption languages. Is only meaningful if captionLanguageSetting is set to “insert”.\n\n(structure)\n\nMaps a caption channel to an ISO 693-2 language code (http://www.loc.gov/standards/iso639-2), with an optional description.\n\nCaptionChannel -> (integer)\n\nThe closed caption channel being described by this CaptionLanguageMapping. Each channel mapping must have a unique channel number (maximum of 4)\n\nLanguageCode -> (string)\n\nThree character ISO 639-2 language code (see http://www.loc.gov/standards/iso639-2)\n\nLanguageDescription -> (string)\n\nTextual description of language\n\nCaptionLanguageSetting -> (string)\n\nApplies only to 608 Embedded output captions. insert: Include CLOSED-CAPTIONS lines in the manifest. Specify at least one language in the CC1 Language Code field. One CLOSED-CAPTION line is added for each Language Code you specify. Make sure to specify the languages in the order in which they appear in the original source (if the source is embedded format) or the order of the caption selectors (if the source is other than embedded). Otherwise, languages in the manifest will not match up properly with the output captions. none: Include CLOSED-CAPTIONS=NONE line in the manifest. omit: Omit any CLOSED-CAPTIONS line from the manifest.\n\nClientCache -> (string)\n\nWhen set to “disabled”, sets the #EXT-X-ALLOW-CACHE:no tag in the manifest, which prevents clients from saving media segments for later replay.\n\nCodecSpecification -> (string)\n\nSpecification to use (RFC-6381 or the default RFC-4281) during m3u8 playlist generation.\n\nConstantIv -> (string)\n\nFor use with encryptionType. This is a 128-bit, 16-byte hex value represented by a 32-character text string. If ivSource is set to “explicit” then this parameter is required and is used as the IV for encryption.\n\nDestination -> (structure)\n\nA directory or HTTP destination for the HLS segments, manifest files, and encryption keys (if enabled).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nDirectoryStructure -> (string)\n\nPlace segments in subdirectories.\n\nDiscontinuityTags -> (string)\n\nSpecifies whether to insert EXT-X-DISCONTINUITY tags in the HLS child manifests for this output group. Typically, choose Insert because these tags are required in the manifest (according to the HLS specification) and serve an important purpose. Choose Never Insert only if the downstream system is doing real-time failover (without using the MediaLive automatic failover feature) and only if that downstream system has advised you to exclude the tags.\n\nEncryptionType -> (string)\n\nEncrypts the segments with the given encryption scheme. Exclude this parameter if no encryption is desired.\n\nHlsCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nHlsAkamaiSettings -> (structure)\n\nHls Akamai Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to Akamai. User should contact Akamai to enable this feature.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nSalt -> (string)\n\nSalt for authenticated Akamai.\n\nToken -> (string)\n\nToken parameter for authenticated akamai. If not specified, _gda_ is used.\n\nHlsBasicPutSettings -> (structure)\n\nHls Basic Put Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsMediaStoreSettings -> (structure)\n\nHls Media Store Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nMediaStoreStorageClass -> (string)\n\nWhen set to temporal, output files are stored in non-persistent memory for faster reading and writing.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsS3Settings -> (structure)\n\nHls S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsWebdavSettings -> (structure)\n\nHls Webdav Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to WebDAV.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsId3SegmentTagging -> (string)\n\nState of HLS ID3 Segment Tagging\n\nIFrameOnlyPlaylists -> (string)\n\nDISABLED: Do not create an I-frame-only manifest, but do create the master and media manifests (according to the Output Selection field). STANDARD: Create an I-frame-only manifest for each output that contains video, as well as the other manifests (according to the Output Selection field). The I-frame manifest contains a #EXT-X-I-FRAMES-ONLY tag to indicate it is I-frame only, and one or more #EXT-X-BYTERANGE entries identifying the I-frame position. For example, #EXT-X-BYTERANGE:160364@1461888”\n\nIncompleteSegmentBehavior -> (string)\n\nSpecifies whether to include the final (incomplete) segment in the media output when the pipeline stops producing output because of a channel stop, a channel pause or a loss of input to the pipeline. Auto means that MediaLive decides whether to include the final segment, depending on the channel class and the types of output groups. Suppress means to never include the incomplete segment. We recommend you choose Auto and let MediaLive control the behavior.\n\nIndexNSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the maximum number of segments in the media manifest file. After this maximum, older segments are removed from the media manifest. This number must be smaller than the number in the Keep Segments field.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nIvInManifest -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If set to “include”, IV is listed in the manifest, otherwise the IV is not in the manifest.\n\nIvSource -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If this setting is “followsSegmentNumber”, it will cause the IV to change every segment (to match the segment number). If this is set to “explicit”, you must enter a constantIv value.\n\nKeepSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the number of media segments to retain in the destination directory. This number should be bigger than indexNSegments (Num segments). We recommend (value = (2 x indexNsegments) + 1). If this “keep segments” number is too low, the following might happen: the player is still reading a media manifest file that lists this segment, but that segment has been removed from the destination directory (as directed by indexNSegments). This situation would result in a 404 HTTP error on the player.\n\nKeyFormat -> (string)\n\nThe value specifies how the key is represented in the resource identified by the URI. If parameter is absent, an implicit value of “identity” is used. A reverse DNS string can also be given.\n\nKeyFormatVersions -> (string)\n\nEither a single positive integer version value or a slash delimited list of version values (1/2/3).\n\nKeyProviderSettings -> (structure)\n\nThe key provider settings.\n\nStaticKeySettings -> (structure)\n\nStatic Key Settings\n\nKeyProviderServer -> (structure)\n\nThe URL of the license server used for protecting content.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nStaticKeyValue -> (string)\n\nStatic key value as a 32 character hexadecimal string.\n\nManifestCompression -> (string)\n\nWhen set to gzip, compresses HLS playlist.\n\nManifestDurationFormat -> (string)\n\nIndicates whether the output manifest should use floating point or integer values for segment duration.\n\nMinSegmentLength -> (integer)\n\nWhen set, minimumSegmentLength is enforced by looking ahead and back within the specified range for a nearby avail and extending the segment size if needed.\n\nMode -> (string)\n\nIf “vod”, all segments are indexed and kept permanently in the destination and manifest. If “live”, only the number segments specified in keepSegments and indexNSegments are kept; newer segments replace older segments, which may prevent players from rewinding all the way to the beginning of the event. VOD mode uses HLS EXT-X-PLAYLIST-TYPE of EVENT while the channel is running, converting it to a “VOD” type manifest on completion of the stream.\n\nOutputSelection -> (string)\n\nMANIFESTS_AND_SEGMENTS: Generates manifests (master manifest, if applicable, and media manifests) for this output group. VARIANT_MANIFESTS_AND_SEGMENTS: Generates media manifests for this output group, but not a master manifest. SEGMENTS_ONLY: Does not generate any manifests for this output group.\n\nProgramDateTime -> (string)\n\nIncludes or excludes EXT-X-PROGRAM-DATE-TIME tag in .m3u8 manifest files. The value is calculated as follows: either the program date and time are initialized using the input timecode source, or the time is initialized using the input timecode source and the date is initialized using the timestampOffset.\n\nProgramDateTimePeriod -> (integer)\n\nPeriod of insertion of EXT-X-PROGRAM-DATE-TIME entry, in seconds.\n\nRedundantManifest -> (string)\n\nENABLED: The master manifest (.m3u8 file) for each pipeline includes information about both pipelines: first its own media files, then the media files of the other pipeline. This feature allows playout device that support stale manifest detection to switch from one manifest to the other, when the current manifest seems to be stale. There are still two destinations and two master manifests, but both master manifests reference the media files from both pipelines. DISABLED: The master manifest (.m3u8 file) for each pipeline includes information about its own pipeline only. For an HLS output group with MediaPackage as the destination, the DISABLED behavior is always followed. MediaPackage regenerates the manifests it serves to players so a redundant manifest from MediaLive is irrelevant.\n\nSegmentLength -> (integer)\n\nLength of MPEG-2 Transport Stream segments to create (in seconds). Note that segments will end on the next keyframe after this number of seconds, so actual segment length may be longer.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSegmentsPerSubdirectory -> (integer)\n\nNumber of segments to write to a subdirectory before starting a new one. directoryStructure must be subdirectoryPerStream for this setting to have an effect.\n\nStreamInfResolution -> (string)\n\nInclude or exclude RESOLUTION attribute for video in EXT-X-STREAM-INF tag of variant manifest.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nTimestampDeltaMilliseconds -> (integer)\n\nProvides an extra millisecond delta offset to fine tune the timestamps.\n\nTsFileMode -> (string)\n\nSEGMENTED_FILES: Emit the program as segments - multiple .ts media files. SINGLE_FILE: Applies only if Mode field is VOD. Emit the program as a single .ts media file. The media manifest includes #EXT-X-BYTERANGE tags to index segments for playback. A typical use for this value is when sending the output to AWS Elemental MediaConvert, which can accept only a single media file. Playback while the channel is running is not guaranteed due to HTTP server caching.\n\nMediaPackageGroupSettings -> (structure)\n\nMedia Package Group Settings\n\nDestination -> (structure)\n\nMediaPackage channel destination.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nMsSmoothGroupSettings -> (structure)\n\nMs Smooth Group Settings\n\nAcquisitionPointId -> (string)\n\nThe ID to include in each message in the sparse track. Ignored if sparseTrackType is NONE.\n\nAudioOnlyTimecodeControl -> (string)\n\nIf set to passthrough for an audio-only MS Smooth output, the fragment absolute time will be set to the current timecode. This option does not write timecodes to the audio elementary stream.\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the https certificate chain to a trusted Certificate Authority (CA). This will cause https outputs to self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the IIS server if the connection is lost. Content will be cached during this time and the cache will be be delivered to the IIS server once the connection is re-established.\n\nDestination -> (structure)\n\nSmooth Streaming publish point on an IIS server. Elemental Live acts as a “Push” encoder to IIS.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nEventId -> (string)\n\nMS Smooth event ID to be sent to the IIS server. Should only be specified if eventIdMode is set to useConfigured.\n\nEventIdMode -> (string)\n\nSpecifies whether or not to send an event ID to the IIS server. If no event ID is sent and the same Live Event is used without changing the publishing point, clients might see cached video from the previous run. Options: - “useConfigured” - use the value provided in eventId - “useTimestamp” - generate and send an event ID based on the current timestamp - “noEventId” - do not send an event ID to the IIS server.\n\nEventStopBehavior -> (string)\n\nWhen set to sendEos, send EOS signal to IIS server when stopping the event\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nFragmentLength -> (integer)\n\nLength of mp4 fragments to generate (in seconds). Fragment length must be compatible with GOP size and framerate.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nRestartDelay -> (integer)\n\nNumber of seconds before initiating a restart due to output failure, due to exhausting the numRetries on one segment, or exceeding filecacheDuration.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSendDelayMs -> (integer)\n\nNumber of milliseconds to delay the output from the second pipeline.\n\nSparseTrackType -> (string)\n\nIdentifies the type of data to place in the sparse track: - SCTE35: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame to start a new segment. - SCTE35_WITHOUT_SEGMENTATION: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame but don’t start a new segment. - NONE: Don’t generate a sparse track for any outputs in this output group.\n\nStreamManifestBehavior -> (string)\n\nWhen set to send, send stream manifest so publishing point doesn’t start until all streams start.\n\nTimestampOffset -> (string)\n\nTimestamp offset for the event. Only used if timestampOffsetMode is set to useConfiguredOffset.\n\nTimestampOffsetMode -> (string)\n\nType of timestamp date offset to use. - useEventStartDate: Use the date the event was started as the offset - useConfiguredOffset: Use an explicitly configured date as the offset\n\nMultiplexGroupSettings -> (structure)\n\nMultiplex Group Settings\n\nRtmpGroupSettings -> (structure)\n\nRtmp Group Settings\n\nAdMarkers -> (list)\n\nChoose the ad marker type for this output group. MediaLive will create a message based on the content of each SCTE-35 message, format it for that marker type, and insert it in the datastream.\n\n(string)\n\nRtmp Ad Markers\n\nAuthenticationScheme -> (string)\n\nAuthentication scheme to use when connecting with CDN\n\nCacheFullBehavior -> (string)\n\nControls behavior when content cache fills up. If remote origin server stalls the RTMP connection and does not accept content fast enough the ‘Media Cache’ will fill up. When the cache reaches the duration specified by cacheLength the cache will stop accepting new content. If set to disconnectImmediately, the RTMP output will force a disconnect. Clear the media cache, and reconnect after restartDelay seconds. If set to waitForServer, the RTMP output will wait up to 5 minutes to allow the origin server to begin accepting data again.\n\nCacheLength -> (integer)\n\nCache length, in seconds, is used to calculate buffer size.\n\nCaptionData -> (string)\n\nControls the types of data that passes to onCaptionInfo outputs. If set to ‘all’ then 608 and 708 carried DTVCC data will be passed. If set to ‘field1AndField2608’ then DTVCC data will be stripped out, but 608 data from both fields will be passed. If set to ‘field1608’ then only the data carried in 608 from field 1 video will be passed.\n\nInputLossAction -> (string)\n\nControls the behavior of this RTMP group if input becomes unavailable. - emitOutput: Emit a slate until input returns. - pauseOutput: Stop transmitting data until input returns. This does not close the underlying RTMP connection.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nUdpGroupSettings -> (structure)\n\nUdp Group Settings\n\nInputLossAction -> (string)\n\nSpecifies behavior of last resort when input video is lost, and no more backup inputs are available. When dropTs is selected the entire transport stream will stop being emitted. When dropProgram is selected the program can be dropped from the transport stream (and replaced with null packets to meet the TS bitrate requirement). Or, when emitProgram is chosen the transport stream will continue to be produced normally with repeat frames, black frames, or slate frames substituted for the absent input video.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nOutputs -> (list)\n\nPlaceholder documentation for __listOfOutput\n\n(structure)\n\nOutput settings. There can be multiple outputs within a group.\n\nAudioDescriptionNames -> (list)\n\nThe names of the AudioDescriptions used as audio sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nCaptionDescriptionNames -> (list)\n\nThe names of the CaptionDescriptions used as caption sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nOutputName -> (string)\n\nThe name used to identify an output.\n\nOutputSettings -> (structure)\n\nOutput type-specific settings.\n\nArchiveOutputSettings -> (structure)\n\nArchive Output Settings\n\nContainerSettings -> (structure)\n\nSettings specific to the container type of the file.\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nRawSettings -> (structure)\n\nRaw Settings\n\nExtension -> (string)\n\nOutput file extension. If excluded, this will be auto-selected from the container type.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nFrameCaptureOutputSettings -> (structure)\n\nFrame Capture Output Settings\n\nNameModifier -> (string)\n\nRequired if the output group contains more than one output. This modifier forms part of the output file name.\n\nHlsOutputSettings -> (structure)\n\nHls Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nHlsSettings -> (structure)\n\nSettings regarding the underlying stream. These settings are different for audio-only outputs.\n\nAudioOnlyHlsSettings -> (structure)\n\nAudio Only Hls Settings\n\nAudioGroupId -> (string)\n\nSpecifies the group to which the audio Rendition belongs.\n\nAudioOnlyImage -> (structure)\n\nOptional. Specifies the .jpg or .png image to use as the cover art for an audio-only output. We recommend a low bit-size file because the image increases the output audio bandwidth. The image is attached to the audio as an ID3 tag, frame type APIC, picture type 0x10, as per the “ID3 tag version 2.4.0 - Native Frames” standard.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nAudioTrackType -> (string)\n\nFour types of audio-only tracks are supported: Audio-Only Variant Stream The client can play back this audio-only stream instead of video in low-bandwidth scenarios. Represented as an EXT-X-STREAM-INF in the HLS manifest. Alternate Audio, Auto Select, Default Alternate rendition that the client should try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=YES, AUTOSELECT=YES Alternate Audio, Auto Select, Not Default Alternate rendition that the client may try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=YES Alternate Audio, not Auto Select Alternate rendition that the client will not try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=NO\n\nSegmentType -> (string)\n\nSpecifies the segment type.\n\nFmp4HlsSettings -> (structure)\n\nFmp4 Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nFrameCaptureHlsSettings -> (structure)\n\nFrame Capture Hls Settings\n\nStandardHlsSettings -> (structure)\n\nStandard Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nM3u8Settings -> (structure)\n\nSettings information for the .m3u8 container\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values.\n\nEcmPid -> (string)\n\nThis parameter is unused and deprecated.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock References (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value.\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nScte35Behavior -> (string)\n\nIf set to passthrough, passes any SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Accepts “Format Identifiers”:#formatIdentifierParameters.\n\nSegmentModifier -> (string)\n\nString concatenated to end of segment filenames.\n\nMediaPackageOutputSettings -> (structure)\n\nMedia Package Output Settings\n\nMsSmoothOutputSettings -> (structure)\n\nMs Smooth Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nMultiplexOutputSettings -> (structure)\n\nMultiplex Output Settings\n\nDestination -> (structure)\n\nDestination is a Multiplex.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRtmpOutputSettings -> (structure)\n\nRtmp Output Settings\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the tls certificate chain to a trusted Certificate Authority (CA). This will cause rtmps outputs with self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying a connection to the Flash Media server if the connection is lost.\n\nDestination -> (structure)\n\nThe RTMP endpoint excluding the stream name (eg. rtmp://host/appname). For connection to Akamai, a username and password must be supplied. URI fields accept format identifiers.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nUdpOutputSettings -> (structure)\n\nUdp Output Settings\n\nBufferMsec -> (integer)\n\nUDP output buffering in milliseconds. Larger values increase latency through the transcoder but simultaneously assist the transcoder in maintaining a constant, low-jitter UDP/RTP output while accommodating clock recovery, input switching, input disruptions, picture reordering, etc.\n\nContainerSettings -> (structure)\n\nUdp Container Settings\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nDestination -> (structure)\n\nDestination address and port number for RTP or UDP packets. Can be unicast or multicast RTP or UDP (eg. rtp://239.10.10.10:5001 or udp://10.100.100.100:5002).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFecOutputSettings -> (structure)\n\nSettings for enabling and adjusting Forward Error Correction on UDP outputs.\n\nColumnDepth -> (integer)\n\nParameter D from SMPTE 2022-1. The height of the FEC protection matrix. The number of transport stream packets per column error correction packet. Must be between 4 and 20, inclusive.\n\nIncludeFec -> (string)\n\nEnables column only or column and row based FEC\n\nRowLength -> (integer)\n\nParameter L from SMPTE 2022-1. The width of the FEC protection matrix. Must be between 1 and 20, inclusive. If only Column FEC is used, then larger values increase robustness. If Row FEC is used, then this is the number of transport stream packets per row error correction packet, and the value must be between 4 and 20, inclusive, if includeFec is columnAndRow. If includeFec is column, this value must be 1 to 20, inclusive.\n\nVideoDescriptionName -> (string)\n\nThe name of the VideoDescription used as the source for this output.\n\nTimecodeConfig -> (structure)\n\nContains settings used to acquire and adjust timecode information from inputs.\n\nSource -> (string)\n\nIdentifies the source for the timecode that will be associated with the events outputs. -Embedded (embedded): Initialize the output timecode with timecode from the the source. If no embedded timecode is detected in the source, the system falls back to using “Start at 0” (zerobased). -System Clock (systemclock): Use the UTC time. -Start at 0 (zerobased): The time of the first frame of the event will be 00:00:00:00.\n\nSyncThreshold -> (integer)\n\nThreshold in frames beyond which output timecode is resynchronized to the input timecode. Discrepancies below this threshold are permitted to avoid unnecessary discontinuities in the output timecode. No timecode sync when this is not specified.\n\nVideoDescriptions -> (list)\n\nPlaceholder documentation for __listOfVideoDescription\n\n(structure)\n\nVideo settings for this stream.\n\nCodecSettings -> (structure)\n\nVideo codec settings.\n\nFrameCaptureSettings -> (structure)\n\nFrame Capture Settings\n\nCaptureInterval -> (integer)\n\nThe frequency at which to capture frames for inclusion in the output. May be specified in either seconds or milliseconds, as specified by captureIntervalUnits.\n\nCaptureIntervalUnits -> (string)\n\nUnit for the frame capture interval.\n\nH264Settings -> (structure)\n\nH264 Settings\n\nAdaptiveQuantization -> (string)\n\nEnables or disables adaptive quantization, which is a technique MediaLive can apply to video on a frame-by-frame basis to produce more compression without losing quality. There are three types of adaptive quantization: flicker, spatial, and temporal. Set the field in one of these ways: Set to Auto. Recommended. For each type of AQ, MediaLive will determine if AQ is needed, and if so, the appropriate strength. Set a strength (a value other than Auto or Disable). This strength will apply to any of the AQ fields that you choose to enable. Set to Disabled to disable all types of adaptive quantization.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufFillPct -> (integer)\n\nPercentage of the buffer that should initially be filled (HRD buffer model).\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nEntropyEncoding -> (string)\n\nEntropy encoding mode. Use cabac (must be in Main or High profile) or cavlc.\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nFlicker AQ makes adjustments within each frame to reduce flicker or ‘pop’ on I-frames. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if flicker AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply flicker AQ using the specified strength. Disabled: MediaLive won’t apply flicker AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply flicker AQ.\n\nForceFieldPictures -> (string)\n\nThis setting applies only when scan type is “interlaced.” It controls whether coding is performed on a field basis or on a frame basis. (When the video is progressive, the coding is always performed on a frame basis.) enabled: Force MediaLive to code on a field basis, so that odd and even sets of fields are coded separately. disabled: Code the two sets of fields separately (on a field basis) or together (on a frame basis using PAFF), depending on what is most appropriate for the content.\n\nFramerateControl -> (string)\n\nThis field indicates how the output video frame rate is specified. If “specified” is selected then the output video frame rate is determined by framerateNumerator and framerateDenominator, else if “initializeFromSource” is selected then the output video frame rate will be set equal to the input video frame rate of the first input.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopBReference -> (string)\n\nDocumentation update needed\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopNumBFrames -> (integer)\n\nNumber of B-frames between reference frames.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.264 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level For VBR: Set the maximum bitrate in order to accommodate expected spikes in the complexity of the video.\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nNumRefFrames -> (integer)\n\nNumber of reference frames to use. The encoder may use more than requested if using B-frames and/or interlaced encoding.\n\nParControl -> (string)\n\nThis field indicates how the output pixel aspect ratio is specified. If “specified” is selected then the output video pixel aspect ratio is determined by parNumerator and parDenominator, else if “initializeFromSource” is selected then the output pixsel aspect ratio will be set equal to the input video pixel aspect ratio of the first input.\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.264 Profile.\n\nQualityLevel -> (string)\n\nLeave as STANDARD_QUALITY or choose a different value (which might result in additional costs to run the channel). - ENHANCED_QUALITY: Produces a slightly better video quality without an increase in the bitrate. Has an effect only when the Rate control mode is QVBR or CBR. If this channel is in a MediaLive multiplex, the value must be ENHANCED_QUALITY. - STANDARD_QUALITY: Valid for any Rate control mode.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. You can set a target quality or you can let MediaLive determine the best quality. To set a target quality, enter values in the QVBR quality level field and the Max bitrate field. Enter values that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M To let MediaLive decide, leave the QVBR quality level field empty, and in Max bitrate enter the maximum rate you want in the video. For more information, see the section called “Video - rate control mode” in the MediaLive user guide\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. VBR: Quality and bitrate vary, depending on the video complexity. Recommended instead of QVBR if you want to maintain a specific average bitrate over the duration of the channel. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection. - On: inserts I-frames when scene change is detected. - Off: does not force an I-frame when scene change is detected.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nSoftness -> (integer)\n\nSoftness. Selects quantizer matrix, larger values reduce high-frequency content in the encoded image. If not set to zero, must be greater than 15.\n\nSpatialAq -> (string)\n\nSpatial AQ makes adjustments within each frame based on spatial variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if spatial AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply spatial AQ using the specified strength. Disabled: MediaLive won’t apply spatial AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply spatial AQ.\n\nSubgopLength -> (string)\n\nIf set to fixed, use gopNumBFrames B-frames per sub-GOP. If set to dynamic, optimize the number of B-frames used for each sub-GOP to improve visual quality.\n\nSyntax -> (string)\n\nProduces a bitstream compliant with SMPTE RP-2027.\n\nTemporalAq -> (string)\n\nTemporal makes adjustments within each frame based on temporal variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if temporal AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply temporal AQ using the specified strength. Disabled: MediaLive won’t apply temporal AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply temporal AQ.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nH265Settings -> (structure)\n\nH265 Settings\n\nAdaptiveQuantization -> (string)\n\nAdaptive quantization. Allows intra-frame quantizers to vary to improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nAlternativeTransferFunction -> (string)\n\nWhether or not EML should insert an Alternative Transfer Function SEI message to support backwards compatibility with non-HDR decoders and displays.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nIf set to enabled, adjust quantization within each frame to reduce flicker or ‘pop’ on I-frames.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.265 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.265 Profile.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. Set values for the QVBR quality level field and Max bitrate field that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nTier -> (string)\n\nH.265 Tier.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nMpeg2Settings -> (structure)\n\nMpeg2 Settings\n\nAdaptiveQuantization -> (string)\n\nChoose Off to disable adaptive quantization. Or choose another value to enable the quantizer and set its strength. The strengths are: Auto, Off, Low, Medium, High. When you enable this field, MediaLive allows intra-frame quantizers to vary, which might improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates the AFD values that MediaLive will write into the video encode. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose AUTO. AUTO: MediaLive will try to preserve the input AFD value (in cases where multiple AFD values are valid). FIXED: MediaLive will use the value you specify in fixedAFD.\n\nColorMetadata -> (string)\n\nSpecifies whether to include the color space metadata. The metadata describes the color space that applies to the video (the colorSpace field). We recommend that you insert the metadata.\n\nColorSpace -> (string)\n\nChoose the type of color space conversion to apply to the output. For detailed information on setting up both the input and the output to obtain the desired color space in the output, see the section on “MediaLive Features - Video - color space” in the MediaLive User Guide. PASSTHROUGH: Keep the color space of the input content - do not convert it. AUTO:Convert all content that is SD to rec 601, and convert all content that is HD to rec 709.\n\nDisplayAspectRatio -> (string)\n\nSets the pixel aspect ratio for the encode.\n\nFilterSettings -> (structure)\n\nOptionally specify a noise reduction filter, which can improve quality of compressed content. If you do not choose a filter, no filter will be applied. TEMPORAL: This filter is useful for both source content that is noisy (when it has excessive digital artifacts) and source content that is clean. When the content is noisy, the filter cleans up the source content before the encoding phase, with these two effects: First, it improves the output video quality because the content has been cleaned up. Secondly, it decreases the bandwidth because MediaLive does not waste bits on encoding noise. When the content is reasonably clean, the filter tends to decrease the bitrate.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nComplete this field only when afdSignaling is set to FIXED. Enter the AFD value (4 bits) to write on all frames of the video encode.\n\nFramerateDenominator -> (integer)\n\ndescription”: “The framerate denominator. For example, 1001. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nFramerateNumerator -> (integer)\n\nThe framerate numerator. For example, 24000. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nGopClosedCadence -> (integer)\n\nMPEG2: default is open GOP.\n\nGopNumBFrames -> (integer)\n\nRelates to the GOP structure. The number of B-frames between reference frames. If you do not know what a B-frame is, use the default.\n\nGopSize -> (double)\n\nRelates to the GOP structure. The GOP size (keyframe interval) in the units specified in gopSizeUnits. If you do not know what GOP is, use the default. If gopSizeUnits is frames, then the gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, the gopSize must be greater than 0, but does not need to be an integer.\n\nGopSizeUnits -> (string)\n\nRelates to the GOP structure. Specifies whether the gopSize is specified in frames or seconds. If you do not plan to change the default gopSize, leave the default. If you specify SECONDS, MediaLive will internally convert the gop size to a frame count.\n\nScanType -> (string)\n\nSet the scan type of the output to PROGRESSIVE or INTERLACED (top field first).\n\nSubgopLength -> (string)\n\nRelates to the GOP structure. If you do not know what GOP is, use the default. FIXED: Set the number of B-frames in each sub-GOP to the value in gopNumBFrames. DYNAMIC: Let MediaLive optimize the number of B-frames in each sub-GOP, to improve visual quality.\n\nTimecodeInsertion -> (string)\n\nDetermines how MediaLive inserts timecodes in the output video. For detailed information about setting up the input and the output for a timecode, see the section on “MediaLive Features - Timecode configuration” in the MediaLive User Guide. DISABLED: do not include timecodes. GOP_TIMECODE: Include timecode metadata in the GOP header.\n\nHeight -> (integer)\n\nOutput video height, in pixels. Must be an even number. For most codecs, you can leave this field and width blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nName -> (string)\n\nThe name of this VideoDescription. Outputs will use this name to uniquely identify this Description. Description names should be unique within this Live Event.\n\nRespondToAfd -> (string)\n\nIndicates how MediaLive will respond to the AFD values that might be in the input video. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose PASSTHROUGH. RESPOND: MediaLive clips the input video using a formula that uses the AFD values (configured in afdSignaling ), the input display aspect ratio, and the output display aspect ratio. MediaLive also includes the AFD values in the output, unless the codec for this encode is FRAME_CAPTURE. PASSTHROUGH: MediaLive ignores the AFD values and does not clip the video. But MediaLive does include the values in the output. NONE: MediaLive does not clip the input video and does not include the AFD values in the output\n\nScalingBehavior -> (string)\n\nSTRETCH_TO_OUTPUT configures the output position to stretch the video to the specified output resolution (height and width). This option will override any position value. DEFAULT may insert black boxes (pillar boxes or letter boxes) around the video to provide the specified output resolution.\n\nSharpness -> (integer)\n\nChanges the strength of the anti-alias filter used for scaling. 0 is the softest setting, 100 is the sharpest. A setting of 50 is recommended for most content.\n\nWidth -> (integer)\n\nOutput video width, in pixels. Must be an even number. For most codecs, you can leave this field and height blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nId -> (string)\n\nThe unique id of the channel.\n\nInputAttachments -> (list)\n\nList of input attachments for channel.\n\n(structure)\n\nPlaceholder documentation for InputAttachment\n\nAutomaticInputFailoverSettings -> (structure)\n\nUser-specified settings for defining what the conditions are for declaring the input unhealthy and failing over to a different input.\n\nErrorClearTimeMsec -> (integer)\n\nThis clear time defines the requirement a recovered input must meet to be considered healthy. The input must have no failover conditions for this length of time. Enter a time in milliseconds. This value is particularly important if the input_preference for the failover pair is set to PRIMARY_INPUT_PREFERRED, because after this time, MediaLive will switch back to the primary input.\n\nFailoverConditions -> (list)\n\nA list of failover conditions. If any of these conditions occur, MediaLive will perform a failover to the other input.\n\n(structure)\n\nFailover Condition settings. There can be multiple failover conditions inside AutomaticInputFailoverSettings.\n\nFailoverConditionSettings -> (structure)\n\nFailover condition type-specific settings.\n\nAudioSilenceSettings -> (structure)\n\nMediaLive will perform a failover if the specified audio selector is silent for the specified period.\n\nAudioSelectorName -> (string)\n\nThe name of the audio selector in the input that MediaLive should monitor to detect silence. Select your most important rendition. If you didn’t create an audio selector in this input, leave blank.\n\nAudioSilenceThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be silent before automatic input failover occurs. Silence is defined as audio loss or audio quieter than -50 dBFS.\n\nInputLossSettings -> (structure)\n\nMediaLive will perform a failover if content is not detected in this input for the specified period.\n\nInputLossThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that no input is detected. After that time, an input failover will occur.\n\nVideoBlackSettings -> (structure)\n\nMediaLive will perform a failover if content is considered black for the specified period.\n\nBlackDetectThreshold -> (double)\n\nA value used in calculating the threshold below which MediaLive considers a pixel to be ‘black’. For the input to be considered black, every pixel in a frame must be below this threshold. The threshold is calculated as a percentage (expressed as a decimal) of white. Therefore .1 means 10% white (or 90% black). Note how the formula works for any color depth. For example, if you set this field to 0.1 in 10-bit color depth: (1023*0.1=102.3), which means a pixel value of 102 or less is ‘black’. If you set this field to .1 in an 8-bit color depth: (255*0.1=25.5), which means a pixel value of 25 or less is ‘black’. The range is 0.0 to 1.0, with any number of decimal places.\n\nVideoBlackThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be black before automatic input failover occurs.\n\nInputPreference -> (string)\n\nInput preference when deciding which input to make active when a previously failed input has recovered.\n\nSecondaryInputId -> (string)\n\nThe input ID of the secondary input in the automatic input failover pair.\n\nInputAttachmentName -> (string)\n\nUser-specified name for the attachment. This is required if the user wants to use this input in an input switch action.\n\nInputId -> (string)\n\nThe ID of the input\n\nInputSettings -> (structure)\n\nSettings of an input (caption selector, etc.)\n\nAudioSelectors -> (list)\n\nUsed to select the audio stream to decode for inputs that have multiple available.\n\n(structure)\n\nAudio Selector\n\nName -> (string)\n\nThe name of this AudioSelector. AudioDescriptions will use this name to uniquely identify this Selector. Selector names should be unique per input.\n\nSelectorSettings -> (structure)\n\nThe audio selector settings.\n\nAudioHlsRenditionSelection -> (structure)\n\nAudio Hls Rendition Selection\n\nGroupId -> (string)\n\nSpecifies the GROUP-ID in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nName -> (string)\n\nSpecifies the NAME in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nAudioLanguageSelection -> (structure)\n\nAudio Language Selection\n\nLanguageCode -> (string)\n\nSelects a specific three-letter language code from within an audio source.\n\nLanguageSelectionPolicy -> (string)\n\nWhen set to “strict”, the transport stream demux strictly identifies audio streams by their language descriptor. If a PMT update occurs such that an audio stream matching the initially selected language is no longer present then mute will be encoded until the language returns. If “loose”, then on a PMT update the demux will choose another audio stream in the program with the same stream type if it can’t find one with the same language.\n\nAudioPidSelection -> (structure)\n\nAudio Pid Selection\n\nPid -> (integer)\n\nSelects a specific PID from within a source.\n\nAudioTrackSelection -> (structure)\n\nAudio Track Selection\n\nTracks -> (list)\n\nSelects one or more unique audio tracks from within a source.\n\n(structure)\n\nAudio Track\n\nTrack -> (integer)\n\n1-based integer value that maps to a specific audio track\n\nCaptionSelectors -> (list)\n\nUsed to select the caption input to use for inputs that have multiple available.\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nLanguageCode -> (string)\n\nWhen specified this field indicates the three letter language code of the caption track to extract from the source.\n\nName -> (string)\n\nName identifier for a caption selector. This name is used to associate this caption selector with one or more caption descriptions. Names must be unique within an event.\n\nSelectorSettings -> (structure)\n\nCaption selector settings.\n\nAncillarySourceSettings -> (structure)\n\nAncillary Source Settings\n\nSourceAncillaryChannelNumber -> (integer)\n\nSpecifies the number (1 to 4) of the captions channel you want to extract from the ancillary captions. If you plan to convert the ancillary captions to another format, complete this field. If you plan to choose Embedded as the captions destination in the output (to pass through all the channels in the ancillary captions), leave this field blank because MediaLive ignores the field.\n\nAribSourceSettings -> (structure)\n\nArib Source Settings\n\nDvbSubSourceSettings -> (structure)\n\nDvb Sub Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nWhen using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through, regardless of selectors.\n\nEmbeddedSourceSettings -> (structure)\n\nEmbedded Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nScte20Detection -> (string)\n\nSet to “auto” to handle streams with intermittent and/or non-aligned SCTE-20 and Embedded captions.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nSource608TrackNumber -> (integer)\n\nThis field is unused and deprecated.\n\nScte20SourceSettings -> (structure)\n\nScte20 Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nScte27SourceSettings -> (structure)\n\nScte27 Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nThe pid field is used in conjunction with the caption selector languageCode field as follows: - Specify PID and Language: Extracts captions from that PID; the language is “informational”. - Specify PID and omit Language: Extracts the specified PID. - Omit PID and specify Language: Extracts the specified language, whichever PID that happens to be. - Omit PID and omit Language: Valid only if source is DVB-Sub that is being passed through; all languages will be passed through.\n\nTeletextSourceSettings -> (structure)\n\nTeletext Source Settings\n\nOutputRectangle -> (structure)\n\nOptionally defines a region where TTML style captions will be displayed\n\nHeight -> (double)\n\nSee the description in leftOffset. For height, specify the entire height of the rectangle as a percentage of the underlying frame height. For example, “80” means the rectangle height is 80% of the underlying frame height. The topOffset and rectangleHeight must add up to 100% or less. This field corresponds to tts:extent - Y in the TTML standard.\n\nLeftOffset -> (double)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. (Make sure to leave the default if you don’t have either of these formats in the output.) You can define a display rectangle for the captions that is smaller than the underlying video frame. You define the rectangle by specifying the position of the left edge, top edge, bottom edge, and right edge of the rectangle, all within the underlying video frame. The units for the measurements are percentages. If you specify a value for one of these fields, you must specify a value for all of them. For leftOffset, specify the position of the left edge of the rectangle, as a percentage of the underlying frame width, and relative to the left edge of the frame. For example, “10” means the measurement is 10% of the underlying frame width. The rectangle left edge starts at that position from the left edge of the frame. This field corresponds to tts:origin - X in the TTML standard.\n\nTopOffset -> (double)\n\nSee the description in leftOffset. For topOffset, specify the position of the top edge of the rectangle, as a percentage of the underlying frame height, and relative to the top edge of the frame. For example, “10” means the measurement is 10% of the underlying frame height. The rectangle top edge starts at that position from the top edge of the frame. This field corresponds to tts:origin - Y in the TTML standard.\n\nWidth -> (double)\n\nSee the description in leftOffset. For width, specify the entire width of the rectangle as a percentage of the underlying frame width. For example, “80” means the rectangle width is 80% of the underlying frame width. The leftOffset and rectangleWidth must add up to 100% or less. This field corresponds to tts:extent - X in the TTML standard.\n\nPageNumber -> (string)\n\nSpecifies the teletext page number within the data stream from which to extract captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should be specified as a hexadecimal string with no “0x” prefix.\n\nDeblockFilter -> (string)\n\nEnable or disable the deblock filter when filtering.\n\nDenoiseFilter -> (string)\n\nEnable or disable the denoise filter when filtering.\n\nFilterStrength -> (integer)\n\nAdjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).\n\nInputFilter -> (string)\n\nTurns on the filter for this input. MPEG-2 inputs have the deblocking filter enabled by default. 1) auto - filtering will be applied depending on input type/quality 2) disabled - no filtering will be applied to the input 3) forced - filtering will be applied regardless of input type\n\nNetworkInputSettings -> (structure)\n\nInput settings.\n\nHlsInputSettings -> (structure)\n\nSpecifies HLS input settings when the uri is for a HLS manifest.\n\nBandwidth -> (integer)\n\nWhen specified the HLS stream with the m3u8 BANDWIDTH that most closely matches this value will be chosen, otherwise the highest bandwidth stream in the m3u8 will be chosen. The bitrate is specified in bits per second, as in an HLS manifest.\n\nBufferSegments -> (integer)\n\nWhen specified, reading of the HLS input will begin this many buffer segments from the end (most recently written segment). When not specified, the HLS input will begin with the first segment specified in the m3u8.\n\nRetries -> (integer)\n\nThe number of consecutive times that attempts to read a manifest or segment must fail before the input is considered unavailable.\n\nRetryInterval -> (integer)\n\nThe number of seconds between retries when an attempt to read a manifest or segment fails.\n\nScte35Source -> (string)\n\nIdentifies the source for the SCTE-35 messages that MediaLive will ingest. Messages can be ingested from the content segments (in the stream) or from tags in the playlist (the HLS manifest). MediaLive ignores SCTE-35 information in the source that is not selected.\n\nServerValidation -> (string)\n\nCheck HTTPS server certificates. When set to checkCryptographyOnly, cryptography in the certificate will be checked, but not the server’s name. Certain subdomains (notably S3 buckets that use dots in the bucket name) do not strictly match the corresponding certificate’s wildcard pattern and would otherwise cause the event to error. This setting is ignored for protocols that do not use https.\n\nSmpte2038DataPreference -> (string)\n\nSpecifies whether to extract applicable ancillary data from a SMPTE-2038 source in this input. Applicable data types are captions, timecode, AFD, and SCTE-104 messages. - PREFER: Extract from SMPTE-2038 if present in this input, otherwise extract from another source (if any). - IGNORE: Never extract any ancillary data from SMPTE-2038.\n\nSourceEndBehavior -> (string)\n\nLoop input if it is a file. This allows a file input to be streamed indefinitely.\n\nVideoSelector -> (structure)\n\nInforms which video elementary stream to decode for input types that have multiple available.\n\nColorSpace -> (string)\n\nSpecifies the color space of an input. This setting works in tandem with colorSpaceUsage and a video description’s colorSpaceSettingsChoice to determine if any conversion will be performed.\n\nColorSpaceSettings -> (structure)\n\nColor space settings\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nColorSpaceUsage -> (string)\n\nApplies only if colorSpace is a value other than follow. This field controls how the value in the colorSpace field will be used. fallback means that when the input does include color space data, that data will be used, but when the input has no color space data, the value in colorSpace will be used. Choose fallback if your input is sometimes missing color space data, but when it does have color space data, that data is correct. force means to always use the value in colorSpace. Choose force if your input usually has no color space data or might have unreliable color space data.\n\nSelectorSettings -> (structure)\n\nThe video selector settings.\n\nVideoSelectorPid -> (structure)\n\nVideo Selector Pid\n\nPid -> (integer)\n\nSelects a specific PID from within a video source.\n\nVideoSelectorProgramId -> (structure)\n\nVideo Selector Program Id\n\nProgramId -> (integer)\n\nSelects a specific program from within a multi-program transport stream. If the program doesn’t exist, the first program within the transport stream will be selected by default.\n\nInputSpecification -> (structure)\n\nSpecification of network and file inputs for this channel\n\nCodec -> (string)\n\nInput codec\n\nMaximumBitrate -> (string)\n\nMaximum input bitrate, categorized coarsely\n\nResolution -> (string)\n\nInput resolution, categorized coarsely\n\nLogLevel -> (string)\n\nThe log level being written to CloudWatch Logs.\n\nName -> (string)\n\nThe name of the channel. (user-mutable)\n\nPipelineDetails -> (list)\n\nRuntime details for the pipelines of a running channel.\n\n(structure)\n\nRuntime details of a pipeline when a channel is running.\n\nActiveInputAttachmentName -> (string)\n\nThe name of the active input attachment currently being ingested by this pipeline.\n\nActiveInputSwitchActionName -> (string)\n\nThe name of the input switch schedule action that occurred most recently and that resulted in the switch to the current input attachment for this pipeline.\n\nActiveMotionGraphicsActionName -> (string)\n\nThe name of the motion graphics activate action that occurred most recently and that resulted in the current graphics URI for this pipeline.\n\nActiveMotionGraphicsUri -> (string)\n\nThe current URI being used for HTML5 motion graphics for this pipeline.\n\nPipelineId -> (string)\n\nPipeline ID\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role assumed when running the Channel.\n\nState -> (string)\n\nPlaceholder documentation for ChannelState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nVpc -> (structure)\n\nSettings for VPC output\n\nAvailabilityZones -> (list)\n\nThe Availability Zones where the vpc subnets are located. The first Availability Zone applies to the first subnet in the list of subnets. The second Availability Zone applies to the second subnet.\n\n(string)\n\nPlaceholder documentation for __string\n\nNetworkInterfaceIds -> (list)\n\nA list of Elastic Network Interfaces created by MediaLive in the customer’s VPC\n\n(string)\n\nPlaceholder documentation for __string\n\nSecurityGroupIds -> (list)\n\nA list of up EC2 VPC security group IDs attached to the Output VPC network interfaces.\n\n(string)\n\nPlaceholder documentation for __string\n\nSubnetIds -> (list)\n\nA list of VPC subnet IDs from the same VPC. If STANDARD channel, subnet IDs must be mapped to two unique availability zones (AZ).\n\n(string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "describe-input",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/describe-input.html",
      "command_description": "Description\n\nProduces details about an input\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-input\n--input-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-id (string) Unique ID of the input\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe Unique ARN of the input (generated, immutable).\n\nAttachedChannels -> (list)\n\nA list of channel IDs that that input is attached to (currently an input can only be attached to one channel).\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the destinations of the input (PUSH-type).\n\n(structure)\n\nThe settings for a PUSH type input.\n\nIp -> (string)\n\nThe system-generated static IP address of endpoint. It remains fixed for the lifetime of the input.\n\nPort -> (string)\n\nThe port number for the input.\n\nUrl -> (string)\n\nThis represents the endpoint that the customer stream will be pushed to.\n\nVpc -> (structure)\n\nThe properties for a VPC type input destination.\n\nAvailabilityZone -> (string)\n\nThe availability zone of the Input destination.\n\nNetworkInterfaceId -> (string)\n\nThe network interface ID of the Input destination in the VPC.\n\nId -> (string)\n\nThe generated ID of the input (unique for user account, immutable).\n\nInputClass -> (string)\n\nSTANDARD - MediaLive expects two sources to be connected to this input. If the channel is also STANDARD, both sources will be ingested. If the channel is SINGLE_PIPELINE, only the first source will be ingested; the second source will always be ignored, even if the first source fails. SINGLE_PIPELINE - You can connect only one source to this input. If the ChannelClass is also SINGLE_PIPELINE, this value is valid. If the ChannelClass is STANDARD, this value is not valid because the channel requires two sources in the input.\n\nInputDevices -> (list)\n\nSettings for the input devices.\n\n(structure)\n\nSettings for an input device.\n\nId -> (string)\n\nThe unique ID for the device.\n\nInputPartnerIds -> (list)\n\nA list of IDs for all Inputs which are partners of this one.\n\n(string)\n\nPlaceholder documentation for __string\n\nInputSourceType -> (string)\n\nCertain pull input sources can be dynamic, meaning that they can have their URL’s dynamically changes during input switch actions. Presently, this functionality only works with MP4_FILE and TS_FILE inputs.\n\nMediaConnectFlows -> (list)\n\nA list of MediaConnect Flows for this input.\n\n(structure)\n\nThe settings for a MediaConnect Flow.\n\nFlowArn -> (string)\n\nThe unique ARN of the MediaConnect Flow being used as a source.\n\nName -> (string)\n\nThe user-assigned name (This is a mutable value).\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role this input assumes during and after creation.\n\nSecurityGroups -> (list)\n\nA list of IDs for all the Input Security Groups attached to the input.\n\n(string)\n\nPlaceholder documentation for __string\n\nSources -> (list)\n\nA list of the sources of the input (PULL-type).\n\n(structure)\n\nThe settings for a PULL type input.\n\nPasswordParam -> (string)\n\nThe key used to extract the password from EC2 Parameter store.\n\nUrl -> (string)\n\nThis represents the customer’s source URL where stream is pulled from.\n\nUsername -> (string)\n\nThe username for the input source.\n\nState -> (string)\n\nPlaceholder documentation for InputState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nType -> (string)\n\nThe different types of inputs that AWS Elemental MediaLive supports."
    },
    {
      "command_name": "describe-input-device",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/describe-input-device.html",
      "command_description": "Description\n\nGets the details for the input device\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-input-device\n--input-device-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-device-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-device-id (string) The unique ID of this input device. For example, hd-123456789abcdef.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe unique ARN of the input device.\n\nConnectionState -> (string)\n\nThe state of the connection between the input device and AWS.\n\nDeviceSettingsSyncState -> (string)\n\nThe status of the action to synchronize the device configuration. If you change the configuration of the input device (for example, the maximum bitrate), MediaLive sends the new data to the device. The device might not update itself immediately. SYNCED means the device has updated its configuration. SYNCING means that it has not updated its configuration.\n\nDeviceUpdateStatus -> (string)\n\nThe status of software on the input device.\n\nHdDeviceSettings -> (structure)\n\nSettings that describe an input device that is type HD.\n\nActiveInput -> (string)\n\nIf you specified Auto as the configured input, specifies which of the sources is currently active (SDI or HDMI).\n\nConfiguredInput -> (string)\n\nThe source at the input device that is currently active. You can specify this source.\n\nDeviceState -> (string)\n\nThe state of the input device.\n\nFramerate -> (double)\n\nThe frame rate of the video source.\n\nHeight -> (integer)\n\nThe height of the video source, in pixels.\n\nMaxBitrate -> (integer)\n\nThe current maximum bitrate for ingesting this source, in bits per second. You can specify this maximum.\n\nScanType -> (string)\n\nThe scan type of the video source.\n\nWidth -> (integer)\n\nThe width of the video source, in pixels.\n\nId -> (string)\n\nThe unique ID of the input device.\n\nMacAddress -> (string)\n\nThe network MAC address of the input device.\n\nName -> (string)\n\nA name that you specify for the input device.\n\nNetworkSettings -> (structure)\n\nThe network settings for the input device.\n\nDnsAddresses -> (list)\n\nThe DNS addresses of the input device.\n\n(string)\n\nPlaceholder documentation for __string\n\nGateway -> (string)\n\nThe network gateway IP address.\n\nIpAddress -> (string)\n\nThe IP address of the input device.\n\nIpScheme -> (string)\n\nSpecifies whether the input device has been configured (outside of MediaLive) to use a dynamic IP address assignment (DHCP) or a static IP address.\n\nSubnetMask -> (string)\n\nThe subnet mask of the input device.\n\nSerialNumber -> (string)\n\nThe unique serial number of the input device.\n\nType -> (string)\n\nThe type of the input device.\n\nUhdDeviceSettings -> (structure)\n\nSettings that describe an input device that is type UHD.\n\nActiveInput -> (string)\n\nIf you specified Auto as the configured input, specifies which of the sources is currently active (SDI or HDMI).\n\nConfiguredInput -> (string)\n\nThe source at the input device that is currently active. You can specify this source.\n\nDeviceState -> (string)\n\nThe state of the input device.\n\nFramerate -> (double)\n\nThe frame rate of the video source.\n\nHeight -> (integer)\n\nThe height of the video source, in pixels.\n\nMaxBitrate -> (integer)\n\nThe current maximum bitrate for ingesting this source, in bits per second. You can specify this maximum.\n\nScanType -> (string)\n\nThe scan type of the video source.\n\nWidth -> (integer)\n\nThe width of the video source, in pixels."
    },
    {
      "command_name": "describe-input-device-thumbnail",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/describe-input-device-thumbnail.html",
      "command_description": "Description\n\nGet the latest thumbnail data for the input device.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-input-device-thumbnail\n--input-device-id <value>\n--accept <value>\n<outfile>\n",
      "command_options": [
        "--input-device-id <value>",
        "--accept <value>",
        "<outfile>"
      ],
      "command_options_description": "Options\n\n--input-device-id (string) The unique ID of this input device. For example, hd-123456789abcdef.\n\n--accept (string) The HTTP Accept header. Indicates the requested type for the thumbnail.\n\nPossible values:\n\nimage/jpeg\n\noutfile (string) Filename where the content will be saved\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nBody -> (blob)\n\nThe binary data for the thumbnail that the Link device has most recently sent to MediaLive.\n\nContentType -> (string)\n\nSpecifies the media type of the thumbnail.\n\nContentLength -> (long)\n\nThe length of the content.\n\nETag -> (string)\n\nThe unique, cacheable version of this thumbnail.\n\nLastModified -> (timestamp)\n\nThe date and time the thumbnail was last updated at the device."
    },
    {
      "command_name": "describe-input-security-group",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/describe-input-security-group.html",
      "command_description": "Description\n\nProduces a summary of an Input Security Group\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-input-security-group\n--input-security-group-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-security-group-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-security-group-id (string) The id of the Input Security Group to describe\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nUnique ARN of Input Security Group\n\nId -> (string)\n\nThe Id of the Input Security Group\n\nInputs -> (list)\n\nThe list of inputs currently using this Input Security Group.\n\n(string)\n\nPlaceholder documentation for __string\n\nState -> (string)\n\nThe current state of the Input Security Group.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nWhitelistRules -> (list)\n\nWhitelist rules and their sync status\n\n(structure)\n\nWhitelist rule\n\nCidr -> (string)\n\nThe IPv4 CIDR that’s whitelisted."
    },
    {
      "command_name": "describe-multiplex",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/describe-multiplex.html",
      "command_description": "Description\n\nGets details about a multiplex.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-multiplex\n--multiplex-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--multiplex-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--multiplex-id (string) The ID of the multiplex.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe unique arn of the multiplex.\n\nAvailabilityZones -> (list)\n\nA list of availability zones for the multiplex.\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the multiplex output destinations.\n\n(structure)\n\nMultiplex output destination settings\n\nMediaConnectSettings -> (structure)\n\nMultiplex MediaConnect output destination settings.\n\nEntitlementArn -> (string)\n\nThe MediaConnect entitlement ARN available as a Flow source.\n\nId -> (string)\n\nThe unique id of the multiplex.\n\nMultiplexSettings -> (structure)\n\nConfiguration for a multiplex event.\n\nMaximumVideoBufferDelayMilliseconds -> (integer)\n\nMaximum video buffer delay in milliseconds.\n\nTransportStreamBitrate -> (integer)\n\nTransport stream bit rate.\n\nTransportStreamId -> (integer)\n\nTransport stream ID.\n\nTransportStreamReservedBitrate -> (integer)\n\nTransport stream reserved bit rate.\n\nName -> (string)\n\nThe name of the multiplex.\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nProgramCount -> (integer)\n\nThe number of programs in the multiplex.\n\nState -> (string)\n\nThe current state of the multiplex.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "describe-multiplex-program",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/describe-multiplex-program.html",
      "command_description": "Description\n\nGet the details for a program in a multiplex.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-multiplex-program\n--multiplex-id <value>\n--program-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--multiplex-id <value>",
        "--program-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--multiplex-id (string) The ID of the multiplex that the program belongs to.\n\n--program-name (string) The name of the program.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nChannelId -> (string)\n\nThe MediaLive channel associated with the program.\n\nMultiplexProgramSettings -> (structure)\n\nThe settings for this multiplex program.\n\nPreferredChannelPipeline -> (string)\n\nIndicates which pipeline is preferred by the multiplex for program ingest.\n\nProgramNumber -> (integer)\n\nUnique program number.\n\nServiceDescriptor -> (structure)\n\nTransport stream service descriptor configuration for the Multiplex program.\n\nProviderName -> (string)\n\nName of the provider.\n\nServiceName -> (string)\n\nName of the service.\n\nVideoSettings -> (structure)\n\nProgram video settings configuration.\n\nConstantBitrate -> (integer)\n\nThe constant bitrate configuration for the video encode. When this field is defined, StatmuxSettings must be undefined.\n\nStatmuxSettings -> (structure)\n\nStatmux rate control settings. When this field is defined, ConstantBitrate must be undefined.\n\nMaximumBitrate -> (integer)\n\nMaximum statmux bitrate.\n\nMinimumBitrate -> (integer)\n\nMinimum statmux bitrate.\n\nPriority -> (integer)\n\nThe purpose of the priority is to use a combination of thenmultiplex rate control algorithm and the QVBR capability of thenencoder to prioritize the video quality of some channels in anmultiplex over others. Channels that have a higher priority willnget higher video quality at the expense of the video quality ofnother channels in the multiplex with lower priority.\n\nPacketIdentifiersMap -> (structure)\n\nThe packet identifier map for this multiplex program.\n\nAudioPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nDvbSubPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nDvbTeletextPid -> (integer)\n\nPlaceholder documentation for __integer\n\nEtvPlatformPid -> (integer)\n\nPlaceholder documentation for __integer\n\nEtvSignalPid -> (integer)\n\nPlaceholder documentation for __integer\n\nKlvDataPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nPcrPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPmtPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPrivateMetadataPid -> (integer)\n\nPlaceholder documentation for __integer\n\nScte27Pids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nScte35Pid -> (integer)\n\nPlaceholder documentation for __integer\n\nTimedMetadataPid -> (integer)\n\nPlaceholder documentation for __integer\n\nVideoPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPipelineDetails -> (list)\n\nContains information about the current sources for the specified program in the specified multiplex. Keep in mind that each multiplex pipeline connects to both pipelines in a given source channel (the channel identified by the program). But only one of those channel pipelines is ever active at one time.\n\n(structure)\n\nThe current source for one of the pipelines in the multiplex.\n\nActiveChannelPipeline -> (string)\n\nIdentifies the channel pipeline that is currently active for the pipeline (identified by PipelineId) in the multiplex.\n\nPipelineId -> (string)\n\nIdentifies a specific pipeline in the multiplex.\n\nProgramName -> (string)\n\nThe name of the multiplex program."
    },
    {
      "command_name": "describe-offering",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/describe-offering.html",
      "command_description": "Description\n\nGet details for an offering.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-offering\n--offering-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--offering-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--offering-id (string) Unique offering ID, e.g. ‘87654321’\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nUnique offering ARN, e.g. ‘arn:aws:medialive:us-west-2:123456789012:offering:87654321’\n\nCurrencyCode -> (string)\n\nCurrency code for usagePrice and fixedPrice in ISO-4217 format, e.g. ‘USD’\n\nDuration -> (integer)\n\nLease duration, e.g. ‘12’\n\nDurationUnits -> (string)\n\nUnits for duration, e.g. ‘MONTHS’\n\nFixedPrice -> (double)\n\nOne-time charge for each reserved resource, e.g. ‘0.0’ for a NO_UPFRONT offering\n\nOfferingDescription -> (string)\n\nOffering description, e.g. ‘HD AVC output at 10-20 Mbps, 30 fps, and standard VQ in US West (Oregon)’\n\nOfferingId -> (string)\n\nUnique offering ID, e.g. ‘87654321’\n\nOfferingType -> (string)\n\nOffering type, e.g. ‘NO_UPFRONT’\n\nRegion -> (string)\n\nAWS region, e.g. ‘us-west-2’\n\nResourceSpecification -> (structure)\n\nResource configuration details\n\nChannelClass -> (string)\n\nChannel class, e.g. ‘STANDARD’\n\nCodec -> (string)\n\nCodec, e.g. ‘AVC’\n\nMaximumBitrate -> (string)\n\nMaximum bitrate, e.g. ‘MAX_20_MBPS’\n\nMaximumFramerate -> (string)\n\nMaximum framerate, e.g. ‘MAX_30_FPS’ (Outputs only)\n\nResolution -> (string)\n\nResolution, e.g. ‘HD’\n\nResourceType -> (string)\n\nResource type, ‘INPUT’, ‘OUTPUT’, ‘MULTIPLEX’, or ‘CHANNEL’\n\nSpecialFeature -> (string)\n\nSpecial feature, e.g. ‘AUDIO_NORMALIZATION’ (Channels only)\n\nVideoQuality -> (string)\n\nVideo quality, e.g. ‘STANDARD’ (Outputs only)\n\nUsagePrice -> (double)\n\nRecurring usage charge for each reserved resource, e.g. ‘157.0’"
    },
    {
      "command_name": "describe-reservation",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/describe-reservation.html",
      "command_description": "Description\n\nGet details for a reservation.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-reservation\n--reservation-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--reservation-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--reservation-id (string) Unique reservation ID, e.g. ‘1234567’\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nUnique reservation ARN, e.g. ‘arn:aws:medialive:us-west-2:123456789012:reservation:1234567’\n\nCount -> (integer)\n\nNumber of reserved resources\n\nCurrencyCode -> (string)\n\nCurrency code for usagePrice and fixedPrice in ISO-4217 format, e.g. ‘USD’\n\nDuration -> (integer)\n\nLease duration, e.g. ‘12’\n\nDurationUnits -> (string)\n\nUnits for duration, e.g. ‘MONTHS’\n\nEnd -> (string)\n\nReservation UTC end date and time in ISO-8601 format, e.g. ‘2019-03-01T00:00:00’\n\nFixedPrice -> (double)\n\nOne-time charge for each reserved resource, e.g. ‘0.0’ for a NO_UPFRONT offering\n\nName -> (string)\n\nUser specified reservation name\n\nOfferingDescription -> (string)\n\nOffering description, e.g. ‘HD AVC output at 10-20 Mbps, 30 fps, and standard VQ in US West (Oregon)’\n\nOfferingId -> (string)\n\nUnique offering ID, e.g. ‘87654321’\n\nOfferingType -> (string)\n\nOffering type, e.g. ‘NO_UPFRONT’\n\nRegion -> (string)\n\nAWS region, e.g. ‘us-west-2’\n\nReservationId -> (string)\n\nUnique reservation ID, e.g. ‘1234567’\n\nResourceSpecification -> (structure)\n\nResource configuration details\n\nChannelClass -> (string)\n\nChannel class, e.g. ‘STANDARD’\n\nCodec -> (string)\n\nCodec, e.g. ‘AVC’\n\nMaximumBitrate -> (string)\n\nMaximum bitrate, e.g. ‘MAX_20_MBPS’\n\nMaximumFramerate -> (string)\n\nMaximum framerate, e.g. ‘MAX_30_FPS’ (Outputs only)\n\nResolution -> (string)\n\nResolution, e.g. ‘HD’\n\nResourceType -> (string)\n\nResource type, ‘INPUT’, ‘OUTPUT’, ‘MULTIPLEX’, or ‘CHANNEL’\n\nSpecialFeature -> (string)\n\nSpecial feature, e.g. ‘AUDIO_NORMALIZATION’ (Channels only)\n\nVideoQuality -> (string)\n\nVideo quality, e.g. ‘STANDARD’ (Outputs only)\n\nStart -> (string)\n\nReservation UTC start date and time in ISO-8601 format, e.g. ‘2018-03-01T00:00:00’\n\nState -> (string)\n\nCurrent state of reservation, e.g. ‘ACTIVE’\n\nTags -> (map)\n\nA collection of key-value pairs\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nUsagePrice -> (double)\n\nRecurring usage charge for each reserved resource, e.g. ‘157.0’"
    },
    {
      "command_name": "describe-schedule",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/describe-schedule.html",
      "command_description": "Description\n\nGet a channel schedule\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\ndescribe-schedule is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: ScheduleActions",
      "command_synopsis": "Synopsis\n  describe-schedule\n--channel-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-id (string) Id of the channel whose schedule is being updated.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNextToken -> (string)\n\nThe next token; for use in pagination.\n\nScheduleActions -> (list)\n\nThe list of actions in the schedule.\n\n(structure)\n\nContains information on a single schedule action.\n\nActionName -> (string)\n\nThe name of the action, must be unique within the schedule. This name provides the main reference to an action once it is added to the schedule. A name is unique if it is no longer in the schedule. The schedule is automatically cleaned up to remove actions with a start time of more than 1 hour ago (approximately) so at that point a name can be reused.\n\nScheduleActionSettings -> (structure)\n\nSettings for this schedule action.\n\nHlsId3SegmentTaggingSettings -> (structure)\n\nAction to insert HLS ID3 segment tagging\n\nTag -> (string)\n\nID3 tag to insert into each segment. Supports special keyword identifiers to substitute in segment-related values.nSupported keyword identifiers: https://docs.aws.amazon.com/medialive/latest/ug/variable-data-identifiers.html\n\nHlsTimedMetadataSettings -> (structure)\n\nAction to insert HLS metadata\n\nId3 -> (string)\n\nBase64 string formatted according to the ID3 specification: http://id3.org/id3v2.4.0-structure\n\nInputPrepareSettings -> (structure)\n\nAction to prepare an input for a future immediate input switch\n\nInputAttachmentNameReference -> (string)\n\nThe name of the input attachment that should be prepared by this action. If no name is provided, the action will stop the most recent prepare (if any) when activated.\n\nInputClippingSettings -> (structure)\n\nSettings to let you create a clip of the file input, in order to set up the input to ingest only a portion of the file.\n\nInputTimecodeSource -> (string)\n\nThe source of the timecodes in the source being clipped.\n\nStartTimecode -> (structure)\n\nSettings to identify the start of the clip.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to start the clip. Optional; if not specified, the clip starts at first frame in the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nStopTimecode -> (structure)\n\nSettings to identify the end of the clip.\n\nLastFrameClippingBehavior -> (string)\n\nIf you specify a StopTimecode in an input (in order to clip the file), you can specify if you want the clip to exclude (the default) or include the frame specified by the timecode.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to stop the clip. Optional; if not specified, the clip continues to the end of the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nUrlPath -> (list)\n\nThe value for the variable portion of the URL for the dynamic input, for this instance of the input. Each time you use the same dynamic input in an input switch action, you can provide a different value, in order to connect the input to a different content source.\n\n(string)\n\nPlaceholder documentation for __string\n\nInputSwitchSettings -> (structure)\n\nAction to switch the input\n\nInputAttachmentNameReference -> (string)\n\nThe name of the input attachment (not the name of the input!) to switch to. The name is specified in the channel configuration.\n\nInputClippingSettings -> (structure)\n\nSettings to let you create a clip of the file input, in order to set up the input to ingest only a portion of the file.\n\nInputTimecodeSource -> (string)\n\nThe source of the timecodes in the source being clipped.\n\nStartTimecode -> (structure)\n\nSettings to identify the start of the clip.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to start the clip. Optional; if not specified, the clip starts at first frame in the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nStopTimecode -> (structure)\n\nSettings to identify the end of the clip.\n\nLastFrameClippingBehavior -> (string)\n\nIf you specify a StopTimecode in an input (in order to clip the file), you can specify if you want the clip to exclude (the default) or include the frame specified by the timecode.\n\nTimecode -> (string)\n\nThe timecode for the frame where you want to stop the clip. Optional; if not specified, the clip continues to the end of the file. Enter the timecode as HH:MM:SS:FF or HH:MM:SS;FF.\n\nUrlPath -> (list)\n\nThe value for the variable portion of the URL for the dynamic input, for this instance of the input. Each time you use the same dynamic input in an input switch action, you can provide a different value, in order to connect the input to a different content source.\n\n(string)\n\nPlaceholder documentation for __string\n\nMotionGraphicsImageActivateSettings -> (structure)\n\nAction to activate a motion graphics image overlay\n\nDuration -> (long)\n\nDuration (in milliseconds) that motion graphics should render on to the video stream. Leaving out this property or setting to 0 will result in rendering continuing until a deactivate action is processed.\n\nPasswordParam -> (string)\n\nKey used to extract the password from EC2 Parameter store\n\nUrl -> (string)\n\nURI of the HTML5 content to be rendered into the live stream.\n\nUsername -> (string)\n\nDocumentation update needed\n\nMotionGraphicsImageDeactivateSettings -> (structure)\n\nAction to deactivate a motion graphics image overlay\n\nPauseStateSettings -> (structure)\n\nAction to pause or unpause one or both channel pipelines\n\nPipelines -> (list)\n\nPlaceholder documentation for __listOfPipelinePauseStateSettings\n\n(structure)\n\nSettings for pausing a pipeline.\n\nPipelineId -> (string)\n\nPipeline ID to pause (“PIPELINE_0” or “PIPELINE_1”).\n\nScte35ReturnToNetworkSettings -> (structure)\n\nAction to insert SCTE-35 return_to_network message\n\nSpliceEventId -> (long)\n\nThe splice_event_id for the SCTE-35 splice_insert, as defined in SCTE-35.\n\nScte35SpliceInsertSettings -> (structure)\n\nAction to insert SCTE-35 splice_insert message\n\nDuration -> (long)\n\nOptional, the duration for the splice_insert, in 90 KHz ticks. To convert seconds to ticks, multiple the seconds by 90,000. If you enter a duration, there is an expectation that the downstream system can read the duration and cue in at that time. If you do not enter a duration, the splice_insert will continue indefinitely and there is an expectation that you will enter a return_to_network to end the splice_insert at the appropriate time.\n\nSpliceEventId -> (long)\n\nThe splice_event_id for the SCTE-35 splice_insert, as defined in SCTE-35.\n\nScte35TimeSignalSettings -> (structure)\n\nAction to insert SCTE-35 time_signal message\n\nScte35Descriptors -> (list)\n\nThe list of SCTE-35 descriptors accompanying the SCTE-35 time_signal.\n\n(structure)\n\nHolds one set of SCTE-35 Descriptor Settings.\n\nScte35DescriptorSettings -> (structure)\n\nSCTE-35 Descriptor Settings.\n\nSegmentationDescriptorScte35DescriptorSettings -> (structure)\n\nSCTE-35 Segmentation Descriptor.\n\nDeliveryRestrictions -> (structure)\n\nHolds the four SCTE-35 delivery restriction parameters.\n\nArchiveAllowedFlag -> (string)\n\nCorresponds to SCTE-35 archive_allowed_flag.\n\nDeviceRestrictions -> (string)\n\nCorresponds to SCTE-35 device_restrictions parameter.\n\nNoRegionalBlackoutFlag -> (string)\n\nCorresponds to SCTE-35 no_regional_blackout_flag parameter.\n\nWebDeliveryAllowedFlag -> (string)\n\nCorresponds to SCTE-35 web_delivery_allowed_flag parameter.\n\nSegmentNum -> (integer)\n\nCorresponds to SCTE-35 segment_num. A value that is valid for the specified segmentation_type_id.\n\nSegmentationCancelIndicator -> (string)\n\nCorresponds to SCTE-35 segmentation_event_cancel_indicator.\n\nSegmentationDuration -> (long)\n\nCorresponds to SCTE-35 segmentation_duration. Optional. The duration for the time_signal, in 90 KHz ticks. To convert seconds to ticks, multiple the seconds by 90,000. Enter time in 90 KHz clock ticks. If you do not enter a duration, the time_signal will continue until you insert a cancellation message.\n\nSegmentationEventId -> (long)\n\nCorresponds to SCTE-35 segmentation_event_id.\n\nSegmentationTypeId -> (integer)\n\nCorresponds to SCTE-35 segmentation_type_id. One of the segmentation_type_id values listed in the SCTE-35 specification. On the console, enter the ID in decimal (for example, “52”). In the CLI, API, or an SDK, enter the ID in hex (for example, “0x34”) or decimal (for example, “52”).\n\nSegmentationUpid -> (string)\n\nCorresponds to SCTE-35 segmentation_upid. Enter a string containing the hexadecimal representation of the characters that make up the SCTE-35 segmentation_upid value. Must contain an even number of hex characters. Do not include spaces between each hex pair. For example, the ASCII “ADS Information” becomes hex “41445320496e666f726d6174696f6e.\n\nSegmentationUpidType -> (integer)\n\nCorresponds to SCTE-35 segmentation_upid_type. On the console, enter one of the types listed in the SCTE-35 specification, converted to a decimal. For example, “0x0C” hex from the specification is “12” in decimal. In the CLI, API, or an SDK, enter one of the types listed in the SCTE-35 specification, in either hex (for example, “0x0C” ) or in decimal (for example, “12”).\n\nSegmentsExpected -> (integer)\n\nCorresponds to SCTE-35 segments_expected. A value that is valid for the specified segmentation_type_id.\n\nSubSegmentNum -> (integer)\n\nCorresponds to SCTE-35 sub_segment_num. A value that is valid for the specified segmentation_type_id.\n\nSubSegmentsExpected -> (integer)\n\nCorresponds to SCTE-35 sub_segments_expected. A value that is valid for the specified segmentation_type_id.\n\nStaticImageActivateSettings -> (structure)\n\nAction to activate a static image overlay\n\nDuration -> (integer)\n\nThe duration in milliseconds for the image to remain on the video. If omitted or set to 0 the duration is unlimited and the image will remain until it is explicitly deactivated.\n\nFadeIn -> (integer)\n\nThe time in milliseconds for the image to fade in. The fade-in starts at the start time of the overlay. Default is 0 (no fade-in).\n\nFadeOut -> (integer)\n\nApplies only if a duration is specified. The time in milliseconds for the image to fade out. The fade-out starts when the duration time is hit, so it effectively extends the duration. Default is 0 (no fade-out).\n\nHeight -> (integer)\n\nThe height of the image when inserted into the video, in pixels. The overlay will be scaled up or down to the specified height. Leave blank to use the native height of the overlay.\n\nImage -> (structure)\n\nThe location and filename of the image file to overlay on the video. The file must be a 32-bit BMP, PNG, or TGA file, and must not be larger (in pixels) than the input video.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nImageX -> (integer)\n\nPlacement of the left edge of the overlay relative to the left edge of the video frame, in pixels. 0 (the default) is the left edge of the frame. If the placement causes the overlay to extend beyond the right edge of the underlying video, then the overlay is cropped on the right.\n\nImageY -> (integer)\n\nPlacement of the top edge of the overlay relative to the top edge of the video frame, in pixels. 0 (the default) is the top edge of the frame. If the placement causes the overlay to extend beyond the bottom edge of the underlying video, then the overlay is cropped on the bottom.\n\nLayer -> (integer)\n\nThe number of the layer, 0 to 7. There are 8 layers that can be overlaid on the video, each layer with a different image. The layers are in Z order, which means that overlays with higher values of layer are inserted on top of overlays with lower values of layer. Default is 0.\n\nOpacity -> (integer)\n\nOpacity of image where 0 is transparent and 100 is fully opaque. Default is 100.\n\nWidth -> (integer)\n\nThe width of the image when inserted into the video, in pixels. The overlay will be scaled up or down to the specified width. Leave blank to use the native width of the overlay.\n\nStaticImageDeactivateSettings -> (structure)\n\nAction to deactivate a static image overlay\n\nFadeOut -> (integer)\n\nThe time in milliseconds for the image to fade out. Default is 0 (no fade-out).\n\nLayer -> (integer)\n\nThe image overlay layer to deactivate, 0 to 7. Default is 0.\n\nScheduleActionStartSettings -> (structure)\n\nThe time for the action to start in the channel.\n\nFixedModeScheduleActionStartSettings -> (structure)\n\nOption for specifying the start time for an action.\n\nTime -> (string)\n\nStart time for the action to start in the channel. (Not the time for the action to be added to the schedule: actions are always added to the schedule immediately.) UTC format: yyyy-mm-ddThh:mm:ss.nnnZ. All the letters are digits (for example, mm might be 01) except for the two constants “T” for time and “Z” for “UTC format”.\n\nFollowModeScheduleActionStartSettings -> (structure)\n\nOption for specifying an action as relative to another action.\n\nFollowPoint -> (string)\n\nIdentifies whether this action starts relative to the start or relative to the end of the reference action.\n\nReferenceActionName -> (string)\n\nThe action name of another action that this one refers to.\n\nImmediateModeScheduleActionStartSettings -> (structure)\n\nOption for specifying an action that should be applied immediately."
    },
    {
      "command_name": "list-channels",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/list-channels.html",
      "command_description": "Description\n\nProduces list of channels that have been created\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-channels is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: Channels",
      "command_synopsis": "Synopsis\n  list-channels\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nChannels -> (list)\n\nPlaceholder documentation for __listOfChannelSummary\n\n(structure)\n\nPlaceholder documentation for ChannelSummary\n\nArn -> (string)\n\nThe unique arn of the channel.\n\nCdiInputSpecification -> (structure)\n\nSpecification of CDI inputs for this channel\n\nResolution -> (string)\n\nMaximum CDI input resolution\n\nChannelClass -> (string)\n\nThe class for this channel. STANDARD for a channel with two pipelines or SINGLE_PIPELINE for a channel with one pipeline.\n\nDestinations -> (list)\n\nA list of destinations of the channel. For UDP outputs, there is one destination per output. For other types (HLS, for example), there is one destination per packager.\n\n(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nEgressEndpoints -> (list)\n\nThe endpoints where outgoing connections initiate from\n\n(structure)\n\nPlaceholder documentation for ChannelEgressEndpoint\n\nSourceIp -> (string)\n\nPublic IP of where a channel’s output comes from\n\nId -> (string)\n\nThe unique id of the channel.\n\nInputAttachments -> (list)\n\nList of input attachments for channel.\n\n(structure)\n\nPlaceholder documentation for InputAttachment\n\nAutomaticInputFailoverSettings -> (structure)\n\nUser-specified settings for defining what the conditions are for declaring the input unhealthy and failing over to a different input.\n\nErrorClearTimeMsec -> (integer)\n\nThis clear time defines the requirement a recovered input must meet to be considered healthy. The input must have no failover conditions for this length of time. Enter a time in milliseconds. This value is particularly important if the input_preference for the failover pair is set to PRIMARY_INPUT_PREFERRED, because after this time, MediaLive will switch back to the primary input.\n\nFailoverConditions -> (list)\n\nA list of failover conditions. If any of these conditions occur, MediaLive will perform a failover to the other input.\n\n(structure)\n\nFailover Condition settings. There can be multiple failover conditions inside AutomaticInputFailoverSettings.\n\nFailoverConditionSettings -> (structure)\n\nFailover condition type-specific settings.\n\nAudioSilenceSettings -> (structure)\n\nMediaLive will perform a failover if the specified audio selector is silent for the specified period.\n\nAudioSelectorName -> (string)\n\nThe name of the audio selector in the input that MediaLive should monitor to detect silence. Select your most important rendition. If you didn’t create an audio selector in this input, leave blank.\n\nAudioSilenceThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be silent before automatic input failover occurs. Silence is defined as audio loss or audio quieter than -50 dBFS.\n\nInputLossSettings -> (structure)\n\nMediaLive will perform a failover if content is not detected in this input for the specified period.\n\nInputLossThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that no input is detected. After that time, an input failover will occur.\n\nVideoBlackSettings -> (structure)\n\nMediaLive will perform a failover if content is considered black for the specified period.\n\nBlackDetectThreshold -> (double)\n\nA value used in calculating the threshold below which MediaLive considers a pixel to be ‘black’. For the input to be considered black, every pixel in a frame must be below this threshold. The threshold is calculated as a percentage (expressed as a decimal) of white. Therefore .1 means 10% white (or 90% black). Note how the formula works for any color depth. For example, if you set this field to 0.1 in 10-bit color depth: (1023*0.1=102.3), which means a pixel value of 102 or less is ‘black’. If you set this field to .1 in an 8-bit color depth: (255*0.1=25.5), which means a pixel value of 25 or less is ‘black’. The range is 0.0 to 1.0, with any number of decimal places.\n\nVideoBlackThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be black before automatic input failover occurs.\n\nInputPreference -> (string)\n\nInput preference when deciding which input to make active when a previously failed input has recovered.\n\nSecondaryInputId -> (string)\n\nThe input ID of the secondary input in the automatic input failover pair.\n\nInputAttachmentName -> (string)\n\nUser-specified name for the attachment. This is required if the user wants to use this input in an input switch action.\n\nInputId -> (string)\n\nThe ID of the input\n\nInputSettings -> (structure)\n\nSettings of an input (caption selector, etc.)\n\nAudioSelectors -> (list)\n\nUsed to select the audio stream to decode for inputs that have multiple available.\n\n(structure)\n\nAudio Selector\n\nName -> (string)\n\nThe name of this AudioSelector. AudioDescriptions will use this name to uniquely identify this Selector. Selector names should be unique per input.\n\nSelectorSettings -> (structure)\n\nThe audio selector settings.\n\nAudioHlsRenditionSelection -> (structure)\n\nAudio Hls Rendition Selection\n\nGroupId -> (string)\n\nSpecifies the GROUP-ID in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nName -> (string)\n\nSpecifies the NAME in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nAudioLanguageSelection -> (structure)\n\nAudio Language Selection\n\nLanguageCode -> (string)\n\nSelects a specific three-letter language code from within an audio source.\n\nLanguageSelectionPolicy -> (string)\n\nWhen set to “strict”, the transport stream demux strictly identifies audio streams by their language descriptor. If a PMT update occurs such that an audio stream matching the initially selected language is no longer present then mute will be encoded until the language returns. If “loose”, then on a PMT update the demux will choose another audio stream in the program with the same stream type if it can’t find one with the same language.\n\nAudioPidSelection -> (structure)\n\nAudio Pid Selection\n\nPid -> (integer)\n\nSelects a specific PID from within a source.\n\nAudioTrackSelection -> (structure)\n\nAudio Track Selection\n\nTracks -> (list)\n\nSelects one or more unique audio tracks from within a source.\n\n(structure)\n\nAudio Track\n\nTrack -> (integer)\n\n1-based integer value that maps to a specific audio track\n\nCaptionSelectors -> (list)\n\nUsed to select the caption input to use for inputs that have multiple available.\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nLanguageCode -> (string)\n\nWhen specified this field indicates the three letter language code of the caption track to extract from the source.\n\nName -> (string)\n\nName identifier for a caption selector. This name is used to associate this caption selector with one or more caption descriptions. Names must be unique within an event.\n\nSelectorSettings -> (structure)\n\nCaption selector settings.\n\nAncillarySourceSettings -> (structure)\n\nAncillary Source Settings\n\nSourceAncillaryChannelNumber -> (integer)\n\nSpecifies the number (1 to 4) of the captions channel you want to extract from the ancillary captions. If you plan to convert the ancillary captions to another format, complete this field. If you plan to choose Embedded as the captions destination in the output (to pass through all the channels in the ancillary captions), leave this field blank because MediaLive ignores the field.\n\nAribSourceSettings -> (structure)\n\nArib Source Settings\n\nDvbSubSourceSettings -> (structure)\n\nDvb Sub Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nWhen using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through, regardless of selectors.\n\nEmbeddedSourceSettings -> (structure)\n\nEmbedded Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nScte20Detection -> (string)\n\nSet to “auto” to handle streams with intermittent and/or non-aligned SCTE-20 and Embedded captions.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nSource608TrackNumber -> (integer)\n\nThis field is unused and deprecated.\n\nScte20SourceSettings -> (structure)\n\nScte20 Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nScte27SourceSettings -> (structure)\n\nScte27 Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nThe pid field is used in conjunction with the caption selector languageCode field as follows: - Specify PID and Language: Extracts captions from that PID; the language is “informational”. - Specify PID and omit Language: Extracts the specified PID. - Omit PID and specify Language: Extracts the specified language, whichever PID that happens to be. - Omit PID and omit Language: Valid only if source is DVB-Sub that is being passed through; all languages will be passed through.\n\nTeletextSourceSettings -> (structure)\n\nTeletext Source Settings\n\nOutputRectangle -> (structure)\n\nOptionally defines a region where TTML style captions will be displayed\n\nHeight -> (double)\n\nSee the description in leftOffset. For height, specify the entire height of the rectangle as a percentage of the underlying frame height. For example, “80” means the rectangle height is 80% of the underlying frame height. The topOffset and rectangleHeight must add up to 100% or less. This field corresponds to tts:extent - Y in the TTML standard.\n\nLeftOffset -> (double)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. (Make sure to leave the default if you don’t have either of these formats in the output.) You can define a display rectangle for the captions that is smaller than the underlying video frame. You define the rectangle by specifying the position of the left edge, top edge, bottom edge, and right edge of the rectangle, all within the underlying video frame. The units for the measurements are percentages. If you specify a value for one of these fields, you must specify a value for all of them. For leftOffset, specify the position of the left edge of the rectangle, as a percentage of the underlying frame width, and relative to the left edge of the frame. For example, “10” means the measurement is 10% of the underlying frame width. The rectangle left edge starts at that position from the left edge of the frame. This field corresponds to tts:origin - X in the TTML standard.\n\nTopOffset -> (double)\n\nSee the description in leftOffset. For topOffset, specify the position of the top edge of the rectangle, as a percentage of the underlying frame height, and relative to the top edge of the frame. For example, “10” means the measurement is 10% of the underlying frame height. The rectangle top edge starts at that position from the top edge of the frame. This field corresponds to tts:origin - Y in the TTML standard.\n\nWidth -> (double)\n\nSee the description in leftOffset. For width, specify the entire width of the rectangle as a percentage of the underlying frame width. For example, “80” means the rectangle width is 80% of the underlying frame width. The leftOffset and rectangleWidth must add up to 100% or less. This field corresponds to tts:extent - X in the TTML standard.\n\nPageNumber -> (string)\n\nSpecifies the teletext page number within the data stream from which to extract captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should be specified as a hexadecimal string with no “0x” prefix.\n\nDeblockFilter -> (string)\n\nEnable or disable the deblock filter when filtering.\n\nDenoiseFilter -> (string)\n\nEnable or disable the denoise filter when filtering.\n\nFilterStrength -> (integer)\n\nAdjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).\n\nInputFilter -> (string)\n\nTurns on the filter for this input. MPEG-2 inputs have the deblocking filter enabled by default. 1) auto - filtering will be applied depending on input type/quality 2) disabled - no filtering will be applied to the input 3) forced - filtering will be applied regardless of input type\n\nNetworkInputSettings -> (structure)\n\nInput settings.\n\nHlsInputSettings -> (structure)\n\nSpecifies HLS input settings when the uri is for a HLS manifest.\n\nBandwidth -> (integer)\n\nWhen specified the HLS stream with the m3u8 BANDWIDTH that most closely matches this value will be chosen, otherwise the highest bandwidth stream in the m3u8 will be chosen. The bitrate is specified in bits per second, as in an HLS manifest.\n\nBufferSegments -> (integer)\n\nWhen specified, reading of the HLS input will begin this many buffer segments from the end (most recently written segment). When not specified, the HLS input will begin with the first segment specified in the m3u8.\n\nRetries -> (integer)\n\nThe number of consecutive times that attempts to read a manifest or segment must fail before the input is considered unavailable.\n\nRetryInterval -> (integer)\n\nThe number of seconds between retries when an attempt to read a manifest or segment fails.\n\nScte35Source -> (string)\n\nIdentifies the source for the SCTE-35 messages that MediaLive will ingest. Messages can be ingested from the content segments (in the stream) or from tags in the playlist (the HLS manifest). MediaLive ignores SCTE-35 information in the source that is not selected.\n\nServerValidation -> (string)\n\nCheck HTTPS server certificates. When set to checkCryptographyOnly, cryptography in the certificate will be checked, but not the server’s name. Certain subdomains (notably S3 buckets that use dots in the bucket name) do not strictly match the corresponding certificate’s wildcard pattern and would otherwise cause the event to error. This setting is ignored for protocols that do not use https.\n\nSmpte2038DataPreference -> (string)\n\nSpecifies whether to extract applicable ancillary data from a SMPTE-2038 source in this input. Applicable data types are captions, timecode, AFD, and SCTE-104 messages. - PREFER: Extract from SMPTE-2038 if present in this input, otherwise extract from another source (if any). - IGNORE: Never extract any ancillary data from SMPTE-2038.\n\nSourceEndBehavior -> (string)\n\nLoop input if it is a file. This allows a file input to be streamed indefinitely.\n\nVideoSelector -> (structure)\n\nInforms which video elementary stream to decode for input types that have multiple available.\n\nColorSpace -> (string)\n\nSpecifies the color space of an input. This setting works in tandem with colorSpaceUsage and a video description’s colorSpaceSettingsChoice to determine if any conversion will be performed.\n\nColorSpaceSettings -> (structure)\n\nColor space settings\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nColorSpaceUsage -> (string)\n\nApplies only if colorSpace is a value other than follow. This field controls how the value in the colorSpace field will be used. fallback means that when the input does include color space data, that data will be used, but when the input has no color space data, the value in colorSpace will be used. Choose fallback if your input is sometimes missing color space data, but when it does have color space data, that data is correct. force means to always use the value in colorSpace. Choose force if your input usually has no color space data or might have unreliable color space data.\n\nSelectorSettings -> (structure)\n\nThe video selector settings.\n\nVideoSelectorPid -> (structure)\n\nVideo Selector Pid\n\nPid -> (integer)\n\nSelects a specific PID from within a video source.\n\nVideoSelectorProgramId -> (structure)\n\nVideo Selector Program Id\n\nProgramId -> (integer)\n\nSelects a specific program from within a multi-program transport stream. If the program doesn’t exist, the first program within the transport stream will be selected by default.\n\nInputSpecification -> (structure)\n\nSpecification of network and file inputs for this channel\n\nCodec -> (string)\n\nInput codec\n\nMaximumBitrate -> (string)\n\nMaximum input bitrate, categorized coarsely\n\nResolution -> (string)\n\nInput resolution, categorized coarsely\n\nLogLevel -> (string)\n\nThe log level being written to CloudWatch Logs.\n\nName -> (string)\n\nThe name of the channel. (user-mutable)\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role assumed when running the Channel.\n\nState -> (string)\n\nPlaceholder documentation for ChannelState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nVpc -> (structure)\n\nSettings for any VPC outputs.\n\nAvailabilityZones -> (list)\n\nThe Availability Zones where the vpc subnets are located. The first Availability Zone applies to the first subnet in the list of subnets. The second Availability Zone applies to the second subnet.\n\n(string)\n\nPlaceholder documentation for __string\n\nNetworkInterfaceIds -> (list)\n\nA list of Elastic Network Interfaces created by MediaLive in the customer’s VPC\n\n(string)\n\nPlaceholder documentation for __string\n\nSecurityGroupIds -> (list)\n\nA list of up EC2 VPC security group IDs attached to the Output VPC network interfaces.\n\n(string)\n\nPlaceholder documentation for __string\n\nSubnetIds -> (list)\n\nA list of VPC subnet IDs from the same VPC. If STANDARD channel, subnet IDs must be mapped to two unique availability zones (AZ).\n\n(string)\n\nPlaceholder documentation for __string\n\nNextToken -> (string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "list-input-device-transfers",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/list-input-device-transfers.html",
      "command_description": "Description\n\nList input devices that are currently being transferred. List input devices that you are transferring from your AWS account or input devices that another AWS account is transferring to you.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-input-device-transfers is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: InputDeviceTransfers",
      "command_synopsis": "Synopsis\n  list-input-device-transfers\n--transfer-type <value>\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--transfer-type <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--transfer-type (string) Placeholder documentation for __string\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nInputDeviceTransfers -> (list)\n\nThe list of devices that you are transferring or are being transferred to you.\n\n(structure)\n\nDetails about the input device that is being transferred.\n\nId -> (string)\n\nThe unique ID of the input device.\n\nMessage -> (string)\n\nThe optional message that the sender has attached to the transfer.\n\nTargetCustomerId -> (string)\n\nThe AWS account ID for the recipient of the input device transfer.\n\nTransferType -> (string)\n\nThe type (direction) of the input device transfer.\n\nNextToken -> (string)\n\nA token to get additional list results."
    },
    {
      "command_name": "list-input-devices",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/list-input-devices.html",
      "command_description": "Description\n\nList input devices\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-input-devices is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: InputDevices",
      "command_synopsis": "Synopsis\n  list-input-devices\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nInputDevices -> (list)\n\nThe list of input devices.\n\n(structure)\n\nDetails of the input device.\n\nArn -> (string)\n\nThe unique ARN of the input device.\n\nConnectionState -> (string)\n\nThe state of the connection between the input device and AWS.\n\nDeviceSettingsSyncState -> (string)\n\nThe status of the action to synchronize the device configuration. If you change the configuration of the input device (for example, the maximum bitrate), MediaLive sends the new data to the device. The device might not update itself immediately. SYNCED means the device has updated its configuration. SYNCING means that it has not updated its configuration.\n\nDeviceUpdateStatus -> (string)\n\nThe status of software on the input device.\n\nHdDeviceSettings -> (structure)\n\nSettings that describe an input device that is type HD.\n\nActiveInput -> (string)\n\nIf you specified Auto as the configured input, specifies which of the sources is currently active (SDI or HDMI).\n\nConfiguredInput -> (string)\n\nThe source at the input device that is currently active. You can specify this source.\n\nDeviceState -> (string)\n\nThe state of the input device.\n\nFramerate -> (double)\n\nThe frame rate of the video source.\n\nHeight -> (integer)\n\nThe height of the video source, in pixels.\n\nMaxBitrate -> (integer)\n\nThe current maximum bitrate for ingesting this source, in bits per second. You can specify this maximum.\n\nScanType -> (string)\n\nThe scan type of the video source.\n\nWidth -> (integer)\n\nThe width of the video source, in pixels.\n\nId -> (string)\n\nThe unique ID of the input device.\n\nMacAddress -> (string)\n\nThe network MAC address of the input device.\n\nName -> (string)\n\nA name that you specify for the input device.\n\nNetworkSettings -> (structure)\n\nNetwork settings for the input device.\n\nDnsAddresses -> (list)\n\nThe DNS addresses of the input device.\n\n(string)\n\nPlaceholder documentation for __string\n\nGateway -> (string)\n\nThe network gateway IP address.\n\nIpAddress -> (string)\n\nThe IP address of the input device.\n\nIpScheme -> (string)\n\nSpecifies whether the input device has been configured (outside of MediaLive) to use a dynamic IP address assignment (DHCP) or a static IP address.\n\nSubnetMask -> (string)\n\nThe subnet mask of the input device.\n\nSerialNumber -> (string)\n\nThe unique serial number of the input device.\n\nType -> (string)\n\nThe type of the input device.\n\nUhdDeviceSettings -> (structure)\n\nSettings that describe an input device that is type UHD.\n\nActiveInput -> (string)\n\nIf you specified Auto as the configured input, specifies which of the sources is currently active (SDI or HDMI).\n\nConfiguredInput -> (string)\n\nThe source at the input device that is currently active. You can specify this source.\n\nDeviceState -> (string)\n\nThe state of the input device.\n\nFramerate -> (double)\n\nThe frame rate of the video source.\n\nHeight -> (integer)\n\nThe height of the video source, in pixels.\n\nMaxBitrate -> (integer)\n\nThe current maximum bitrate for ingesting this source, in bits per second. You can specify this maximum.\n\nScanType -> (string)\n\nThe scan type of the video source.\n\nWidth -> (integer)\n\nThe width of the video source, in pixels.\n\nNextToken -> (string)\n\nA token to get additional list results."
    },
    {
      "command_name": "list-input-security-groups",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/list-input-security-groups.html",
      "command_description": "Description\n\nProduces a list of Input Security Groups for an account\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-input-security-groups is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: InputSecurityGroups",
      "command_synopsis": "Synopsis\n  list-input-security-groups\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nInputSecurityGroups -> (list)\n\nList of input security groups\n\n(structure)\n\nAn Input Security Group\n\nArn -> (string)\n\nUnique ARN of Input Security Group\n\nId -> (string)\n\nThe Id of the Input Security Group\n\nInputs -> (list)\n\nThe list of inputs currently using this Input Security Group.\n\n(string)\n\nPlaceholder documentation for __string\n\nState -> (string)\n\nThe current state of the Input Security Group.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nWhitelistRules -> (list)\n\nWhitelist rules and their sync status\n\n(structure)\n\nWhitelist rule\n\nCidr -> (string)\n\nThe IPv4 CIDR that’s whitelisted.\n\nNextToken -> (string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "list-inputs",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/list-inputs.html",
      "command_description": "Description\n\nProduces list of inputs that have been created\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-inputs is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: Inputs",
      "command_synopsis": "Synopsis\n  list-inputs\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nInputs -> (list)\n\nPlaceholder documentation for __listOfInput\n\n(structure)\n\nPlaceholder documentation for Input\n\nArn -> (string)\n\nThe Unique ARN of the input (generated, immutable).\n\nAttachedChannels -> (list)\n\nA list of channel IDs that that input is attached to (currently an input can only be attached to one channel).\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the destinations of the input (PUSH-type).\n\n(structure)\n\nThe settings for a PUSH type input.\n\nIp -> (string)\n\nThe system-generated static IP address of endpoint. It remains fixed for the lifetime of the input.\n\nPort -> (string)\n\nThe port number for the input.\n\nUrl -> (string)\n\nThis represents the endpoint that the customer stream will be pushed to.\n\nVpc -> (structure)\n\nThe properties for a VPC type input destination.\n\nAvailabilityZone -> (string)\n\nThe availability zone of the Input destination.\n\nNetworkInterfaceId -> (string)\n\nThe network interface ID of the Input destination in the VPC.\n\nId -> (string)\n\nThe generated ID of the input (unique for user account, immutable).\n\nInputClass -> (string)\n\nSTANDARD - MediaLive expects two sources to be connected to this input. If the channel is also STANDARD, both sources will be ingested. If the channel is SINGLE_PIPELINE, only the first source will be ingested; the second source will always be ignored, even if the first source fails. SINGLE_PIPELINE - You can connect only one source to this input. If the ChannelClass is also SINGLE_PIPELINE, this value is valid. If the ChannelClass is STANDARD, this value is not valid because the channel requires two sources in the input.\n\nInputDevices -> (list)\n\nSettings for the input devices.\n\n(structure)\n\nSettings for an input device.\n\nId -> (string)\n\nThe unique ID for the device.\n\nInputPartnerIds -> (list)\n\nA list of IDs for all Inputs which are partners of this one.\n\n(string)\n\nPlaceholder documentation for __string\n\nInputSourceType -> (string)\n\nCertain pull input sources can be dynamic, meaning that they can have their URL’s dynamically changes during input switch actions. Presently, this functionality only works with MP4_FILE and TS_FILE inputs.\n\nMediaConnectFlows -> (list)\n\nA list of MediaConnect Flows for this input.\n\n(structure)\n\nThe settings for a MediaConnect Flow.\n\nFlowArn -> (string)\n\nThe unique ARN of the MediaConnect Flow being used as a source.\n\nName -> (string)\n\nThe user-assigned name (This is a mutable value).\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role this input assumes during and after creation.\n\nSecurityGroups -> (list)\n\nA list of IDs for all the Input Security Groups attached to the input.\n\n(string)\n\nPlaceholder documentation for __string\n\nSources -> (list)\n\nA list of the sources of the input (PULL-type).\n\n(structure)\n\nThe settings for a PULL type input.\n\nPasswordParam -> (string)\n\nThe key used to extract the password from EC2 Parameter store.\n\nUrl -> (string)\n\nThis represents the customer’s source URL where stream is pulled from.\n\nUsername -> (string)\n\nThe username for the input source.\n\nState -> (string)\n\nPlaceholder documentation for InputState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nType -> (string)\n\nThe different types of inputs that AWS Elemental MediaLive supports.\n\nNextToken -> (string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "list-multiplex-programs",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/list-multiplex-programs.html",
      "command_description": "Description\n\nList the programs that currently exist for a specific multiplex.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-multiplex-programs is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: MultiplexPrograms",
      "command_synopsis": "Synopsis\n  list-multiplex-programs\n--multiplex-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--multiplex-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--multiplex-id (string) The ID of the multiplex that the programs belong to.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nMultiplexPrograms -> (list)\n\nList of multiplex programs.\n\n(structure)\n\nPlaceholder documentation for MultiplexProgramSummary\n\nChannelId -> (string)\n\nThe MediaLive Channel associated with the program.\n\nProgramName -> (string)\n\nThe name of the multiplex program.\n\nNextToken -> (string)\n\nToken for the next ListMultiplexProgram request."
    },
    {
      "command_name": "list-multiplexes",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/list-multiplexes.html",
      "command_description": "Description\n\nRetrieve a list of the existing multiplexes.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-multiplexes is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: Multiplexes",
      "command_synopsis": "Synopsis\n  list-multiplexes\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nMultiplexes -> (list)\n\nList of multiplexes.\n\n(structure)\n\nPlaceholder documentation for MultiplexSummary\n\nArn -> (string)\n\nThe unique arn of the multiplex.\n\nAvailabilityZones -> (list)\n\nA list of availability zones for the multiplex.\n\n(string)\n\nPlaceholder documentation for __string\n\nId -> (string)\n\nThe unique id of the multiplex.\n\nMultiplexSettings -> (structure)\n\nConfiguration for a multiplex event.\n\nTransportStreamBitrate -> (integer)\n\nTransport stream bit rate.\n\nName -> (string)\n\nThe name of the multiplex.\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nProgramCount -> (integer)\n\nThe number of programs in the multiplex.\n\nState -> (string)\n\nThe current state of the multiplex.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nNextToken -> (string)\n\nToken for the next ListMultiplexes request."
    },
    {
      "command_name": "list-offerings",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/list-offerings.html",
      "command_description": "Description\n\nList offerings available for purchase.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-offerings is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: Offerings",
      "command_synopsis": "Synopsis\n  list-offerings\n[--channel-class <value>]\n[--channel-configuration <value>]\n[--codec <value>]\n[--duration <value>]\n[--maximum-bitrate <value>]\n[--maximum-framerate <value>]\n[--resolution <value>]\n[--resource-type <value>]\n[--special-feature <value>]\n[--video-quality <value>]\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--channel-class <value>]",
        "[--channel-configuration <value>]",
        "[--codec <value>]",
        "[--duration <value>]",
        "[--maximum-bitrate <value>]",
        "[--maximum-framerate <value>]",
        "[--resolution <value>]",
        "[--resource-type <value>]",
        "[--special-feature <value>]",
        "[--video-quality <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-class (string) Filter by channel class, ‘STANDARD’ or ‘SINGLE_PIPELINE’\n\n--channel-configuration (string) Filter to offerings that match the configuration of an existing channel, e.g. ‘2345678’ (a channel ID)\n\n--codec (string) Filter by codec, ‘AVC’, ‘HEVC’, ‘MPEG2’, ‘AUDIO’, or ‘LINK’\n\n--duration (string) Filter by offering duration, e.g. ‘12’\n\n--maximum-bitrate (string) Filter by bitrate, ‘MAX_10_MBPS’, ‘MAX_20_MBPS’, or ‘MAX_50_MBPS’\n\n--maximum-framerate (string) Filter by framerate, ‘MAX_30_FPS’ or ‘MAX_60_FPS’\n\n--resolution (string) Filter by resolution, ‘SD’, ‘HD’, ‘FHD’, or ‘UHD’\n\n--resource-type (string) Filter by resource type, ‘INPUT’, ‘OUTPUT’, ‘MULTIPLEX’, or ‘CHANNEL’\n\n--special-feature (string) Filter by special feature, ‘ADVANCED_AUDIO’ or ‘AUDIO_NORMALIZATION’\n\n--video-quality (string) Filter by video quality, ‘STANDARD’, ‘ENHANCED’, or ‘PREMIUM’\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNextToken -> (string)\n\nToken to retrieve the next page of results\n\nOfferings -> (list)\n\nList of offerings\n\n(structure)\n\nReserved resources available for purchase\n\nArn -> (string)\n\nUnique offering ARN, e.g. ‘arn:aws:medialive:us-west-2:123456789012:offering:87654321’\n\nCurrencyCode -> (string)\n\nCurrency code for usagePrice and fixedPrice in ISO-4217 format, e.g. ‘USD’\n\nDuration -> (integer)\n\nLease duration, e.g. ‘12’\n\nDurationUnits -> (string)\n\nUnits for duration, e.g. ‘MONTHS’\n\nFixedPrice -> (double)\n\nOne-time charge for each reserved resource, e.g. ‘0.0’ for a NO_UPFRONT offering\n\nOfferingDescription -> (string)\n\nOffering description, e.g. ‘HD AVC output at 10-20 Mbps, 30 fps, and standard VQ in US West (Oregon)’\n\nOfferingId -> (string)\n\nUnique offering ID, e.g. ‘87654321’\n\nOfferingType -> (string)\n\nOffering type, e.g. ‘NO_UPFRONT’\n\nRegion -> (string)\n\nAWS region, e.g. ‘us-west-2’\n\nResourceSpecification -> (structure)\n\nResource configuration details\n\nChannelClass -> (string)\n\nChannel class, e.g. ‘STANDARD’\n\nCodec -> (string)\n\nCodec, e.g. ‘AVC’\n\nMaximumBitrate -> (string)\n\nMaximum bitrate, e.g. ‘MAX_20_MBPS’\n\nMaximumFramerate -> (string)\n\nMaximum framerate, e.g. ‘MAX_30_FPS’ (Outputs only)\n\nResolution -> (string)\n\nResolution, e.g. ‘HD’\n\nResourceType -> (string)\n\nResource type, ‘INPUT’, ‘OUTPUT’, ‘MULTIPLEX’, or ‘CHANNEL’\n\nSpecialFeature -> (string)\n\nSpecial feature, e.g. ‘AUDIO_NORMALIZATION’ (Channels only)\n\nVideoQuality -> (string)\n\nVideo quality, e.g. ‘STANDARD’ (Outputs only)\n\nUsagePrice -> (double)\n\nRecurring usage charge for each reserved resource, e.g. ‘157.0’"
    },
    {
      "command_name": "list-reservations",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/list-reservations.html",
      "command_description": "Description\n\nList purchased reservations.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-reservations is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: Reservations",
      "command_synopsis": "Synopsis\n  list-reservations\n[--channel-class <value>]\n[--codec <value>]\n[--maximum-bitrate <value>]\n[--maximum-framerate <value>]\n[--resolution <value>]\n[--resource-type <value>]\n[--special-feature <value>]\n[--video-quality <value>]\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--channel-class <value>]",
        "[--codec <value>]",
        "[--maximum-bitrate <value>]",
        "[--maximum-framerate <value>]",
        "[--resolution <value>]",
        "[--resource-type <value>]",
        "[--special-feature <value>]",
        "[--video-quality <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-class (string) Filter by channel class, ‘STANDARD’ or ‘SINGLE_PIPELINE’\n\n--codec (string) Filter by codec, ‘AVC’, ‘HEVC’, ‘MPEG2’, ‘AUDIO’, or ‘LINK’\n\n--maximum-bitrate (string) Filter by bitrate, ‘MAX_10_MBPS’, ‘MAX_20_MBPS’, or ‘MAX_50_MBPS’\n\n--maximum-framerate (string) Filter by framerate, ‘MAX_30_FPS’ or ‘MAX_60_FPS’\n\n--resolution (string) Filter by resolution, ‘SD’, ‘HD’, ‘FHD’, or ‘UHD’\n\n--resource-type (string) Filter by resource type, ‘INPUT’, ‘OUTPUT’, ‘MULTIPLEX’, or ‘CHANNEL’\n\n--special-feature (string) Filter by special feature, ‘ADVANCED_AUDIO’ or ‘AUDIO_NORMALIZATION’\n\n--video-quality (string) Filter by video quality, ‘STANDARD’, ‘ENHANCED’, or ‘PREMIUM’\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNextToken -> (string)\n\nToken to retrieve the next page of results\n\nReservations -> (list)\n\nList of reservations\n\n(structure)\n\nReserved resources available to use\n\nArn -> (string)\n\nUnique reservation ARN, e.g. ‘arn:aws:medialive:us-west-2:123456789012:reservation:1234567’\n\nCount -> (integer)\n\nNumber of reserved resources\n\nCurrencyCode -> (string)\n\nCurrency code for usagePrice and fixedPrice in ISO-4217 format, e.g. ‘USD’\n\nDuration -> (integer)\n\nLease duration, e.g. ‘12’\n\nDurationUnits -> (string)\n\nUnits for duration, e.g. ‘MONTHS’\n\nEnd -> (string)\n\nReservation UTC end date and time in ISO-8601 format, e.g. ‘2019-03-01T00:00:00’\n\nFixedPrice -> (double)\n\nOne-time charge for each reserved resource, e.g. ‘0.0’ for a NO_UPFRONT offering\n\nName -> (string)\n\nUser specified reservation name\n\nOfferingDescription -> (string)\n\nOffering description, e.g. ‘HD AVC output at 10-20 Mbps, 30 fps, and standard VQ in US West (Oregon)’\n\nOfferingId -> (string)\n\nUnique offering ID, e.g. ‘87654321’\n\nOfferingType -> (string)\n\nOffering type, e.g. ‘NO_UPFRONT’\n\nRegion -> (string)\n\nAWS region, e.g. ‘us-west-2’\n\nReservationId -> (string)\n\nUnique reservation ID, e.g. ‘1234567’\n\nResourceSpecification -> (structure)\n\nResource configuration details\n\nChannelClass -> (string)\n\nChannel class, e.g. ‘STANDARD’\n\nCodec -> (string)\n\nCodec, e.g. ‘AVC’\n\nMaximumBitrate -> (string)\n\nMaximum bitrate, e.g. ‘MAX_20_MBPS’\n\nMaximumFramerate -> (string)\n\nMaximum framerate, e.g. ‘MAX_30_FPS’ (Outputs only)\n\nResolution -> (string)\n\nResolution, e.g. ‘HD’\n\nResourceType -> (string)\n\nResource type, ‘INPUT’, ‘OUTPUT’, ‘MULTIPLEX’, or ‘CHANNEL’\n\nSpecialFeature -> (string)\n\nSpecial feature, e.g. ‘AUDIO_NORMALIZATION’ (Channels only)\n\nVideoQuality -> (string)\n\nVideo quality, e.g. ‘STANDARD’ (Outputs only)\n\nStart -> (string)\n\nReservation UTC start date and time in ISO-8601 format, e.g. ‘2018-03-01T00:00:00’\n\nState -> (string)\n\nCurrent state of reservation, e.g. ‘ACTIVE’\n\nTags -> (map)\n\nA collection of key-value pairs\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nUsagePrice -> (double)\n\nRecurring usage charge for each reserved resource, e.g. ‘157.0’"
    },
    {
      "command_name": "list-tags-for-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/list-tags-for-resource.html",
      "command_description": "Description\n\nProduces list of tags that have been created for a resource\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-tags-for-resource\n--resource-arn <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string) Placeholder documentation for __string\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nTags -> (map)\n\nPlaceholder documentation for Tags\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "purchase-offering",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/purchase-offering.html",
      "command_description": "Description\n\nPurchase an offering and create a reservation.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  purchase-offering\n--count <value>\n[--name <value>]\n--offering-id <value>\n[--request-id <value>]\n[--start <value>]\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--count <value>",
        "[--name <value>]",
        "--offering-id <value>",
        "[--request-id <value>]",
        "[--start <value>]",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--count (integer) Number of resources\n\n--name (string) Name for the new reservation\n\n--offering-id (string) Offering to purchase, e.g. ‘87654321’\n\n--request-id (string) Unique request ID to be specified. This is needed to prevent retries from creating multiple resources.\n\n--start (string) Requested reservation start time (UTC) in ISO-8601 format. The specified time must be between the first day of the current month and one year from now. If no value is given, the default is now.\n\n--tags (map) A collection of key-value pairskey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nReservation -> (structure)\n\nReserved resources available to use\n\nArn -> (string)\n\nUnique reservation ARN, e.g. ‘arn:aws:medialive:us-west-2:123456789012:reservation:1234567’\n\nCount -> (integer)\n\nNumber of reserved resources\n\nCurrencyCode -> (string)\n\nCurrency code for usagePrice and fixedPrice in ISO-4217 format, e.g. ‘USD’\n\nDuration -> (integer)\n\nLease duration, e.g. ‘12’\n\nDurationUnits -> (string)\n\nUnits for duration, e.g. ‘MONTHS’\n\nEnd -> (string)\n\nReservation UTC end date and time in ISO-8601 format, e.g. ‘2019-03-01T00:00:00’\n\nFixedPrice -> (double)\n\nOne-time charge for each reserved resource, e.g. ‘0.0’ for a NO_UPFRONT offering\n\nName -> (string)\n\nUser specified reservation name\n\nOfferingDescription -> (string)\n\nOffering description, e.g. ‘HD AVC output at 10-20 Mbps, 30 fps, and standard VQ in US West (Oregon)’\n\nOfferingId -> (string)\n\nUnique offering ID, e.g. ‘87654321’\n\nOfferingType -> (string)\n\nOffering type, e.g. ‘NO_UPFRONT’\n\nRegion -> (string)\n\nAWS region, e.g. ‘us-west-2’\n\nReservationId -> (string)\n\nUnique reservation ID, e.g. ‘1234567’\n\nResourceSpecification -> (structure)\n\nResource configuration details\n\nChannelClass -> (string)\n\nChannel class, e.g. ‘STANDARD’\n\nCodec -> (string)\n\nCodec, e.g. ‘AVC’\n\nMaximumBitrate -> (string)\n\nMaximum bitrate, e.g. ‘MAX_20_MBPS’\n\nMaximumFramerate -> (string)\n\nMaximum framerate, e.g. ‘MAX_30_FPS’ (Outputs only)\n\nResolution -> (string)\n\nResolution, e.g. ‘HD’\n\nResourceType -> (string)\n\nResource type, ‘INPUT’, ‘OUTPUT’, ‘MULTIPLEX’, or ‘CHANNEL’\n\nSpecialFeature -> (string)\n\nSpecial feature, e.g. ‘AUDIO_NORMALIZATION’ (Channels only)\n\nVideoQuality -> (string)\n\nVideo quality, e.g. ‘STANDARD’ (Outputs only)\n\nStart -> (string)\n\nReservation UTC start date and time in ISO-8601 format, e.g. ‘2018-03-01T00:00:00’\n\nState -> (string)\n\nCurrent state of reservation, e.g. ‘ACTIVE’\n\nTags -> (map)\n\nA collection of key-value pairs\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nUsagePrice -> (double)\n\nRecurring usage charge for each reserved resource, e.g. ‘157.0’"
    },
    {
      "command_name": "reject-input-device-transfer",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/reject-input-device-transfer.html",
      "command_description": "Description\n\nReject the transfer of the specified input device to your AWS account.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  reject-input-device-transfer\n--input-device-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-device-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-device-id (string) The unique ID of the input device to reject. For example, hd-123456789abcdef.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "start-channel",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/start-channel.html",
      "command_description": "Description\n\nStarts an existing channel\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-channel\n--channel-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-id (string) A request to start a channel\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe unique arn of the channel.\n\nCdiInputSpecification -> (structure)\n\nSpecification of CDI inputs for this channel\n\nResolution -> (string)\n\nMaximum CDI input resolution\n\nChannelClass -> (string)\n\nThe class for this channel. STANDARD for a channel with two pipelines or SINGLE_PIPELINE for a channel with one pipeline.\n\nDestinations -> (list)\n\nA list of destinations of the channel. For UDP outputs, there is one destination per output. For other types (HLS, for example), there is one destination per packager.\n\n(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nEgressEndpoints -> (list)\n\nThe endpoints where outgoing connections initiate from\n\n(structure)\n\nPlaceholder documentation for ChannelEgressEndpoint\n\nSourceIp -> (string)\n\nPublic IP of where a channel’s output comes from\n\nEncoderSettings -> (structure)\n\nEncoder Settings\n\nAudioDescriptions -> (list)\n\nPlaceholder documentation for __listOfAudioDescription\n\n(structure)\n\nAudio Description\n\nAudioNormalizationSettings -> (structure)\n\nAdvanced audio normalization settings.\n\nAlgorithm -> (string)\n\nAudio normalization algorithm to use. itu17701 conforms to the CALM Act specification, itu17702 conforms to the EBU R-128 specification.\n\nAlgorithmControl -> (string)\n\nWhen set to correctAudio the output audio is corrected using the chosen algorithm. If set to measureOnly, the audio will be measured but not adjusted.\n\nTargetLkfs -> (double)\n\nTarget LKFS(loudness) to adjust volume to. If no value is entered, a default value will be used according to the chosen algorithm. The CALM Act (1770-1) recommends a target of -24 LKFS. The EBU R-128 specification (1770-2) recommends a target of -23 LKFS.\n\nAudioSelectorName -> (string)\n\nThe name of the AudioSelector used as the source for this AudioDescription.\n\nAudioType -> (string)\n\nApplies only if audioTypeControl is useConfigured. The values for audioType are defined in ISO-IEC 13818-1.\n\nAudioTypeControl -> (string)\n\nDetermines how audio type is determined. followInput: If the input contains an ISO 639 audioType, then that value is passed through to the output. If the input contains no ISO 639 audioType, the value in Audio Type is included in the output. useConfigured: The value in Audio Type is included in the output. Note that this field and audioType are both ignored if inputType is broadcasterMixedAd.\n\nAudioWatermarkingSettings -> (structure)\n\nSettings to configure one or more solutions that insert audio watermarks in the audio encode\n\nNielsenWatermarksSettings -> (structure)\n\nSettings to configure Nielsen Watermarks in the audio encode\n\nNielsenCbetSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen CBET\n\nCbetCheckDigitString -> (string)\n\nEnter the CBET check digits to use in the watermark.\n\nCbetStepaside -> (string)\n\nDetermines the method of CBET insertion mode when prior encoding is detected on the same layer.\n\nCsid -> (string)\n\nEnter the CBET Source ID (CSID) to use in the watermark\n\nNielsenDistributionType -> (string)\n\nChoose the distribution types that you want to assign to the watermarks: - PROGRAM_CONTENT - FINAL_DISTRIBUTOR\n\nNielsenNaesIiNwSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen NAES II (N2) and Nielsen NAES VI (NW).\n\nCheckDigitString -> (string)\n\nEnter the check digit string for the watermark\n\nSid -> (double)\n\nEnter the Nielsen Source ID (SID) to include in the watermark\n\nCodecSettings -> (structure)\n\nAudio codec settings.\n\nAacSettings -> (structure)\n\nAac Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid values depend on rate control mode and profile.\n\nCodingMode -> (string)\n\nMono, Stereo, or 5.1 channel layout. Valid values depend on rate control mode and profile. The adReceiverMix setting receives a stereo description plus control track and emits a mono AAC encode of the description track, with control data emitted in the PES header as per ETSI TS 101 154 Annex E.\n\nInputType -> (string)\n\nSet to “broadcasterMixedAd” when input contains pre-mixed main audio + AD (narration) as a stereo pair. The Audio Type field (audioType) will be set to 3, which signals to downstream systems that this stream contains “broadcaster mixed AD”. Note that the input received by the encoder must contain pre-mixed audio; the encoder does not perform the mixing. The values in audioTypeControl and audioType (in AudioDescription) are ignored when set to broadcasterMixedAd. Leave set to “normal” when input does not contain pre-mixed audio + AD.\n\nProfile -> (string)\n\nAAC Profile.\n\nRateControlMode -> (string)\n\nRate Control Mode.\n\nRawFormat -> (string)\n\nSets LATM / LOAS AAC output for raw containers.\n\nSampleRate -> (double)\n\nSample rate in Hz. Valid values depend on rate control mode and profile.\n\nSpec -> (string)\n\nUse MPEG-2 AAC audio instead of MPEG-4 AAC audio for raw or MPEG-2 Transport Stream containers.\n\nVbrQuality -> (string)\n\nVBR Quality Level - Only used if rateControlMode is VBR.\n\nAc3Settings -> (structure)\n\nAc3 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted AC-3 stream. See ATSC A/52-2012 for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital coding mode. Determines number of channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If excluded and input audio is Dolby Digital, dialnorm will be passed through.\n\nDrcProfile -> (string)\n\nIf set to filmStandard, adds dynamic range compression signaling to the output bitstream as defined in the Dolby Digital specification.\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid in codingMode32Lfe mode.\n\nMetadataControl -> (string)\n\nWhen set to “followInput”, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nEac3Settings -> (structure)\n\nEac3 Settings\n\nAttenuationControl -> (string)\n\nWhen set to attenuate3Db, applies a 3 dB attenuation to the surround channels. Only used for 3/2 coding mode.\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted E-AC-3 stream. See ATSC A/52-2012 (Annex E) for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital Plus coding mode. Determines number of channels.\n\nDcFilter -> (string)\n\nWhen set to enabled, activates a DC highpass filter for all input channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If blank and input audio is Dolby Digital Plus, dialnorm will be passed through.\n\nDrcLine -> (string)\n\nSets the Dolby dynamic range compression profile.\n\nDrcRf -> (string)\n\nSets the profile for heavy Dolby dynamic range compression, ensures that the instantaneous signal peaks do not exceed specified levels.\n\nLfeControl -> (string)\n\nWhen encoding 3/2 audio, setting to lfe enables the LFE channel\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid with codingMode32 coding mode.\n\nLoRoCenterMixLevel -> (double)\n\nLeft only/Right only center mix level. Only used for 3/2 coding mode.\n\nLoRoSurroundMixLevel -> (double)\n\nLeft only/Right only surround mix level. Only used for 3/2 coding mode.\n\nLtRtCenterMixLevel -> (double)\n\nLeft total/Right total center mix level. Only used for 3/2 coding mode.\n\nLtRtSurroundMixLevel -> (double)\n\nLeft total/Right total surround mix level. Only used for 3/2 coding mode.\n\nMetadataControl -> (string)\n\nWhen set to followInput, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nPassthroughControl -> (string)\n\nWhen set to whenPossible, input DD+ audio will be passed through if it is present on the input. This detection is dynamic over the life of the transcode. Inputs that alternate between DD+ and non-DD+ content will have a consistent DD+ output as the system alternates between passthrough and encoding.\n\nPhaseControl -> (string)\n\nWhen set to shift90Degrees, applies a 90-degree phase shift to the surround channels. Only used for 3/2 coding mode.\n\nStereoDownmix -> (string)\n\nStereo downmix preference. Only used for 3/2 coding mode.\n\nSurroundExMode -> (string)\n\nWhen encoding 3/2 audio, sets whether an extra center back surround channel is matrix encoded into the left and right surround channels.\n\nSurroundMode -> (string)\n\nWhen encoding 2/0 audio, sets whether Dolby Surround is matrix encoded into the two channels.\n\nMp2Settings -> (structure)\n\nMp2 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second.\n\nCodingMode -> (string)\n\nThe MPEG2 Audio coding mode. Valid values are codingMode10 (for mono) or codingMode20 (for stereo).\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nPassThroughSettings -> (structure)\n\nPass Through Settings\n\nWavSettings -> (structure)\n\nWav Settings\n\nBitDepth -> (double)\n\nBits per sample.\n\nCodingMode -> (string)\n\nThe audio coding mode for the WAV audio. The mode determines the number of channels in the audio.\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nLanguageCode -> (string)\n\nRFC 5646 language code representing the language of the audio output track. Only used if languageControlMode is useConfigured, or there is no ISO 639 language code specified in the input.\n\nLanguageCodeControl -> (string)\n\nChoosing followInput will cause the ISO 639 language code of the output to follow the ISO 639 language code of the input. The languageCode will be used when useConfigured is set, or when followInput is selected but there is no ISO 639 language code specified by the input.\n\nName -> (string)\n\nThe name of this AudioDescription. Outputs will use this name to uniquely identify this AudioDescription. Description names should be unique within this Live Event.\n\nRemixSettings -> (structure)\n\nSettings that control how input audio channels are remixed into the output audio channels.\n\nChannelMappings -> (list)\n\nMapping of input channels to output channels, with appropriate gain adjustments.\n\n(structure)\n\nAudio Channel Mapping\n\nInputChannelLevels -> (list)\n\nIndices and gain values for each input channel that should be remixed into this output channel.\n\n(structure)\n\nInput Channel Level\n\nGain -> (integer)\n\nRemixing value. Units are in dB and acceptable values are within the range from -60 (mute) and 6 dB.\n\nInputChannel -> (integer)\n\nThe index of the input channel used as a source.\n\nOutputChannel -> (integer)\n\nThe index of the output channel being produced.\n\nChannelsIn -> (integer)\n\nNumber of input channels to be used.\n\nChannelsOut -> (integer)\n\nNumber of output channels to be produced. Valid values: 1, 2, 4, 6, 8\n\nStreamName -> (string)\n\nUsed for MS Smooth and Apple HLS outputs. Indicates the name displayed by the player (eg. English, or Director Commentary).\n\nAvailBlanking -> (structure)\n\nSettings for ad avail blanking.\n\nAvailBlankingImage -> (structure)\n\nBlanking image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when insertion metadata is added.\n\nAvailConfiguration -> (structure)\n\nEvent-wide configuration settings for ad avail insertion.\n\nAvailSettings -> (structure)\n\nAd avail settings.\n\nScte35SpliceInsert -> (structure)\n\nScte35 Splice Insert\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nScte35TimeSignalApos -> (structure)\n\nScte35 Time Signal Apos\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nBlackoutSlate -> (structure)\n\nSettings for blackout slate.\n\nBlackoutSlateImage -> (structure)\n\nBlackout slate image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkEndBlackout -> (string)\n\nSetting to enabled causes the encoder to blackout the video, audio, and captions, and raise the “Network Blackout Image” slate when an SCTE104/35 Network End Segmentation Descriptor is encountered. The blackout will be lifted when the Network Start Segmentation Descriptor is encountered. The Network End and Network Start descriptors must contain a network ID that matches the value entered in “Network ID”.\n\nNetworkEndBlackoutImage -> (structure)\n\nPath to local file to use as Network End Blackout image. Image will be scaled to fill the entire output raster.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkId -> (string)\n\nProvides Network ID that matches EIDR ID format (e.g., “10.XXXX/XXXX-XXXX-XXXX-XXXX-XXXX-C”).\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when indicated by program metadata.\n\nCaptionDescriptions -> (list)\n\nSettings for caption decriptions\n\n(structure)\n\nCaption Description\n\nCaptionSelectorName -> (string)\n\nSpecifies which input caption selector to use as a caption source when generating output captions. This field should match a captionSelector name.\n\nDestinationSettings -> (structure)\n\nAdditional settings for captions destination that depend on the destination type.\n\nAribDestinationSettings -> (structure)\n\nArib Destination Settings\n\nBurnInDestinationSettings -> (structure)\n\nBurn In Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to ‘auto’ fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. All burn-in and DVB-Sub font settings must match.\n\nDvbSubDestinationSettings -> (structure)\n\nDvb Sub Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. This option is not valid for source captions that are STL or 608/embedded. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to auto fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nEbuTtDDestinationSettings -> (structure)\n\nEbu Tt DDestination Settings\n\nCopyrightHolder -> (string)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. Complete this field if you want to include the name of the copyright holder in the copyright metadata tag in the TTML\n\nFillLineGap -> (string)\n\nSpecifies how to handle the gap between the lines (in multi-line captions). - enabled: Fill with the captions background color (as specified in the input captions). - disabled: Leave the gap unfilled.\n\nFontFamily -> (string)\n\nSpecifies the font family to include in the font data attached to the EBU-TT captions. Valid only if styleControl is set to include. If you leave this field empty, the font family is set to “monospaced”. (If styleControl is set to exclude, the font family is always set to “monospaced”.) You specify only the font family. All other style information (color, bold, position and so on) is copied from the input captions. The size is always set to 100% to allow the downstream player to choose the size. - Enter a list of font families, as a comma-separated list of font names, in order of preference. The name can be a font family (such as “Arial”), or a generic font family (such as “serif”), or “default” (to let the downstream player choose the font). - Leave blank to set the family to “monospace”.\n\nStyleControl -> (string)\n\nSpecifies the style information (font color, font position, and so on) to include in the font data that is attached to the EBU-TT captions. - include: Take the style information (font color, font position, and so on) from the source captions and include that information in the font data attached to the EBU-TT captions. This option is valid only if the source captions are Embedded or Teletext. - exclude: In the font data attached to the EBU-TT captions, set the font family to “monospaced”. Do not include any other style information.\n\nEmbeddedDestinationSettings -> (structure)\n\nEmbedded Destination Settings\n\nEmbeddedPlusScte20DestinationSettings -> (structure)\n\nEmbedded Plus Scte20 Destination Settings\n\nRtmpCaptionInfoDestinationSettings -> (structure)\n\nRtmp Caption Info Destination Settings\n\nScte20PlusEmbeddedDestinationSettings -> (structure)\n\nScte20 Plus Embedded Destination Settings\n\nScte27DestinationSettings -> (structure)\n\nScte27 Destination Settings\n\nSmpteTtDestinationSettings -> (structure)\n\nSmpte Tt Destination Settings\n\nTeletextDestinationSettings -> (structure)\n\nTeletext Destination Settings\n\nTtmlDestinationSettings -> (structure)\n\nTtml Destination Settings\n\nStyleControl -> (string)\n\nWhen set to passthrough, passes through style and position information from a TTML-like input source (TTML, SMPTE-TT, CFF-TT) to the CFF-TT output or TTML output.\n\nWebvttDestinationSettings -> (structure)\n\nWebvtt Destination Settings\n\nStyleControl -> (string)\n\nControls whether the color and position of the source captions is passed through to the WebVTT output captions. PASSTHROUGH - Valid only if the source captions are EMBEDDED or TELETEXT. NO_STYLE_DATA - Don’t pass through the style. The output captions will not contain any font styling information.\n\nLanguageCode -> (string)\n\nISO 639-2 three-digit code: http://www.loc.gov/standards/iso639-2/\n\nLanguageDescription -> (string)\n\nHuman readable information to indicate captions available for players (eg. English, or Spanish).\n\nName -> (string)\n\nName of the caption description. Used to associate a caption description with an output. Names must be unique within an event.\n\nFeatureActivations -> (structure)\n\nFeature Activations\n\nInputPrepareScheduleActions -> (string)\n\nEnables the Input Prepare feature. You can create Input Prepare actions in the schedule only if this feature is enabled. If you disable the feature on an existing schedule, make sure that you first delete all input prepare actions from the schedule.\n\nGlobalConfiguration -> (structure)\n\nConfiguration settings that apply to the event as a whole.\n\nInitialAudioGain -> (integer)\n\nValue to set the initial audio gain for the Live Event.\n\nInputEndAction -> (string)\n\nIndicates the action to take when the current input completes (e.g. end-of-file). When switchAndLoopInputs is configured the encoder will restart at the beginning of the first input. When “none” is configured the encoder will transcode either black, a solid color, or a user specified slate images per the “Input Loss Behavior” configuration until the next input switch occurs (which is controlled through the Channel Schedule API).\n\nInputLossBehavior -> (structure)\n\nSettings for system actions when input is lost.\n\nBlackFrameMsec -> (integer)\n\nDocumentation update needed\n\nInputLossImageColor -> (string)\n\nWhen input loss image type is “color” this field specifies the color to use. Value: 6 hex characters representing the values of RGB.\n\nInputLossImageSlate -> (structure)\n\nWhen input loss image type is “slate” these fields specify the parameters for accessing the slate.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nInputLossImageType -> (string)\n\nIndicates whether to substitute a solid color or a slate into the output after input loss exceeds blackFrameMsec.\n\nRepeatFrameMsec -> (integer)\n\nDocumentation update needed\n\nOutputLockingMode -> (string)\n\nIndicates how MediaLive pipelines are synchronized. PIPELINE_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the other. EPOCH_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the Unix epoch.\n\nOutputTimingSource -> (string)\n\nIndicates whether the rate of frames emitted by the Live encoder should be paced by its system clock (which optionally may be locked to another source via NTP) or should be locked to the clock of the source that is providing the input stream.\n\nSupportLowFramerateInputs -> (string)\n\nAdjusts video input buffer for streams with very low video framerates. This is commonly set to enabled for music channels with less than one video frame per second.\n\nMotionGraphicsConfiguration -> (structure)\n\nSettings for motion graphics.\n\nMotionGraphicsInsertion -> (string)\n\nMotion Graphics Insertion\n\nMotionGraphicsSettings -> (structure)\n\nMotion Graphics Settings\n\nHtmlMotionGraphicsSettings -> (structure)\n\nHtml Motion Graphics Settings\n\nNielsenConfiguration -> (structure)\n\nNielsen configuration settings.\n\nDistributorId -> (string)\n\nEnter the Distributor ID assigned to your organization by Nielsen.\n\nNielsenPcmToId3Tagging -> (string)\n\nEnables Nielsen PCM to ID3 tagging\n\nOutputGroups -> (list)\n\nPlaceholder documentation for __listOfOutputGroup\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nName -> (string)\n\nCustom output group name optionally defined by the user. Only letters, numbers, and the underscore character allowed; only 32 characters allowed.\n\nOutputGroupSettings -> (structure)\n\nSettings associated with the output group.\n\nArchiveGroupSettings -> (structure)\n\nArchive Group Settings\n\nArchiveCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nArchiveS3Settings -> (structure)\n\nArchive S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nDestination -> (structure)\n\nA directory and base filename where archive files should be written.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRolloverInterval -> (integer)\n\nNumber of seconds to write to archive file before closing and starting a new one.\n\nFrameCaptureGroupSettings -> (structure)\n\nFrame Capture Group Settings\n\nDestination -> (structure)\n\nThe destination for the frame capture files. Either the URI for an Amazon S3 bucket and object, plus a file name prefix (for example, s3ssl://sportsDelivery/highlights/20180820/curling-) or the URI for a MediaStore container, plus a file name prefix (for example, mediastoressl://sportsDelivery/20180820/curling-). The final file names consist of the prefix from the destination field (for example, “curling-“) + name modifier + the counter (5 digits, starting from 00001) + extension (which is always .jpg). For example, curling-low.00001.jpg\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFrameCaptureCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nFrameCaptureS3Settings -> (structure)\n\nFrame Capture S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsGroupSettings -> (structure)\n\nHls Group Settings\n\nAdMarkers -> (list)\n\nChoose one or more ad marker types to pass SCTE35 signals through to this group of Apple HLS outputs.\n\n(string)\n\nHls Ad Markers\n\nBaseUrlContent -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlContent1 -> (string)\n\nOptional. One value per output group. This field is required only if you are completing Base URL content A, and the downstream system has notified you that the media files for pipeline 1 of all outputs are in a location different from the media files for pipeline 0.\n\nBaseUrlManifest -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlManifest1 -> (string)\n\nOptional. One value per output group. Complete this field only if you are completing Base URL manifest A, and the downstream system has notified you that the child manifest files for pipeline 1 of all outputs are in a location different from the child manifest files for pipeline 0.\n\nCaptionLanguageMappings -> (list)\n\nMapping of up to 4 caption channels to caption languages. Is only meaningful if captionLanguageSetting is set to “insert”.\n\n(structure)\n\nMaps a caption channel to an ISO 693-2 language code (http://www.loc.gov/standards/iso639-2), with an optional description.\n\nCaptionChannel -> (integer)\n\nThe closed caption channel being described by this CaptionLanguageMapping. Each channel mapping must have a unique channel number (maximum of 4)\n\nLanguageCode -> (string)\n\nThree character ISO 639-2 language code (see http://www.loc.gov/standards/iso639-2)\n\nLanguageDescription -> (string)\n\nTextual description of language\n\nCaptionLanguageSetting -> (string)\n\nApplies only to 608 Embedded output captions. insert: Include CLOSED-CAPTIONS lines in the manifest. Specify at least one language in the CC1 Language Code field. One CLOSED-CAPTION line is added for each Language Code you specify. Make sure to specify the languages in the order in which they appear in the original source (if the source is embedded format) or the order of the caption selectors (if the source is other than embedded). Otherwise, languages in the manifest will not match up properly with the output captions. none: Include CLOSED-CAPTIONS=NONE line in the manifest. omit: Omit any CLOSED-CAPTIONS line from the manifest.\n\nClientCache -> (string)\n\nWhen set to “disabled”, sets the #EXT-X-ALLOW-CACHE:no tag in the manifest, which prevents clients from saving media segments for later replay.\n\nCodecSpecification -> (string)\n\nSpecification to use (RFC-6381 or the default RFC-4281) during m3u8 playlist generation.\n\nConstantIv -> (string)\n\nFor use with encryptionType. This is a 128-bit, 16-byte hex value represented by a 32-character text string. If ivSource is set to “explicit” then this parameter is required and is used as the IV for encryption.\n\nDestination -> (structure)\n\nA directory or HTTP destination for the HLS segments, manifest files, and encryption keys (if enabled).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nDirectoryStructure -> (string)\n\nPlace segments in subdirectories.\n\nDiscontinuityTags -> (string)\n\nSpecifies whether to insert EXT-X-DISCONTINUITY tags in the HLS child manifests for this output group. Typically, choose Insert because these tags are required in the manifest (according to the HLS specification) and serve an important purpose. Choose Never Insert only if the downstream system is doing real-time failover (without using the MediaLive automatic failover feature) and only if that downstream system has advised you to exclude the tags.\n\nEncryptionType -> (string)\n\nEncrypts the segments with the given encryption scheme. Exclude this parameter if no encryption is desired.\n\nHlsCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nHlsAkamaiSettings -> (structure)\n\nHls Akamai Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to Akamai. User should contact Akamai to enable this feature.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nSalt -> (string)\n\nSalt for authenticated Akamai.\n\nToken -> (string)\n\nToken parameter for authenticated akamai. If not specified, _gda_ is used.\n\nHlsBasicPutSettings -> (structure)\n\nHls Basic Put Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsMediaStoreSettings -> (structure)\n\nHls Media Store Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nMediaStoreStorageClass -> (string)\n\nWhen set to temporal, output files are stored in non-persistent memory for faster reading and writing.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsS3Settings -> (structure)\n\nHls S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsWebdavSettings -> (structure)\n\nHls Webdav Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to WebDAV.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsId3SegmentTagging -> (string)\n\nState of HLS ID3 Segment Tagging\n\nIFrameOnlyPlaylists -> (string)\n\nDISABLED: Do not create an I-frame-only manifest, but do create the master and media manifests (according to the Output Selection field). STANDARD: Create an I-frame-only manifest for each output that contains video, as well as the other manifests (according to the Output Selection field). The I-frame manifest contains a #EXT-X-I-FRAMES-ONLY tag to indicate it is I-frame only, and one or more #EXT-X-BYTERANGE entries identifying the I-frame position. For example, #EXT-X-BYTERANGE:160364@1461888”\n\nIncompleteSegmentBehavior -> (string)\n\nSpecifies whether to include the final (incomplete) segment in the media output when the pipeline stops producing output because of a channel stop, a channel pause or a loss of input to the pipeline. Auto means that MediaLive decides whether to include the final segment, depending on the channel class and the types of output groups. Suppress means to never include the incomplete segment. We recommend you choose Auto and let MediaLive control the behavior.\n\nIndexNSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the maximum number of segments in the media manifest file. After this maximum, older segments are removed from the media manifest. This number must be smaller than the number in the Keep Segments field.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nIvInManifest -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If set to “include”, IV is listed in the manifest, otherwise the IV is not in the manifest.\n\nIvSource -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If this setting is “followsSegmentNumber”, it will cause the IV to change every segment (to match the segment number). If this is set to “explicit”, you must enter a constantIv value.\n\nKeepSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the number of media segments to retain in the destination directory. This number should be bigger than indexNSegments (Num segments). We recommend (value = (2 x indexNsegments) + 1). If this “keep segments” number is too low, the following might happen: the player is still reading a media manifest file that lists this segment, but that segment has been removed from the destination directory (as directed by indexNSegments). This situation would result in a 404 HTTP error on the player.\n\nKeyFormat -> (string)\n\nThe value specifies how the key is represented in the resource identified by the URI. If parameter is absent, an implicit value of “identity” is used. A reverse DNS string can also be given.\n\nKeyFormatVersions -> (string)\n\nEither a single positive integer version value or a slash delimited list of version values (1/2/3).\n\nKeyProviderSettings -> (structure)\n\nThe key provider settings.\n\nStaticKeySettings -> (structure)\n\nStatic Key Settings\n\nKeyProviderServer -> (structure)\n\nThe URL of the license server used for protecting content.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nStaticKeyValue -> (string)\n\nStatic key value as a 32 character hexadecimal string.\n\nManifestCompression -> (string)\n\nWhen set to gzip, compresses HLS playlist.\n\nManifestDurationFormat -> (string)\n\nIndicates whether the output manifest should use floating point or integer values for segment duration.\n\nMinSegmentLength -> (integer)\n\nWhen set, minimumSegmentLength is enforced by looking ahead and back within the specified range for a nearby avail and extending the segment size if needed.\n\nMode -> (string)\n\nIf “vod”, all segments are indexed and kept permanently in the destination and manifest. If “live”, only the number segments specified in keepSegments and indexNSegments are kept; newer segments replace older segments, which may prevent players from rewinding all the way to the beginning of the event. VOD mode uses HLS EXT-X-PLAYLIST-TYPE of EVENT while the channel is running, converting it to a “VOD” type manifest on completion of the stream.\n\nOutputSelection -> (string)\n\nMANIFESTS_AND_SEGMENTS: Generates manifests (master manifest, if applicable, and media manifests) for this output group. VARIANT_MANIFESTS_AND_SEGMENTS: Generates media manifests for this output group, but not a master manifest. SEGMENTS_ONLY: Does not generate any manifests for this output group.\n\nProgramDateTime -> (string)\n\nIncludes or excludes EXT-X-PROGRAM-DATE-TIME tag in .m3u8 manifest files. The value is calculated as follows: either the program date and time are initialized using the input timecode source, or the time is initialized using the input timecode source and the date is initialized using the timestampOffset.\n\nProgramDateTimePeriod -> (integer)\n\nPeriod of insertion of EXT-X-PROGRAM-DATE-TIME entry, in seconds.\n\nRedundantManifest -> (string)\n\nENABLED: The master manifest (.m3u8 file) for each pipeline includes information about both pipelines: first its own media files, then the media files of the other pipeline. This feature allows playout device that support stale manifest detection to switch from one manifest to the other, when the current manifest seems to be stale. There are still two destinations and two master manifests, but both master manifests reference the media files from both pipelines. DISABLED: The master manifest (.m3u8 file) for each pipeline includes information about its own pipeline only. For an HLS output group with MediaPackage as the destination, the DISABLED behavior is always followed. MediaPackage regenerates the manifests it serves to players so a redundant manifest from MediaLive is irrelevant.\n\nSegmentLength -> (integer)\n\nLength of MPEG-2 Transport Stream segments to create (in seconds). Note that segments will end on the next keyframe after this number of seconds, so actual segment length may be longer.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSegmentsPerSubdirectory -> (integer)\n\nNumber of segments to write to a subdirectory before starting a new one. directoryStructure must be subdirectoryPerStream for this setting to have an effect.\n\nStreamInfResolution -> (string)\n\nInclude or exclude RESOLUTION attribute for video in EXT-X-STREAM-INF tag of variant manifest.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nTimestampDeltaMilliseconds -> (integer)\n\nProvides an extra millisecond delta offset to fine tune the timestamps.\n\nTsFileMode -> (string)\n\nSEGMENTED_FILES: Emit the program as segments - multiple .ts media files. SINGLE_FILE: Applies only if Mode field is VOD. Emit the program as a single .ts media file. The media manifest includes #EXT-X-BYTERANGE tags to index segments for playback. A typical use for this value is when sending the output to AWS Elemental MediaConvert, which can accept only a single media file. Playback while the channel is running is not guaranteed due to HTTP server caching.\n\nMediaPackageGroupSettings -> (structure)\n\nMedia Package Group Settings\n\nDestination -> (structure)\n\nMediaPackage channel destination.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nMsSmoothGroupSettings -> (structure)\n\nMs Smooth Group Settings\n\nAcquisitionPointId -> (string)\n\nThe ID to include in each message in the sparse track. Ignored if sparseTrackType is NONE.\n\nAudioOnlyTimecodeControl -> (string)\n\nIf set to passthrough for an audio-only MS Smooth output, the fragment absolute time will be set to the current timecode. This option does not write timecodes to the audio elementary stream.\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the https certificate chain to a trusted Certificate Authority (CA). This will cause https outputs to self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the IIS server if the connection is lost. Content will be cached during this time and the cache will be be delivered to the IIS server once the connection is re-established.\n\nDestination -> (structure)\n\nSmooth Streaming publish point on an IIS server. Elemental Live acts as a “Push” encoder to IIS.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nEventId -> (string)\n\nMS Smooth event ID to be sent to the IIS server. Should only be specified if eventIdMode is set to useConfigured.\n\nEventIdMode -> (string)\n\nSpecifies whether or not to send an event ID to the IIS server. If no event ID is sent and the same Live Event is used without changing the publishing point, clients might see cached video from the previous run. Options: - “useConfigured” - use the value provided in eventId - “useTimestamp” - generate and send an event ID based on the current timestamp - “noEventId” - do not send an event ID to the IIS server.\n\nEventStopBehavior -> (string)\n\nWhen set to sendEos, send EOS signal to IIS server when stopping the event\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nFragmentLength -> (integer)\n\nLength of mp4 fragments to generate (in seconds). Fragment length must be compatible with GOP size and framerate.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nRestartDelay -> (integer)\n\nNumber of seconds before initiating a restart due to output failure, due to exhausting the numRetries on one segment, or exceeding filecacheDuration.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSendDelayMs -> (integer)\n\nNumber of milliseconds to delay the output from the second pipeline.\n\nSparseTrackType -> (string)\n\nIdentifies the type of data to place in the sparse track: - SCTE35: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame to start a new segment. - SCTE35_WITHOUT_SEGMENTATION: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame but don’t start a new segment. - NONE: Don’t generate a sparse track for any outputs in this output group.\n\nStreamManifestBehavior -> (string)\n\nWhen set to send, send stream manifest so publishing point doesn’t start until all streams start.\n\nTimestampOffset -> (string)\n\nTimestamp offset for the event. Only used if timestampOffsetMode is set to useConfiguredOffset.\n\nTimestampOffsetMode -> (string)\n\nType of timestamp date offset to use. - useEventStartDate: Use the date the event was started as the offset - useConfiguredOffset: Use an explicitly configured date as the offset\n\nMultiplexGroupSettings -> (structure)\n\nMultiplex Group Settings\n\nRtmpGroupSettings -> (structure)\n\nRtmp Group Settings\n\nAdMarkers -> (list)\n\nChoose the ad marker type for this output group. MediaLive will create a message based on the content of each SCTE-35 message, format it for that marker type, and insert it in the datastream.\n\n(string)\n\nRtmp Ad Markers\n\nAuthenticationScheme -> (string)\n\nAuthentication scheme to use when connecting with CDN\n\nCacheFullBehavior -> (string)\n\nControls behavior when content cache fills up. If remote origin server stalls the RTMP connection and does not accept content fast enough the ‘Media Cache’ will fill up. When the cache reaches the duration specified by cacheLength the cache will stop accepting new content. If set to disconnectImmediately, the RTMP output will force a disconnect. Clear the media cache, and reconnect after restartDelay seconds. If set to waitForServer, the RTMP output will wait up to 5 minutes to allow the origin server to begin accepting data again.\n\nCacheLength -> (integer)\n\nCache length, in seconds, is used to calculate buffer size.\n\nCaptionData -> (string)\n\nControls the types of data that passes to onCaptionInfo outputs. If set to ‘all’ then 608 and 708 carried DTVCC data will be passed. If set to ‘field1AndField2608’ then DTVCC data will be stripped out, but 608 data from both fields will be passed. If set to ‘field1608’ then only the data carried in 608 from field 1 video will be passed.\n\nInputLossAction -> (string)\n\nControls the behavior of this RTMP group if input becomes unavailable. - emitOutput: Emit a slate until input returns. - pauseOutput: Stop transmitting data until input returns. This does not close the underlying RTMP connection.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nUdpGroupSettings -> (structure)\n\nUdp Group Settings\n\nInputLossAction -> (string)\n\nSpecifies behavior of last resort when input video is lost, and no more backup inputs are available. When dropTs is selected the entire transport stream will stop being emitted. When dropProgram is selected the program can be dropped from the transport stream (and replaced with null packets to meet the TS bitrate requirement). Or, when emitProgram is chosen the transport stream will continue to be produced normally with repeat frames, black frames, or slate frames substituted for the absent input video.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nOutputs -> (list)\n\nPlaceholder documentation for __listOfOutput\n\n(structure)\n\nOutput settings. There can be multiple outputs within a group.\n\nAudioDescriptionNames -> (list)\n\nThe names of the AudioDescriptions used as audio sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nCaptionDescriptionNames -> (list)\n\nThe names of the CaptionDescriptions used as caption sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nOutputName -> (string)\n\nThe name used to identify an output.\n\nOutputSettings -> (structure)\n\nOutput type-specific settings.\n\nArchiveOutputSettings -> (structure)\n\nArchive Output Settings\n\nContainerSettings -> (structure)\n\nSettings specific to the container type of the file.\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nRawSettings -> (structure)\n\nRaw Settings\n\nExtension -> (string)\n\nOutput file extension. If excluded, this will be auto-selected from the container type.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nFrameCaptureOutputSettings -> (structure)\n\nFrame Capture Output Settings\n\nNameModifier -> (string)\n\nRequired if the output group contains more than one output. This modifier forms part of the output file name.\n\nHlsOutputSettings -> (structure)\n\nHls Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nHlsSettings -> (structure)\n\nSettings regarding the underlying stream. These settings are different for audio-only outputs.\n\nAudioOnlyHlsSettings -> (structure)\n\nAudio Only Hls Settings\n\nAudioGroupId -> (string)\n\nSpecifies the group to which the audio Rendition belongs.\n\nAudioOnlyImage -> (structure)\n\nOptional. Specifies the .jpg or .png image to use as the cover art for an audio-only output. We recommend a low bit-size file because the image increases the output audio bandwidth. The image is attached to the audio as an ID3 tag, frame type APIC, picture type 0x10, as per the “ID3 tag version 2.4.0 - Native Frames” standard.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nAudioTrackType -> (string)\n\nFour types of audio-only tracks are supported: Audio-Only Variant Stream The client can play back this audio-only stream instead of video in low-bandwidth scenarios. Represented as an EXT-X-STREAM-INF in the HLS manifest. Alternate Audio, Auto Select, Default Alternate rendition that the client should try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=YES, AUTOSELECT=YES Alternate Audio, Auto Select, Not Default Alternate rendition that the client may try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=YES Alternate Audio, not Auto Select Alternate rendition that the client will not try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=NO\n\nSegmentType -> (string)\n\nSpecifies the segment type.\n\nFmp4HlsSettings -> (structure)\n\nFmp4 Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nFrameCaptureHlsSettings -> (structure)\n\nFrame Capture Hls Settings\n\nStandardHlsSettings -> (structure)\n\nStandard Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nM3u8Settings -> (structure)\n\nSettings information for the .m3u8 container\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values.\n\nEcmPid -> (string)\n\nThis parameter is unused and deprecated.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock References (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value.\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nScte35Behavior -> (string)\n\nIf set to passthrough, passes any SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Accepts “Format Identifiers”:#formatIdentifierParameters.\n\nSegmentModifier -> (string)\n\nString concatenated to end of segment filenames.\n\nMediaPackageOutputSettings -> (structure)\n\nMedia Package Output Settings\n\nMsSmoothOutputSettings -> (structure)\n\nMs Smooth Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nMultiplexOutputSettings -> (structure)\n\nMultiplex Output Settings\n\nDestination -> (structure)\n\nDestination is a Multiplex.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRtmpOutputSettings -> (structure)\n\nRtmp Output Settings\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the tls certificate chain to a trusted Certificate Authority (CA). This will cause rtmps outputs with self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying a connection to the Flash Media server if the connection is lost.\n\nDestination -> (structure)\n\nThe RTMP endpoint excluding the stream name (eg. rtmp://host/appname). For connection to Akamai, a username and password must be supplied. URI fields accept format identifiers.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nUdpOutputSettings -> (structure)\n\nUdp Output Settings\n\nBufferMsec -> (integer)\n\nUDP output buffering in milliseconds. Larger values increase latency through the transcoder but simultaneously assist the transcoder in maintaining a constant, low-jitter UDP/RTP output while accommodating clock recovery, input switching, input disruptions, picture reordering, etc.\n\nContainerSettings -> (structure)\n\nUdp Container Settings\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nDestination -> (structure)\n\nDestination address and port number for RTP or UDP packets. Can be unicast or multicast RTP or UDP (eg. rtp://239.10.10.10:5001 or udp://10.100.100.100:5002).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFecOutputSettings -> (structure)\n\nSettings for enabling and adjusting Forward Error Correction on UDP outputs.\n\nColumnDepth -> (integer)\n\nParameter D from SMPTE 2022-1. The height of the FEC protection matrix. The number of transport stream packets per column error correction packet. Must be between 4 and 20, inclusive.\n\nIncludeFec -> (string)\n\nEnables column only or column and row based FEC\n\nRowLength -> (integer)\n\nParameter L from SMPTE 2022-1. The width of the FEC protection matrix. Must be between 1 and 20, inclusive. If only Column FEC is used, then larger values increase robustness. If Row FEC is used, then this is the number of transport stream packets per row error correction packet, and the value must be between 4 and 20, inclusive, if includeFec is columnAndRow. If includeFec is column, this value must be 1 to 20, inclusive.\n\nVideoDescriptionName -> (string)\n\nThe name of the VideoDescription used as the source for this output.\n\nTimecodeConfig -> (structure)\n\nContains settings used to acquire and adjust timecode information from inputs.\n\nSource -> (string)\n\nIdentifies the source for the timecode that will be associated with the events outputs. -Embedded (embedded): Initialize the output timecode with timecode from the the source. If no embedded timecode is detected in the source, the system falls back to using “Start at 0” (zerobased). -System Clock (systemclock): Use the UTC time. -Start at 0 (zerobased): The time of the first frame of the event will be 00:00:00:00.\n\nSyncThreshold -> (integer)\n\nThreshold in frames beyond which output timecode is resynchronized to the input timecode. Discrepancies below this threshold are permitted to avoid unnecessary discontinuities in the output timecode. No timecode sync when this is not specified.\n\nVideoDescriptions -> (list)\n\nPlaceholder documentation for __listOfVideoDescription\n\n(structure)\n\nVideo settings for this stream.\n\nCodecSettings -> (structure)\n\nVideo codec settings.\n\nFrameCaptureSettings -> (structure)\n\nFrame Capture Settings\n\nCaptureInterval -> (integer)\n\nThe frequency at which to capture frames for inclusion in the output. May be specified in either seconds or milliseconds, as specified by captureIntervalUnits.\n\nCaptureIntervalUnits -> (string)\n\nUnit for the frame capture interval.\n\nH264Settings -> (structure)\n\nH264 Settings\n\nAdaptiveQuantization -> (string)\n\nEnables or disables adaptive quantization, which is a technique MediaLive can apply to video on a frame-by-frame basis to produce more compression without losing quality. There are three types of adaptive quantization: flicker, spatial, and temporal. Set the field in one of these ways: Set to Auto. Recommended. For each type of AQ, MediaLive will determine if AQ is needed, and if so, the appropriate strength. Set a strength (a value other than Auto or Disable). This strength will apply to any of the AQ fields that you choose to enable. Set to Disabled to disable all types of adaptive quantization.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufFillPct -> (integer)\n\nPercentage of the buffer that should initially be filled (HRD buffer model).\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nEntropyEncoding -> (string)\n\nEntropy encoding mode. Use cabac (must be in Main or High profile) or cavlc.\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nFlicker AQ makes adjustments within each frame to reduce flicker or ‘pop’ on I-frames. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if flicker AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply flicker AQ using the specified strength. Disabled: MediaLive won’t apply flicker AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply flicker AQ.\n\nForceFieldPictures -> (string)\n\nThis setting applies only when scan type is “interlaced.” It controls whether coding is performed on a field basis or on a frame basis. (When the video is progressive, the coding is always performed on a frame basis.) enabled: Force MediaLive to code on a field basis, so that odd and even sets of fields are coded separately. disabled: Code the two sets of fields separately (on a field basis) or together (on a frame basis using PAFF), depending on what is most appropriate for the content.\n\nFramerateControl -> (string)\n\nThis field indicates how the output video frame rate is specified. If “specified” is selected then the output video frame rate is determined by framerateNumerator and framerateDenominator, else if “initializeFromSource” is selected then the output video frame rate will be set equal to the input video frame rate of the first input.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopBReference -> (string)\n\nDocumentation update needed\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopNumBFrames -> (integer)\n\nNumber of B-frames between reference frames.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.264 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level For VBR: Set the maximum bitrate in order to accommodate expected spikes in the complexity of the video.\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nNumRefFrames -> (integer)\n\nNumber of reference frames to use. The encoder may use more than requested if using B-frames and/or interlaced encoding.\n\nParControl -> (string)\n\nThis field indicates how the output pixel aspect ratio is specified. If “specified” is selected then the output video pixel aspect ratio is determined by parNumerator and parDenominator, else if “initializeFromSource” is selected then the output pixsel aspect ratio will be set equal to the input video pixel aspect ratio of the first input.\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.264 Profile.\n\nQualityLevel -> (string)\n\nLeave as STANDARD_QUALITY or choose a different value (which might result in additional costs to run the channel). - ENHANCED_QUALITY: Produces a slightly better video quality without an increase in the bitrate. Has an effect only when the Rate control mode is QVBR or CBR. If this channel is in a MediaLive multiplex, the value must be ENHANCED_QUALITY. - STANDARD_QUALITY: Valid for any Rate control mode.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. You can set a target quality or you can let MediaLive determine the best quality. To set a target quality, enter values in the QVBR quality level field and the Max bitrate field. Enter values that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M To let MediaLive decide, leave the QVBR quality level field empty, and in Max bitrate enter the maximum rate you want in the video. For more information, see the section called “Video - rate control mode” in the MediaLive user guide\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. VBR: Quality and bitrate vary, depending on the video complexity. Recommended instead of QVBR if you want to maintain a specific average bitrate over the duration of the channel. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection. - On: inserts I-frames when scene change is detected. - Off: does not force an I-frame when scene change is detected.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nSoftness -> (integer)\n\nSoftness. Selects quantizer matrix, larger values reduce high-frequency content in the encoded image. If not set to zero, must be greater than 15.\n\nSpatialAq -> (string)\n\nSpatial AQ makes adjustments within each frame based on spatial variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if spatial AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply spatial AQ using the specified strength. Disabled: MediaLive won’t apply spatial AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply spatial AQ.\n\nSubgopLength -> (string)\n\nIf set to fixed, use gopNumBFrames B-frames per sub-GOP. If set to dynamic, optimize the number of B-frames used for each sub-GOP to improve visual quality.\n\nSyntax -> (string)\n\nProduces a bitstream compliant with SMPTE RP-2027.\n\nTemporalAq -> (string)\n\nTemporal makes adjustments within each frame based on temporal variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if temporal AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply temporal AQ using the specified strength. Disabled: MediaLive won’t apply temporal AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply temporal AQ.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nH265Settings -> (structure)\n\nH265 Settings\n\nAdaptiveQuantization -> (string)\n\nAdaptive quantization. Allows intra-frame quantizers to vary to improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nAlternativeTransferFunction -> (string)\n\nWhether or not EML should insert an Alternative Transfer Function SEI message to support backwards compatibility with non-HDR decoders and displays.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nIf set to enabled, adjust quantization within each frame to reduce flicker or ‘pop’ on I-frames.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.265 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.265 Profile.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. Set values for the QVBR quality level field and Max bitrate field that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nTier -> (string)\n\nH.265 Tier.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nMpeg2Settings -> (structure)\n\nMpeg2 Settings\n\nAdaptiveQuantization -> (string)\n\nChoose Off to disable adaptive quantization. Or choose another value to enable the quantizer and set its strength. The strengths are: Auto, Off, Low, Medium, High. When you enable this field, MediaLive allows intra-frame quantizers to vary, which might improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates the AFD values that MediaLive will write into the video encode. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose AUTO. AUTO: MediaLive will try to preserve the input AFD value (in cases where multiple AFD values are valid). FIXED: MediaLive will use the value you specify in fixedAFD.\n\nColorMetadata -> (string)\n\nSpecifies whether to include the color space metadata. The metadata describes the color space that applies to the video (the colorSpace field). We recommend that you insert the metadata.\n\nColorSpace -> (string)\n\nChoose the type of color space conversion to apply to the output. For detailed information on setting up both the input and the output to obtain the desired color space in the output, see the section on “MediaLive Features - Video - color space” in the MediaLive User Guide. PASSTHROUGH: Keep the color space of the input content - do not convert it. AUTO:Convert all content that is SD to rec 601, and convert all content that is HD to rec 709.\n\nDisplayAspectRatio -> (string)\n\nSets the pixel aspect ratio for the encode.\n\nFilterSettings -> (structure)\n\nOptionally specify a noise reduction filter, which can improve quality of compressed content. If you do not choose a filter, no filter will be applied. TEMPORAL: This filter is useful for both source content that is noisy (when it has excessive digital artifacts) and source content that is clean. When the content is noisy, the filter cleans up the source content before the encoding phase, with these two effects: First, it improves the output video quality because the content has been cleaned up. Secondly, it decreases the bandwidth because MediaLive does not waste bits on encoding noise. When the content is reasonably clean, the filter tends to decrease the bitrate.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nComplete this field only when afdSignaling is set to FIXED. Enter the AFD value (4 bits) to write on all frames of the video encode.\n\nFramerateDenominator -> (integer)\n\ndescription”: “The framerate denominator. For example, 1001. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nFramerateNumerator -> (integer)\n\nThe framerate numerator. For example, 24000. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nGopClosedCadence -> (integer)\n\nMPEG2: default is open GOP.\n\nGopNumBFrames -> (integer)\n\nRelates to the GOP structure. The number of B-frames between reference frames. If you do not know what a B-frame is, use the default.\n\nGopSize -> (double)\n\nRelates to the GOP structure. The GOP size (keyframe interval) in the units specified in gopSizeUnits. If you do not know what GOP is, use the default. If gopSizeUnits is frames, then the gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, the gopSize must be greater than 0, but does not need to be an integer.\n\nGopSizeUnits -> (string)\n\nRelates to the GOP structure. Specifies whether the gopSize is specified in frames or seconds. If you do not plan to change the default gopSize, leave the default. If you specify SECONDS, MediaLive will internally convert the gop size to a frame count.\n\nScanType -> (string)\n\nSet the scan type of the output to PROGRESSIVE or INTERLACED (top field first).\n\nSubgopLength -> (string)\n\nRelates to the GOP structure. If you do not know what GOP is, use the default. FIXED: Set the number of B-frames in each sub-GOP to the value in gopNumBFrames. DYNAMIC: Let MediaLive optimize the number of B-frames in each sub-GOP, to improve visual quality.\n\nTimecodeInsertion -> (string)\n\nDetermines how MediaLive inserts timecodes in the output video. For detailed information about setting up the input and the output for a timecode, see the section on “MediaLive Features - Timecode configuration” in the MediaLive User Guide. DISABLED: do not include timecodes. GOP_TIMECODE: Include timecode metadata in the GOP header.\n\nHeight -> (integer)\n\nOutput video height, in pixels. Must be an even number. For most codecs, you can leave this field and width blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nName -> (string)\n\nThe name of this VideoDescription. Outputs will use this name to uniquely identify this Description. Description names should be unique within this Live Event.\n\nRespondToAfd -> (string)\n\nIndicates how MediaLive will respond to the AFD values that might be in the input video. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose PASSTHROUGH. RESPOND: MediaLive clips the input video using a formula that uses the AFD values (configured in afdSignaling ), the input display aspect ratio, and the output display aspect ratio. MediaLive also includes the AFD values in the output, unless the codec for this encode is FRAME_CAPTURE. PASSTHROUGH: MediaLive ignores the AFD values and does not clip the video. But MediaLive does include the values in the output. NONE: MediaLive does not clip the input video and does not include the AFD values in the output\n\nScalingBehavior -> (string)\n\nSTRETCH_TO_OUTPUT configures the output position to stretch the video to the specified output resolution (height and width). This option will override any position value. DEFAULT may insert black boxes (pillar boxes or letter boxes) around the video to provide the specified output resolution.\n\nSharpness -> (integer)\n\nChanges the strength of the anti-alias filter used for scaling. 0 is the softest setting, 100 is the sharpest. A setting of 50 is recommended for most content.\n\nWidth -> (integer)\n\nOutput video width, in pixels. Must be an even number. For most codecs, you can leave this field and height blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nId -> (string)\n\nThe unique id of the channel.\n\nInputAttachments -> (list)\n\nList of input attachments for channel.\n\n(structure)\n\nPlaceholder documentation for InputAttachment\n\nAutomaticInputFailoverSettings -> (structure)\n\nUser-specified settings for defining what the conditions are for declaring the input unhealthy and failing over to a different input.\n\nErrorClearTimeMsec -> (integer)\n\nThis clear time defines the requirement a recovered input must meet to be considered healthy. The input must have no failover conditions for this length of time. Enter a time in milliseconds. This value is particularly important if the input_preference for the failover pair is set to PRIMARY_INPUT_PREFERRED, because after this time, MediaLive will switch back to the primary input.\n\nFailoverConditions -> (list)\n\nA list of failover conditions. If any of these conditions occur, MediaLive will perform a failover to the other input.\n\n(structure)\n\nFailover Condition settings. There can be multiple failover conditions inside AutomaticInputFailoverSettings.\n\nFailoverConditionSettings -> (structure)\n\nFailover condition type-specific settings.\n\nAudioSilenceSettings -> (structure)\n\nMediaLive will perform a failover if the specified audio selector is silent for the specified period.\n\nAudioSelectorName -> (string)\n\nThe name of the audio selector in the input that MediaLive should monitor to detect silence. Select your most important rendition. If you didn’t create an audio selector in this input, leave blank.\n\nAudioSilenceThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be silent before automatic input failover occurs. Silence is defined as audio loss or audio quieter than -50 dBFS.\n\nInputLossSettings -> (structure)\n\nMediaLive will perform a failover if content is not detected in this input for the specified period.\n\nInputLossThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that no input is detected. After that time, an input failover will occur.\n\nVideoBlackSettings -> (structure)\n\nMediaLive will perform a failover if content is considered black for the specified period.\n\nBlackDetectThreshold -> (double)\n\nA value used in calculating the threshold below which MediaLive considers a pixel to be ‘black’. For the input to be considered black, every pixel in a frame must be below this threshold. The threshold is calculated as a percentage (expressed as a decimal) of white. Therefore .1 means 10% white (or 90% black). Note how the formula works for any color depth. For example, if you set this field to 0.1 in 10-bit color depth: (1023*0.1=102.3), which means a pixel value of 102 or less is ‘black’. If you set this field to .1 in an 8-bit color depth: (255*0.1=25.5), which means a pixel value of 25 or less is ‘black’. The range is 0.0 to 1.0, with any number of decimal places.\n\nVideoBlackThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be black before automatic input failover occurs.\n\nInputPreference -> (string)\n\nInput preference when deciding which input to make active when a previously failed input has recovered.\n\nSecondaryInputId -> (string)\n\nThe input ID of the secondary input in the automatic input failover pair.\n\nInputAttachmentName -> (string)\n\nUser-specified name for the attachment. This is required if the user wants to use this input in an input switch action.\n\nInputId -> (string)\n\nThe ID of the input\n\nInputSettings -> (structure)\n\nSettings of an input (caption selector, etc.)\n\nAudioSelectors -> (list)\n\nUsed to select the audio stream to decode for inputs that have multiple available.\n\n(structure)\n\nAudio Selector\n\nName -> (string)\n\nThe name of this AudioSelector. AudioDescriptions will use this name to uniquely identify this Selector. Selector names should be unique per input.\n\nSelectorSettings -> (structure)\n\nThe audio selector settings.\n\nAudioHlsRenditionSelection -> (structure)\n\nAudio Hls Rendition Selection\n\nGroupId -> (string)\n\nSpecifies the GROUP-ID in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nName -> (string)\n\nSpecifies the NAME in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nAudioLanguageSelection -> (structure)\n\nAudio Language Selection\n\nLanguageCode -> (string)\n\nSelects a specific three-letter language code from within an audio source.\n\nLanguageSelectionPolicy -> (string)\n\nWhen set to “strict”, the transport stream demux strictly identifies audio streams by their language descriptor. If a PMT update occurs such that an audio stream matching the initially selected language is no longer present then mute will be encoded until the language returns. If “loose”, then on a PMT update the demux will choose another audio stream in the program with the same stream type if it can’t find one with the same language.\n\nAudioPidSelection -> (structure)\n\nAudio Pid Selection\n\nPid -> (integer)\n\nSelects a specific PID from within a source.\n\nAudioTrackSelection -> (structure)\n\nAudio Track Selection\n\nTracks -> (list)\n\nSelects one or more unique audio tracks from within a source.\n\n(structure)\n\nAudio Track\n\nTrack -> (integer)\n\n1-based integer value that maps to a specific audio track\n\nCaptionSelectors -> (list)\n\nUsed to select the caption input to use for inputs that have multiple available.\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nLanguageCode -> (string)\n\nWhen specified this field indicates the three letter language code of the caption track to extract from the source.\n\nName -> (string)\n\nName identifier for a caption selector. This name is used to associate this caption selector with one or more caption descriptions. Names must be unique within an event.\n\nSelectorSettings -> (structure)\n\nCaption selector settings.\n\nAncillarySourceSettings -> (structure)\n\nAncillary Source Settings\n\nSourceAncillaryChannelNumber -> (integer)\n\nSpecifies the number (1 to 4) of the captions channel you want to extract from the ancillary captions. If you plan to convert the ancillary captions to another format, complete this field. If you plan to choose Embedded as the captions destination in the output (to pass through all the channels in the ancillary captions), leave this field blank because MediaLive ignores the field.\n\nAribSourceSettings -> (structure)\n\nArib Source Settings\n\nDvbSubSourceSettings -> (structure)\n\nDvb Sub Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nWhen using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through, regardless of selectors.\n\nEmbeddedSourceSettings -> (structure)\n\nEmbedded Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nScte20Detection -> (string)\n\nSet to “auto” to handle streams with intermittent and/or non-aligned SCTE-20 and Embedded captions.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nSource608TrackNumber -> (integer)\n\nThis field is unused and deprecated.\n\nScte20SourceSettings -> (structure)\n\nScte20 Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nScte27SourceSettings -> (structure)\n\nScte27 Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nThe pid field is used in conjunction with the caption selector languageCode field as follows: - Specify PID and Language: Extracts captions from that PID; the language is “informational”. - Specify PID and omit Language: Extracts the specified PID. - Omit PID and specify Language: Extracts the specified language, whichever PID that happens to be. - Omit PID and omit Language: Valid only if source is DVB-Sub that is being passed through; all languages will be passed through.\n\nTeletextSourceSettings -> (structure)\n\nTeletext Source Settings\n\nOutputRectangle -> (structure)\n\nOptionally defines a region where TTML style captions will be displayed\n\nHeight -> (double)\n\nSee the description in leftOffset. For height, specify the entire height of the rectangle as a percentage of the underlying frame height. For example, “80” means the rectangle height is 80% of the underlying frame height. The topOffset and rectangleHeight must add up to 100% or less. This field corresponds to tts:extent - Y in the TTML standard.\n\nLeftOffset -> (double)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. (Make sure to leave the default if you don’t have either of these formats in the output.) You can define a display rectangle for the captions that is smaller than the underlying video frame. You define the rectangle by specifying the position of the left edge, top edge, bottom edge, and right edge of the rectangle, all within the underlying video frame. The units for the measurements are percentages. If you specify a value for one of these fields, you must specify a value for all of them. For leftOffset, specify the position of the left edge of the rectangle, as a percentage of the underlying frame width, and relative to the left edge of the frame. For example, “10” means the measurement is 10% of the underlying frame width. The rectangle left edge starts at that position from the left edge of the frame. This field corresponds to tts:origin - X in the TTML standard.\n\nTopOffset -> (double)\n\nSee the description in leftOffset. For topOffset, specify the position of the top edge of the rectangle, as a percentage of the underlying frame height, and relative to the top edge of the frame. For example, “10” means the measurement is 10% of the underlying frame height. The rectangle top edge starts at that position from the top edge of the frame. This field corresponds to tts:origin - Y in the TTML standard.\n\nWidth -> (double)\n\nSee the description in leftOffset. For width, specify the entire width of the rectangle as a percentage of the underlying frame width. For example, “80” means the rectangle width is 80% of the underlying frame width. The leftOffset and rectangleWidth must add up to 100% or less. This field corresponds to tts:extent - X in the TTML standard.\n\nPageNumber -> (string)\n\nSpecifies the teletext page number within the data stream from which to extract captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should be specified as a hexadecimal string with no “0x” prefix.\n\nDeblockFilter -> (string)\n\nEnable or disable the deblock filter when filtering.\n\nDenoiseFilter -> (string)\n\nEnable or disable the denoise filter when filtering.\n\nFilterStrength -> (integer)\n\nAdjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).\n\nInputFilter -> (string)\n\nTurns on the filter for this input. MPEG-2 inputs have the deblocking filter enabled by default. 1) auto - filtering will be applied depending on input type/quality 2) disabled - no filtering will be applied to the input 3) forced - filtering will be applied regardless of input type\n\nNetworkInputSettings -> (structure)\n\nInput settings.\n\nHlsInputSettings -> (structure)\n\nSpecifies HLS input settings when the uri is for a HLS manifest.\n\nBandwidth -> (integer)\n\nWhen specified the HLS stream with the m3u8 BANDWIDTH that most closely matches this value will be chosen, otherwise the highest bandwidth stream in the m3u8 will be chosen. The bitrate is specified in bits per second, as in an HLS manifest.\n\nBufferSegments -> (integer)\n\nWhen specified, reading of the HLS input will begin this many buffer segments from the end (most recently written segment). When not specified, the HLS input will begin with the first segment specified in the m3u8.\n\nRetries -> (integer)\n\nThe number of consecutive times that attempts to read a manifest or segment must fail before the input is considered unavailable.\n\nRetryInterval -> (integer)\n\nThe number of seconds between retries when an attempt to read a manifest or segment fails.\n\nScte35Source -> (string)\n\nIdentifies the source for the SCTE-35 messages that MediaLive will ingest. Messages can be ingested from the content segments (in the stream) or from tags in the playlist (the HLS manifest). MediaLive ignores SCTE-35 information in the source that is not selected.\n\nServerValidation -> (string)\n\nCheck HTTPS server certificates. When set to checkCryptographyOnly, cryptography in the certificate will be checked, but not the server’s name. Certain subdomains (notably S3 buckets that use dots in the bucket name) do not strictly match the corresponding certificate’s wildcard pattern and would otherwise cause the event to error. This setting is ignored for protocols that do not use https.\n\nSmpte2038DataPreference -> (string)\n\nSpecifies whether to extract applicable ancillary data from a SMPTE-2038 source in this input. Applicable data types are captions, timecode, AFD, and SCTE-104 messages. - PREFER: Extract from SMPTE-2038 if present in this input, otherwise extract from another source (if any). - IGNORE: Never extract any ancillary data from SMPTE-2038.\n\nSourceEndBehavior -> (string)\n\nLoop input if it is a file. This allows a file input to be streamed indefinitely.\n\nVideoSelector -> (structure)\n\nInforms which video elementary stream to decode for input types that have multiple available.\n\nColorSpace -> (string)\n\nSpecifies the color space of an input. This setting works in tandem with colorSpaceUsage and a video description’s colorSpaceSettingsChoice to determine if any conversion will be performed.\n\nColorSpaceSettings -> (structure)\n\nColor space settings\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nColorSpaceUsage -> (string)\n\nApplies only if colorSpace is a value other than follow. This field controls how the value in the colorSpace field will be used. fallback means that when the input does include color space data, that data will be used, but when the input has no color space data, the value in colorSpace will be used. Choose fallback if your input is sometimes missing color space data, but when it does have color space data, that data is correct. force means to always use the value in colorSpace. Choose force if your input usually has no color space data or might have unreliable color space data.\n\nSelectorSettings -> (structure)\n\nThe video selector settings.\n\nVideoSelectorPid -> (structure)\n\nVideo Selector Pid\n\nPid -> (integer)\n\nSelects a specific PID from within a video source.\n\nVideoSelectorProgramId -> (structure)\n\nVideo Selector Program Id\n\nProgramId -> (integer)\n\nSelects a specific program from within a multi-program transport stream. If the program doesn’t exist, the first program within the transport stream will be selected by default.\n\nInputSpecification -> (structure)\n\nSpecification of network and file inputs for this channel\n\nCodec -> (string)\n\nInput codec\n\nMaximumBitrate -> (string)\n\nMaximum input bitrate, categorized coarsely\n\nResolution -> (string)\n\nInput resolution, categorized coarsely\n\nLogLevel -> (string)\n\nThe log level being written to CloudWatch Logs.\n\nName -> (string)\n\nThe name of the channel. (user-mutable)\n\nPipelineDetails -> (list)\n\nRuntime details for the pipelines of a running channel.\n\n(structure)\n\nRuntime details of a pipeline when a channel is running.\n\nActiveInputAttachmentName -> (string)\n\nThe name of the active input attachment currently being ingested by this pipeline.\n\nActiveInputSwitchActionName -> (string)\n\nThe name of the input switch schedule action that occurred most recently and that resulted in the switch to the current input attachment for this pipeline.\n\nActiveMotionGraphicsActionName -> (string)\n\nThe name of the motion graphics activate action that occurred most recently and that resulted in the current graphics URI for this pipeline.\n\nActiveMotionGraphicsUri -> (string)\n\nThe current URI being used for HTML5 motion graphics for this pipeline.\n\nPipelineId -> (string)\n\nPipeline ID\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role assumed when running the Channel.\n\nState -> (string)\n\nPlaceholder documentation for ChannelState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nVpc -> (structure)\n\nSettings for VPC output\n\nAvailabilityZones -> (list)\n\nThe Availability Zones where the vpc subnets are located. The first Availability Zone applies to the first subnet in the list of subnets. The second Availability Zone applies to the second subnet.\n\n(string)\n\nPlaceholder documentation for __string\n\nNetworkInterfaceIds -> (list)\n\nA list of Elastic Network Interfaces created by MediaLive in the customer’s VPC\n\n(string)\n\nPlaceholder documentation for __string\n\nSecurityGroupIds -> (list)\n\nA list of up EC2 VPC security group IDs attached to the Output VPC network interfaces.\n\n(string)\n\nPlaceholder documentation for __string\n\nSubnetIds -> (list)\n\nA list of VPC subnet IDs from the same VPC. If STANDARD channel, subnet IDs must be mapped to two unique availability zones (AZ).\n\n(string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "start-multiplex",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/start-multiplex.html",
      "command_description": "Description\n\nStart (run) the multiplex. Starting the multiplex does not start the channels. You must explicitly start each channel.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-multiplex\n--multiplex-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--multiplex-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--multiplex-id (string) The ID of the multiplex.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe unique arn of the multiplex.\n\nAvailabilityZones -> (list)\n\nA list of availability zones for the multiplex.\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the multiplex output destinations.\n\n(structure)\n\nMultiplex output destination settings\n\nMediaConnectSettings -> (structure)\n\nMultiplex MediaConnect output destination settings.\n\nEntitlementArn -> (string)\n\nThe MediaConnect entitlement ARN available as a Flow source.\n\nId -> (string)\n\nThe unique id of the multiplex.\n\nMultiplexSettings -> (structure)\n\nConfiguration for a multiplex event.\n\nMaximumVideoBufferDelayMilliseconds -> (integer)\n\nMaximum video buffer delay in milliseconds.\n\nTransportStreamBitrate -> (integer)\n\nTransport stream bit rate.\n\nTransportStreamId -> (integer)\n\nTransport stream ID.\n\nTransportStreamReservedBitrate -> (integer)\n\nTransport stream reserved bit rate.\n\nName -> (string)\n\nThe name of the multiplex.\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nProgramCount -> (integer)\n\nThe number of programs in the multiplex.\n\nState -> (string)\n\nThe current state of the multiplex.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "stop-channel",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/stop-channel.html",
      "command_description": "Description\n\nStops a running channel\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  stop-channel\n--channel-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-id (string) A request to stop a running channel\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe unique arn of the channel.\n\nCdiInputSpecification -> (structure)\n\nSpecification of CDI inputs for this channel\n\nResolution -> (string)\n\nMaximum CDI input resolution\n\nChannelClass -> (string)\n\nThe class for this channel. STANDARD for a channel with two pipelines or SINGLE_PIPELINE for a channel with one pipeline.\n\nDestinations -> (list)\n\nA list of destinations of the channel. For UDP outputs, there is one destination per output. For other types (HLS, for example), there is one destination per packager.\n\n(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nEgressEndpoints -> (list)\n\nThe endpoints where outgoing connections initiate from\n\n(structure)\n\nPlaceholder documentation for ChannelEgressEndpoint\n\nSourceIp -> (string)\n\nPublic IP of where a channel’s output comes from\n\nEncoderSettings -> (structure)\n\nEncoder Settings\n\nAudioDescriptions -> (list)\n\nPlaceholder documentation for __listOfAudioDescription\n\n(structure)\n\nAudio Description\n\nAudioNormalizationSettings -> (structure)\n\nAdvanced audio normalization settings.\n\nAlgorithm -> (string)\n\nAudio normalization algorithm to use. itu17701 conforms to the CALM Act specification, itu17702 conforms to the EBU R-128 specification.\n\nAlgorithmControl -> (string)\n\nWhen set to correctAudio the output audio is corrected using the chosen algorithm. If set to measureOnly, the audio will be measured but not adjusted.\n\nTargetLkfs -> (double)\n\nTarget LKFS(loudness) to adjust volume to. If no value is entered, a default value will be used according to the chosen algorithm. The CALM Act (1770-1) recommends a target of -24 LKFS. The EBU R-128 specification (1770-2) recommends a target of -23 LKFS.\n\nAudioSelectorName -> (string)\n\nThe name of the AudioSelector used as the source for this AudioDescription.\n\nAudioType -> (string)\n\nApplies only if audioTypeControl is useConfigured. The values for audioType are defined in ISO-IEC 13818-1.\n\nAudioTypeControl -> (string)\n\nDetermines how audio type is determined. followInput: If the input contains an ISO 639 audioType, then that value is passed through to the output. If the input contains no ISO 639 audioType, the value in Audio Type is included in the output. useConfigured: The value in Audio Type is included in the output. Note that this field and audioType are both ignored if inputType is broadcasterMixedAd.\n\nAudioWatermarkingSettings -> (structure)\n\nSettings to configure one or more solutions that insert audio watermarks in the audio encode\n\nNielsenWatermarksSettings -> (structure)\n\nSettings to configure Nielsen Watermarks in the audio encode\n\nNielsenCbetSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen CBET\n\nCbetCheckDigitString -> (string)\n\nEnter the CBET check digits to use in the watermark.\n\nCbetStepaside -> (string)\n\nDetermines the method of CBET insertion mode when prior encoding is detected on the same layer.\n\nCsid -> (string)\n\nEnter the CBET Source ID (CSID) to use in the watermark\n\nNielsenDistributionType -> (string)\n\nChoose the distribution types that you want to assign to the watermarks: - PROGRAM_CONTENT - FINAL_DISTRIBUTOR\n\nNielsenNaesIiNwSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen NAES II (N2) and Nielsen NAES VI (NW).\n\nCheckDigitString -> (string)\n\nEnter the check digit string for the watermark\n\nSid -> (double)\n\nEnter the Nielsen Source ID (SID) to include in the watermark\n\nCodecSettings -> (structure)\n\nAudio codec settings.\n\nAacSettings -> (structure)\n\nAac Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid values depend on rate control mode and profile.\n\nCodingMode -> (string)\n\nMono, Stereo, or 5.1 channel layout. Valid values depend on rate control mode and profile. The adReceiverMix setting receives a stereo description plus control track and emits a mono AAC encode of the description track, with control data emitted in the PES header as per ETSI TS 101 154 Annex E.\n\nInputType -> (string)\n\nSet to “broadcasterMixedAd” when input contains pre-mixed main audio + AD (narration) as a stereo pair. The Audio Type field (audioType) will be set to 3, which signals to downstream systems that this stream contains “broadcaster mixed AD”. Note that the input received by the encoder must contain pre-mixed audio; the encoder does not perform the mixing. The values in audioTypeControl and audioType (in AudioDescription) are ignored when set to broadcasterMixedAd. Leave set to “normal” when input does not contain pre-mixed audio + AD.\n\nProfile -> (string)\n\nAAC Profile.\n\nRateControlMode -> (string)\n\nRate Control Mode.\n\nRawFormat -> (string)\n\nSets LATM / LOAS AAC output for raw containers.\n\nSampleRate -> (double)\n\nSample rate in Hz. Valid values depend on rate control mode and profile.\n\nSpec -> (string)\n\nUse MPEG-2 AAC audio instead of MPEG-4 AAC audio for raw or MPEG-2 Transport Stream containers.\n\nVbrQuality -> (string)\n\nVBR Quality Level - Only used if rateControlMode is VBR.\n\nAc3Settings -> (structure)\n\nAc3 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted AC-3 stream. See ATSC A/52-2012 for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital coding mode. Determines number of channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If excluded and input audio is Dolby Digital, dialnorm will be passed through.\n\nDrcProfile -> (string)\n\nIf set to filmStandard, adds dynamic range compression signaling to the output bitstream as defined in the Dolby Digital specification.\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid in codingMode32Lfe mode.\n\nMetadataControl -> (string)\n\nWhen set to “followInput”, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nEac3Settings -> (structure)\n\nEac3 Settings\n\nAttenuationControl -> (string)\n\nWhen set to attenuate3Db, applies a 3 dB attenuation to the surround channels. Only used for 3/2 coding mode.\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted E-AC-3 stream. See ATSC A/52-2012 (Annex E) for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital Plus coding mode. Determines number of channels.\n\nDcFilter -> (string)\n\nWhen set to enabled, activates a DC highpass filter for all input channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If blank and input audio is Dolby Digital Plus, dialnorm will be passed through.\n\nDrcLine -> (string)\n\nSets the Dolby dynamic range compression profile.\n\nDrcRf -> (string)\n\nSets the profile for heavy Dolby dynamic range compression, ensures that the instantaneous signal peaks do not exceed specified levels.\n\nLfeControl -> (string)\n\nWhen encoding 3/2 audio, setting to lfe enables the LFE channel\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid with codingMode32 coding mode.\n\nLoRoCenterMixLevel -> (double)\n\nLeft only/Right only center mix level. Only used for 3/2 coding mode.\n\nLoRoSurroundMixLevel -> (double)\n\nLeft only/Right only surround mix level. Only used for 3/2 coding mode.\n\nLtRtCenterMixLevel -> (double)\n\nLeft total/Right total center mix level. Only used for 3/2 coding mode.\n\nLtRtSurroundMixLevel -> (double)\n\nLeft total/Right total surround mix level. Only used for 3/2 coding mode.\n\nMetadataControl -> (string)\n\nWhen set to followInput, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nPassthroughControl -> (string)\n\nWhen set to whenPossible, input DD+ audio will be passed through if it is present on the input. This detection is dynamic over the life of the transcode. Inputs that alternate between DD+ and non-DD+ content will have a consistent DD+ output as the system alternates between passthrough and encoding.\n\nPhaseControl -> (string)\n\nWhen set to shift90Degrees, applies a 90-degree phase shift to the surround channels. Only used for 3/2 coding mode.\n\nStereoDownmix -> (string)\n\nStereo downmix preference. Only used for 3/2 coding mode.\n\nSurroundExMode -> (string)\n\nWhen encoding 3/2 audio, sets whether an extra center back surround channel is matrix encoded into the left and right surround channels.\n\nSurroundMode -> (string)\n\nWhen encoding 2/0 audio, sets whether Dolby Surround is matrix encoded into the two channels.\n\nMp2Settings -> (structure)\n\nMp2 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second.\n\nCodingMode -> (string)\n\nThe MPEG2 Audio coding mode. Valid values are codingMode10 (for mono) or codingMode20 (for stereo).\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nPassThroughSettings -> (structure)\n\nPass Through Settings\n\nWavSettings -> (structure)\n\nWav Settings\n\nBitDepth -> (double)\n\nBits per sample.\n\nCodingMode -> (string)\n\nThe audio coding mode for the WAV audio. The mode determines the number of channels in the audio.\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nLanguageCode -> (string)\n\nRFC 5646 language code representing the language of the audio output track. Only used if languageControlMode is useConfigured, or there is no ISO 639 language code specified in the input.\n\nLanguageCodeControl -> (string)\n\nChoosing followInput will cause the ISO 639 language code of the output to follow the ISO 639 language code of the input. The languageCode will be used when useConfigured is set, or when followInput is selected but there is no ISO 639 language code specified by the input.\n\nName -> (string)\n\nThe name of this AudioDescription. Outputs will use this name to uniquely identify this AudioDescription. Description names should be unique within this Live Event.\n\nRemixSettings -> (structure)\n\nSettings that control how input audio channels are remixed into the output audio channels.\n\nChannelMappings -> (list)\n\nMapping of input channels to output channels, with appropriate gain adjustments.\n\n(structure)\n\nAudio Channel Mapping\n\nInputChannelLevels -> (list)\n\nIndices and gain values for each input channel that should be remixed into this output channel.\n\n(structure)\n\nInput Channel Level\n\nGain -> (integer)\n\nRemixing value. Units are in dB and acceptable values are within the range from -60 (mute) and 6 dB.\n\nInputChannel -> (integer)\n\nThe index of the input channel used as a source.\n\nOutputChannel -> (integer)\n\nThe index of the output channel being produced.\n\nChannelsIn -> (integer)\n\nNumber of input channels to be used.\n\nChannelsOut -> (integer)\n\nNumber of output channels to be produced. Valid values: 1, 2, 4, 6, 8\n\nStreamName -> (string)\n\nUsed for MS Smooth and Apple HLS outputs. Indicates the name displayed by the player (eg. English, or Director Commentary).\n\nAvailBlanking -> (structure)\n\nSettings for ad avail blanking.\n\nAvailBlankingImage -> (structure)\n\nBlanking image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when insertion metadata is added.\n\nAvailConfiguration -> (structure)\n\nEvent-wide configuration settings for ad avail insertion.\n\nAvailSettings -> (structure)\n\nAd avail settings.\n\nScte35SpliceInsert -> (structure)\n\nScte35 Splice Insert\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nScte35TimeSignalApos -> (structure)\n\nScte35 Time Signal Apos\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nBlackoutSlate -> (structure)\n\nSettings for blackout slate.\n\nBlackoutSlateImage -> (structure)\n\nBlackout slate image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkEndBlackout -> (string)\n\nSetting to enabled causes the encoder to blackout the video, audio, and captions, and raise the “Network Blackout Image” slate when an SCTE104/35 Network End Segmentation Descriptor is encountered. The blackout will be lifted when the Network Start Segmentation Descriptor is encountered. The Network End and Network Start descriptors must contain a network ID that matches the value entered in “Network ID”.\n\nNetworkEndBlackoutImage -> (structure)\n\nPath to local file to use as Network End Blackout image. Image will be scaled to fill the entire output raster.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkId -> (string)\n\nProvides Network ID that matches EIDR ID format (e.g., “10.XXXX/XXXX-XXXX-XXXX-XXXX-XXXX-C”).\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when indicated by program metadata.\n\nCaptionDescriptions -> (list)\n\nSettings for caption decriptions\n\n(structure)\n\nCaption Description\n\nCaptionSelectorName -> (string)\n\nSpecifies which input caption selector to use as a caption source when generating output captions. This field should match a captionSelector name.\n\nDestinationSettings -> (structure)\n\nAdditional settings for captions destination that depend on the destination type.\n\nAribDestinationSettings -> (structure)\n\nArib Destination Settings\n\nBurnInDestinationSettings -> (structure)\n\nBurn In Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to ‘auto’ fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. All burn-in and DVB-Sub font settings must match.\n\nDvbSubDestinationSettings -> (structure)\n\nDvb Sub Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. This option is not valid for source captions that are STL or 608/embedded. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to auto fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nEbuTtDDestinationSettings -> (structure)\n\nEbu Tt DDestination Settings\n\nCopyrightHolder -> (string)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. Complete this field if you want to include the name of the copyright holder in the copyright metadata tag in the TTML\n\nFillLineGap -> (string)\n\nSpecifies how to handle the gap between the lines (in multi-line captions). - enabled: Fill with the captions background color (as specified in the input captions). - disabled: Leave the gap unfilled.\n\nFontFamily -> (string)\n\nSpecifies the font family to include in the font data attached to the EBU-TT captions. Valid only if styleControl is set to include. If you leave this field empty, the font family is set to “monospaced”. (If styleControl is set to exclude, the font family is always set to “monospaced”.) You specify only the font family. All other style information (color, bold, position and so on) is copied from the input captions. The size is always set to 100% to allow the downstream player to choose the size. - Enter a list of font families, as a comma-separated list of font names, in order of preference. The name can be a font family (such as “Arial”), or a generic font family (such as “serif”), or “default” (to let the downstream player choose the font). - Leave blank to set the family to “monospace”.\n\nStyleControl -> (string)\n\nSpecifies the style information (font color, font position, and so on) to include in the font data that is attached to the EBU-TT captions. - include: Take the style information (font color, font position, and so on) from the source captions and include that information in the font data attached to the EBU-TT captions. This option is valid only if the source captions are Embedded or Teletext. - exclude: In the font data attached to the EBU-TT captions, set the font family to “monospaced”. Do not include any other style information.\n\nEmbeddedDestinationSettings -> (structure)\n\nEmbedded Destination Settings\n\nEmbeddedPlusScte20DestinationSettings -> (structure)\n\nEmbedded Plus Scte20 Destination Settings\n\nRtmpCaptionInfoDestinationSettings -> (structure)\n\nRtmp Caption Info Destination Settings\n\nScte20PlusEmbeddedDestinationSettings -> (structure)\n\nScte20 Plus Embedded Destination Settings\n\nScte27DestinationSettings -> (structure)\n\nScte27 Destination Settings\n\nSmpteTtDestinationSettings -> (structure)\n\nSmpte Tt Destination Settings\n\nTeletextDestinationSettings -> (structure)\n\nTeletext Destination Settings\n\nTtmlDestinationSettings -> (structure)\n\nTtml Destination Settings\n\nStyleControl -> (string)\n\nWhen set to passthrough, passes through style and position information from a TTML-like input source (TTML, SMPTE-TT, CFF-TT) to the CFF-TT output or TTML output.\n\nWebvttDestinationSettings -> (structure)\n\nWebvtt Destination Settings\n\nStyleControl -> (string)\n\nControls whether the color and position of the source captions is passed through to the WebVTT output captions. PASSTHROUGH - Valid only if the source captions are EMBEDDED or TELETEXT. NO_STYLE_DATA - Don’t pass through the style. The output captions will not contain any font styling information.\n\nLanguageCode -> (string)\n\nISO 639-2 three-digit code: http://www.loc.gov/standards/iso639-2/\n\nLanguageDescription -> (string)\n\nHuman readable information to indicate captions available for players (eg. English, or Spanish).\n\nName -> (string)\n\nName of the caption description. Used to associate a caption description with an output. Names must be unique within an event.\n\nFeatureActivations -> (structure)\n\nFeature Activations\n\nInputPrepareScheduleActions -> (string)\n\nEnables the Input Prepare feature. You can create Input Prepare actions in the schedule only if this feature is enabled. If you disable the feature on an existing schedule, make sure that you first delete all input prepare actions from the schedule.\n\nGlobalConfiguration -> (structure)\n\nConfiguration settings that apply to the event as a whole.\n\nInitialAudioGain -> (integer)\n\nValue to set the initial audio gain for the Live Event.\n\nInputEndAction -> (string)\n\nIndicates the action to take when the current input completes (e.g. end-of-file). When switchAndLoopInputs is configured the encoder will restart at the beginning of the first input. When “none” is configured the encoder will transcode either black, a solid color, or a user specified slate images per the “Input Loss Behavior” configuration until the next input switch occurs (which is controlled through the Channel Schedule API).\n\nInputLossBehavior -> (structure)\n\nSettings for system actions when input is lost.\n\nBlackFrameMsec -> (integer)\n\nDocumentation update needed\n\nInputLossImageColor -> (string)\n\nWhen input loss image type is “color” this field specifies the color to use. Value: 6 hex characters representing the values of RGB.\n\nInputLossImageSlate -> (structure)\n\nWhen input loss image type is “slate” these fields specify the parameters for accessing the slate.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nInputLossImageType -> (string)\n\nIndicates whether to substitute a solid color or a slate into the output after input loss exceeds blackFrameMsec.\n\nRepeatFrameMsec -> (integer)\n\nDocumentation update needed\n\nOutputLockingMode -> (string)\n\nIndicates how MediaLive pipelines are synchronized. PIPELINE_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the other. EPOCH_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the Unix epoch.\n\nOutputTimingSource -> (string)\n\nIndicates whether the rate of frames emitted by the Live encoder should be paced by its system clock (which optionally may be locked to another source via NTP) or should be locked to the clock of the source that is providing the input stream.\n\nSupportLowFramerateInputs -> (string)\n\nAdjusts video input buffer for streams with very low video framerates. This is commonly set to enabled for music channels with less than one video frame per second.\n\nMotionGraphicsConfiguration -> (structure)\n\nSettings for motion graphics.\n\nMotionGraphicsInsertion -> (string)\n\nMotion Graphics Insertion\n\nMotionGraphicsSettings -> (structure)\n\nMotion Graphics Settings\n\nHtmlMotionGraphicsSettings -> (structure)\n\nHtml Motion Graphics Settings\n\nNielsenConfiguration -> (structure)\n\nNielsen configuration settings.\n\nDistributorId -> (string)\n\nEnter the Distributor ID assigned to your organization by Nielsen.\n\nNielsenPcmToId3Tagging -> (string)\n\nEnables Nielsen PCM to ID3 tagging\n\nOutputGroups -> (list)\n\nPlaceholder documentation for __listOfOutputGroup\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nName -> (string)\n\nCustom output group name optionally defined by the user. Only letters, numbers, and the underscore character allowed; only 32 characters allowed.\n\nOutputGroupSettings -> (structure)\n\nSettings associated with the output group.\n\nArchiveGroupSettings -> (structure)\n\nArchive Group Settings\n\nArchiveCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nArchiveS3Settings -> (structure)\n\nArchive S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nDestination -> (structure)\n\nA directory and base filename where archive files should be written.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRolloverInterval -> (integer)\n\nNumber of seconds to write to archive file before closing and starting a new one.\n\nFrameCaptureGroupSettings -> (structure)\n\nFrame Capture Group Settings\n\nDestination -> (structure)\n\nThe destination for the frame capture files. Either the URI for an Amazon S3 bucket and object, plus a file name prefix (for example, s3ssl://sportsDelivery/highlights/20180820/curling-) or the URI for a MediaStore container, plus a file name prefix (for example, mediastoressl://sportsDelivery/20180820/curling-). The final file names consist of the prefix from the destination field (for example, “curling-“) + name modifier + the counter (5 digits, starting from 00001) + extension (which is always .jpg). For example, curling-low.00001.jpg\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFrameCaptureCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nFrameCaptureS3Settings -> (structure)\n\nFrame Capture S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsGroupSettings -> (structure)\n\nHls Group Settings\n\nAdMarkers -> (list)\n\nChoose one or more ad marker types to pass SCTE35 signals through to this group of Apple HLS outputs.\n\n(string)\n\nHls Ad Markers\n\nBaseUrlContent -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlContent1 -> (string)\n\nOptional. One value per output group. This field is required only if you are completing Base URL content A, and the downstream system has notified you that the media files for pipeline 1 of all outputs are in a location different from the media files for pipeline 0.\n\nBaseUrlManifest -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlManifest1 -> (string)\n\nOptional. One value per output group. Complete this field only if you are completing Base URL manifest A, and the downstream system has notified you that the child manifest files for pipeline 1 of all outputs are in a location different from the child manifest files for pipeline 0.\n\nCaptionLanguageMappings -> (list)\n\nMapping of up to 4 caption channels to caption languages. Is only meaningful if captionLanguageSetting is set to “insert”.\n\n(structure)\n\nMaps a caption channel to an ISO 693-2 language code (http://www.loc.gov/standards/iso639-2), with an optional description.\n\nCaptionChannel -> (integer)\n\nThe closed caption channel being described by this CaptionLanguageMapping. Each channel mapping must have a unique channel number (maximum of 4)\n\nLanguageCode -> (string)\n\nThree character ISO 639-2 language code (see http://www.loc.gov/standards/iso639-2)\n\nLanguageDescription -> (string)\n\nTextual description of language\n\nCaptionLanguageSetting -> (string)\n\nApplies only to 608 Embedded output captions. insert: Include CLOSED-CAPTIONS lines in the manifest. Specify at least one language in the CC1 Language Code field. One CLOSED-CAPTION line is added for each Language Code you specify. Make sure to specify the languages in the order in which they appear in the original source (if the source is embedded format) or the order of the caption selectors (if the source is other than embedded). Otherwise, languages in the manifest will not match up properly with the output captions. none: Include CLOSED-CAPTIONS=NONE line in the manifest. omit: Omit any CLOSED-CAPTIONS line from the manifest.\n\nClientCache -> (string)\n\nWhen set to “disabled”, sets the #EXT-X-ALLOW-CACHE:no tag in the manifest, which prevents clients from saving media segments for later replay.\n\nCodecSpecification -> (string)\n\nSpecification to use (RFC-6381 or the default RFC-4281) during m3u8 playlist generation.\n\nConstantIv -> (string)\n\nFor use with encryptionType. This is a 128-bit, 16-byte hex value represented by a 32-character text string. If ivSource is set to “explicit” then this parameter is required and is used as the IV for encryption.\n\nDestination -> (structure)\n\nA directory or HTTP destination for the HLS segments, manifest files, and encryption keys (if enabled).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nDirectoryStructure -> (string)\n\nPlace segments in subdirectories.\n\nDiscontinuityTags -> (string)\n\nSpecifies whether to insert EXT-X-DISCONTINUITY tags in the HLS child manifests for this output group. Typically, choose Insert because these tags are required in the manifest (according to the HLS specification) and serve an important purpose. Choose Never Insert only if the downstream system is doing real-time failover (without using the MediaLive automatic failover feature) and only if that downstream system has advised you to exclude the tags.\n\nEncryptionType -> (string)\n\nEncrypts the segments with the given encryption scheme. Exclude this parameter if no encryption is desired.\n\nHlsCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nHlsAkamaiSettings -> (structure)\n\nHls Akamai Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to Akamai. User should contact Akamai to enable this feature.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nSalt -> (string)\n\nSalt for authenticated Akamai.\n\nToken -> (string)\n\nToken parameter for authenticated akamai. If not specified, _gda_ is used.\n\nHlsBasicPutSettings -> (structure)\n\nHls Basic Put Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsMediaStoreSettings -> (structure)\n\nHls Media Store Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nMediaStoreStorageClass -> (string)\n\nWhen set to temporal, output files are stored in non-persistent memory for faster reading and writing.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsS3Settings -> (structure)\n\nHls S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsWebdavSettings -> (structure)\n\nHls Webdav Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to WebDAV.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsId3SegmentTagging -> (string)\n\nState of HLS ID3 Segment Tagging\n\nIFrameOnlyPlaylists -> (string)\n\nDISABLED: Do not create an I-frame-only manifest, but do create the master and media manifests (according to the Output Selection field). STANDARD: Create an I-frame-only manifest for each output that contains video, as well as the other manifests (according to the Output Selection field). The I-frame manifest contains a #EXT-X-I-FRAMES-ONLY tag to indicate it is I-frame only, and one or more #EXT-X-BYTERANGE entries identifying the I-frame position. For example, #EXT-X-BYTERANGE:160364@1461888”\n\nIncompleteSegmentBehavior -> (string)\n\nSpecifies whether to include the final (incomplete) segment in the media output when the pipeline stops producing output because of a channel stop, a channel pause or a loss of input to the pipeline. Auto means that MediaLive decides whether to include the final segment, depending on the channel class and the types of output groups. Suppress means to never include the incomplete segment. We recommend you choose Auto and let MediaLive control the behavior.\n\nIndexNSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the maximum number of segments in the media manifest file. After this maximum, older segments are removed from the media manifest. This number must be smaller than the number in the Keep Segments field.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nIvInManifest -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If set to “include”, IV is listed in the manifest, otherwise the IV is not in the manifest.\n\nIvSource -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If this setting is “followsSegmentNumber”, it will cause the IV to change every segment (to match the segment number). If this is set to “explicit”, you must enter a constantIv value.\n\nKeepSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the number of media segments to retain in the destination directory. This number should be bigger than indexNSegments (Num segments). We recommend (value = (2 x indexNsegments) + 1). If this “keep segments” number is too low, the following might happen: the player is still reading a media manifest file that lists this segment, but that segment has been removed from the destination directory (as directed by indexNSegments). This situation would result in a 404 HTTP error on the player.\n\nKeyFormat -> (string)\n\nThe value specifies how the key is represented in the resource identified by the URI. If parameter is absent, an implicit value of “identity” is used. A reverse DNS string can also be given.\n\nKeyFormatVersions -> (string)\n\nEither a single positive integer version value or a slash delimited list of version values (1/2/3).\n\nKeyProviderSettings -> (structure)\n\nThe key provider settings.\n\nStaticKeySettings -> (structure)\n\nStatic Key Settings\n\nKeyProviderServer -> (structure)\n\nThe URL of the license server used for protecting content.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nStaticKeyValue -> (string)\n\nStatic key value as a 32 character hexadecimal string.\n\nManifestCompression -> (string)\n\nWhen set to gzip, compresses HLS playlist.\n\nManifestDurationFormat -> (string)\n\nIndicates whether the output manifest should use floating point or integer values for segment duration.\n\nMinSegmentLength -> (integer)\n\nWhen set, minimumSegmentLength is enforced by looking ahead and back within the specified range for a nearby avail and extending the segment size if needed.\n\nMode -> (string)\n\nIf “vod”, all segments are indexed and kept permanently in the destination and manifest. If “live”, only the number segments specified in keepSegments and indexNSegments are kept; newer segments replace older segments, which may prevent players from rewinding all the way to the beginning of the event. VOD mode uses HLS EXT-X-PLAYLIST-TYPE of EVENT while the channel is running, converting it to a “VOD” type manifest on completion of the stream.\n\nOutputSelection -> (string)\n\nMANIFESTS_AND_SEGMENTS: Generates manifests (master manifest, if applicable, and media manifests) for this output group. VARIANT_MANIFESTS_AND_SEGMENTS: Generates media manifests for this output group, but not a master manifest. SEGMENTS_ONLY: Does not generate any manifests for this output group.\n\nProgramDateTime -> (string)\n\nIncludes or excludes EXT-X-PROGRAM-DATE-TIME tag in .m3u8 manifest files. The value is calculated as follows: either the program date and time are initialized using the input timecode source, or the time is initialized using the input timecode source and the date is initialized using the timestampOffset.\n\nProgramDateTimePeriod -> (integer)\n\nPeriod of insertion of EXT-X-PROGRAM-DATE-TIME entry, in seconds.\n\nRedundantManifest -> (string)\n\nENABLED: The master manifest (.m3u8 file) for each pipeline includes information about both pipelines: first its own media files, then the media files of the other pipeline. This feature allows playout device that support stale manifest detection to switch from one manifest to the other, when the current manifest seems to be stale. There are still two destinations and two master manifests, but both master manifests reference the media files from both pipelines. DISABLED: The master manifest (.m3u8 file) for each pipeline includes information about its own pipeline only. For an HLS output group with MediaPackage as the destination, the DISABLED behavior is always followed. MediaPackage regenerates the manifests it serves to players so a redundant manifest from MediaLive is irrelevant.\n\nSegmentLength -> (integer)\n\nLength of MPEG-2 Transport Stream segments to create (in seconds). Note that segments will end on the next keyframe after this number of seconds, so actual segment length may be longer.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSegmentsPerSubdirectory -> (integer)\n\nNumber of segments to write to a subdirectory before starting a new one. directoryStructure must be subdirectoryPerStream for this setting to have an effect.\n\nStreamInfResolution -> (string)\n\nInclude or exclude RESOLUTION attribute for video in EXT-X-STREAM-INF tag of variant manifest.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nTimestampDeltaMilliseconds -> (integer)\n\nProvides an extra millisecond delta offset to fine tune the timestamps.\n\nTsFileMode -> (string)\n\nSEGMENTED_FILES: Emit the program as segments - multiple .ts media files. SINGLE_FILE: Applies only if Mode field is VOD. Emit the program as a single .ts media file. The media manifest includes #EXT-X-BYTERANGE tags to index segments for playback. A typical use for this value is when sending the output to AWS Elemental MediaConvert, which can accept only a single media file. Playback while the channel is running is not guaranteed due to HTTP server caching.\n\nMediaPackageGroupSettings -> (structure)\n\nMedia Package Group Settings\n\nDestination -> (structure)\n\nMediaPackage channel destination.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nMsSmoothGroupSettings -> (structure)\n\nMs Smooth Group Settings\n\nAcquisitionPointId -> (string)\n\nThe ID to include in each message in the sparse track. Ignored if sparseTrackType is NONE.\n\nAudioOnlyTimecodeControl -> (string)\n\nIf set to passthrough for an audio-only MS Smooth output, the fragment absolute time will be set to the current timecode. This option does not write timecodes to the audio elementary stream.\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the https certificate chain to a trusted Certificate Authority (CA). This will cause https outputs to self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the IIS server if the connection is lost. Content will be cached during this time and the cache will be be delivered to the IIS server once the connection is re-established.\n\nDestination -> (structure)\n\nSmooth Streaming publish point on an IIS server. Elemental Live acts as a “Push” encoder to IIS.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nEventId -> (string)\n\nMS Smooth event ID to be sent to the IIS server. Should only be specified if eventIdMode is set to useConfigured.\n\nEventIdMode -> (string)\n\nSpecifies whether or not to send an event ID to the IIS server. If no event ID is sent and the same Live Event is used without changing the publishing point, clients might see cached video from the previous run. Options: - “useConfigured” - use the value provided in eventId - “useTimestamp” - generate and send an event ID based on the current timestamp - “noEventId” - do not send an event ID to the IIS server.\n\nEventStopBehavior -> (string)\n\nWhen set to sendEos, send EOS signal to IIS server when stopping the event\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nFragmentLength -> (integer)\n\nLength of mp4 fragments to generate (in seconds). Fragment length must be compatible with GOP size and framerate.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nRestartDelay -> (integer)\n\nNumber of seconds before initiating a restart due to output failure, due to exhausting the numRetries on one segment, or exceeding filecacheDuration.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSendDelayMs -> (integer)\n\nNumber of milliseconds to delay the output from the second pipeline.\n\nSparseTrackType -> (string)\n\nIdentifies the type of data to place in the sparse track: - SCTE35: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame to start a new segment. - SCTE35_WITHOUT_SEGMENTATION: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame but don’t start a new segment. - NONE: Don’t generate a sparse track for any outputs in this output group.\n\nStreamManifestBehavior -> (string)\n\nWhen set to send, send stream manifest so publishing point doesn’t start until all streams start.\n\nTimestampOffset -> (string)\n\nTimestamp offset for the event. Only used if timestampOffsetMode is set to useConfiguredOffset.\n\nTimestampOffsetMode -> (string)\n\nType of timestamp date offset to use. - useEventStartDate: Use the date the event was started as the offset - useConfiguredOffset: Use an explicitly configured date as the offset\n\nMultiplexGroupSettings -> (structure)\n\nMultiplex Group Settings\n\nRtmpGroupSettings -> (structure)\n\nRtmp Group Settings\n\nAdMarkers -> (list)\n\nChoose the ad marker type for this output group. MediaLive will create a message based on the content of each SCTE-35 message, format it for that marker type, and insert it in the datastream.\n\n(string)\n\nRtmp Ad Markers\n\nAuthenticationScheme -> (string)\n\nAuthentication scheme to use when connecting with CDN\n\nCacheFullBehavior -> (string)\n\nControls behavior when content cache fills up. If remote origin server stalls the RTMP connection and does not accept content fast enough the ‘Media Cache’ will fill up. When the cache reaches the duration specified by cacheLength the cache will stop accepting new content. If set to disconnectImmediately, the RTMP output will force a disconnect. Clear the media cache, and reconnect after restartDelay seconds. If set to waitForServer, the RTMP output will wait up to 5 minutes to allow the origin server to begin accepting data again.\n\nCacheLength -> (integer)\n\nCache length, in seconds, is used to calculate buffer size.\n\nCaptionData -> (string)\n\nControls the types of data that passes to onCaptionInfo outputs. If set to ‘all’ then 608 and 708 carried DTVCC data will be passed. If set to ‘field1AndField2608’ then DTVCC data will be stripped out, but 608 data from both fields will be passed. If set to ‘field1608’ then only the data carried in 608 from field 1 video will be passed.\n\nInputLossAction -> (string)\n\nControls the behavior of this RTMP group if input becomes unavailable. - emitOutput: Emit a slate until input returns. - pauseOutput: Stop transmitting data until input returns. This does not close the underlying RTMP connection.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nUdpGroupSettings -> (structure)\n\nUdp Group Settings\n\nInputLossAction -> (string)\n\nSpecifies behavior of last resort when input video is lost, and no more backup inputs are available. When dropTs is selected the entire transport stream will stop being emitted. When dropProgram is selected the program can be dropped from the transport stream (and replaced with null packets to meet the TS bitrate requirement). Or, when emitProgram is chosen the transport stream will continue to be produced normally with repeat frames, black frames, or slate frames substituted for the absent input video.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nOutputs -> (list)\n\nPlaceholder documentation for __listOfOutput\n\n(structure)\n\nOutput settings. There can be multiple outputs within a group.\n\nAudioDescriptionNames -> (list)\n\nThe names of the AudioDescriptions used as audio sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nCaptionDescriptionNames -> (list)\n\nThe names of the CaptionDescriptions used as caption sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nOutputName -> (string)\n\nThe name used to identify an output.\n\nOutputSettings -> (structure)\n\nOutput type-specific settings.\n\nArchiveOutputSettings -> (structure)\n\nArchive Output Settings\n\nContainerSettings -> (structure)\n\nSettings specific to the container type of the file.\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nRawSettings -> (structure)\n\nRaw Settings\n\nExtension -> (string)\n\nOutput file extension. If excluded, this will be auto-selected from the container type.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nFrameCaptureOutputSettings -> (structure)\n\nFrame Capture Output Settings\n\nNameModifier -> (string)\n\nRequired if the output group contains more than one output. This modifier forms part of the output file name.\n\nHlsOutputSettings -> (structure)\n\nHls Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nHlsSettings -> (structure)\n\nSettings regarding the underlying stream. These settings are different for audio-only outputs.\n\nAudioOnlyHlsSettings -> (structure)\n\nAudio Only Hls Settings\n\nAudioGroupId -> (string)\n\nSpecifies the group to which the audio Rendition belongs.\n\nAudioOnlyImage -> (structure)\n\nOptional. Specifies the .jpg or .png image to use as the cover art for an audio-only output. We recommend a low bit-size file because the image increases the output audio bandwidth. The image is attached to the audio as an ID3 tag, frame type APIC, picture type 0x10, as per the “ID3 tag version 2.4.0 - Native Frames” standard.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nAudioTrackType -> (string)\n\nFour types of audio-only tracks are supported: Audio-Only Variant Stream The client can play back this audio-only stream instead of video in low-bandwidth scenarios. Represented as an EXT-X-STREAM-INF in the HLS manifest. Alternate Audio, Auto Select, Default Alternate rendition that the client should try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=YES, AUTOSELECT=YES Alternate Audio, Auto Select, Not Default Alternate rendition that the client may try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=YES Alternate Audio, not Auto Select Alternate rendition that the client will not try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=NO\n\nSegmentType -> (string)\n\nSpecifies the segment type.\n\nFmp4HlsSettings -> (structure)\n\nFmp4 Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nFrameCaptureHlsSettings -> (structure)\n\nFrame Capture Hls Settings\n\nStandardHlsSettings -> (structure)\n\nStandard Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nM3u8Settings -> (structure)\n\nSettings information for the .m3u8 container\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values.\n\nEcmPid -> (string)\n\nThis parameter is unused and deprecated.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock References (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value.\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nScte35Behavior -> (string)\n\nIf set to passthrough, passes any SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Accepts “Format Identifiers”:#formatIdentifierParameters.\n\nSegmentModifier -> (string)\n\nString concatenated to end of segment filenames.\n\nMediaPackageOutputSettings -> (structure)\n\nMedia Package Output Settings\n\nMsSmoothOutputSettings -> (structure)\n\nMs Smooth Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nMultiplexOutputSettings -> (structure)\n\nMultiplex Output Settings\n\nDestination -> (structure)\n\nDestination is a Multiplex.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRtmpOutputSettings -> (structure)\n\nRtmp Output Settings\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the tls certificate chain to a trusted Certificate Authority (CA). This will cause rtmps outputs with self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying a connection to the Flash Media server if the connection is lost.\n\nDestination -> (structure)\n\nThe RTMP endpoint excluding the stream name (eg. rtmp://host/appname). For connection to Akamai, a username and password must be supplied. URI fields accept format identifiers.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nUdpOutputSettings -> (structure)\n\nUdp Output Settings\n\nBufferMsec -> (integer)\n\nUDP output buffering in milliseconds. Larger values increase latency through the transcoder but simultaneously assist the transcoder in maintaining a constant, low-jitter UDP/RTP output while accommodating clock recovery, input switching, input disruptions, picture reordering, etc.\n\nContainerSettings -> (structure)\n\nUdp Container Settings\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nDestination -> (structure)\n\nDestination address and port number for RTP or UDP packets. Can be unicast or multicast RTP or UDP (eg. rtp://239.10.10.10:5001 or udp://10.100.100.100:5002).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFecOutputSettings -> (structure)\n\nSettings for enabling and adjusting Forward Error Correction on UDP outputs.\n\nColumnDepth -> (integer)\n\nParameter D from SMPTE 2022-1. The height of the FEC protection matrix. The number of transport stream packets per column error correction packet. Must be between 4 and 20, inclusive.\n\nIncludeFec -> (string)\n\nEnables column only or column and row based FEC\n\nRowLength -> (integer)\n\nParameter L from SMPTE 2022-1. The width of the FEC protection matrix. Must be between 1 and 20, inclusive. If only Column FEC is used, then larger values increase robustness. If Row FEC is used, then this is the number of transport stream packets per row error correction packet, and the value must be between 4 and 20, inclusive, if includeFec is columnAndRow. If includeFec is column, this value must be 1 to 20, inclusive.\n\nVideoDescriptionName -> (string)\n\nThe name of the VideoDescription used as the source for this output.\n\nTimecodeConfig -> (structure)\n\nContains settings used to acquire and adjust timecode information from inputs.\n\nSource -> (string)\n\nIdentifies the source for the timecode that will be associated with the events outputs. -Embedded (embedded): Initialize the output timecode with timecode from the the source. If no embedded timecode is detected in the source, the system falls back to using “Start at 0” (zerobased). -System Clock (systemclock): Use the UTC time. -Start at 0 (zerobased): The time of the first frame of the event will be 00:00:00:00.\n\nSyncThreshold -> (integer)\n\nThreshold in frames beyond which output timecode is resynchronized to the input timecode. Discrepancies below this threshold are permitted to avoid unnecessary discontinuities in the output timecode. No timecode sync when this is not specified.\n\nVideoDescriptions -> (list)\n\nPlaceholder documentation for __listOfVideoDescription\n\n(structure)\n\nVideo settings for this stream.\n\nCodecSettings -> (structure)\n\nVideo codec settings.\n\nFrameCaptureSettings -> (structure)\n\nFrame Capture Settings\n\nCaptureInterval -> (integer)\n\nThe frequency at which to capture frames for inclusion in the output. May be specified in either seconds or milliseconds, as specified by captureIntervalUnits.\n\nCaptureIntervalUnits -> (string)\n\nUnit for the frame capture interval.\n\nH264Settings -> (structure)\n\nH264 Settings\n\nAdaptiveQuantization -> (string)\n\nEnables or disables adaptive quantization, which is a technique MediaLive can apply to video on a frame-by-frame basis to produce more compression without losing quality. There are three types of adaptive quantization: flicker, spatial, and temporal. Set the field in one of these ways: Set to Auto. Recommended. For each type of AQ, MediaLive will determine if AQ is needed, and if so, the appropriate strength. Set a strength (a value other than Auto or Disable). This strength will apply to any of the AQ fields that you choose to enable. Set to Disabled to disable all types of adaptive quantization.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufFillPct -> (integer)\n\nPercentage of the buffer that should initially be filled (HRD buffer model).\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nEntropyEncoding -> (string)\n\nEntropy encoding mode. Use cabac (must be in Main or High profile) or cavlc.\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nFlicker AQ makes adjustments within each frame to reduce flicker or ‘pop’ on I-frames. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if flicker AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply flicker AQ using the specified strength. Disabled: MediaLive won’t apply flicker AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply flicker AQ.\n\nForceFieldPictures -> (string)\n\nThis setting applies only when scan type is “interlaced.” It controls whether coding is performed on a field basis or on a frame basis. (When the video is progressive, the coding is always performed on a frame basis.) enabled: Force MediaLive to code on a field basis, so that odd and even sets of fields are coded separately. disabled: Code the two sets of fields separately (on a field basis) or together (on a frame basis using PAFF), depending on what is most appropriate for the content.\n\nFramerateControl -> (string)\n\nThis field indicates how the output video frame rate is specified. If “specified” is selected then the output video frame rate is determined by framerateNumerator and framerateDenominator, else if “initializeFromSource” is selected then the output video frame rate will be set equal to the input video frame rate of the first input.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopBReference -> (string)\n\nDocumentation update needed\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopNumBFrames -> (integer)\n\nNumber of B-frames between reference frames.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.264 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level For VBR: Set the maximum bitrate in order to accommodate expected spikes in the complexity of the video.\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nNumRefFrames -> (integer)\n\nNumber of reference frames to use. The encoder may use more than requested if using B-frames and/or interlaced encoding.\n\nParControl -> (string)\n\nThis field indicates how the output pixel aspect ratio is specified. If “specified” is selected then the output video pixel aspect ratio is determined by parNumerator and parDenominator, else if “initializeFromSource” is selected then the output pixsel aspect ratio will be set equal to the input video pixel aspect ratio of the first input.\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.264 Profile.\n\nQualityLevel -> (string)\n\nLeave as STANDARD_QUALITY or choose a different value (which might result in additional costs to run the channel). - ENHANCED_QUALITY: Produces a slightly better video quality without an increase in the bitrate. Has an effect only when the Rate control mode is QVBR or CBR. If this channel is in a MediaLive multiplex, the value must be ENHANCED_QUALITY. - STANDARD_QUALITY: Valid for any Rate control mode.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. You can set a target quality or you can let MediaLive determine the best quality. To set a target quality, enter values in the QVBR quality level field and the Max bitrate field. Enter values that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M To let MediaLive decide, leave the QVBR quality level field empty, and in Max bitrate enter the maximum rate you want in the video. For more information, see the section called “Video - rate control mode” in the MediaLive user guide\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. VBR: Quality and bitrate vary, depending on the video complexity. Recommended instead of QVBR if you want to maintain a specific average bitrate over the duration of the channel. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection. - On: inserts I-frames when scene change is detected. - Off: does not force an I-frame when scene change is detected.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nSoftness -> (integer)\n\nSoftness. Selects quantizer matrix, larger values reduce high-frequency content in the encoded image. If not set to zero, must be greater than 15.\n\nSpatialAq -> (string)\n\nSpatial AQ makes adjustments within each frame based on spatial variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if spatial AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply spatial AQ using the specified strength. Disabled: MediaLive won’t apply spatial AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply spatial AQ.\n\nSubgopLength -> (string)\n\nIf set to fixed, use gopNumBFrames B-frames per sub-GOP. If set to dynamic, optimize the number of B-frames used for each sub-GOP to improve visual quality.\n\nSyntax -> (string)\n\nProduces a bitstream compliant with SMPTE RP-2027.\n\nTemporalAq -> (string)\n\nTemporal makes adjustments within each frame based on temporal variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if temporal AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply temporal AQ using the specified strength. Disabled: MediaLive won’t apply temporal AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply temporal AQ.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nH265Settings -> (structure)\n\nH265 Settings\n\nAdaptiveQuantization -> (string)\n\nAdaptive quantization. Allows intra-frame quantizers to vary to improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nAlternativeTransferFunction -> (string)\n\nWhether or not EML should insert an Alternative Transfer Function SEI message to support backwards compatibility with non-HDR decoders and displays.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nIf set to enabled, adjust quantization within each frame to reduce flicker or ‘pop’ on I-frames.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.265 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.265 Profile.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. Set values for the QVBR quality level field and Max bitrate field that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nTier -> (string)\n\nH.265 Tier.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nMpeg2Settings -> (structure)\n\nMpeg2 Settings\n\nAdaptiveQuantization -> (string)\n\nChoose Off to disable adaptive quantization. Or choose another value to enable the quantizer and set its strength. The strengths are: Auto, Off, Low, Medium, High. When you enable this field, MediaLive allows intra-frame quantizers to vary, which might improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates the AFD values that MediaLive will write into the video encode. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose AUTO. AUTO: MediaLive will try to preserve the input AFD value (in cases where multiple AFD values are valid). FIXED: MediaLive will use the value you specify in fixedAFD.\n\nColorMetadata -> (string)\n\nSpecifies whether to include the color space metadata. The metadata describes the color space that applies to the video (the colorSpace field). We recommend that you insert the metadata.\n\nColorSpace -> (string)\n\nChoose the type of color space conversion to apply to the output. For detailed information on setting up both the input and the output to obtain the desired color space in the output, see the section on “MediaLive Features - Video - color space” in the MediaLive User Guide. PASSTHROUGH: Keep the color space of the input content - do not convert it. AUTO:Convert all content that is SD to rec 601, and convert all content that is HD to rec 709.\n\nDisplayAspectRatio -> (string)\n\nSets the pixel aspect ratio for the encode.\n\nFilterSettings -> (structure)\n\nOptionally specify a noise reduction filter, which can improve quality of compressed content. If you do not choose a filter, no filter will be applied. TEMPORAL: This filter is useful for both source content that is noisy (when it has excessive digital artifacts) and source content that is clean. When the content is noisy, the filter cleans up the source content before the encoding phase, with these two effects: First, it improves the output video quality because the content has been cleaned up. Secondly, it decreases the bandwidth because MediaLive does not waste bits on encoding noise. When the content is reasonably clean, the filter tends to decrease the bitrate.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nComplete this field only when afdSignaling is set to FIXED. Enter the AFD value (4 bits) to write on all frames of the video encode.\n\nFramerateDenominator -> (integer)\n\ndescription”: “The framerate denominator. For example, 1001. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nFramerateNumerator -> (integer)\n\nThe framerate numerator. For example, 24000. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nGopClosedCadence -> (integer)\n\nMPEG2: default is open GOP.\n\nGopNumBFrames -> (integer)\n\nRelates to the GOP structure. The number of B-frames between reference frames. If you do not know what a B-frame is, use the default.\n\nGopSize -> (double)\n\nRelates to the GOP structure. The GOP size (keyframe interval) in the units specified in gopSizeUnits. If you do not know what GOP is, use the default. If gopSizeUnits is frames, then the gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, the gopSize must be greater than 0, but does not need to be an integer.\n\nGopSizeUnits -> (string)\n\nRelates to the GOP structure. Specifies whether the gopSize is specified in frames or seconds. If you do not plan to change the default gopSize, leave the default. If you specify SECONDS, MediaLive will internally convert the gop size to a frame count.\n\nScanType -> (string)\n\nSet the scan type of the output to PROGRESSIVE or INTERLACED (top field first).\n\nSubgopLength -> (string)\n\nRelates to the GOP structure. If you do not know what GOP is, use the default. FIXED: Set the number of B-frames in each sub-GOP to the value in gopNumBFrames. DYNAMIC: Let MediaLive optimize the number of B-frames in each sub-GOP, to improve visual quality.\n\nTimecodeInsertion -> (string)\n\nDetermines how MediaLive inserts timecodes in the output video. For detailed information about setting up the input and the output for a timecode, see the section on “MediaLive Features - Timecode configuration” in the MediaLive User Guide. DISABLED: do not include timecodes. GOP_TIMECODE: Include timecode metadata in the GOP header.\n\nHeight -> (integer)\n\nOutput video height, in pixels. Must be an even number. For most codecs, you can leave this field and width blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nName -> (string)\n\nThe name of this VideoDescription. Outputs will use this name to uniquely identify this Description. Description names should be unique within this Live Event.\n\nRespondToAfd -> (string)\n\nIndicates how MediaLive will respond to the AFD values that might be in the input video. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose PASSTHROUGH. RESPOND: MediaLive clips the input video using a formula that uses the AFD values (configured in afdSignaling ), the input display aspect ratio, and the output display aspect ratio. MediaLive also includes the AFD values in the output, unless the codec for this encode is FRAME_CAPTURE. PASSTHROUGH: MediaLive ignores the AFD values and does not clip the video. But MediaLive does include the values in the output. NONE: MediaLive does not clip the input video and does not include the AFD values in the output\n\nScalingBehavior -> (string)\n\nSTRETCH_TO_OUTPUT configures the output position to stretch the video to the specified output resolution (height and width). This option will override any position value. DEFAULT may insert black boxes (pillar boxes or letter boxes) around the video to provide the specified output resolution.\n\nSharpness -> (integer)\n\nChanges the strength of the anti-alias filter used for scaling. 0 is the softest setting, 100 is the sharpest. A setting of 50 is recommended for most content.\n\nWidth -> (integer)\n\nOutput video width, in pixels. Must be an even number. For most codecs, you can leave this field and height blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nId -> (string)\n\nThe unique id of the channel.\n\nInputAttachments -> (list)\n\nList of input attachments for channel.\n\n(structure)\n\nPlaceholder documentation for InputAttachment\n\nAutomaticInputFailoverSettings -> (structure)\n\nUser-specified settings for defining what the conditions are for declaring the input unhealthy and failing over to a different input.\n\nErrorClearTimeMsec -> (integer)\n\nThis clear time defines the requirement a recovered input must meet to be considered healthy. The input must have no failover conditions for this length of time. Enter a time in milliseconds. This value is particularly important if the input_preference for the failover pair is set to PRIMARY_INPUT_PREFERRED, because after this time, MediaLive will switch back to the primary input.\n\nFailoverConditions -> (list)\n\nA list of failover conditions. If any of these conditions occur, MediaLive will perform a failover to the other input.\n\n(structure)\n\nFailover Condition settings. There can be multiple failover conditions inside AutomaticInputFailoverSettings.\n\nFailoverConditionSettings -> (structure)\n\nFailover condition type-specific settings.\n\nAudioSilenceSettings -> (structure)\n\nMediaLive will perform a failover if the specified audio selector is silent for the specified period.\n\nAudioSelectorName -> (string)\n\nThe name of the audio selector in the input that MediaLive should monitor to detect silence. Select your most important rendition. If you didn’t create an audio selector in this input, leave blank.\n\nAudioSilenceThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be silent before automatic input failover occurs. Silence is defined as audio loss or audio quieter than -50 dBFS.\n\nInputLossSettings -> (structure)\n\nMediaLive will perform a failover if content is not detected in this input for the specified period.\n\nInputLossThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that no input is detected. After that time, an input failover will occur.\n\nVideoBlackSettings -> (structure)\n\nMediaLive will perform a failover if content is considered black for the specified period.\n\nBlackDetectThreshold -> (double)\n\nA value used in calculating the threshold below which MediaLive considers a pixel to be ‘black’. For the input to be considered black, every pixel in a frame must be below this threshold. The threshold is calculated as a percentage (expressed as a decimal) of white. Therefore .1 means 10% white (or 90% black). Note how the formula works for any color depth. For example, if you set this field to 0.1 in 10-bit color depth: (1023*0.1=102.3), which means a pixel value of 102 or less is ‘black’. If you set this field to .1 in an 8-bit color depth: (255*0.1=25.5), which means a pixel value of 25 or less is ‘black’. The range is 0.0 to 1.0, with any number of decimal places.\n\nVideoBlackThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be black before automatic input failover occurs.\n\nInputPreference -> (string)\n\nInput preference when deciding which input to make active when a previously failed input has recovered.\n\nSecondaryInputId -> (string)\n\nThe input ID of the secondary input in the automatic input failover pair.\n\nInputAttachmentName -> (string)\n\nUser-specified name for the attachment. This is required if the user wants to use this input in an input switch action.\n\nInputId -> (string)\n\nThe ID of the input\n\nInputSettings -> (structure)\n\nSettings of an input (caption selector, etc.)\n\nAudioSelectors -> (list)\n\nUsed to select the audio stream to decode for inputs that have multiple available.\n\n(structure)\n\nAudio Selector\n\nName -> (string)\n\nThe name of this AudioSelector. AudioDescriptions will use this name to uniquely identify this Selector. Selector names should be unique per input.\n\nSelectorSettings -> (structure)\n\nThe audio selector settings.\n\nAudioHlsRenditionSelection -> (structure)\n\nAudio Hls Rendition Selection\n\nGroupId -> (string)\n\nSpecifies the GROUP-ID in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nName -> (string)\n\nSpecifies the NAME in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nAudioLanguageSelection -> (structure)\n\nAudio Language Selection\n\nLanguageCode -> (string)\n\nSelects a specific three-letter language code from within an audio source.\n\nLanguageSelectionPolicy -> (string)\n\nWhen set to “strict”, the transport stream demux strictly identifies audio streams by their language descriptor. If a PMT update occurs such that an audio stream matching the initially selected language is no longer present then mute will be encoded until the language returns. If “loose”, then on a PMT update the demux will choose another audio stream in the program with the same stream type if it can’t find one with the same language.\n\nAudioPidSelection -> (structure)\n\nAudio Pid Selection\n\nPid -> (integer)\n\nSelects a specific PID from within a source.\n\nAudioTrackSelection -> (structure)\n\nAudio Track Selection\n\nTracks -> (list)\n\nSelects one or more unique audio tracks from within a source.\n\n(structure)\n\nAudio Track\n\nTrack -> (integer)\n\n1-based integer value that maps to a specific audio track\n\nCaptionSelectors -> (list)\n\nUsed to select the caption input to use for inputs that have multiple available.\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nLanguageCode -> (string)\n\nWhen specified this field indicates the three letter language code of the caption track to extract from the source.\n\nName -> (string)\n\nName identifier for a caption selector. This name is used to associate this caption selector with one or more caption descriptions. Names must be unique within an event.\n\nSelectorSettings -> (structure)\n\nCaption selector settings.\n\nAncillarySourceSettings -> (structure)\n\nAncillary Source Settings\n\nSourceAncillaryChannelNumber -> (integer)\n\nSpecifies the number (1 to 4) of the captions channel you want to extract from the ancillary captions. If you plan to convert the ancillary captions to another format, complete this field. If you plan to choose Embedded as the captions destination in the output (to pass through all the channels in the ancillary captions), leave this field blank because MediaLive ignores the field.\n\nAribSourceSettings -> (structure)\n\nArib Source Settings\n\nDvbSubSourceSettings -> (structure)\n\nDvb Sub Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nWhen using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through, regardless of selectors.\n\nEmbeddedSourceSettings -> (structure)\n\nEmbedded Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nScte20Detection -> (string)\n\nSet to “auto” to handle streams with intermittent and/or non-aligned SCTE-20 and Embedded captions.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nSource608TrackNumber -> (integer)\n\nThis field is unused and deprecated.\n\nScte20SourceSettings -> (structure)\n\nScte20 Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nScte27SourceSettings -> (structure)\n\nScte27 Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nThe pid field is used in conjunction with the caption selector languageCode field as follows: - Specify PID and Language: Extracts captions from that PID; the language is “informational”. - Specify PID and omit Language: Extracts the specified PID. - Omit PID and specify Language: Extracts the specified language, whichever PID that happens to be. - Omit PID and omit Language: Valid only if source is DVB-Sub that is being passed through; all languages will be passed through.\n\nTeletextSourceSettings -> (structure)\n\nTeletext Source Settings\n\nOutputRectangle -> (structure)\n\nOptionally defines a region where TTML style captions will be displayed\n\nHeight -> (double)\n\nSee the description in leftOffset. For height, specify the entire height of the rectangle as a percentage of the underlying frame height. For example, “80” means the rectangle height is 80% of the underlying frame height. The topOffset and rectangleHeight must add up to 100% or less. This field corresponds to tts:extent - Y in the TTML standard.\n\nLeftOffset -> (double)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. (Make sure to leave the default if you don’t have either of these formats in the output.) You can define a display rectangle for the captions that is smaller than the underlying video frame. You define the rectangle by specifying the position of the left edge, top edge, bottom edge, and right edge of the rectangle, all within the underlying video frame. The units for the measurements are percentages. If you specify a value for one of these fields, you must specify a value for all of them. For leftOffset, specify the position of the left edge of the rectangle, as a percentage of the underlying frame width, and relative to the left edge of the frame. For example, “10” means the measurement is 10% of the underlying frame width. The rectangle left edge starts at that position from the left edge of the frame. This field corresponds to tts:origin - X in the TTML standard.\n\nTopOffset -> (double)\n\nSee the description in leftOffset. For topOffset, specify the position of the top edge of the rectangle, as a percentage of the underlying frame height, and relative to the top edge of the frame. For example, “10” means the measurement is 10% of the underlying frame height. The rectangle top edge starts at that position from the top edge of the frame. This field corresponds to tts:origin - Y in the TTML standard.\n\nWidth -> (double)\n\nSee the description in leftOffset. For width, specify the entire width of the rectangle as a percentage of the underlying frame width. For example, “80” means the rectangle width is 80% of the underlying frame width. The leftOffset and rectangleWidth must add up to 100% or less. This field corresponds to tts:extent - X in the TTML standard.\n\nPageNumber -> (string)\n\nSpecifies the teletext page number within the data stream from which to extract captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should be specified as a hexadecimal string with no “0x” prefix.\n\nDeblockFilter -> (string)\n\nEnable or disable the deblock filter when filtering.\n\nDenoiseFilter -> (string)\n\nEnable or disable the denoise filter when filtering.\n\nFilterStrength -> (integer)\n\nAdjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).\n\nInputFilter -> (string)\n\nTurns on the filter for this input. MPEG-2 inputs have the deblocking filter enabled by default. 1) auto - filtering will be applied depending on input type/quality 2) disabled - no filtering will be applied to the input 3) forced - filtering will be applied regardless of input type\n\nNetworkInputSettings -> (structure)\n\nInput settings.\n\nHlsInputSettings -> (structure)\n\nSpecifies HLS input settings when the uri is for a HLS manifest.\n\nBandwidth -> (integer)\n\nWhen specified the HLS stream with the m3u8 BANDWIDTH that most closely matches this value will be chosen, otherwise the highest bandwidth stream in the m3u8 will be chosen. The bitrate is specified in bits per second, as in an HLS manifest.\n\nBufferSegments -> (integer)\n\nWhen specified, reading of the HLS input will begin this many buffer segments from the end (most recently written segment). When not specified, the HLS input will begin with the first segment specified in the m3u8.\n\nRetries -> (integer)\n\nThe number of consecutive times that attempts to read a manifest or segment must fail before the input is considered unavailable.\n\nRetryInterval -> (integer)\n\nThe number of seconds between retries when an attempt to read a manifest or segment fails.\n\nScte35Source -> (string)\n\nIdentifies the source for the SCTE-35 messages that MediaLive will ingest. Messages can be ingested from the content segments (in the stream) or from tags in the playlist (the HLS manifest). MediaLive ignores SCTE-35 information in the source that is not selected.\n\nServerValidation -> (string)\n\nCheck HTTPS server certificates. When set to checkCryptographyOnly, cryptography in the certificate will be checked, but not the server’s name. Certain subdomains (notably S3 buckets that use dots in the bucket name) do not strictly match the corresponding certificate’s wildcard pattern and would otherwise cause the event to error. This setting is ignored for protocols that do not use https.\n\nSmpte2038DataPreference -> (string)\n\nSpecifies whether to extract applicable ancillary data from a SMPTE-2038 source in this input. Applicable data types are captions, timecode, AFD, and SCTE-104 messages. - PREFER: Extract from SMPTE-2038 if present in this input, otherwise extract from another source (if any). - IGNORE: Never extract any ancillary data from SMPTE-2038.\n\nSourceEndBehavior -> (string)\n\nLoop input if it is a file. This allows a file input to be streamed indefinitely.\n\nVideoSelector -> (structure)\n\nInforms which video elementary stream to decode for input types that have multiple available.\n\nColorSpace -> (string)\n\nSpecifies the color space of an input. This setting works in tandem with colorSpaceUsage and a video description’s colorSpaceSettingsChoice to determine if any conversion will be performed.\n\nColorSpaceSettings -> (structure)\n\nColor space settings\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nColorSpaceUsage -> (string)\n\nApplies only if colorSpace is a value other than follow. This field controls how the value in the colorSpace field will be used. fallback means that when the input does include color space data, that data will be used, but when the input has no color space data, the value in colorSpace will be used. Choose fallback if your input is sometimes missing color space data, but when it does have color space data, that data is correct. force means to always use the value in colorSpace. Choose force if your input usually has no color space data or might have unreliable color space data.\n\nSelectorSettings -> (structure)\n\nThe video selector settings.\n\nVideoSelectorPid -> (structure)\n\nVideo Selector Pid\n\nPid -> (integer)\n\nSelects a specific PID from within a video source.\n\nVideoSelectorProgramId -> (structure)\n\nVideo Selector Program Id\n\nProgramId -> (integer)\n\nSelects a specific program from within a multi-program transport stream. If the program doesn’t exist, the first program within the transport stream will be selected by default.\n\nInputSpecification -> (structure)\n\nSpecification of network and file inputs for this channel\n\nCodec -> (string)\n\nInput codec\n\nMaximumBitrate -> (string)\n\nMaximum input bitrate, categorized coarsely\n\nResolution -> (string)\n\nInput resolution, categorized coarsely\n\nLogLevel -> (string)\n\nThe log level being written to CloudWatch Logs.\n\nName -> (string)\n\nThe name of the channel. (user-mutable)\n\nPipelineDetails -> (list)\n\nRuntime details for the pipelines of a running channel.\n\n(structure)\n\nRuntime details of a pipeline when a channel is running.\n\nActiveInputAttachmentName -> (string)\n\nThe name of the active input attachment currently being ingested by this pipeline.\n\nActiveInputSwitchActionName -> (string)\n\nThe name of the input switch schedule action that occurred most recently and that resulted in the switch to the current input attachment for this pipeline.\n\nActiveMotionGraphicsActionName -> (string)\n\nThe name of the motion graphics activate action that occurred most recently and that resulted in the current graphics URI for this pipeline.\n\nActiveMotionGraphicsUri -> (string)\n\nThe current URI being used for HTML5 motion graphics for this pipeline.\n\nPipelineId -> (string)\n\nPipeline ID\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role assumed when running the Channel.\n\nState -> (string)\n\nPlaceholder documentation for ChannelState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nVpc -> (structure)\n\nSettings for VPC output\n\nAvailabilityZones -> (list)\n\nThe Availability Zones where the vpc subnets are located. The first Availability Zone applies to the first subnet in the list of subnets. The second Availability Zone applies to the second subnet.\n\n(string)\n\nPlaceholder documentation for __string\n\nNetworkInterfaceIds -> (list)\n\nA list of Elastic Network Interfaces created by MediaLive in the customer’s VPC\n\n(string)\n\nPlaceholder documentation for __string\n\nSecurityGroupIds -> (list)\n\nA list of up EC2 VPC security group IDs attached to the Output VPC network interfaces.\n\n(string)\n\nPlaceholder documentation for __string\n\nSubnetIds -> (list)\n\nA list of VPC subnet IDs from the same VPC. If STANDARD channel, subnet IDs must be mapped to two unique availability zones (AZ).\n\n(string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "stop-multiplex",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/stop-multiplex.html",
      "command_description": "Description\n\nStops a running multiplex. If the multiplex isn’t running, this action has no effect.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  stop-multiplex\n--multiplex-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--multiplex-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--multiplex-id (string) The ID of the multiplex.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe unique arn of the multiplex.\n\nAvailabilityZones -> (list)\n\nA list of availability zones for the multiplex.\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the multiplex output destinations.\n\n(structure)\n\nMultiplex output destination settings\n\nMediaConnectSettings -> (structure)\n\nMultiplex MediaConnect output destination settings.\n\nEntitlementArn -> (string)\n\nThe MediaConnect entitlement ARN available as a Flow source.\n\nId -> (string)\n\nThe unique id of the multiplex.\n\nMultiplexSettings -> (structure)\n\nConfiguration for a multiplex event.\n\nMaximumVideoBufferDelayMilliseconds -> (integer)\n\nMaximum video buffer delay in milliseconds.\n\nTransportStreamBitrate -> (integer)\n\nTransport stream bit rate.\n\nTransportStreamId -> (integer)\n\nTransport stream ID.\n\nTransportStreamReservedBitrate -> (integer)\n\nTransport stream reserved bit rate.\n\nName -> (string)\n\nThe name of the multiplex.\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nProgramCount -> (integer)\n\nThe number of programs in the multiplex.\n\nState -> (string)\n\nThe current state of the multiplex.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "transfer-input-device",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/transfer-input-device.html",
      "command_description": "Description\n\nStart an input device transfer to another AWS account. After you make the request, the other account must accept or reject the transfer.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  transfer-input-device\n--input-device-id <value>\n[--target-customer-id <value>]\n[--target-region <value>]\n[--transfer-message <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-device-id <value>",
        "[--target-customer-id <value>]",
        "[--target-region <value>]",
        "[--transfer-message <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-device-id (string) The unique ID of this input device. For example, hd-123456789abcdef.\n\n--target-customer-id (string) The AWS account ID (12 digits) for the recipient of the device transfer.\n\n--target-region (string) The target AWS region to transfer the device.\n\n--transfer-message (string) An optional message for the recipient. Maximum 280 characters.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "update-channel",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/update-channel.html",
      "command_description": "Description\n\nUpdates a channel.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-channel\n[--cdi-input-specification <value>]\n--channel-id <value>\n[--destinations <value>]\n[--encoder-settings <value>]\n[--input-attachments <value>]\n[--input-specification <value>]\n[--log-level <value>]\n[--name <value>]\n[--role-arn <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cdi-input-specification <value>]",
        "--channel-id <value>",
        "[--destinations <value>]",
        "[--encoder-settings <value>]",
        "[--input-attachments <value>]",
        "[--input-specification <value>]",
        "[--log-level <value>]",
        "[--name <value>]",
        "[--role-arn <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cdi-input-specification (structure) Specification of CDI inputs for this channelResolution -> (string)\n\nMaximum CDI input resolution\n\nShorthand Syntax:\n\nResolution=string\n\n\nJSON Syntax:\n\n{\n  \"Resolution\": \"SD\"|\"HD\"|\"FHD\"|\"UHD\"\n}\n\n\n--channel-id (string) channel ID\n\n--destinations (list) A list of output destinations for this channel.(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nShorthand Syntax:\n\nId=string,MediaPackageSettings=[{ChannelId=string},{ChannelId=string}],MultiplexSettings={MultiplexId=string,ProgramName=string},Settings=[{PasswordParam=string,StreamName=string,Url=string,Username=string},{PasswordParam=string,StreamName=string,Url=string,Username=string}] ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Id\": \"string\",\n    \"MediaPackageSettings\": [\n      {\n        \"ChannelId\": \"string\"\n      }\n      ...\n    ],\n    \"MultiplexSettings\": {\n      \"MultiplexId\": \"string\",\n      \"ProgramName\": \"string\"\n    },\n    \"Settings\": [\n      {\n        \"PasswordParam\": \"string\",\n        \"StreamName\": \"string\",\n        \"Url\": \"string\",\n        \"Username\": \"string\"\n      }\n      ...\n    ]\n  }\n  ...\n]\n\n\n--encoder-settings (structure) The encoder settings for this channel.AudioDescriptions -> (list)\n\nPlaceholder documentation for __listOfAudioDescription\n\n(structure)\n\nAudio Description\n\nAudioNormalizationSettings -> (structure)\n\nAdvanced audio normalization settings.\n\nAlgorithm -> (string)\n\nAudio normalization algorithm to use. itu17701 conforms to the CALM Act specification, itu17702 conforms to the EBU R-128 specification.\n\nAlgorithmControl -> (string)\n\nWhen set to correctAudio the output audio is corrected using the chosen algorithm. If set to measureOnly, the audio will be measured but not adjusted.\n\nTargetLkfs -> (double)\n\nTarget LKFS(loudness) to adjust volume to. If no value is entered, a default value will be used according to the chosen algorithm. The CALM Act (1770-1) recommends a target of -24 LKFS. The EBU R-128 specification (1770-2) recommends a target of -23 LKFS.\n\nAudioSelectorName -> (string)\n\nThe name of the AudioSelector used as the source for this AudioDescription.\n\nAudioType -> (string)\n\nApplies only if audioTypeControl is useConfigured. The values for audioType are defined in ISO-IEC 13818-1.\n\nAudioTypeControl -> (string)\n\nDetermines how audio type is determined. followInput: If the input contains an ISO 639 audioType, then that value is passed through to the output. If the input contains no ISO 639 audioType, the value in Audio Type is included in the output. useConfigured: The value in Audio Type is included in the output. Note that this field and audioType are both ignored if inputType is broadcasterMixedAd.\n\nAudioWatermarkingSettings -> (structure)\n\nSettings to configure one or more solutions that insert audio watermarks in the audio encode\n\nNielsenWatermarksSettings -> (structure)\n\nSettings to configure Nielsen Watermarks in the audio encode\n\nNielsenCbetSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen CBET\n\nCbetCheckDigitString -> (string)\n\nEnter the CBET check digits to use in the watermark.\n\nCbetStepaside -> (string)\n\nDetermines the method of CBET insertion mode when prior encoding is detected on the same layer.\n\nCsid -> (string)\n\nEnter the CBET Source ID (CSID) to use in the watermark\n\nNielsenDistributionType -> (string)\n\nChoose the distribution types that you want to assign to the watermarks: - PROGRAM_CONTENT - FINAL_DISTRIBUTOR\n\nNielsenNaesIiNwSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen NAES II (N2) and Nielsen NAES VI (NW).\n\nCheckDigitString -> (string)\n\nEnter the check digit string for the watermark\n\nSid -> (double)\n\nEnter the Nielsen Source ID (SID) to include in the watermark\n\nCodecSettings -> (structure)\n\nAudio codec settings.\n\nAacSettings -> (structure)\n\nAac Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid values depend on rate control mode and profile.\n\nCodingMode -> (string)\n\nMono, Stereo, or 5.1 channel layout. Valid values depend on rate control mode and profile. The adReceiverMix setting receives a stereo description plus control track and emits a mono AAC encode of the description track, with control data emitted in the PES header as per ETSI TS 101 154 Annex E.\n\nInputType -> (string)\n\nSet to “broadcasterMixedAd” when input contains pre-mixed main audio + AD (narration) as a stereo pair. The Audio Type field (audioType) will be set to 3, which signals to downstream systems that this stream contains “broadcaster mixed AD”. Note that the input received by the encoder must contain pre-mixed audio; the encoder does not perform the mixing. The values in audioTypeControl and audioType (in AudioDescription) are ignored when set to broadcasterMixedAd. Leave set to “normal” when input does not contain pre-mixed audio + AD.\n\nProfile -> (string)\n\nAAC Profile.\n\nRateControlMode -> (string)\n\nRate Control Mode.\n\nRawFormat -> (string)\n\nSets LATM / LOAS AAC output for raw containers.\n\nSampleRate -> (double)\n\nSample rate in Hz. Valid values depend on rate control mode and profile.\n\nSpec -> (string)\n\nUse MPEG-2 AAC audio instead of MPEG-4 AAC audio for raw or MPEG-2 Transport Stream containers.\n\nVbrQuality -> (string)\n\nVBR Quality Level - Only used if rateControlMode is VBR.\n\nAc3Settings -> (structure)\n\nAc3 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted AC-3 stream. See ATSC A/52-2012 for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital coding mode. Determines number of channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If excluded and input audio is Dolby Digital, dialnorm will be passed through.\n\nDrcProfile -> (string)\n\nIf set to filmStandard, adds dynamic range compression signaling to the output bitstream as defined in the Dolby Digital specification.\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid in codingMode32Lfe mode.\n\nMetadataControl -> (string)\n\nWhen set to “followInput”, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nEac3Settings -> (structure)\n\nEac3 Settings\n\nAttenuationControl -> (string)\n\nWhen set to attenuate3Db, applies a 3 dB attenuation to the surround channels. Only used for 3/2 coding mode.\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted E-AC-3 stream. See ATSC A/52-2012 (Annex E) for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital Plus coding mode. Determines number of channels.\n\nDcFilter -> (string)\n\nWhen set to enabled, activates a DC highpass filter for all input channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If blank and input audio is Dolby Digital Plus, dialnorm will be passed through.\n\nDrcLine -> (string)\n\nSets the Dolby dynamic range compression profile.\n\nDrcRf -> (string)\n\nSets the profile for heavy Dolby dynamic range compression, ensures that the instantaneous signal peaks do not exceed specified levels.\n\nLfeControl -> (string)\n\nWhen encoding 3/2 audio, setting to lfe enables the LFE channel\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid with codingMode32 coding mode.\n\nLoRoCenterMixLevel -> (double)\n\nLeft only/Right only center mix level. Only used for 3/2 coding mode.\n\nLoRoSurroundMixLevel -> (double)\n\nLeft only/Right only surround mix level. Only used for 3/2 coding mode.\n\nLtRtCenterMixLevel -> (double)\n\nLeft total/Right total center mix level. Only used for 3/2 coding mode.\n\nLtRtSurroundMixLevel -> (double)\n\nLeft total/Right total surround mix level. Only used for 3/2 coding mode.\n\nMetadataControl -> (string)\n\nWhen set to followInput, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nPassthroughControl -> (string)\n\nWhen set to whenPossible, input DD+ audio will be passed through if it is present on the input. This detection is dynamic over the life of the transcode. Inputs that alternate between DD+ and non-DD+ content will have a consistent DD+ output as the system alternates between passthrough and encoding.\n\nPhaseControl -> (string)\n\nWhen set to shift90Degrees, applies a 90-degree phase shift to the surround channels. Only used for 3/2 coding mode.\n\nStereoDownmix -> (string)\n\nStereo downmix preference. Only used for 3/2 coding mode.\n\nSurroundExMode -> (string)\n\nWhen encoding 3/2 audio, sets whether an extra center back surround channel is matrix encoded into the left and right surround channels.\n\nSurroundMode -> (string)\n\nWhen encoding 2/0 audio, sets whether Dolby Surround is matrix encoded into the two channels.\n\nMp2Settings -> (structure)\n\nMp2 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second.\n\nCodingMode -> (string)\n\nThe MPEG2 Audio coding mode. Valid values are codingMode10 (for mono) or codingMode20 (for stereo).\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nPassThroughSettings -> (structure)\n\nPass Through Settings\n\nWavSettings -> (structure)\n\nWav Settings\n\nBitDepth -> (double)\n\nBits per sample.\n\nCodingMode -> (string)\n\nThe audio coding mode for the WAV audio. The mode determines the number of channels in the audio.\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nLanguageCode -> (string)\n\nRFC 5646 language code representing the language of the audio output track. Only used if languageControlMode is useConfigured, or there is no ISO 639 language code specified in the input.\n\nLanguageCodeControl -> (string)\n\nChoosing followInput will cause the ISO 639 language code of the output to follow the ISO 639 language code of the input. The languageCode will be used when useConfigured is set, or when followInput is selected but there is no ISO 639 language code specified by the input.\n\nName -> (string)\n\nThe name of this AudioDescription. Outputs will use this name to uniquely identify this AudioDescription. Description names should be unique within this Live Event.\n\nRemixSettings -> (structure)\n\nSettings that control how input audio channels are remixed into the output audio channels.\n\nChannelMappings -> (list)\n\nMapping of input channels to output channels, with appropriate gain adjustments.\n\n(structure)\n\nAudio Channel Mapping\n\nInputChannelLevels -> (list)\n\nIndices and gain values for each input channel that should be remixed into this output channel.\n\n(structure)\n\nInput Channel Level\n\nGain -> (integer)\n\nRemixing value. Units are in dB and acceptable values are within the range from -60 (mute) and 6 dB.\n\nInputChannel -> (integer)\n\nThe index of the input channel used as a source.\n\nOutputChannel -> (integer)\n\nThe index of the output channel being produced.\n\nChannelsIn -> (integer)\n\nNumber of input channels to be used.\n\nChannelsOut -> (integer)\n\nNumber of output channels to be produced. Valid values: 1, 2, 4, 6, 8\n\nStreamName -> (string)\n\nUsed for MS Smooth and Apple HLS outputs. Indicates the name displayed by the player (eg. English, or Director Commentary).\n\nAvailBlanking -> (structure)\n\nSettings for ad avail blanking.\n\nAvailBlankingImage -> (structure)\n\nBlanking image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when insertion metadata is added.\n\nAvailConfiguration -> (structure)\n\nEvent-wide configuration settings for ad avail insertion.\n\nAvailSettings -> (structure)\n\nAd avail settings.\n\nScte35SpliceInsert -> (structure)\n\nScte35 Splice Insert\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nScte35TimeSignalApos -> (structure)\n\nScte35 Time Signal Apos\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nBlackoutSlate -> (structure)\n\nSettings for blackout slate.\n\nBlackoutSlateImage -> (structure)\n\nBlackout slate image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkEndBlackout -> (string)\n\nSetting to enabled causes the encoder to blackout the video, audio, and captions, and raise the “Network Blackout Image” slate when an SCTE104/35 Network End Segmentation Descriptor is encountered. The blackout will be lifted when the Network Start Segmentation Descriptor is encountered. The Network End and Network Start descriptors must contain a network ID that matches the value entered in “Network ID”.\n\nNetworkEndBlackoutImage -> (structure)\n\nPath to local file to use as Network End Blackout image. Image will be scaled to fill the entire output raster.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkId -> (string)\n\nProvides Network ID that matches EIDR ID format (e.g., “10.XXXX/XXXX-XXXX-XXXX-XXXX-XXXX-C”).\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when indicated by program metadata.\n\nCaptionDescriptions -> (list)\n\nSettings for caption decriptions\n\n(structure)\n\nCaption Description\n\nCaptionSelectorName -> (string)\n\nSpecifies which input caption selector to use as a caption source when generating output captions. This field should match a captionSelector name.\n\nDestinationSettings -> (structure)\n\nAdditional settings for captions destination that depend on the destination type.\n\nAribDestinationSettings -> (structure)\n\nArib Destination Settings\n\nBurnInDestinationSettings -> (structure)\n\nBurn In Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to ‘auto’ fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. All burn-in and DVB-Sub font settings must match.\n\nDvbSubDestinationSettings -> (structure)\n\nDvb Sub Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. This option is not valid for source captions that are STL or 608/embedded. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to auto fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nEbuTtDDestinationSettings -> (structure)\n\nEbu Tt DDestination Settings\n\nCopyrightHolder -> (string)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. Complete this field if you want to include the name of the copyright holder in the copyright metadata tag in the TTML\n\nFillLineGap -> (string)\n\nSpecifies how to handle the gap between the lines (in multi-line captions). - enabled: Fill with the captions background color (as specified in the input captions). - disabled: Leave the gap unfilled.\n\nFontFamily -> (string)\n\nSpecifies the font family to include in the font data attached to the EBU-TT captions. Valid only if styleControl is set to include. If you leave this field empty, the font family is set to “monospaced”. (If styleControl is set to exclude, the font family is always set to “monospaced”.) You specify only the font family. All other style information (color, bold, position and so on) is copied from the input captions. The size is always set to 100% to allow the downstream player to choose the size. - Enter a list of font families, as a comma-separated list of font names, in order of preference. The name can be a font family (such as “Arial”), or a generic font family (such as “serif”), or “default” (to let the downstream player choose the font). - Leave blank to set the family to “monospace”.\n\nStyleControl -> (string)\n\nSpecifies the style information (font color, font position, and so on) to include in the font data that is attached to the EBU-TT captions. - include: Take the style information (font color, font position, and so on) from the source captions and include that information in the font data attached to the EBU-TT captions. This option is valid only if the source captions are Embedded or Teletext. - exclude: In the font data attached to the EBU-TT captions, set the font family to “monospaced”. Do not include any other style information.\n\nEmbeddedDestinationSettings -> (structure)\n\nEmbedded Destination Settings\n\nEmbeddedPlusScte20DestinationSettings -> (structure)\n\nEmbedded Plus Scte20 Destination Settings\n\nRtmpCaptionInfoDestinationSettings -> (structure)\n\nRtmp Caption Info Destination Settings\n\nScte20PlusEmbeddedDestinationSettings -> (structure)\n\nScte20 Plus Embedded Destination Settings\n\nScte27DestinationSettings -> (structure)\n\nScte27 Destination Settings\n\nSmpteTtDestinationSettings -> (structure)\n\nSmpte Tt Destination Settings\n\nTeletextDestinationSettings -> (structure)\n\nTeletext Destination Settings\n\nTtmlDestinationSettings -> (structure)\n\nTtml Destination Settings\n\nStyleControl -> (string)\n\nWhen set to passthrough, passes through style and position information from a TTML-like input source (TTML, SMPTE-TT, CFF-TT) to the CFF-TT output or TTML output.\n\nWebvttDestinationSettings -> (structure)\n\nWebvtt Destination Settings\n\nStyleControl -> (string)\n\nControls whether the color and position of the source captions is passed through to the WebVTT output captions. PASSTHROUGH - Valid only if the source captions are EMBEDDED or TELETEXT. NO_STYLE_DATA - Don’t pass through the style. The output captions will not contain any font styling information.\n\nLanguageCode -> (string)\n\nISO 639-2 three-digit code: http://www.loc.gov/standards/iso639-2/\n\nLanguageDescription -> (string)\n\nHuman readable information to indicate captions available for players (eg. English, or Spanish).\n\nName -> (string)\n\nName of the caption description. Used to associate a caption description with an output. Names must be unique within an event.\n\nFeatureActivations -> (structure)\n\nFeature Activations\n\nInputPrepareScheduleActions -> (string)\n\nEnables the Input Prepare feature. You can create Input Prepare actions in the schedule only if this feature is enabled. If you disable the feature on an existing schedule, make sure that you first delete all input prepare actions from the schedule.\n\nGlobalConfiguration -> (structure)\n\nConfiguration settings that apply to the event as a whole.\n\nInitialAudioGain -> (integer)\n\nValue to set the initial audio gain for the Live Event.\n\nInputEndAction -> (string)\n\nIndicates the action to take when the current input completes (e.g. end-of-file). When switchAndLoopInputs is configured the encoder will restart at the beginning of the first input. When “none” is configured the encoder will transcode either black, a solid color, or a user specified slate images per the “Input Loss Behavior” configuration until the next input switch occurs (which is controlled through the Channel Schedule API).\n\nInputLossBehavior -> (structure)\n\nSettings for system actions when input is lost.\n\nBlackFrameMsec -> (integer)\n\nDocumentation update needed\n\nInputLossImageColor -> (string)\n\nWhen input loss image type is “color” this field specifies the color to use. Value: 6 hex characters representing the values of RGB.\n\nInputLossImageSlate -> (structure)\n\nWhen input loss image type is “slate” these fields specify the parameters for accessing the slate.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nInputLossImageType -> (string)\n\nIndicates whether to substitute a solid color or a slate into the output after input loss exceeds blackFrameMsec.\n\nRepeatFrameMsec -> (integer)\n\nDocumentation update needed\n\nOutputLockingMode -> (string)\n\nIndicates how MediaLive pipelines are synchronized. PIPELINE_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the other. EPOCH_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the Unix epoch.\n\nOutputTimingSource -> (string)\n\nIndicates whether the rate of frames emitted by the Live encoder should be paced by its system clock (which optionally may be locked to another source via NTP) or should be locked to the clock of the source that is providing the input stream.\n\nSupportLowFramerateInputs -> (string)\n\nAdjusts video input buffer for streams with very low video framerates. This is commonly set to enabled for music channels with less than one video frame per second.\n\nMotionGraphicsConfiguration -> (structure)\n\nSettings for motion graphics.\n\nMotionGraphicsInsertion -> (string)\n\nMotion Graphics Insertion\n\nMotionGraphicsSettings -> (structure)\n\nMotion Graphics Settings\n\nHtmlMotionGraphicsSettings -> (structure)\n\nHtml Motion Graphics Settings\n\nNielsenConfiguration -> (structure)\n\nNielsen configuration settings.\n\nDistributorId -> (string)\n\nEnter the Distributor ID assigned to your organization by Nielsen.\n\nNielsenPcmToId3Tagging -> (string)\n\nEnables Nielsen PCM to ID3 tagging\n\nOutputGroups -> (list)\n\nPlaceholder documentation for __listOfOutputGroup\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nName -> (string)\n\nCustom output group name optionally defined by the user. Only letters, numbers, and the underscore character allowed; only 32 characters allowed.\n\nOutputGroupSettings -> (structure)\n\nSettings associated with the output group.\n\nArchiveGroupSettings -> (structure)\n\nArchive Group Settings\n\nArchiveCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nArchiveS3Settings -> (structure)\n\nArchive S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nDestination -> (structure)\n\nA directory and base filename where archive files should be written.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRolloverInterval -> (integer)\n\nNumber of seconds to write to archive file before closing and starting a new one.\n\nFrameCaptureGroupSettings -> (structure)\n\nFrame Capture Group Settings\n\nDestination -> (structure)\n\nThe destination for the frame capture files. Either the URI for an Amazon S3 bucket and object, plus a file name prefix (for example, s3ssl://sportsDelivery/highlights/20180820/curling-) or the URI for a MediaStore container, plus a file name prefix (for example, mediastoressl://sportsDelivery/20180820/curling-). The final file names consist of the prefix from the destination field (for example, “curling-“) + name modifier + the counter (5 digits, starting from 00001) + extension (which is always .jpg). For example, curling-low.00001.jpg\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFrameCaptureCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nFrameCaptureS3Settings -> (structure)\n\nFrame Capture S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsGroupSettings -> (structure)\n\nHls Group Settings\n\nAdMarkers -> (list)\n\nChoose one or more ad marker types to pass SCTE35 signals through to this group of Apple HLS outputs.\n\n(string)\n\nHls Ad Markers\n\nBaseUrlContent -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlContent1 -> (string)\n\nOptional. One value per output group. This field is required only if you are completing Base URL content A, and the downstream system has notified you that the media files for pipeline 1 of all outputs are in a location different from the media files for pipeline 0.\n\nBaseUrlManifest -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlManifest1 -> (string)\n\nOptional. One value per output group. Complete this field only if you are completing Base URL manifest A, and the downstream system has notified you that the child manifest files for pipeline 1 of all outputs are in a location different from the child manifest files for pipeline 0.\n\nCaptionLanguageMappings -> (list)\n\nMapping of up to 4 caption channels to caption languages. Is only meaningful if captionLanguageSetting is set to “insert”.\n\n(structure)\n\nMaps a caption channel to an ISO 693-2 language code (http://www.loc.gov/standards/iso639-2), with an optional description.\n\nCaptionChannel -> (integer)\n\nThe closed caption channel being described by this CaptionLanguageMapping. Each channel mapping must have a unique channel number (maximum of 4)\n\nLanguageCode -> (string)\n\nThree character ISO 639-2 language code (see http://www.loc.gov/standards/iso639-2)\n\nLanguageDescription -> (string)\n\nTextual description of language\n\nCaptionLanguageSetting -> (string)\n\nApplies only to 608 Embedded output captions. insert: Include CLOSED-CAPTIONS lines in the manifest. Specify at least one language in the CC1 Language Code field. One CLOSED-CAPTION line is added for each Language Code you specify. Make sure to specify the languages in the order in which they appear in the original source (if the source is embedded format) or the order of the caption selectors (if the source is other than embedded). Otherwise, languages in the manifest will not match up properly with the output captions. none: Include CLOSED-CAPTIONS=NONE line in the manifest. omit: Omit any CLOSED-CAPTIONS line from the manifest.\n\nClientCache -> (string)\n\nWhen set to “disabled”, sets the #EXT-X-ALLOW-CACHE:no tag in the manifest, which prevents clients from saving media segments for later replay.\n\nCodecSpecification -> (string)\n\nSpecification to use (RFC-6381 or the default RFC-4281) during m3u8 playlist generation.\n\nConstantIv -> (string)\n\nFor use with encryptionType. This is a 128-bit, 16-byte hex value represented by a 32-character text string. If ivSource is set to “explicit” then this parameter is required and is used as the IV for encryption.\n\nDestination -> (structure)\n\nA directory or HTTP destination for the HLS segments, manifest files, and encryption keys (if enabled).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nDirectoryStructure -> (string)\n\nPlace segments in subdirectories.\n\nDiscontinuityTags -> (string)\n\nSpecifies whether to insert EXT-X-DISCONTINUITY tags in the HLS child manifests for this output group. Typically, choose Insert because these tags are required in the manifest (according to the HLS specification) and serve an important purpose. Choose Never Insert only if the downstream system is doing real-time failover (without using the MediaLive automatic failover feature) and only if that downstream system has advised you to exclude the tags.\n\nEncryptionType -> (string)\n\nEncrypts the segments with the given encryption scheme. Exclude this parameter if no encryption is desired.\n\nHlsCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nHlsAkamaiSettings -> (structure)\n\nHls Akamai Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to Akamai. User should contact Akamai to enable this feature.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nSalt -> (string)\n\nSalt for authenticated Akamai.\n\nToken -> (string)\n\nToken parameter for authenticated akamai. If not specified, _gda_ is used.\n\nHlsBasicPutSettings -> (structure)\n\nHls Basic Put Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsMediaStoreSettings -> (structure)\n\nHls Media Store Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nMediaStoreStorageClass -> (string)\n\nWhen set to temporal, output files are stored in non-persistent memory for faster reading and writing.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsS3Settings -> (structure)\n\nHls S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsWebdavSettings -> (structure)\n\nHls Webdav Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to WebDAV.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsId3SegmentTagging -> (string)\n\nState of HLS ID3 Segment Tagging\n\nIFrameOnlyPlaylists -> (string)\n\nDISABLED: Do not create an I-frame-only manifest, but do create the master and media manifests (according to the Output Selection field). STANDARD: Create an I-frame-only manifest for each output that contains video, as well as the other manifests (according to the Output Selection field). The I-frame manifest contains a #EXT-X-I-FRAMES-ONLY tag to indicate it is I-frame only, and one or more #EXT-X-BYTERANGE entries identifying the I-frame position. For example, #EXT-X-BYTERANGE:160364@1461888”\n\nIncompleteSegmentBehavior -> (string)\n\nSpecifies whether to include the final (incomplete) segment in the media output when the pipeline stops producing output because of a channel stop, a channel pause or a loss of input to the pipeline. Auto means that MediaLive decides whether to include the final segment, depending on the channel class and the types of output groups. Suppress means to never include the incomplete segment. We recommend you choose Auto and let MediaLive control the behavior.\n\nIndexNSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the maximum number of segments in the media manifest file. After this maximum, older segments are removed from the media manifest. This number must be smaller than the number in the Keep Segments field.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nIvInManifest -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If set to “include”, IV is listed in the manifest, otherwise the IV is not in the manifest.\n\nIvSource -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If this setting is “followsSegmentNumber”, it will cause the IV to change every segment (to match the segment number). If this is set to “explicit”, you must enter a constantIv value.\n\nKeepSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the number of media segments to retain in the destination directory. This number should be bigger than indexNSegments (Num segments). We recommend (value = (2 x indexNsegments) + 1). If this “keep segments” number is too low, the following might happen: the player is still reading a media manifest file that lists this segment, but that segment has been removed from the destination directory (as directed by indexNSegments). This situation would result in a 404 HTTP error on the player.\n\nKeyFormat -> (string)\n\nThe value specifies how the key is represented in the resource identified by the URI. If parameter is absent, an implicit value of “identity” is used. A reverse DNS string can also be given.\n\nKeyFormatVersions -> (string)\n\nEither a single positive integer version value or a slash delimited list of version values (1/2/3).\n\nKeyProviderSettings -> (structure)\n\nThe key provider settings.\n\nStaticKeySettings -> (structure)\n\nStatic Key Settings\n\nKeyProviderServer -> (structure)\n\nThe URL of the license server used for protecting content.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nStaticKeyValue -> (string)\n\nStatic key value as a 32 character hexadecimal string.\n\nManifestCompression -> (string)\n\nWhen set to gzip, compresses HLS playlist.\n\nManifestDurationFormat -> (string)\n\nIndicates whether the output manifest should use floating point or integer values for segment duration.\n\nMinSegmentLength -> (integer)\n\nWhen set, minimumSegmentLength is enforced by looking ahead and back within the specified range for a nearby avail and extending the segment size if needed.\n\nMode -> (string)\n\nIf “vod”, all segments are indexed and kept permanently in the destination and manifest. If “live”, only the number segments specified in keepSegments and indexNSegments are kept; newer segments replace older segments, which may prevent players from rewinding all the way to the beginning of the event. VOD mode uses HLS EXT-X-PLAYLIST-TYPE of EVENT while the channel is running, converting it to a “VOD” type manifest on completion of the stream.\n\nOutputSelection -> (string)\n\nMANIFESTS_AND_SEGMENTS: Generates manifests (master manifest, if applicable, and media manifests) for this output group. VARIANT_MANIFESTS_AND_SEGMENTS: Generates media manifests for this output group, but not a master manifest. SEGMENTS_ONLY: Does not generate any manifests for this output group.\n\nProgramDateTime -> (string)\n\nIncludes or excludes EXT-X-PROGRAM-DATE-TIME tag in .m3u8 manifest files. The value is calculated as follows: either the program date and time are initialized using the input timecode source, or the time is initialized using the input timecode source and the date is initialized using the timestampOffset.\n\nProgramDateTimePeriod -> (integer)\n\nPeriod of insertion of EXT-X-PROGRAM-DATE-TIME entry, in seconds.\n\nRedundantManifest -> (string)\n\nENABLED: The master manifest (.m3u8 file) for each pipeline includes information about both pipelines: first its own media files, then the media files of the other pipeline. This feature allows playout device that support stale manifest detection to switch from one manifest to the other, when the current manifest seems to be stale. There are still two destinations and two master manifests, but both master manifests reference the media files from both pipelines. DISABLED: The master manifest (.m3u8 file) for each pipeline includes information about its own pipeline only. For an HLS output group with MediaPackage as the destination, the DISABLED behavior is always followed. MediaPackage regenerates the manifests it serves to players so a redundant manifest from MediaLive is irrelevant.\n\nSegmentLength -> (integer)\n\nLength of MPEG-2 Transport Stream segments to create (in seconds). Note that segments will end on the next keyframe after this number of seconds, so actual segment length may be longer.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSegmentsPerSubdirectory -> (integer)\n\nNumber of segments to write to a subdirectory before starting a new one. directoryStructure must be subdirectoryPerStream for this setting to have an effect.\n\nStreamInfResolution -> (string)\n\nInclude or exclude RESOLUTION attribute for video in EXT-X-STREAM-INF tag of variant manifest.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nTimestampDeltaMilliseconds -> (integer)\n\nProvides an extra millisecond delta offset to fine tune the timestamps.\n\nTsFileMode -> (string)\n\nSEGMENTED_FILES: Emit the program as segments - multiple .ts media files. SINGLE_FILE: Applies only if Mode field is VOD. Emit the program as a single .ts media file. The media manifest includes #EXT-X-BYTERANGE tags to index segments for playback. A typical use for this value is when sending the output to AWS Elemental MediaConvert, which can accept only a single media file. Playback while the channel is running is not guaranteed due to HTTP server caching.\n\nMediaPackageGroupSettings -> (structure)\n\nMedia Package Group Settings\n\nDestination -> (structure)\n\nMediaPackage channel destination.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nMsSmoothGroupSettings -> (structure)\n\nMs Smooth Group Settings\n\nAcquisitionPointId -> (string)\n\nThe ID to include in each message in the sparse track. Ignored if sparseTrackType is NONE.\n\nAudioOnlyTimecodeControl -> (string)\n\nIf set to passthrough for an audio-only MS Smooth output, the fragment absolute time will be set to the current timecode. This option does not write timecodes to the audio elementary stream.\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the https certificate chain to a trusted Certificate Authority (CA). This will cause https outputs to self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the IIS server if the connection is lost. Content will be cached during this time and the cache will be be delivered to the IIS server once the connection is re-established.\n\nDestination -> (structure)\n\nSmooth Streaming publish point on an IIS server. Elemental Live acts as a “Push” encoder to IIS.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nEventId -> (string)\n\nMS Smooth event ID to be sent to the IIS server. Should only be specified if eventIdMode is set to useConfigured.\n\nEventIdMode -> (string)\n\nSpecifies whether or not to send an event ID to the IIS server. If no event ID is sent and the same Live Event is used without changing the publishing point, clients might see cached video from the previous run. Options: - “useConfigured” - use the value provided in eventId - “useTimestamp” - generate and send an event ID based on the current timestamp - “noEventId” - do not send an event ID to the IIS server.\n\nEventStopBehavior -> (string)\n\nWhen set to sendEos, send EOS signal to IIS server when stopping the event\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nFragmentLength -> (integer)\n\nLength of mp4 fragments to generate (in seconds). Fragment length must be compatible with GOP size and framerate.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nRestartDelay -> (integer)\n\nNumber of seconds before initiating a restart due to output failure, due to exhausting the numRetries on one segment, or exceeding filecacheDuration.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSendDelayMs -> (integer)\n\nNumber of milliseconds to delay the output from the second pipeline.\n\nSparseTrackType -> (string)\n\nIdentifies the type of data to place in the sparse track: - SCTE35: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame to start a new segment. - SCTE35_WITHOUT_SEGMENTATION: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame but don’t start a new segment. - NONE: Don’t generate a sparse track for any outputs in this output group.\n\nStreamManifestBehavior -> (string)\n\nWhen set to send, send stream manifest so publishing point doesn’t start until all streams start.\n\nTimestampOffset -> (string)\n\nTimestamp offset for the event. Only used if timestampOffsetMode is set to useConfiguredOffset.\n\nTimestampOffsetMode -> (string)\n\nType of timestamp date offset to use. - useEventStartDate: Use the date the event was started as the offset - useConfiguredOffset: Use an explicitly configured date as the offset\n\nMultiplexGroupSettings -> (structure)\n\nMultiplex Group Settings\n\nRtmpGroupSettings -> (structure)\n\nRtmp Group Settings\n\nAdMarkers -> (list)\n\nChoose the ad marker type for this output group. MediaLive will create a message based on the content of each SCTE-35 message, format it for that marker type, and insert it in the datastream.\n\n(string)\n\nRtmp Ad Markers\n\nAuthenticationScheme -> (string)\n\nAuthentication scheme to use when connecting with CDN\n\nCacheFullBehavior -> (string)\n\nControls behavior when content cache fills up. If remote origin server stalls the RTMP connection and does not accept content fast enough the ‘Media Cache’ will fill up. When the cache reaches the duration specified by cacheLength the cache will stop accepting new content. If set to disconnectImmediately, the RTMP output will force a disconnect. Clear the media cache, and reconnect after restartDelay seconds. If set to waitForServer, the RTMP output will wait up to 5 minutes to allow the origin server to begin accepting data again.\n\nCacheLength -> (integer)\n\nCache length, in seconds, is used to calculate buffer size.\n\nCaptionData -> (string)\n\nControls the types of data that passes to onCaptionInfo outputs. If set to ‘all’ then 608 and 708 carried DTVCC data will be passed. If set to ‘field1AndField2608’ then DTVCC data will be stripped out, but 608 data from both fields will be passed. If set to ‘field1608’ then only the data carried in 608 from field 1 video will be passed.\n\nInputLossAction -> (string)\n\nControls the behavior of this RTMP group if input becomes unavailable. - emitOutput: Emit a slate until input returns. - pauseOutput: Stop transmitting data until input returns. This does not close the underlying RTMP connection.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nUdpGroupSettings -> (structure)\n\nUdp Group Settings\n\nInputLossAction -> (string)\n\nSpecifies behavior of last resort when input video is lost, and no more backup inputs are available. When dropTs is selected the entire transport stream will stop being emitted. When dropProgram is selected the program can be dropped from the transport stream (and replaced with null packets to meet the TS bitrate requirement). Or, when emitProgram is chosen the transport stream will continue to be produced normally with repeat frames, black frames, or slate frames substituted for the absent input video.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nOutputs -> (list)\n\nPlaceholder documentation for __listOfOutput\n\n(structure)\n\nOutput settings. There can be multiple outputs within a group.\n\nAudioDescriptionNames -> (list)\n\nThe names of the AudioDescriptions used as audio sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nCaptionDescriptionNames -> (list)\n\nThe names of the CaptionDescriptions used as caption sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nOutputName -> (string)\n\nThe name used to identify an output.\n\nOutputSettings -> (structure)\n\nOutput type-specific settings.\n\nArchiveOutputSettings -> (structure)\n\nArchive Output Settings\n\nContainerSettings -> (structure)\n\nSettings specific to the container type of the file.\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nRawSettings -> (structure)\n\nRaw Settings\n\nExtension -> (string)\n\nOutput file extension. If excluded, this will be auto-selected from the container type.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nFrameCaptureOutputSettings -> (structure)\n\nFrame Capture Output Settings\n\nNameModifier -> (string)\n\nRequired if the output group contains more than one output. This modifier forms part of the output file name.\n\nHlsOutputSettings -> (structure)\n\nHls Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nHlsSettings -> (structure)\n\nSettings regarding the underlying stream. These settings are different for audio-only outputs.\n\nAudioOnlyHlsSettings -> (structure)\n\nAudio Only Hls Settings\n\nAudioGroupId -> (string)\n\nSpecifies the group to which the audio Rendition belongs.\n\nAudioOnlyImage -> (structure)\n\nOptional. Specifies the .jpg or .png image to use as the cover art for an audio-only output. We recommend a low bit-size file because the image increases the output audio bandwidth. The image is attached to the audio as an ID3 tag, frame type APIC, picture type 0x10, as per the “ID3 tag version 2.4.0 - Native Frames” standard.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nAudioTrackType -> (string)\n\nFour types of audio-only tracks are supported: Audio-Only Variant Stream The client can play back this audio-only stream instead of video in low-bandwidth scenarios. Represented as an EXT-X-STREAM-INF in the HLS manifest. Alternate Audio, Auto Select, Default Alternate rendition that the client should try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=YES, AUTOSELECT=YES Alternate Audio, Auto Select, Not Default Alternate rendition that the client may try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=YES Alternate Audio, not Auto Select Alternate rendition that the client will not try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=NO\n\nSegmentType -> (string)\n\nSpecifies the segment type.\n\nFmp4HlsSettings -> (structure)\n\nFmp4 Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nFrameCaptureHlsSettings -> (structure)\n\nFrame Capture Hls Settings\n\nStandardHlsSettings -> (structure)\n\nStandard Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nM3u8Settings -> (structure)\n\nSettings information for the .m3u8 container\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values.\n\nEcmPid -> (string)\n\nThis parameter is unused and deprecated.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock References (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value.\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nScte35Behavior -> (string)\n\nIf set to passthrough, passes any SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Accepts “Format Identifiers”:#formatIdentifierParameters.\n\nSegmentModifier -> (string)\n\nString concatenated to end of segment filenames.\n\nMediaPackageOutputSettings -> (structure)\n\nMedia Package Output Settings\n\nMsSmoothOutputSettings -> (structure)\n\nMs Smooth Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nMultiplexOutputSettings -> (structure)\n\nMultiplex Output Settings\n\nDestination -> (structure)\n\nDestination is a Multiplex.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRtmpOutputSettings -> (structure)\n\nRtmp Output Settings\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the tls certificate chain to a trusted Certificate Authority (CA). This will cause rtmps outputs with self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying a connection to the Flash Media server if the connection is lost.\n\nDestination -> (structure)\n\nThe RTMP endpoint excluding the stream name (eg. rtmp://host/appname). For connection to Akamai, a username and password must be supplied. URI fields accept format identifiers.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nUdpOutputSettings -> (structure)\n\nUdp Output Settings\n\nBufferMsec -> (integer)\n\nUDP output buffering in milliseconds. Larger values increase latency through the transcoder but simultaneously assist the transcoder in maintaining a constant, low-jitter UDP/RTP output while accommodating clock recovery, input switching, input disruptions, picture reordering, etc.\n\nContainerSettings -> (structure)\n\nUdp Container Settings\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nDestination -> (structure)\n\nDestination address and port number for RTP or UDP packets. Can be unicast or multicast RTP or UDP (eg. rtp://239.10.10.10:5001 or udp://10.100.100.100:5002).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFecOutputSettings -> (structure)\n\nSettings for enabling and adjusting Forward Error Correction on UDP outputs.\n\nColumnDepth -> (integer)\n\nParameter D from SMPTE 2022-1. The height of the FEC protection matrix. The number of transport stream packets per column error correction packet. Must be between 4 and 20, inclusive.\n\nIncludeFec -> (string)\n\nEnables column only or column and row based FEC\n\nRowLength -> (integer)\n\nParameter L from SMPTE 2022-1. The width of the FEC protection matrix. Must be between 1 and 20, inclusive. If only Column FEC is used, then larger values increase robustness. If Row FEC is used, then this is the number of transport stream packets per row error correction packet, and the value must be between 4 and 20, inclusive, if includeFec is columnAndRow. If includeFec is column, this value must be 1 to 20, inclusive.\n\nVideoDescriptionName -> (string)\n\nThe name of the VideoDescription used as the source for this output.\n\nTimecodeConfig -> (structure)\n\nContains settings used to acquire and adjust timecode information from inputs.\n\nSource -> (string)\n\nIdentifies the source for the timecode that will be associated with the events outputs. -Embedded (embedded): Initialize the output timecode with timecode from the the source. If no embedded timecode is detected in the source, the system falls back to using “Start at 0” (zerobased). -System Clock (systemclock): Use the UTC time. -Start at 0 (zerobased): The time of the first frame of the event will be 00:00:00:00.\n\nSyncThreshold -> (integer)\n\nThreshold in frames beyond which output timecode is resynchronized to the input timecode. Discrepancies below this threshold are permitted to avoid unnecessary discontinuities in the output timecode. No timecode sync when this is not specified.\n\nVideoDescriptions -> (list)\n\nPlaceholder documentation for __listOfVideoDescription\n\n(structure)\n\nVideo settings for this stream.\n\nCodecSettings -> (structure)\n\nVideo codec settings.\n\nFrameCaptureSettings -> (structure)\n\nFrame Capture Settings\n\nCaptureInterval -> (integer)\n\nThe frequency at which to capture frames for inclusion in the output. May be specified in either seconds or milliseconds, as specified by captureIntervalUnits.\n\nCaptureIntervalUnits -> (string)\n\nUnit for the frame capture interval.\n\nH264Settings -> (structure)\n\nH264 Settings\n\nAdaptiveQuantization -> (string)\n\nEnables or disables adaptive quantization, which is a technique MediaLive can apply to video on a frame-by-frame basis to produce more compression without losing quality. There are three types of adaptive quantization: flicker, spatial, and temporal. Set the field in one of these ways: Set to Auto. Recommended. For each type of AQ, MediaLive will determine if AQ is needed, and if so, the appropriate strength. Set a strength (a value other than Auto or Disable). This strength will apply to any of the AQ fields that you choose to enable. Set to Disabled to disable all types of adaptive quantization.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufFillPct -> (integer)\n\nPercentage of the buffer that should initially be filled (HRD buffer model).\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nEntropyEncoding -> (string)\n\nEntropy encoding mode. Use cabac (must be in Main or High profile) or cavlc.\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nFlicker AQ makes adjustments within each frame to reduce flicker or ‘pop’ on I-frames. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if flicker AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply flicker AQ using the specified strength. Disabled: MediaLive won’t apply flicker AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply flicker AQ.\n\nForceFieldPictures -> (string)\n\nThis setting applies only when scan type is “interlaced.” It controls whether coding is performed on a field basis or on a frame basis. (When the video is progressive, the coding is always performed on a frame basis.) enabled: Force MediaLive to code on a field basis, so that odd and even sets of fields are coded separately. disabled: Code the two sets of fields separately (on a field basis) or together (on a frame basis using PAFF), depending on what is most appropriate for the content.\n\nFramerateControl -> (string)\n\nThis field indicates how the output video frame rate is specified. If “specified” is selected then the output video frame rate is determined by framerateNumerator and framerateDenominator, else if “initializeFromSource” is selected then the output video frame rate will be set equal to the input video frame rate of the first input.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopBReference -> (string)\n\nDocumentation update needed\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopNumBFrames -> (integer)\n\nNumber of B-frames between reference frames.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.264 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level For VBR: Set the maximum bitrate in order to accommodate expected spikes in the complexity of the video.\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nNumRefFrames -> (integer)\n\nNumber of reference frames to use. The encoder may use more than requested if using B-frames and/or interlaced encoding.\n\nParControl -> (string)\n\nThis field indicates how the output pixel aspect ratio is specified. If “specified” is selected then the output video pixel aspect ratio is determined by parNumerator and parDenominator, else if “initializeFromSource” is selected then the output pixsel aspect ratio will be set equal to the input video pixel aspect ratio of the first input.\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.264 Profile.\n\nQualityLevel -> (string)\n\nLeave as STANDARD_QUALITY or choose a different value (which might result in additional costs to run the channel). - ENHANCED_QUALITY: Produces a slightly better video quality without an increase in the bitrate. Has an effect only when the Rate control mode is QVBR or CBR. If this channel is in a MediaLive multiplex, the value must be ENHANCED_QUALITY. - STANDARD_QUALITY: Valid for any Rate control mode.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. You can set a target quality or you can let MediaLive determine the best quality. To set a target quality, enter values in the QVBR quality level field and the Max bitrate field. Enter values that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M To let MediaLive decide, leave the QVBR quality level field empty, and in Max bitrate enter the maximum rate you want in the video. For more information, see the section called “Video - rate control mode” in the MediaLive user guide\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. VBR: Quality and bitrate vary, depending on the video complexity. Recommended instead of QVBR if you want to maintain a specific average bitrate over the duration of the channel. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection. - On: inserts I-frames when scene change is detected. - Off: does not force an I-frame when scene change is detected.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nSoftness -> (integer)\n\nSoftness. Selects quantizer matrix, larger values reduce high-frequency content in the encoded image. If not set to zero, must be greater than 15.\n\nSpatialAq -> (string)\n\nSpatial AQ makes adjustments within each frame based on spatial variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if spatial AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply spatial AQ using the specified strength. Disabled: MediaLive won’t apply spatial AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply spatial AQ.\n\nSubgopLength -> (string)\n\nIf set to fixed, use gopNumBFrames B-frames per sub-GOP. If set to dynamic, optimize the number of B-frames used for each sub-GOP to improve visual quality.\n\nSyntax -> (string)\n\nProduces a bitstream compliant with SMPTE RP-2027.\n\nTemporalAq -> (string)\n\nTemporal makes adjustments within each frame based on temporal variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if temporal AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply temporal AQ using the specified strength. Disabled: MediaLive won’t apply temporal AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply temporal AQ.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nH265Settings -> (structure)\n\nH265 Settings\n\nAdaptiveQuantization -> (string)\n\nAdaptive quantization. Allows intra-frame quantizers to vary to improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nAlternativeTransferFunction -> (string)\n\nWhether or not EML should insert an Alternative Transfer Function SEI message to support backwards compatibility with non-HDR decoders and displays.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nIf set to enabled, adjust quantization within each frame to reduce flicker or ‘pop’ on I-frames.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.265 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.265 Profile.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. Set values for the QVBR quality level field and Max bitrate field that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nTier -> (string)\n\nH.265 Tier.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nMpeg2Settings -> (structure)\n\nMpeg2 Settings\n\nAdaptiveQuantization -> (string)\n\nChoose Off to disable adaptive quantization. Or choose another value to enable the quantizer and set its strength. The strengths are: Auto, Off, Low, Medium, High. When you enable this field, MediaLive allows intra-frame quantizers to vary, which might improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates the AFD values that MediaLive will write into the video encode. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose AUTO. AUTO: MediaLive will try to preserve the input AFD value (in cases where multiple AFD values are valid). FIXED: MediaLive will use the value you specify in fixedAFD.\n\nColorMetadata -> (string)\n\nSpecifies whether to include the color space metadata. The metadata describes the color space that applies to the video (the colorSpace field). We recommend that you insert the metadata.\n\nColorSpace -> (string)\n\nChoose the type of color space conversion to apply to the output. For detailed information on setting up both the input and the output to obtain the desired color space in the output, see the section on “MediaLive Features - Video - color space” in the MediaLive User Guide. PASSTHROUGH: Keep the color space of the input content - do not convert it. AUTO:Convert all content that is SD to rec 601, and convert all content that is HD to rec 709.\n\nDisplayAspectRatio -> (string)\n\nSets the pixel aspect ratio for the encode.\n\nFilterSettings -> (structure)\n\nOptionally specify a noise reduction filter, which can improve quality of compressed content. If you do not choose a filter, no filter will be applied. TEMPORAL: This filter is useful for both source content that is noisy (when it has excessive digital artifacts) and source content that is clean. When the content is noisy, the filter cleans up the source content before the encoding phase, with these two effects: First, it improves the output video quality because the content has been cleaned up. Secondly, it decreases the bandwidth because MediaLive does not waste bits on encoding noise. When the content is reasonably clean, the filter tends to decrease the bitrate.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nComplete this field only when afdSignaling is set to FIXED. Enter the AFD value (4 bits) to write on all frames of the video encode.\n\nFramerateDenominator -> (integer)\n\ndescription”: “The framerate denominator. For example, 1001. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nFramerateNumerator -> (integer)\n\nThe framerate numerator. For example, 24000. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nGopClosedCadence -> (integer)\n\nMPEG2: default is open GOP.\n\nGopNumBFrames -> (integer)\n\nRelates to the GOP structure. The number of B-frames between reference frames. If you do not know what a B-frame is, use the default.\n\nGopSize -> (double)\n\nRelates to the GOP structure. The GOP size (keyframe interval) in the units specified in gopSizeUnits. If you do not know what GOP is, use the default. If gopSizeUnits is frames, then the gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, the gopSize must be greater than 0, but does not need to be an integer.\n\nGopSizeUnits -> (string)\n\nRelates to the GOP structure. Specifies whether the gopSize is specified in frames or seconds. If you do not plan to change the default gopSize, leave the default. If you specify SECONDS, MediaLive will internally convert the gop size to a frame count.\n\nScanType -> (string)\n\nSet the scan type of the output to PROGRESSIVE or INTERLACED (top field first).\n\nSubgopLength -> (string)\n\nRelates to the GOP structure. If you do not know what GOP is, use the default. FIXED: Set the number of B-frames in each sub-GOP to the value in gopNumBFrames. DYNAMIC: Let MediaLive optimize the number of B-frames in each sub-GOP, to improve visual quality.\n\nTimecodeInsertion -> (string)\n\nDetermines how MediaLive inserts timecodes in the output video. For detailed information about setting up the input and the output for a timecode, see the section on “MediaLive Features - Timecode configuration” in the MediaLive User Guide. DISABLED: do not include timecodes. GOP_TIMECODE: Include timecode metadata in the GOP header.\n\nHeight -> (integer)\n\nOutput video height, in pixels. Must be an even number. For most codecs, you can leave this field and width blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nName -> (string)\n\nThe name of this VideoDescription. Outputs will use this name to uniquely identify this Description. Description names should be unique within this Live Event.\n\nRespondToAfd -> (string)\n\nIndicates how MediaLive will respond to the AFD values that might be in the input video. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose PASSTHROUGH. RESPOND: MediaLive clips the input video using a formula that uses the AFD values (configured in afdSignaling ), the input display aspect ratio, and the output display aspect ratio. MediaLive also includes the AFD values in the output, unless the codec for this encode is FRAME_CAPTURE. PASSTHROUGH: MediaLive ignores the AFD values and does not clip the video. But MediaLive does include the values in the output. NONE: MediaLive does not clip the input video and does not include the AFD values in the output\n\nScalingBehavior -> (string)\n\nSTRETCH_TO_OUTPUT configures the output position to stretch the video to the specified output resolution (height and width). This option will override any position value. DEFAULT may insert black boxes (pillar boxes or letter boxes) around the video to provide the specified output resolution.\n\nSharpness -> (integer)\n\nChanges the strength of the anti-alias filter used for scaling. 0 is the softest setting, 100 is the sharpest. A setting of 50 is recommended for most content.\n\nWidth -> (integer)\n\nOutput video width, in pixels. Must be an even number. For most codecs, you can leave this field and height blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nJSON Syntax:\n\n{\n  \"AudioDescriptions\": [\n    {\n      \"AudioNormalizationSettings\": {\n        \"Algorithm\": \"ITU_1770_1\"|\"ITU_1770_2\",\n        \"AlgorithmControl\": \"CORRECT_AUDIO\",\n        \"TargetLkfs\": double\n      },\n      \"AudioSelectorName\": \"string\",\n      \"AudioType\": \"CLEAN_EFFECTS\"|\"HEARING_IMPAIRED\"|\"UNDEFINED\"|\"VISUAL_IMPAIRED_COMMENTARY\",\n      \"AudioTypeControl\": \"FOLLOW_INPUT\"|\"USE_CONFIGURED\",\n      \"AudioWatermarkingSettings\": {\n        \"NielsenWatermarksSettings\": {\n          \"NielsenCbetSettings\": {\n            \"CbetCheckDigitString\": \"string\",\n            \"CbetStepaside\": \"DISABLED\"|\"ENABLED\",\n            \"Csid\": \"string\"\n          },\n          \"NielsenDistributionType\": \"FINAL_DISTRIBUTOR\"|\"PROGRAM_CONTENT\",\n          \"NielsenNaesIiNwSettings\": {\n            \"CheckDigitString\": \"string\",\n            \"Sid\": double\n          }\n        }\n      },\n      \"CodecSettings\": {\n        \"AacSettings\": {\n          \"Bitrate\": double,\n          \"CodingMode\": \"AD_RECEIVER_MIX\"|\"CODING_MODE_1_0\"|\"CODING_MODE_1_1\"|\"CODING_MODE_2_0\"|\"CODING_MODE_5_1\",\n          \"InputType\": \"BROADCASTER_MIXED_AD\"|\"NORMAL\",\n          \"Profile\": \"HEV1\"|\"HEV2\"|\"LC\",\n          \"RateControlMode\": \"CBR\"|\"VBR\",\n          \"RawFormat\": \"LATM_LOAS\"|\"NONE\",\n          \"SampleRate\": double,\n          \"Spec\": \"MPEG2\"|\"MPEG4\",\n          \"VbrQuality\": \"HIGH\"|\"LOW\"|\"MEDIUM_HIGH\"|\"MEDIUM_LOW\"\n        },\n        \"Ac3Settings\": {\n          \"Bitrate\": double,\n          \"BitstreamMode\": \"COMMENTARY\"|\"COMPLETE_MAIN\"|\"DIALOGUE\"|\"EMERGENCY\"|\"HEARING_IMPAIRED\"|\"MUSIC_AND_EFFECTS\"|\"VISUALLY_IMPAIRED\"|\"VOICE_OVER\",\n          \"CodingMode\": \"CODING_MODE_1_0\"|\"CODING_MODE_1_1\"|\"CODING_MODE_2_0\"|\"CODING_MODE_3_2_LFE\",\n          \"Dialnorm\": integer,\n          \"DrcProfile\": \"FILM_STANDARD\"|\"NONE\",\n          \"LfeFilter\": \"DISABLED\"|\"ENABLED\",\n          \"MetadataControl\": \"FOLLOW_INPUT\"|\"USE_CONFIGURED\"\n        },\n        \"Eac3Settings\": {\n          \"AttenuationControl\": \"ATTENUATE_3_DB\"|\"NONE\",\n          \"Bitrate\": double,\n          \"BitstreamMode\": \"COMMENTARY\"|\"COMPLETE_MAIN\"|\"EMERGENCY\"|\"HEARING_IMPAIRED\"|\"VISUALLY_IMPAIRED\",\n          \"CodingMode\": \"CODING_MODE_1_0\"|\"CODING_MODE_2_0\"|\"CODING_MODE_3_2\",\n          \"DcFilter\": \"DISABLED\"|\"ENABLED\",\n          \"Dialnorm\": integer,\n          \"DrcLine\": \"FILM_LIGHT\"|\"FILM_STANDARD\"|\"MUSIC_LIGHT\"|\"MUSIC_STANDARD\"|\"NONE\"|\"SPEECH\",\n          \"DrcRf\": \"FILM_LIGHT\"|\"FILM_STANDARD\"|\"MUSIC_LIGHT\"|\"MUSIC_STANDARD\"|\"NONE\"|\"SPEECH\",\n          \"LfeControl\": \"LFE\"|\"NO_LFE\",\n          \"LfeFilter\": \"DISABLED\"|\"ENABLED\",\n          \"LoRoCenterMixLevel\": double,\n          \"LoRoSurroundMixLevel\": double,\n          \"LtRtCenterMixLevel\": double,\n          \"LtRtSurroundMixLevel\": double,\n          \"MetadataControl\": \"FOLLOW_INPUT\"|\"USE_CONFIGURED\",\n          \"PassthroughControl\": \"NO_PASSTHROUGH\"|\"WHEN_POSSIBLE\",\n          \"PhaseControl\": \"NO_SHIFT\"|\"SHIFT_90_DEGREES\",\n          \"StereoDownmix\": \"DPL2\"|\"LO_RO\"|\"LT_RT\"|\"NOT_INDICATED\",\n          \"SurroundExMode\": \"DISABLED\"|\"ENABLED\"|\"NOT_INDICATED\",\n          \"SurroundMode\": \"DISABLED\"|\"ENABLED\"|\"NOT_INDICATED\"\n        },\n        \"Mp2Settings\": {\n          \"Bitrate\": double,\n          \"CodingMode\": \"CODING_MODE_1_0\"|\"CODING_MODE_2_0\",\n          \"SampleRate\": double\n        },\n        \"PassThroughSettings\": {\n\n        },\n        \"WavSettings\": {\n          \"BitDepth\": double,\n          \"CodingMode\": \"CODING_MODE_1_0\"|\"CODING_MODE_2_0\"|\"CODING_MODE_4_0\"|\"CODING_MODE_8_0\",\n          \"SampleRate\": double\n        }\n      },\n      \"LanguageCode\": \"string\",\n      \"LanguageCodeControl\": \"FOLLOW_INPUT\"|\"USE_CONFIGURED\",\n      \"Name\": \"string\",\n      \"RemixSettings\": {\n        \"ChannelMappings\": [\n          {\n            \"InputChannelLevels\": [\n              {\n                \"Gain\": integer,\n                \"InputChannel\": integer\n              }\n              ...\n            ],\n            \"OutputChannel\": integer\n          }\n          ...\n        ],\n        \"ChannelsIn\": integer,\n        \"ChannelsOut\": integer\n      },\n      \"StreamName\": \"string\"\n    }\n    ...\n  ],\n  \"AvailBlanking\": {\n    \"AvailBlankingImage\": {\n      \"PasswordParam\": \"string\",\n      \"Uri\": \"string\",\n      \"Username\": \"string\"\n    },\n    \"State\": \"DISABLED\"|\"ENABLED\"\n  },\n  \"AvailConfiguration\": {\n    \"AvailSettings\": {\n      \"Scte35SpliceInsert\": {\n        \"AdAvailOffset\": integer,\n        \"NoRegionalBlackoutFlag\": \"FOLLOW\"|\"IGNORE\",\n        \"WebDeliveryAllowedFlag\": \"FOLLOW\"|\"IGNORE\"\n      },\n      \"Scte35TimeSignalApos\": {\n        \"AdAvailOffset\": integer,\n        \"NoRegionalBlackoutFlag\": \"FOLLOW\"|\"IGNORE\",\n        \"WebDeliveryAllowedFlag\": \"FOLLOW\"|\"IGNORE\"\n      }\n    }\n  },\n  \"BlackoutSlate\": {\n    \"BlackoutSlateImage\": {\n      \"PasswordParam\": \"string\",\n      \"Uri\": \"string\",\n      \"Username\": \"string\"\n    },\n    \"NetworkEndBlackout\": \"DISABLED\"|\"ENABLED\",\n    \"NetworkEndBlackoutImage\": {\n      \"PasswordParam\": \"string\",\n      \"Uri\": \"string\",\n      \"Username\": \"string\"\n    },\n    \"NetworkId\": \"string\",\n    \"State\": \"DISABLED\"|\"ENABLED\"\n  },\n  \"CaptionDescriptions\": [\n    {\n      \"CaptionSelectorName\": \"string\",\n      \"DestinationSettings\": {\n        \"AribDestinationSettings\": {\n\n        },\n        \"BurnInDestinationSettings\": {\n          \"Alignment\": \"CENTERED\"|\"LEFT\"|\"SMART\",\n          \"BackgroundColor\": \"BLACK\"|\"NONE\"|\"WHITE\",\n          \"BackgroundOpacity\": integer,\n          \"Font\": {\n            \"PasswordParam\": \"string\",\n            \"Uri\": \"string\",\n            \"Username\": \"string\"\n          },\n          \"FontColor\": \"BLACK\"|\"BLUE\"|\"GREEN\"|\"RED\"|\"WHITE\"|\"YELLOW\",\n          \"FontOpacity\": integer,\n          \"FontResolution\": integer,\n          \"FontSize\": \"string\",\n          \"OutlineColor\": \"BLACK\"|\"BLUE\"|\"GREEN\"|\"RED\"|\"WHITE\"|\"YELLOW\",\n          \"OutlineSize\": integer,\n          \"ShadowColor\": \"BLACK\"|\"NONE\"|\"WHITE\",\n          \"ShadowOpacity\": integer,\n          \"ShadowXOffset\": integer,\n          \"ShadowYOffset\": integer,\n          \"TeletextGridControl\": \"FIXED\"|\"SCALED\",\n          \"XPosition\": integer,\n          \"YPosition\": integer\n        },\n        \"DvbSubDestinationSettings\": {\n          \"Alignment\": \"CENTERED\"|\"LEFT\"|\"SMART\",\n          \"BackgroundColor\": \"BLACK\"|\"NONE\"|\"WHITE\",\n          \"BackgroundOpacity\": integer,\n          \"Font\": {\n            \"PasswordParam\": \"string\",\n            \"Uri\": \"string\",\n            \"Username\": \"string\"\n          },\n          \"FontColor\": \"BLACK\"|\"BLUE\"|\"GREEN\"|\"RED\"|\"WHITE\"|\"YELLOW\",\n          \"FontOpacity\": integer,\n          \"FontResolution\": integer,\n          \"FontSize\": \"string\",\n          \"OutlineColor\": \"BLACK\"|\"BLUE\"|\"GREEN\"|\"RED\"|\"WHITE\"|\"YELLOW\",\n          \"OutlineSize\": integer,\n          \"ShadowColor\": \"BLACK\"|\"NONE\"|\"WHITE\",\n          \"ShadowOpacity\": integer,\n          \"ShadowXOffset\": integer,\n          \"ShadowYOffset\": integer,\n          \"TeletextGridControl\": \"FIXED\"|\"SCALED\",\n          \"XPosition\": integer,\n          \"YPosition\": integer\n        },\n        \"EbuTtDDestinationSettings\": {\n          \"CopyrightHolder\": \"string\",\n          \"FillLineGap\": \"DISABLED\"|\"ENABLED\",\n          \"FontFamily\": \"string\",\n          \"StyleControl\": \"EXCLUDE\"|\"INCLUDE\"\n        },\n        \"EmbeddedDestinationSettings\": {\n\n        },\n        \"EmbeddedPlusScte20DestinationSettings\": {\n\n        },\n        \"RtmpCaptionInfoDestinationSettings\": {\n\n        },\n        \"Scte20PlusEmbeddedDestinationSettings\": {\n\n        },\n        \"Scte27DestinationSettings\": {\n\n        },\n        \"SmpteTtDestinationSettings\": {\n\n        },\n        \"TeletextDestinationSettings\": {\n\n        },\n        \"TtmlDestinationSettings\": {\n          \"StyleControl\": \"PASSTHROUGH\"|\"USE_CONFIGURED\"\n        },\n        \"WebvttDestinationSettings\": {\n          \"StyleControl\": \"NO_STYLE_DATA\"|\"PASSTHROUGH\"\n        }\n      },\n      \"LanguageCode\": \"string\",\n      \"LanguageDescription\": \"string\",\n      \"Name\": \"string\"\n    }\n    ...\n  ],\n  \"FeatureActivations\": {\n    \"InputPrepareScheduleActions\": \"DISABLED\"|\"ENABLED\"\n  },\n  \"GlobalConfiguration\": {\n    \"InitialAudioGain\": integer,\n    \"InputEndAction\": \"NONE\"|\"SWITCH_AND_LOOP_INPUTS\",\n    \"InputLossBehavior\": {\n      \"BlackFrameMsec\": integer,\n      \"InputLossImageColor\": \"string\",\n      \"InputLossImageSlate\": {\n        \"PasswordParam\": \"string\",\n        \"Uri\": \"string\",\n        \"Username\": \"string\"\n      },\n      \"InputLossImageType\": \"COLOR\"|\"SLATE\",\n      \"RepeatFrameMsec\": integer\n    },\n    \"OutputLockingMode\": \"EPOCH_LOCKING\"|\"PIPELINE_LOCKING\",\n    \"OutputTimingSource\": \"INPUT_CLOCK\"|\"SYSTEM_CLOCK\",\n    \"SupportLowFramerateInputs\": \"DISABLED\"|\"ENABLED\"\n  },\n  \"MotionGraphicsConfiguration\": {\n    \"MotionGraphicsInsertion\": \"DISABLED\"|\"ENABLED\",\n    \"MotionGraphicsSettings\": {\n      \"HtmlMotionGraphicsSettings\": {\n\n      }\n    }\n  },\n  \"NielsenConfiguration\": {\n    \"DistributorId\": \"string\",\n    \"NielsenPcmToId3Tagging\": \"DISABLED\"|\"ENABLED\"\n  },\n  \"OutputGroups\": [\n    {\n      \"Name\": \"string\",\n      \"OutputGroupSettings\": {\n        \"ArchiveGroupSettings\": {\n          \"ArchiveCdnSettings\": {\n            \"ArchiveS3Settings\": {\n              \"CannedAcl\": \"AUTHENTICATED_READ\"|\"BUCKET_OWNER_FULL_CONTROL\"|\"BUCKET_OWNER_READ\"|\"PUBLIC_READ\"\n            }\n          },\n          \"Destination\": {\n            \"DestinationRefId\": \"string\"\n          },\n          \"RolloverInterval\": integer\n        },\n        \"FrameCaptureGroupSettings\": {\n          \"Destination\": {\n            \"DestinationRefId\": \"string\"\n          },\n          \"FrameCaptureCdnSettings\": {\n            \"FrameCaptureS3Settings\": {\n              \"CannedAcl\": \"AUTHENTICATED_READ\"|\"BUCKET_OWNER_FULL_CONTROL\"|\"BUCKET_OWNER_READ\"|\"PUBLIC_READ\"\n            }\n          }\n        },\n        \"HlsGroupSettings\": {\n          \"AdMarkers\": [\"ADOBE\"|\"ELEMENTAL\"|\"ELEMENTAL_SCTE35\", ...],\n          \"BaseUrlContent\": \"string\",\n          \"BaseUrlContent1\": \"string\",\n          \"BaseUrlManifest\": \"string\",\n          \"BaseUrlManifest1\": \"string\",\n          \"CaptionLanguageMappings\": [\n            {\n              \"CaptionChannel\": integer,\n              \"LanguageCode\": \"string\",\n              \"LanguageDescription\": \"string\"\n            }\n            ...\n          ],\n          \"CaptionLanguageSetting\": \"INSERT\"|\"NONE\"|\"OMIT\",\n          \"ClientCache\": \"DISABLED\"|\"ENABLED\",\n          \"CodecSpecification\": \"RFC_4281\"|\"RFC_6381\",\n          \"ConstantIv\": \"string\",\n          \"Destination\": {\n            \"DestinationRefId\": \"string\"\n          },\n          \"DirectoryStructure\": \"SINGLE_DIRECTORY\"|\"SUBDIRECTORY_PER_STREAM\",\n          \"DiscontinuityTags\": \"INSERT\"|\"NEVER_INSERT\",\n          \"EncryptionType\": \"AES128\"|\"SAMPLE_AES\",\n          \"HlsCdnSettings\": {\n            \"HlsAkamaiSettings\": {\n              \"ConnectionRetryInterval\": integer,\n              \"FilecacheDuration\": integer,\n              \"HttpTransferMode\": \"CHUNKED\"|\"NON_CHUNKED\",\n              \"NumRetries\": integer,\n              \"RestartDelay\": integer,\n              \"Salt\": \"string\",\n              \"Token\": \"string\"\n            },\n            \"HlsBasicPutSettings\": {\n              \"ConnectionRetryInterval\": integer,\n              \"FilecacheDuration\": integer,\n              \"NumRetries\": integer,\n              \"RestartDelay\": integer\n            },\n            \"HlsMediaStoreSettings\": {\n              \"ConnectionRetryInterval\": integer,\n              \"FilecacheDuration\": integer,\n              \"MediaStoreStorageClass\": \"TEMPORAL\",\n              \"NumRetries\": integer,\n              \"RestartDelay\": integer\n            },\n            \"HlsS3Settings\": {\n              \"CannedAcl\": \"AUTHENTICATED_READ\"|\"BUCKET_OWNER_FULL_CONTROL\"|\"BUCKET_OWNER_READ\"|\"PUBLIC_READ\"\n            },\n            \"HlsWebdavSettings\": {\n              \"ConnectionRetryInterval\": integer,\n              \"FilecacheDuration\": integer,\n              \"HttpTransferMode\": \"CHUNKED\"|\"NON_CHUNKED\",\n              \"NumRetries\": integer,\n              \"RestartDelay\": integer\n            }\n          },\n          \"HlsId3SegmentTagging\": \"DISABLED\"|\"ENABLED\",\n          \"IFrameOnlyPlaylists\": \"DISABLED\"|\"STANDARD\",\n          \"IncompleteSegmentBehavior\": \"AUTO\"|\"SUPPRESS\",\n          \"IndexNSegments\": integer,\n          \"InputLossAction\": \"EMIT_OUTPUT\"|\"PAUSE_OUTPUT\",\n          \"IvInManifest\": \"EXCLUDE\"|\"INCLUDE\",\n          \"IvSource\": \"EXPLICIT\"|\"FOLLOWS_SEGMENT_NUMBER\",\n          \"KeepSegments\": integer,\n          \"KeyFormat\": \"string\",\n          \"KeyFormatVersions\": \"string\",\n          \"KeyProviderSettings\": {\n            \"StaticKeySettings\": {\n              \"KeyProviderServer\": {\n                \"PasswordParam\": \"string\",\n                \"Uri\": \"string\",\n                \"Username\": \"string\"\n              },\n              \"StaticKeyValue\": \"string\"\n            }\n          },\n          \"ManifestCompression\": \"GZIP\"|\"NONE\",\n          \"ManifestDurationFormat\": \"FLOATING_POINT\"|\"INTEGER\",\n          \"MinSegmentLength\": integer,\n          \"Mode\": \"LIVE\"|\"VOD\",\n          \"OutputSelection\": \"MANIFESTS_AND_SEGMENTS\"|\"SEGMENTS_ONLY\"|\"VARIANT_MANIFESTS_AND_SEGMENTS\",\n          \"ProgramDateTime\": \"EXCLUDE\"|\"INCLUDE\",\n          \"ProgramDateTimePeriod\": integer,\n          \"RedundantManifest\": \"DISABLED\"|\"ENABLED\",\n          \"SegmentLength\": integer,\n          \"SegmentationMode\": \"USE_INPUT_SEGMENTATION\"|\"USE_SEGMENT_DURATION\",\n          \"SegmentsPerSubdirectory\": integer,\n          \"StreamInfResolution\": \"EXCLUDE\"|\"INCLUDE\",\n          \"TimedMetadataId3Frame\": \"NONE\"|\"PRIV\"|\"TDRL\",\n          \"TimedMetadataId3Period\": integer,\n          \"TimestampDeltaMilliseconds\": integer,\n          \"TsFileMode\": \"SEGMENTED_FILES\"|\"SINGLE_FILE\"\n        },\n        \"MediaPackageGroupSettings\": {\n          \"Destination\": {\n            \"DestinationRefId\": \"string\"\n          }\n        },\n        \"MsSmoothGroupSettings\": {\n          \"AcquisitionPointId\": \"string\",\n          \"AudioOnlyTimecodeControl\": \"PASSTHROUGH\"|\"USE_CONFIGURED_CLOCK\",\n          \"CertificateMode\": \"SELF_SIGNED\"|\"VERIFY_AUTHENTICITY\",\n          \"ConnectionRetryInterval\": integer,\n          \"Destination\": {\n            \"DestinationRefId\": \"string\"\n          },\n          \"EventId\": \"string\",\n          \"EventIdMode\": \"NO_EVENT_ID\"|\"USE_CONFIGURED\"|\"USE_TIMESTAMP\",\n          \"EventStopBehavior\": \"NONE\"|\"SEND_EOS\",\n          \"FilecacheDuration\": integer,\n          \"FragmentLength\": integer,\n          \"InputLossAction\": \"EMIT_OUTPUT\"|\"PAUSE_OUTPUT\",\n          \"NumRetries\": integer,\n          \"RestartDelay\": integer,\n          \"SegmentationMode\": \"USE_INPUT_SEGMENTATION\"|\"USE_SEGMENT_DURATION\",\n          \"SendDelayMs\": integer,\n          \"SparseTrackType\": \"NONE\"|\"SCTE_35\"|\"SCTE_35_WITHOUT_SEGMENTATION\",\n          \"StreamManifestBehavior\": \"DO_NOT_SEND\"|\"SEND\",\n          \"TimestampOffset\": \"string\",\n          \"TimestampOffsetMode\": \"USE_CONFIGURED_OFFSET\"|\"USE_EVENT_START_DATE\"\n        },\n        \"MultiplexGroupSettings\": {\n\n        },\n        \"RtmpGroupSettings\": {\n          \"AdMarkers\": [\"ON_CUE_POINT_SCTE35\", ...],\n          \"AuthenticationScheme\": \"AKAMAI\"|\"COMMON\",\n          \"CacheFullBehavior\": \"DISCONNECT_IMMEDIATELY\"|\"WAIT_FOR_SERVER\",\n          \"CacheLength\": integer,\n          \"CaptionData\": \"ALL\"|\"FIELD1_608\"|\"FIELD1_AND_FIELD2_608\",\n          \"InputLossAction\": \"EMIT_OUTPUT\"|\"PAUSE_OUTPUT\",\n          \"RestartDelay\": integer\n        },\n        \"UdpGroupSettings\": {\n          \"InputLossAction\": \"DROP_PROGRAM\"|\"DROP_TS\"|\"EMIT_PROGRAM\",\n          \"TimedMetadataId3Frame\": \"NONE\"|\"PRIV\"|\"TDRL\",\n          \"TimedMetadataId3Period\": integer\n        }\n      },\n      \"Outputs\": [\n        {\n          \"AudioDescriptionNames\": [\"string\", ...],\n          \"CaptionDescriptionNames\": [\"string\", ...],\n          \"OutputName\": \"string\",\n          \"OutputSettings\": {\n            \"ArchiveOutputSettings\": {\n              \"ContainerSettings\": {\n                \"M2tsSettings\": {\n                  \"AbsentInputAudioBehavior\": \"DROP\"|\"ENCODE_SILENCE\",\n                  \"Arib\": \"DISABLED\"|\"ENABLED\",\n                  \"AribCaptionsPid\": \"string\",\n                  \"AribCaptionsPidControl\": \"AUTO\"|\"USE_CONFIGURED\",\n                  \"AudioBufferModel\": \"ATSC\"|\"DVB\",\n                  \"AudioFramesPerPes\": integer,\n                  \"AudioPids\": \"string\",\n                  \"AudioStreamType\": \"ATSC\"|\"DVB\",\n                  \"Bitrate\": integer,\n                  \"BufferModel\": \"MULTIPLEX\"|\"NONE\",\n                  \"CcDescriptor\": \"DISABLED\"|\"ENABLED\",\n                  \"DvbNitSettings\": {\n                    \"NetworkId\": integer,\n                    \"NetworkName\": \"string\",\n                    \"RepInterval\": integer\n                  },\n                  \"DvbSdtSettings\": {\n                    \"OutputSdt\": \"SDT_FOLLOW\"|\"SDT_FOLLOW_IF_PRESENT\"|\"SDT_MANUAL\"|\"SDT_NONE\",\n                    \"RepInterval\": integer,\n                    \"ServiceName\": \"string\",\n                    \"ServiceProviderName\": \"string\"\n                  },\n                  \"DvbSubPids\": \"string\",\n                  \"DvbTdtSettings\": {\n                    \"RepInterval\": integer\n                  },\n                  \"DvbTeletextPid\": \"string\",\n                  \"Ebif\": \"NONE\"|\"PASSTHROUGH\",\n                  \"EbpAudioInterval\": \"VIDEO_AND_FIXED_INTERVALS\"|\"VIDEO_INTERVAL\",\n                  \"EbpLookaheadMs\": integer,\n                  \"EbpPlacement\": \"VIDEO_AND_AUDIO_PIDS\"|\"VIDEO_PID\",\n                  \"EcmPid\": \"string\",\n                  \"EsRateInPes\": \"EXCLUDE\"|\"INCLUDE\",\n                  \"EtvPlatformPid\": \"string\",\n                  \"EtvSignalPid\": \"string\",\n                  \"FragmentTime\": double,\n                  \"Klv\": \"NONE\"|\"PASSTHROUGH\",\n                  \"KlvDataPids\": \"string\",\n                  \"NielsenId3Behavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                  \"NullPacketBitrate\": double,\n                  \"PatInterval\": integer,\n                  \"PcrControl\": \"CONFIGURED_PCR_PERIOD\"|\"PCR_EVERY_PES_PACKET\",\n                  \"PcrPeriod\": integer,\n                  \"PcrPid\": \"string\",\n                  \"PmtInterval\": integer,\n                  \"PmtPid\": \"string\",\n                  \"ProgramNum\": integer,\n                  \"RateMode\": \"CBR\"|\"VBR\",\n                  \"Scte27Pids\": \"string\",\n                  \"Scte35Control\": \"NONE\"|\"PASSTHROUGH\",\n                  \"Scte35Pid\": \"string\",\n                  \"SegmentationMarkers\": \"EBP\"|\"EBP_LEGACY\"|\"NONE\"|\"PSI_SEGSTART\"|\"RAI_ADAPT\"|\"RAI_SEGSTART\",\n                  \"SegmentationStyle\": \"MAINTAIN_CADENCE\"|\"RESET_CADENCE\",\n                  \"SegmentationTime\": double,\n                  \"TimedMetadataBehavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                  \"TimedMetadataPid\": \"string\",\n                  \"TransportStreamId\": integer,\n                  \"VideoPid\": \"string\"\n                },\n                \"RawSettings\": {\n\n                }\n              },\n              \"Extension\": \"string\",\n              \"NameModifier\": \"string\"\n            },\n            \"FrameCaptureOutputSettings\": {\n              \"NameModifier\": \"string\"\n            },\n            \"HlsOutputSettings\": {\n              \"H265PackagingType\": \"HEV1\"|\"HVC1\",\n              \"HlsSettings\": {\n                \"AudioOnlyHlsSettings\": {\n                  \"AudioGroupId\": \"string\",\n                  \"AudioOnlyImage\": {\n                    \"PasswordParam\": \"string\",\n                    \"Uri\": \"string\",\n                    \"Username\": \"string\"\n                  },\n                  \"AudioTrackType\": \"ALTERNATE_AUDIO_AUTO_SELECT\"|\"ALTERNATE_AUDIO_AUTO_SELECT_DEFAULT\"|\"ALTERNATE_AUDIO_NOT_AUTO_SELECT\"|\"AUDIO_ONLY_VARIANT_STREAM\",\n                  \"SegmentType\": \"AAC\"|\"FMP4\"\n                },\n                \"Fmp4HlsSettings\": {\n                  \"AudioRenditionSets\": \"string\",\n                  \"NielsenId3Behavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                  \"TimedMetadataBehavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\"\n                },\n                \"FrameCaptureHlsSettings\": {\n\n                },\n                \"StandardHlsSettings\": {\n                  \"AudioRenditionSets\": \"string\",\n                  \"M3u8Settings\": {\n                    \"AudioFramesPerPes\": integer,\n                    \"AudioPids\": \"string\",\n                    \"EcmPid\": \"string\",\n                    \"NielsenId3Behavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                    \"PatInterval\": integer,\n                    \"PcrControl\": \"CONFIGURED_PCR_PERIOD\"|\"PCR_EVERY_PES_PACKET\",\n                    \"PcrPeriod\": integer,\n                    \"PcrPid\": \"string\",\n                    \"PmtInterval\": integer,\n                    \"PmtPid\": \"string\",\n                    \"ProgramNum\": integer,\n                    \"Scte35Behavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                    \"Scte35Pid\": \"string\",\n                    \"TimedMetadataBehavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                    \"TimedMetadataPid\": \"string\",\n                    \"TransportStreamId\": integer,\n                    \"VideoPid\": \"string\"\n                  }\n                }\n              },\n              \"NameModifier\": \"string\",\n              \"SegmentModifier\": \"string\"\n            },\n            \"MediaPackageOutputSettings\": {\n\n            },\n            \"MsSmoothOutputSettings\": {\n              \"H265PackagingType\": \"HEV1\"|\"HVC1\",\n              \"NameModifier\": \"string\"\n            },\n            \"MultiplexOutputSettings\": {\n              \"Destination\": {\n                \"DestinationRefId\": \"string\"\n              }\n            },\n            \"RtmpOutputSettings\": {\n              \"CertificateMode\": \"SELF_SIGNED\"|\"VERIFY_AUTHENTICITY\",\n              \"ConnectionRetryInterval\": integer,\n              \"Destination\": {\n                \"DestinationRefId\": \"string\"\n              },\n              \"NumRetries\": integer\n            },\n            \"UdpOutputSettings\": {\n              \"BufferMsec\": integer,\n              \"ContainerSettings\": {\n                \"M2tsSettings\": {\n                  \"AbsentInputAudioBehavior\": \"DROP\"|\"ENCODE_SILENCE\",\n                  \"Arib\": \"DISABLED\"|\"ENABLED\",\n                  \"AribCaptionsPid\": \"string\",\n                  \"AribCaptionsPidControl\": \"AUTO\"|\"USE_CONFIGURED\",\n                  \"AudioBufferModel\": \"ATSC\"|\"DVB\",\n                  \"AudioFramesPerPes\": integer,\n                  \"AudioPids\": \"string\",\n                  \"AudioStreamType\": \"ATSC\"|\"DVB\",\n                  \"Bitrate\": integer,\n                  \"BufferModel\": \"MULTIPLEX\"|\"NONE\",\n                  \"CcDescriptor\": \"DISABLED\"|\"ENABLED\",\n                  \"DvbNitSettings\": {\n                    \"NetworkId\": integer,\n                    \"NetworkName\": \"string\",\n                    \"RepInterval\": integer\n                  },\n                  \"DvbSdtSettings\": {\n                    \"OutputSdt\": \"SDT_FOLLOW\"|\"SDT_FOLLOW_IF_PRESENT\"|\"SDT_MANUAL\"|\"SDT_NONE\",\n                    \"RepInterval\": integer,\n                    \"ServiceName\": \"string\",\n                    \"ServiceProviderName\": \"string\"\n                  },\n                  \"DvbSubPids\": \"string\",\n                  \"DvbTdtSettings\": {\n                    \"RepInterval\": integer\n                  },\n                  \"DvbTeletextPid\": \"string\",\n                  \"Ebif\": \"NONE\"|\"PASSTHROUGH\",\n                  \"EbpAudioInterval\": \"VIDEO_AND_FIXED_INTERVALS\"|\"VIDEO_INTERVAL\",\n                  \"EbpLookaheadMs\": integer,\n                  \"EbpPlacement\": \"VIDEO_AND_AUDIO_PIDS\"|\"VIDEO_PID\",\n                  \"EcmPid\": \"string\",\n                  \"EsRateInPes\": \"EXCLUDE\"|\"INCLUDE\",\n                  \"EtvPlatformPid\": \"string\",\n                  \"EtvSignalPid\": \"string\",\n                  \"FragmentTime\": double,\n                  \"Klv\": \"NONE\"|\"PASSTHROUGH\",\n                  \"KlvDataPids\": \"string\",\n                  \"NielsenId3Behavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                  \"NullPacketBitrate\": double,\n                  \"PatInterval\": integer,\n                  \"PcrControl\": \"CONFIGURED_PCR_PERIOD\"|\"PCR_EVERY_PES_PACKET\",\n                  \"PcrPeriod\": integer,\n                  \"PcrPid\": \"string\",\n                  \"PmtInterval\": integer,\n                  \"PmtPid\": \"string\",\n                  \"ProgramNum\": integer,\n                  \"RateMode\": \"CBR\"|\"VBR\",\n                  \"Scte27Pids\": \"string\",\n                  \"Scte35Control\": \"NONE\"|\"PASSTHROUGH\",\n                  \"Scte35Pid\": \"string\",\n                  \"SegmentationMarkers\": \"EBP\"|\"EBP_LEGACY\"|\"NONE\"|\"PSI_SEGSTART\"|\"RAI_ADAPT\"|\"RAI_SEGSTART\",\n                  \"SegmentationStyle\": \"MAINTAIN_CADENCE\"|\"RESET_CADENCE\",\n                  \"SegmentationTime\": double,\n                  \"TimedMetadataBehavior\": \"NO_PASSTHROUGH\"|\"PASSTHROUGH\",\n                  \"TimedMetadataPid\": \"string\",\n                  \"TransportStreamId\": integer,\n                  \"VideoPid\": \"string\"\n                }\n              },\n              \"Destination\": {\n                \"DestinationRefId\": \"string\"\n              },\n              \"FecOutputSettings\": {\n                \"ColumnDepth\": integer,\n                \"IncludeFec\": \"COLUMN\"|\"COLUMN_AND_ROW\",\n                \"RowLength\": integer\n              }\n            }\n          },\n          \"VideoDescriptionName\": \"string\"\n        }\n        ...\n      ]\n    }\n    ...\n  ],\n  \"TimecodeConfig\": {\n    \"Source\": \"EMBEDDED\"|\"SYSTEMCLOCK\"|\"ZEROBASED\",\n    \"SyncThreshold\": integer\n  },\n  \"VideoDescriptions\": [\n    {\n      \"CodecSettings\": {\n        \"FrameCaptureSettings\": {\n          \"CaptureInterval\": integer,\n          \"CaptureIntervalUnits\": \"MILLISECONDS\"|\"SECONDS\"\n        },\n        \"H264Settings\": {\n          \"AdaptiveQuantization\": \"AUTO\"|\"HIGH\"|\"HIGHER\"|\"LOW\"|\"MAX\"|\"MEDIUM\"|\"OFF\",\n          \"AfdSignaling\": \"AUTO\"|\"FIXED\"|\"NONE\",\n          \"Bitrate\": integer,\n          \"BufFillPct\": integer,\n          \"BufSize\": integer,\n          \"ColorMetadata\": \"IGNORE\"|\"INSERT\",\n          \"ColorSpaceSettings\": {\n            \"ColorSpacePassthroughSettings\": {\n\n            },\n            \"Rec601Settings\": {\n\n            },\n            \"Rec709Settings\": {\n\n            }\n          },\n          \"EntropyEncoding\": \"CABAC\"|\"CAVLC\",\n          \"FilterSettings\": {\n            \"TemporalFilterSettings\": {\n              \"PostFilterSharpening\": \"AUTO\"|\"DISABLED\"|\"ENABLED\",\n              \"Strength\": \"AUTO\"|\"STRENGTH_1\"|\"STRENGTH_2\"|\"STRENGTH_3\"|\"STRENGTH_4\"|\"STRENGTH_5\"|\"STRENGTH_6\"|\"STRENGTH_7\"|\"STRENGTH_8\"|\"STRENGTH_9\"|\"STRENGTH_10\"|\"STRENGTH_11\"|\"STRENGTH_12\"|\"STRENGTH_13\"|\"STRENGTH_14\"|\"STRENGTH_15\"|\"STRENGTH_16\"\n            }\n          },\n          \"FixedAfd\": \"AFD_0000\"|\"AFD_0010\"|\"AFD_0011\"|\"AFD_0100\"|\"AFD_1000\"|\"AFD_1001\"|\"AFD_1010\"|\"AFD_1011\"|\"AFD_1101\"|\"AFD_1110\"|\"AFD_1111\",\n          \"FlickerAq\": \"DISABLED\"|\"ENABLED\",\n          \"ForceFieldPictures\": \"DISABLED\"|\"ENABLED\",\n          \"FramerateControl\": \"INITIALIZE_FROM_SOURCE\"|\"SPECIFIED\",\n          \"FramerateDenominator\": integer,\n          \"FramerateNumerator\": integer,\n          \"GopBReference\": \"DISABLED\"|\"ENABLED\",\n          \"GopClosedCadence\": integer,\n          \"GopNumBFrames\": integer,\n          \"GopSize\": double,\n          \"GopSizeUnits\": \"FRAMES\"|\"SECONDS\",\n          \"Level\": \"H264_LEVEL_1\"|\"H264_LEVEL_1_1\"|\"H264_LEVEL_1_2\"|\"H264_LEVEL_1_3\"|\"H264_LEVEL_2\"|\"H264_LEVEL_2_1\"|\"H264_LEVEL_2_2\"|\"H264_LEVEL_3\"|\"H264_LEVEL_3_1\"|\"H264_LEVEL_3_2\"|\"H264_LEVEL_4\"|\"H264_LEVEL_4_1\"|\"H264_LEVEL_4_2\"|\"H264_LEVEL_5\"|\"H264_LEVEL_5_1\"|\"H264_LEVEL_5_2\"|\"H264_LEVEL_AUTO\",\n          \"LookAheadRateControl\": \"HIGH\"|\"LOW\"|\"MEDIUM\",\n          \"MaxBitrate\": integer,\n          \"MinIInterval\": integer,\n          \"NumRefFrames\": integer,\n          \"ParControl\": \"INITIALIZE_FROM_SOURCE\"|\"SPECIFIED\",\n          \"ParDenominator\": integer,\n          \"ParNumerator\": integer,\n          \"Profile\": \"BASELINE\"|\"HIGH\"|\"HIGH_10BIT\"|\"HIGH_422\"|\"HIGH_422_10BIT\"|\"MAIN\",\n          \"QualityLevel\": \"ENHANCED_QUALITY\"|\"STANDARD_QUALITY\",\n          \"QvbrQualityLevel\": integer,\n          \"RateControlMode\": \"CBR\"|\"MULTIPLEX\"|\"QVBR\"|\"VBR\",\n          \"ScanType\": \"INTERLACED\"|\"PROGRESSIVE\",\n          \"SceneChangeDetect\": \"DISABLED\"|\"ENABLED\",\n          \"Slices\": integer,\n          \"Softness\": integer,\n          \"SpatialAq\": \"DISABLED\"|\"ENABLED\",\n          \"SubgopLength\": \"DYNAMIC\"|\"FIXED\",\n          \"Syntax\": \"DEFAULT\"|\"RP2027\",\n          \"TemporalAq\": \"DISABLED\"|\"ENABLED\",\n          \"TimecodeInsertion\": \"DISABLED\"|\"PIC_TIMING_SEI\"\n        },\n        \"H265Settings\": {\n          \"AdaptiveQuantization\": \"AUTO\"|\"HIGH\"|\"HIGHER\"|\"LOW\"|\"MAX\"|\"MEDIUM\"|\"OFF\",\n          \"AfdSignaling\": \"AUTO\"|\"FIXED\"|\"NONE\",\n          \"AlternativeTransferFunction\": \"INSERT\"|\"OMIT\",\n          \"Bitrate\": integer,\n          \"BufSize\": integer,\n          \"ColorMetadata\": \"IGNORE\"|\"INSERT\",\n          \"ColorSpaceSettings\": {\n            \"ColorSpacePassthroughSettings\": {\n\n            },\n            \"Hdr10Settings\": {\n              \"MaxCll\": integer,\n              \"MaxFall\": integer\n            },\n            \"Rec601Settings\": {\n\n            },\n            \"Rec709Settings\": {\n\n            }\n          },\n          \"FilterSettings\": {\n            \"TemporalFilterSettings\": {\n              \"PostFilterSharpening\": \"AUTO\"|\"DISABLED\"|\"ENABLED\",\n              \"Strength\": \"AUTO\"|\"STRENGTH_1\"|\"STRENGTH_2\"|\"STRENGTH_3\"|\"STRENGTH_4\"|\"STRENGTH_5\"|\"STRENGTH_6\"|\"STRENGTH_7\"|\"STRENGTH_8\"|\"STRENGTH_9\"|\"STRENGTH_10\"|\"STRENGTH_11\"|\"STRENGTH_12\"|\"STRENGTH_13\"|\"STRENGTH_14\"|\"STRENGTH_15\"|\"STRENGTH_16\"\n            }\n          },\n          \"FixedAfd\": \"AFD_0000\"|\"AFD_0010\"|\"AFD_0011\"|\"AFD_0100\"|\"AFD_1000\"|\"AFD_1001\"|\"AFD_1010\"|\"AFD_1011\"|\"AFD_1101\"|\"AFD_1110\"|\"AFD_1111\",\n          \"FlickerAq\": \"DISABLED\"|\"ENABLED\",\n          \"FramerateDenominator\": integer,\n          \"FramerateNumerator\": integer,\n          \"GopClosedCadence\": integer,\n          \"GopSize\": double,\n          \"GopSizeUnits\": \"FRAMES\"|\"SECONDS\",\n          \"Level\": \"H265_LEVEL_1\"|\"H265_LEVEL_2\"|\"H265_LEVEL_2_1\"|\"H265_LEVEL_3\"|\"H265_LEVEL_3_1\"|\"H265_LEVEL_4\"|\"H265_LEVEL_4_1\"|\"H265_LEVEL_5\"|\"H265_LEVEL_5_1\"|\"H265_LEVEL_5_2\"|\"H265_LEVEL_6\"|\"H265_LEVEL_6_1\"|\"H265_LEVEL_6_2\"|\"H265_LEVEL_AUTO\",\n          \"LookAheadRateControl\": \"HIGH\"|\"LOW\"|\"MEDIUM\",\n          \"MaxBitrate\": integer,\n          \"MinIInterval\": integer,\n          \"ParDenominator\": integer,\n          \"ParNumerator\": integer,\n          \"Profile\": \"MAIN\"|\"MAIN_10BIT\",\n          \"QvbrQualityLevel\": integer,\n          \"RateControlMode\": \"CBR\"|\"MULTIPLEX\"|\"QVBR\",\n          \"ScanType\": \"INTERLACED\"|\"PROGRESSIVE\",\n          \"SceneChangeDetect\": \"DISABLED\"|\"ENABLED\",\n          \"Slices\": integer,\n          \"Tier\": \"HIGH\"|\"MAIN\",\n          \"TimecodeInsertion\": \"DISABLED\"|\"PIC_TIMING_SEI\"\n        },\n        \"Mpeg2Settings\": {\n          \"AdaptiveQuantization\": \"AUTO\"|\"HIGH\"|\"LOW\"|\"MEDIUM\"|\"OFF\",\n          \"AfdSignaling\": \"AUTO\"|\"FIXED\"|\"NONE\",\n          \"ColorMetadata\": \"IGNORE\"|\"INSERT\",\n          \"ColorSpace\": \"AUTO\"|\"PASSTHROUGH\",\n          \"DisplayAspectRatio\": \"DISPLAYRATIO16X9\"|\"DISPLAYRATIO4X3\",\n          \"FilterSettings\": {\n            \"TemporalFilterSettings\": {\n              \"PostFilterSharpening\": \"AUTO\"|\"DISABLED\"|\"ENABLED\",\n              \"Strength\": \"AUTO\"|\"STRENGTH_1\"|\"STRENGTH_2\"|\"STRENGTH_3\"|\"STRENGTH_4\"|\"STRENGTH_5\"|\"STRENGTH_6\"|\"STRENGTH_7\"|\"STRENGTH_8\"|\"STRENGTH_9\"|\"STRENGTH_10\"|\"STRENGTH_11\"|\"STRENGTH_12\"|\"STRENGTH_13\"|\"STRENGTH_14\"|\"STRENGTH_15\"|\"STRENGTH_16\"\n            }\n          },\n          \"FixedAfd\": \"AFD_0000\"|\"AFD_0010\"|\"AFD_0011\"|\"AFD_0100\"|\"AFD_1000\"|\"AFD_1001\"|\"AFD_1010\"|\"AFD_1011\"|\"AFD_1101\"|\"AFD_1110\"|\"AFD_1111\",\n          \"FramerateDenominator\": integer,\n          \"FramerateNumerator\": integer,\n          \"GopClosedCadence\": integer,\n          \"GopNumBFrames\": integer,\n          \"GopSize\": double,\n          \"GopSizeUnits\": \"FRAMES\"|\"SECONDS\",\n          \"ScanType\": \"INTERLACED\"|\"PROGRESSIVE\",\n          \"SubgopLength\": \"DYNAMIC\"|\"FIXED\",\n          \"TimecodeInsertion\": \"DISABLED\"|\"GOP_TIMECODE\"\n        }\n      },\n      \"Height\": integer,\n      \"Name\": \"string\",\n      \"RespondToAfd\": \"NONE\"|\"PASSTHROUGH\"|\"RESPOND\",\n      \"ScalingBehavior\": \"DEFAULT\"|\"STRETCH_TO_OUTPUT\",\n      \"Sharpness\": integer,\n      \"Width\": integer\n    }\n    ...\n  ]\n}\n\n\n--input-attachments (list) Placeholder documentation for __listOfInputAttachment(structure)\n\nPlaceholder documentation for InputAttachment\n\nAutomaticInputFailoverSettings -> (structure)\n\nUser-specified settings for defining what the conditions are for declaring the input unhealthy and failing over to a different input.\n\nErrorClearTimeMsec -> (integer)\n\nThis clear time defines the requirement a recovered input must meet to be considered healthy. The input must have no failover conditions for this length of time. Enter a time in milliseconds. This value is particularly important if the input_preference for the failover pair is set to PRIMARY_INPUT_PREFERRED, because after this time, MediaLive will switch back to the primary input.\n\nFailoverConditions -> (list)\n\nA list of failover conditions. If any of these conditions occur, MediaLive will perform a failover to the other input.\n\n(structure)\n\nFailover Condition settings. There can be multiple failover conditions inside AutomaticInputFailoverSettings.\n\nFailoverConditionSettings -> (structure)\n\nFailover condition type-specific settings.\n\nAudioSilenceSettings -> (structure)\n\nMediaLive will perform a failover if the specified audio selector is silent for the specified period.\n\nAudioSelectorName -> (string)\n\nThe name of the audio selector in the input that MediaLive should monitor to detect silence. Select your most important rendition. If you didn’t create an audio selector in this input, leave blank.\n\nAudioSilenceThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be silent before automatic input failover occurs. Silence is defined as audio loss or audio quieter than -50 dBFS.\n\nInputLossSettings -> (structure)\n\nMediaLive will perform a failover if content is not detected in this input for the specified period.\n\nInputLossThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that no input is detected. After that time, an input failover will occur.\n\nVideoBlackSettings -> (structure)\n\nMediaLive will perform a failover if content is considered black for the specified period.\n\nBlackDetectThreshold -> (double)\n\nA value used in calculating the threshold below which MediaLive considers a pixel to be ‘black’. For the input to be considered black, every pixel in a frame must be below this threshold. The threshold is calculated as a percentage (expressed as a decimal) of white. Therefore .1 means 10% white (or 90% black). Note how the formula works for any color depth. For example, if you set this field to 0.1 in 10-bit color depth: (1023*0.1=102.3), which means a pixel value of 102 or less is ‘black’. If you set this field to .1 in an 8-bit color depth: (255*0.1=25.5), which means a pixel value of 25 or less is ‘black’. The range is 0.0 to 1.0, with any number of decimal places.\n\nVideoBlackThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be black before automatic input failover occurs.\n\nInputPreference -> (string)\n\nInput preference when deciding which input to make active when a previously failed input has recovered.\n\nSecondaryInputId -> (string)\n\nThe input ID of the secondary input in the automatic input failover pair.\n\nInputAttachmentName -> (string)\n\nUser-specified name for the attachment. This is required if the user wants to use this input in an input switch action.\n\nInputId -> (string)\n\nThe ID of the input\n\nInputSettings -> (structure)\n\nSettings of an input (caption selector, etc.)\n\nAudioSelectors -> (list)\n\nUsed to select the audio stream to decode for inputs that have multiple available.\n\n(structure)\n\nAudio Selector\n\nName -> (string)\n\nThe name of this AudioSelector. AudioDescriptions will use this name to uniquely identify this Selector. Selector names should be unique per input.\n\nSelectorSettings -> (structure)\n\nThe audio selector settings.\n\nAudioHlsRenditionSelection -> (structure)\n\nAudio Hls Rendition Selection\n\nGroupId -> (string)\n\nSpecifies the GROUP-ID in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nName -> (string)\n\nSpecifies the NAME in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nAudioLanguageSelection -> (structure)\n\nAudio Language Selection\n\nLanguageCode -> (string)\n\nSelects a specific three-letter language code from within an audio source.\n\nLanguageSelectionPolicy -> (string)\n\nWhen set to “strict”, the transport stream demux strictly identifies audio streams by their language descriptor. If a PMT update occurs such that an audio stream matching the initially selected language is no longer present then mute will be encoded until the language returns. If “loose”, then on a PMT update the demux will choose another audio stream in the program with the same stream type if it can’t find one with the same language.\n\nAudioPidSelection -> (structure)\n\nAudio Pid Selection\n\nPid -> (integer)\n\nSelects a specific PID from within a source.\n\nAudioTrackSelection -> (structure)\n\nAudio Track Selection\n\nTracks -> (list)\n\nSelects one or more unique audio tracks from within a source.\n\n(structure)\n\nAudio Track\n\nTrack -> (integer)\n\n1-based integer value that maps to a specific audio track\n\nCaptionSelectors -> (list)\n\nUsed to select the caption input to use for inputs that have multiple available.\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nLanguageCode -> (string)\n\nWhen specified this field indicates the three letter language code of the caption track to extract from the source.\n\nName -> (string)\n\nName identifier for a caption selector. This name is used to associate this caption selector with one or more caption descriptions. Names must be unique within an event.\n\nSelectorSettings -> (structure)\n\nCaption selector settings.\n\nAncillarySourceSettings -> (structure)\n\nAncillary Source Settings\n\nSourceAncillaryChannelNumber -> (integer)\n\nSpecifies the number (1 to 4) of the captions channel you want to extract from the ancillary captions. If you plan to convert the ancillary captions to another format, complete this field. If you plan to choose Embedded as the captions destination in the output (to pass through all the channels in the ancillary captions), leave this field blank because MediaLive ignores the field.\n\nAribSourceSettings -> (structure)\n\nArib Source Settings\n\nDvbSubSourceSettings -> (structure)\n\nDvb Sub Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nWhen using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through, regardless of selectors.\n\nEmbeddedSourceSettings -> (structure)\n\nEmbedded Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nScte20Detection -> (string)\n\nSet to “auto” to handle streams with intermittent and/or non-aligned SCTE-20 and Embedded captions.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nSource608TrackNumber -> (integer)\n\nThis field is unused and deprecated.\n\nScte20SourceSettings -> (structure)\n\nScte20 Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nScte27SourceSettings -> (structure)\n\nScte27 Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nThe pid field is used in conjunction with the caption selector languageCode field as follows: - Specify PID and Language: Extracts captions from that PID; the language is “informational”. - Specify PID and omit Language: Extracts the specified PID. - Omit PID and specify Language: Extracts the specified language, whichever PID that happens to be. - Omit PID and omit Language: Valid only if source is DVB-Sub that is being passed through; all languages will be passed through.\n\nTeletextSourceSettings -> (structure)\n\nTeletext Source Settings\n\nOutputRectangle -> (structure)\n\nOptionally defines a region where TTML style captions will be displayed\n\nHeight -> (double)\n\nSee the description in leftOffset. For height, specify the entire height of the rectangle as a percentage of the underlying frame height. For example, “80” means the rectangle height is 80% of the underlying frame height. The topOffset and rectangleHeight must add up to 100% or less. This field corresponds to tts:extent - Y in the TTML standard.\n\nLeftOffset -> (double)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. (Make sure to leave the default if you don’t have either of these formats in the output.) You can define a display rectangle for the captions that is smaller than the underlying video frame. You define the rectangle by specifying the position of the left edge, top edge, bottom edge, and right edge of the rectangle, all within the underlying video frame. The units for the measurements are percentages. If you specify a value for one of these fields, you must specify a value for all of them. For leftOffset, specify the position of the left edge of the rectangle, as a percentage of the underlying frame width, and relative to the left edge of the frame. For example, “10” means the measurement is 10% of the underlying frame width. The rectangle left edge starts at that position from the left edge of the frame. This field corresponds to tts:origin - X in the TTML standard.\n\nTopOffset -> (double)\n\nSee the description in leftOffset. For topOffset, specify the position of the top edge of the rectangle, as a percentage of the underlying frame height, and relative to the top edge of the frame. For example, “10” means the measurement is 10% of the underlying frame height. The rectangle top edge starts at that position from the top edge of the frame. This field corresponds to tts:origin - Y in the TTML standard.\n\nWidth -> (double)\n\nSee the description in leftOffset. For width, specify the entire width of the rectangle as a percentage of the underlying frame width. For example, “80” means the rectangle width is 80% of the underlying frame width. The leftOffset and rectangleWidth must add up to 100% or less. This field corresponds to tts:extent - X in the TTML standard.\n\nPageNumber -> (string)\n\nSpecifies the teletext page number within the data stream from which to extract captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should be specified as a hexadecimal string with no “0x” prefix.\n\nDeblockFilter -> (string)\n\nEnable or disable the deblock filter when filtering.\n\nDenoiseFilter -> (string)\n\nEnable or disable the denoise filter when filtering.\n\nFilterStrength -> (integer)\n\nAdjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).\n\nInputFilter -> (string)\n\nTurns on the filter for this input. MPEG-2 inputs have the deblocking filter enabled by default. 1) auto - filtering will be applied depending on input type/quality 2) disabled - no filtering will be applied to the input 3) forced - filtering will be applied regardless of input type\n\nNetworkInputSettings -> (structure)\n\nInput settings.\n\nHlsInputSettings -> (structure)\n\nSpecifies HLS input settings when the uri is for a HLS manifest.\n\nBandwidth -> (integer)\n\nWhen specified the HLS stream with the m3u8 BANDWIDTH that most closely matches this value will be chosen, otherwise the highest bandwidth stream in the m3u8 will be chosen. The bitrate is specified in bits per second, as in an HLS manifest.\n\nBufferSegments -> (integer)\n\nWhen specified, reading of the HLS input will begin this many buffer segments from the end (most recently written segment). When not specified, the HLS input will begin with the first segment specified in the m3u8.\n\nRetries -> (integer)\n\nThe number of consecutive times that attempts to read a manifest or segment must fail before the input is considered unavailable.\n\nRetryInterval -> (integer)\n\nThe number of seconds between retries when an attempt to read a manifest or segment fails.\n\nScte35Source -> (string)\n\nIdentifies the source for the SCTE-35 messages that MediaLive will ingest. Messages can be ingested from the content segments (in the stream) or from tags in the playlist (the HLS manifest). MediaLive ignores SCTE-35 information in the source that is not selected.\n\nServerValidation -> (string)\n\nCheck HTTPS server certificates. When set to checkCryptographyOnly, cryptography in the certificate will be checked, but not the server’s name. Certain subdomains (notably S3 buckets that use dots in the bucket name) do not strictly match the corresponding certificate’s wildcard pattern and would otherwise cause the event to error. This setting is ignored for protocols that do not use https.\n\nSmpte2038DataPreference -> (string)\n\nSpecifies whether to extract applicable ancillary data from a SMPTE-2038 source in this input. Applicable data types are captions, timecode, AFD, and SCTE-104 messages. - PREFER: Extract from SMPTE-2038 if present in this input, otherwise extract from another source (if any). - IGNORE: Never extract any ancillary data from SMPTE-2038.\n\nSourceEndBehavior -> (string)\n\nLoop input if it is a file. This allows a file input to be streamed indefinitely.\n\nVideoSelector -> (structure)\n\nInforms which video elementary stream to decode for input types that have multiple available.\n\nColorSpace -> (string)\n\nSpecifies the color space of an input. This setting works in tandem with colorSpaceUsage and a video description’s colorSpaceSettingsChoice to determine if any conversion will be performed.\n\nColorSpaceSettings -> (structure)\n\nColor space settings\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nColorSpaceUsage -> (string)\n\nApplies only if colorSpace is a value other than follow. This field controls how the value in the colorSpace field will be used. fallback means that when the input does include color space data, that data will be used, but when the input has no color space data, the value in colorSpace will be used. Choose fallback if your input is sometimes missing color space data, but when it does have color space data, that data is correct. force means to always use the value in colorSpace. Choose force if your input usually has no color space data or might have unreliable color space data.\n\nSelectorSettings -> (structure)\n\nThe video selector settings.\n\nVideoSelectorPid -> (structure)\n\nVideo Selector Pid\n\nPid -> (integer)\n\nSelects a specific PID from within a video source.\n\nVideoSelectorProgramId -> (structure)\n\nVideo Selector Program Id\n\nProgramId -> (integer)\n\nSelects a specific program from within a multi-program transport stream. If the program doesn’t exist, the first program within the transport stream will be selected by default.\n\nJSON Syntax:\n\n[\n  {\n    \"AutomaticInputFailoverSettings\": {\n      \"ErrorClearTimeMsec\": integer,\n      \"FailoverConditions\": [\n        {\n          \"FailoverConditionSettings\": {\n            \"AudioSilenceSettings\": {\n              \"AudioSelectorName\": \"string\",\n              \"AudioSilenceThresholdMsec\": integer\n            },\n            \"InputLossSettings\": {\n              \"InputLossThresholdMsec\": integer\n            },\n            \"VideoBlackSettings\": {\n              \"BlackDetectThreshold\": double,\n              \"VideoBlackThresholdMsec\": integer\n            }\n          }\n        }\n        ...\n      ],\n      \"InputPreference\": \"EQUAL_INPUT_PREFERENCE\"|\"PRIMARY_INPUT_PREFERRED\",\n      \"SecondaryInputId\": \"string\"\n    },\n    \"InputAttachmentName\": \"string\",\n    \"InputId\": \"string\",\n    \"InputSettings\": {\n      \"AudioSelectors\": [\n        {\n          \"Name\": \"string\",\n          \"SelectorSettings\": {\n            \"AudioHlsRenditionSelection\": {\n              \"GroupId\": \"string\",\n              \"Name\": \"string\"\n            },\n            \"AudioLanguageSelection\": {\n              \"LanguageCode\": \"string\",\n              \"LanguageSelectionPolicy\": \"LOOSE\"|\"STRICT\"\n            },\n            \"AudioPidSelection\": {\n              \"Pid\": integer\n            },\n            \"AudioTrackSelection\": {\n              \"Tracks\": [\n                {\n                  \"Track\": integer\n                }\n                ...\n              ]\n            }\n          }\n        }\n        ...\n      ],\n      \"CaptionSelectors\": [\n        {\n          \"LanguageCode\": \"string\",\n          \"Name\": \"string\",\n          \"SelectorSettings\": {\n            \"AncillarySourceSettings\": {\n              \"SourceAncillaryChannelNumber\": integer\n            },\n            \"AribSourceSettings\": {\n\n            },\n            \"DvbSubSourceSettings\": {\n              \"OcrLanguage\": \"DEU\"|\"ENG\"|\"FRA\"|\"NLD\"|\"POR\"|\"SPA\",\n              \"Pid\": integer\n            },\n            \"EmbeddedSourceSettings\": {\n              \"Convert608To708\": \"DISABLED\"|\"UPCONVERT\",\n              \"Scte20Detection\": \"AUTO\"|\"OFF\",\n              \"Source608ChannelNumber\": integer,\n              \"Source608TrackNumber\": integer\n            },\n            \"Scte20SourceSettings\": {\n              \"Convert608To708\": \"DISABLED\"|\"UPCONVERT\",\n              \"Source608ChannelNumber\": integer\n            },\n            \"Scte27SourceSettings\": {\n              \"OcrLanguage\": \"DEU\"|\"ENG\"|\"FRA\"|\"NLD\"|\"POR\"|\"SPA\",\n              \"Pid\": integer\n            },\n            \"TeletextSourceSettings\": {\n              \"OutputRectangle\": {\n                \"Height\": double,\n                \"LeftOffset\": double,\n                \"TopOffset\": double,\n                \"Width\": double\n              },\n              \"PageNumber\": \"string\"\n            }\n          }\n        }\n        ...\n      ],\n      \"DeblockFilter\": \"DISABLED\"|\"ENABLED\",\n      \"DenoiseFilter\": \"DISABLED\"|\"ENABLED\",\n      \"FilterStrength\": integer,\n      \"InputFilter\": \"AUTO\"|\"DISABLED\"|\"FORCED\",\n      \"NetworkInputSettings\": {\n        \"HlsInputSettings\": {\n          \"Bandwidth\": integer,\n          \"BufferSegments\": integer,\n          \"Retries\": integer,\n          \"RetryInterval\": integer,\n          \"Scte35Source\": \"MANIFEST\"|\"SEGMENTS\"\n        },\n        \"ServerValidation\": \"CHECK_CRYPTOGRAPHY_AND_VALIDATE_NAME\"|\"CHECK_CRYPTOGRAPHY_ONLY\"\n      },\n      \"Smpte2038DataPreference\": \"IGNORE\"|\"PREFER\",\n      \"SourceEndBehavior\": \"CONTINUE\"|\"LOOP\",\n      \"VideoSelector\": {\n        \"ColorSpace\": \"FOLLOW\"|\"HDR10\"|\"HLG_2020\"|\"REC_601\"|\"REC_709\",\n        \"ColorSpaceSettings\": {\n          \"Hdr10Settings\": {\n            \"MaxCll\": integer,\n            \"MaxFall\": integer\n          }\n        },\n        \"ColorSpaceUsage\": \"FALLBACK\"|\"FORCE\",\n        \"SelectorSettings\": {\n          \"VideoSelectorPid\": {\n            \"Pid\": integer\n          },\n          \"VideoSelectorProgramId\": {\n            \"ProgramId\": integer\n          }\n        }\n      }\n    }\n  }\n  ...\n]\n\n\n--input-specification (structure) Specification of network and file inputs for this channelCodec -> (string)\n\nInput codec\n\nMaximumBitrate -> (string)\n\nMaximum input bitrate, categorized coarsely\n\nResolution -> (string)\n\nInput resolution, categorized coarsely\n\nShorthand Syntax:\n\nCodec=string,MaximumBitrate=string,Resolution=string\n\n\nJSON Syntax:\n\n{\n  \"Codec\": \"MPEG2\"|\"AVC\"|\"HEVC\",\n  \"MaximumBitrate\": \"MAX_10_MBPS\"|\"MAX_20_MBPS\"|\"MAX_50_MBPS\",\n  \"Resolution\": \"SD\"|\"HD\"|\"UHD\"\n}\n\n\n--log-level (string) The log level to write to CloudWatch Logs.\n\nPossible values:\n\nERROR\n\nWARNING\n\nINFO\n\nDEBUG\n\nDISABLED\n\n--name (string) The name of the channel.\n\n--role-arn (string) An optional Amazon Resource Name (ARN) of the role to assume when running the Channel. If you do not specify this on an update call but the role was previously set that role will be removed.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nChannel -> (structure)\n\nPlaceholder documentation for Channel\n\nArn -> (string)\n\nThe unique arn of the channel.\n\nCdiInputSpecification -> (structure)\n\nSpecification of CDI inputs for this channel\n\nResolution -> (string)\n\nMaximum CDI input resolution\n\nChannelClass -> (string)\n\nThe class for this channel. STANDARD for a channel with two pipelines or SINGLE_PIPELINE for a channel with one pipeline.\n\nDestinations -> (list)\n\nA list of destinations of the channel. For UDP outputs, there is one destination per output. For other types (HLS, for example), there is one destination per packager.\n\n(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nEgressEndpoints -> (list)\n\nThe endpoints where outgoing connections initiate from\n\n(structure)\n\nPlaceholder documentation for ChannelEgressEndpoint\n\nSourceIp -> (string)\n\nPublic IP of where a channel’s output comes from\n\nEncoderSettings -> (structure)\n\nEncoder Settings\n\nAudioDescriptions -> (list)\n\nPlaceholder documentation for __listOfAudioDescription\n\n(structure)\n\nAudio Description\n\nAudioNormalizationSettings -> (structure)\n\nAdvanced audio normalization settings.\n\nAlgorithm -> (string)\n\nAudio normalization algorithm to use. itu17701 conforms to the CALM Act specification, itu17702 conforms to the EBU R-128 specification.\n\nAlgorithmControl -> (string)\n\nWhen set to correctAudio the output audio is corrected using the chosen algorithm. If set to measureOnly, the audio will be measured but not adjusted.\n\nTargetLkfs -> (double)\n\nTarget LKFS(loudness) to adjust volume to. If no value is entered, a default value will be used according to the chosen algorithm. The CALM Act (1770-1) recommends a target of -24 LKFS. The EBU R-128 specification (1770-2) recommends a target of -23 LKFS.\n\nAudioSelectorName -> (string)\n\nThe name of the AudioSelector used as the source for this AudioDescription.\n\nAudioType -> (string)\n\nApplies only if audioTypeControl is useConfigured. The values for audioType are defined in ISO-IEC 13818-1.\n\nAudioTypeControl -> (string)\n\nDetermines how audio type is determined. followInput: If the input contains an ISO 639 audioType, then that value is passed through to the output. If the input contains no ISO 639 audioType, the value in Audio Type is included in the output. useConfigured: The value in Audio Type is included in the output. Note that this field and audioType are both ignored if inputType is broadcasterMixedAd.\n\nAudioWatermarkingSettings -> (structure)\n\nSettings to configure one or more solutions that insert audio watermarks in the audio encode\n\nNielsenWatermarksSettings -> (structure)\n\nSettings to configure Nielsen Watermarks in the audio encode\n\nNielsenCbetSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen CBET\n\nCbetCheckDigitString -> (string)\n\nEnter the CBET check digits to use in the watermark.\n\nCbetStepaside -> (string)\n\nDetermines the method of CBET insertion mode when prior encoding is detected on the same layer.\n\nCsid -> (string)\n\nEnter the CBET Source ID (CSID) to use in the watermark\n\nNielsenDistributionType -> (string)\n\nChoose the distribution types that you want to assign to the watermarks: - PROGRAM_CONTENT - FINAL_DISTRIBUTOR\n\nNielsenNaesIiNwSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen NAES II (N2) and Nielsen NAES VI (NW).\n\nCheckDigitString -> (string)\n\nEnter the check digit string for the watermark\n\nSid -> (double)\n\nEnter the Nielsen Source ID (SID) to include in the watermark\n\nCodecSettings -> (structure)\n\nAudio codec settings.\n\nAacSettings -> (structure)\n\nAac Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid values depend on rate control mode and profile.\n\nCodingMode -> (string)\n\nMono, Stereo, or 5.1 channel layout. Valid values depend on rate control mode and profile. The adReceiverMix setting receives a stereo description plus control track and emits a mono AAC encode of the description track, with control data emitted in the PES header as per ETSI TS 101 154 Annex E.\n\nInputType -> (string)\n\nSet to “broadcasterMixedAd” when input contains pre-mixed main audio + AD (narration) as a stereo pair. The Audio Type field (audioType) will be set to 3, which signals to downstream systems that this stream contains “broadcaster mixed AD”. Note that the input received by the encoder must contain pre-mixed audio; the encoder does not perform the mixing. The values in audioTypeControl and audioType (in AudioDescription) are ignored when set to broadcasterMixedAd. Leave set to “normal” when input does not contain pre-mixed audio + AD.\n\nProfile -> (string)\n\nAAC Profile.\n\nRateControlMode -> (string)\n\nRate Control Mode.\n\nRawFormat -> (string)\n\nSets LATM / LOAS AAC output for raw containers.\n\nSampleRate -> (double)\n\nSample rate in Hz. Valid values depend on rate control mode and profile.\n\nSpec -> (string)\n\nUse MPEG-2 AAC audio instead of MPEG-4 AAC audio for raw or MPEG-2 Transport Stream containers.\n\nVbrQuality -> (string)\n\nVBR Quality Level - Only used if rateControlMode is VBR.\n\nAc3Settings -> (structure)\n\nAc3 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted AC-3 stream. See ATSC A/52-2012 for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital coding mode. Determines number of channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If excluded and input audio is Dolby Digital, dialnorm will be passed through.\n\nDrcProfile -> (string)\n\nIf set to filmStandard, adds dynamic range compression signaling to the output bitstream as defined in the Dolby Digital specification.\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid in codingMode32Lfe mode.\n\nMetadataControl -> (string)\n\nWhen set to “followInput”, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nEac3Settings -> (structure)\n\nEac3 Settings\n\nAttenuationControl -> (string)\n\nWhen set to attenuate3Db, applies a 3 dB attenuation to the surround channels. Only used for 3/2 coding mode.\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted E-AC-3 stream. See ATSC A/52-2012 (Annex E) for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital Plus coding mode. Determines number of channels.\n\nDcFilter -> (string)\n\nWhen set to enabled, activates a DC highpass filter for all input channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If blank and input audio is Dolby Digital Plus, dialnorm will be passed through.\n\nDrcLine -> (string)\n\nSets the Dolby dynamic range compression profile.\n\nDrcRf -> (string)\n\nSets the profile for heavy Dolby dynamic range compression, ensures that the instantaneous signal peaks do not exceed specified levels.\n\nLfeControl -> (string)\n\nWhen encoding 3/2 audio, setting to lfe enables the LFE channel\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid with codingMode32 coding mode.\n\nLoRoCenterMixLevel -> (double)\n\nLeft only/Right only center mix level. Only used for 3/2 coding mode.\n\nLoRoSurroundMixLevel -> (double)\n\nLeft only/Right only surround mix level. Only used for 3/2 coding mode.\n\nLtRtCenterMixLevel -> (double)\n\nLeft total/Right total center mix level. Only used for 3/2 coding mode.\n\nLtRtSurroundMixLevel -> (double)\n\nLeft total/Right total surround mix level. Only used for 3/2 coding mode.\n\nMetadataControl -> (string)\n\nWhen set to followInput, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nPassthroughControl -> (string)\n\nWhen set to whenPossible, input DD+ audio will be passed through if it is present on the input. This detection is dynamic over the life of the transcode. Inputs that alternate between DD+ and non-DD+ content will have a consistent DD+ output as the system alternates between passthrough and encoding.\n\nPhaseControl -> (string)\n\nWhen set to shift90Degrees, applies a 90-degree phase shift to the surround channels. Only used for 3/2 coding mode.\n\nStereoDownmix -> (string)\n\nStereo downmix preference. Only used for 3/2 coding mode.\n\nSurroundExMode -> (string)\n\nWhen encoding 3/2 audio, sets whether an extra center back surround channel is matrix encoded into the left and right surround channels.\n\nSurroundMode -> (string)\n\nWhen encoding 2/0 audio, sets whether Dolby Surround is matrix encoded into the two channels.\n\nMp2Settings -> (structure)\n\nMp2 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second.\n\nCodingMode -> (string)\n\nThe MPEG2 Audio coding mode. Valid values are codingMode10 (for mono) or codingMode20 (for stereo).\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nPassThroughSettings -> (structure)\n\nPass Through Settings\n\nWavSettings -> (structure)\n\nWav Settings\n\nBitDepth -> (double)\n\nBits per sample.\n\nCodingMode -> (string)\n\nThe audio coding mode for the WAV audio. The mode determines the number of channels in the audio.\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nLanguageCode -> (string)\n\nRFC 5646 language code representing the language of the audio output track. Only used if languageControlMode is useConfigured, or there is no ISO 639 language code specified in the input.\n\nLanguageCodeControl -> (string)\n\nChoosing followInput will cause the ISO 639 language code of the output to follow the ISO 639 language code of the input. The languageCode will be used when useConfigured is set, or when followInput is selected but there is no ISO 639 language code specified by the input.\n\nName -> (string)\n\nThe name of this AudioDescription. Outputs will use this name to uniquely identify this AudioDescription. Description names should be unique within this Live Event.\n\nRemixSettings -> (structure)\n\nSettings that control how input audio channels are remixed into the output audio channels.\n\nChannelMappings -> (list)\n\nMapping of input channels to output channels, with appropriate gain adjustments.\n\n(structure)\n\nAudio Channel Mapping\n\nInputChannelLevels -> (list)\n\nIndices and gain values for each input channel that should be remixed into this output channel.\n\n(structure)\n\nInput Channel Level\n\nGain -> (integer)\n\nRemixing value. Units are in dB and acceptable values are within the range from -60 (mute) and 6 dB.\n\nInputChannel -> (integer)\n\nThe index of the input channel used as a source.\n\nOutputChannel -> (integer)\n\nThe index of the output channel being produced.\n\nChannelsIn -> (integer)\n\nNumber of input channels to be used.\n\nChannelsOut -> (integer)\n\nNumber of output channels to be produced. Valid values: 1, 2, 4, 6, 8\n\nStreamName -> (string)\n\nUsed for MS Smooth and Apple HLS outputs. Indicates the name displayed by the player (eg. English, or Director Commentary).\n\nAvailBlanking -> (structure)\n\nSettings for ad avail blanking.\n\nAvailBlankingImage -> (structure)\n\nBlanking image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when insertion metadata is added.\n\nAvailConfiguration -> (structure)\n\nEvent-wide configuration settings for ad avail insertion.\n\nAvailSettings -> (structure)\n\nAd avail settings.\n\nScte35SpliceInsert -> (structure)\n\nScte35 Splice Insert\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nScte35TimeSignalApos -> (structure)\n\nScte35 Time Signal Apos\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nBlackoutSlate -> (structure)\n\nSettings for blackout slate.\n\nBlackoutSlateImage -> (structure)\n\nBlackout slate image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkEndBlackout -> (string)\n\nSetting to enabled causes the encoder to blackout the video, audio, and captions, and raise the “Network Blackout Image” slate when an SCTE104/35 Network End Segmentation Descriptor is encountered. The blackout will be lifted when the Network Start Segmentation Descriptor is encountered. The Network End and Network Start descriptors must contain a network ID that matches the value entered in “Network ID”.\n\nNetworkEndBlackoutImage -> (structure)\n\nPath to local file to use as Network End Blackout image. Image will be scaled to fill the entire output raster.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkId -> (string)\n\nProvides Network ID that matches EIDR ID format (e.g., “10.XXXX/XXXX-XXXX-XXXX-XXXX-XXXX-C”).\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when indicated by program metadata.\n\nCaptionDescriptions -> (list)\n\nSettings for caption decriptions\n\n(structure)\n\nCaption Description\n\nCaptionSelectorName -> (string)\n\nSpecifies which input caption selector to use as a caption source when generating output captions. This field should match a captionSelector name.\n\nDestinationSettings -> (structure)\n\nAdditional settings for captions destination that depend on the destination type.\n\nAribDestinationSettings -> (structure)\n\nArib Destination Settings\n\nBurnInDestinationSettings -> (structure)\n\nBurn In Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to ‘auto’ fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. All burn-in and DVB-Sub font settings must match.\n\nDvbSubDestinationSettings -> (structure)\n\nDvb Sub Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. This option is not valid for source captions that are STL or 608/embedded. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to auto fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nEbuTtDDestinationSettings -> (structure)\n\nEbu Tt DDestination Settings\n\nCopyrightHolder -> (string)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. Complete this field if you want to include the name of the copyright holder in the copyright metadata tag in the TTML\n\nFillLineGap -> (string)\n\nSpecifies how to handle the gap between the lines (in multi-line captions). - enabled: Fill with the captions background color (as specified in the input captions). - disabled: Leave the gap unfilled.\n\nFontFamily -> (string)\n\nSpecifies the font family to include in the font data attached to the EBU-TT captions. Valid only if styleControl is set to include. If you leave this field empty, the font family is set to “monospaced”. (If styleControl is set to exclude, the font family is always set to “monospaced”.) You specify only the font family. All other style information (color, bold, position and so on) is copied from the input captions. The size is always set to 100% to allow the downstream player to choose the size. - Enter a list of font families, as a comma-separated list of font names, in order of preference. The name can be a font family (such as “Arial”), or a generic font family (such as “serif”), or “default” (to let the downstream player choose the font). - Leave blank to set the family to “monospace”.\n\nStyleControl -> (string)\n\nSpecifies the style information (font color, font position, and so on) to include in the font data that is attached to the EBU-TT captions. - include: Take the style information (font color, font position, and so on) from the source captions and include that information in the font data attached to the EBU-TT captions. This option is valid only if the source captions are Embedded or Teletext. - exclude: In the font data attached to the EBU-TT captions, set the font family to “monospaced”. Do not include any other style information.\n\nEmbeddedDestinationSettings -> (structure)\n\nEmbedded Destination Settings\n\nEmbeddedPlusScte20DestinationSettings -> (structure)\n\nEmbedded Plus Scte20 Destination Settings\n\nRtmpCaptionInfoDestinationSettings -> (structure)\n\nRtmp Caption Info Destination Settings\n\nScte20PlusEmbeddedDestinationSettings -> (structure)\n\nScte20 Plus Embedded Destination Settings\n\nScte27DestinationSettings -> (structure)\n\nScte27 Destination Settings\n\nSmpteTtDestinationSettings -> (structure)\n\nSmpte Tt Destination Settings\n\nTeletextDestinationSettings -> (structure)\n\nTeletext Destination Settings\n\nTtmlDestinationSettings -> (structure)\n\nTtml Destination Settings\n\nStyleControl -> (string)\n\nWhen set to passthrough, passes through style and position information from a TTML-like input source (TTML, SMPTE-TT, CFF-TT) to the CFF-TT output or TTML output.\n\nWebvttDestinationSettings -> (structure)\n\nWebvtt Destination Settings\n\nStyleControl -> (string)\n\nControls whether the color and position of the source captions is passed through to the WebVTT output captions. PASSTHROUGH - Valid only if the source captions are EMBEDDED or TELETEXT. NO_STYLE_DATA - Don’t pass through the style. The output captions will not contain any font styling information.\n\nLanguageCode -> (string)\n\nISO 639-2 three-digit code: http://www.loc.gov/standards/iso639-2/\n\nLanguageDescription -> (string)\n\nHuman readable information to indicate captions available for players (eg. English, or Spanish).\n\nName -> (string)\n\nName of the caption description. Used to associate a caption description with an output. Names must be unique within an event.\n\nFeatureActivations -> (structure)\n\nFeature Activations\n\nInputPrepareScheduleActions -> (string)\n\nEnables the Input Prepare feature. You can create Input Prepare actions in the schedule only if this feature is enabled. If you disable the feature on an existing schedule, make sure that you first delete all input prepare actions from the schedule.\n\nGlobalConfiguration -> (structure)\n\nConfiguration settings that apply to the event as a whole.\n\nInitialAudioGain -> (integer)\n\nValue to set the initial audio gain for the Live Event.\n\nInputEndAction -> (string)\n\nIndicates the action to take when the current input completes (e.g. end-of-file). When switchAndLoopInputs is configured the encoder will restart at the beginning of the first input. When “none” is configured the encoder will transcode either black, a solid color, or a user specified slate images per the “Input Loss Behavior” configuration until the next input switch occurs (which is controlled through the Channel Schedule API).\n\nInputLossBehavior -> (structure)\n\nSettings for system actions when input is lost.\n\nBlackFrameMsec -> (integer)\n\nDocumentation update needed\n\nInputLossImageColor -> (string)\n\nWhen input loss image type is “color” this field specifies the color to use. Value: 6 hex characters representing the values of RGB.\n\nInputLossImageSlate -> (structure)\n\nWhen input loss image type is “slate” these fields specify the parameters for accessing the slate.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nInputLossImageType -> (string)\n\nIndicates whether to substitute a solid color or a slate into the output after input loss exceeds blackFrameMsec.\n\nRepeatFrameMsec -> (integer)\n\nDocumentation update needed\n\nOutputLockingMode -> (string)\n\nIndicates how MediaLive pipelines are synchronized. PIPELINE_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the other. EPOCH_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the Unix epoch.\n\nOutputTimingSource -> (string)\n\nIndicates whether the rate of frames emitted by the Live encoder should be paced by its system clock (which optionally may be locked to another source via NTP) or should be locked to the clock of the source that is providing the input stream.\n\nSupportLowFramerateInputs -> (string)\n\nAdjusts video input buffer for streams with very low video framerates. This is commonly set to enabled for music channels with less than one video frame per second.\n\nMotionGraphicsConfiguration -> (structure)\n\nSettings for motion graphics.\n\nMotionGraphicsInsertion -> (string)\n\nMotion Graphics Insertion\n\nMotionGraphicsSettings -> (structure)\n\nMotion Graphics Settings\n\nHtmlMotionGraphicsSettings -> (structure)\n\nHtml Motion Graphics Settings\n\nNielsenConfiguration -> (structure)\n\nNielsen configuration settings.\n\nDistributorId -> (string)\n\nEnter the Distributor ID assigned to your organization by Nielsen.\n\nNielsenPcmToId3Tagging -> (string)\n\nEnables Nielsen PCM to ID3 tagging\n\nOutputGroups -> (list)\n\nPlaceholder documentation for __listOfOutputGroup\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nName -> (string)\n\nCustom output group name optionally defined by the user. Only letters, numbers, and the underscore character allowed; only 32 characters allowed.\n\nOutputGroupSettings -> (structure)\n\nSettings associated with the output group.\n\nArchiveGroupSettings -> (structure)\n\nArchive Group Settings\n\nArchiveCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nArchiveS3Settings -> (structure)\n\nArchive S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nDestination -> (structure)\n\nA directory and base filename where archive files should be written.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRolloverInterval -> (integer)\n\nNumber of seconds to write to archive file before closing and starting a new one.\n\nFrameCaptureGroupSettings -> (structure)\n\nFrame Capture Group Settings\n\nDestination -> (structure)\n\nThe destination for the frame capture files. Either the URI for an Amazon S3 bucket and object, plus a file name prefix (for example, s3ssl://sportsDelivery/highlights/20180820/curling-) or the URI for a MediaStore container, plus a file name prefix (for example, mediastoressl://sportsDelivery/20180820/curling-). The final file names consist of the prefix from the destination field (for example, “curling-“) + name modifier + the counter (5 digits, starting from 00001) + extension (which is always .jpg). For example, curling-low.00001.jpg\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFrameCaptureCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nFrameCaptureS3Settings -> (structure)\n\nFrame Capture S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsGroupSettings -> (structure)\n\nHls Group Settings\n\nAdMarkers -> (list)\n\nChoose one or more ad marker types to pass SCTE35 signals through to this group of Apple HLS outputs.\n\n(string)\n\nHls Ad Markers\n\nBaseUrlContent -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlContent1 -> (string)\n\nOptional. One value per output group. This field is required only if you are completing Base URL content A, and the downstream system has notified you that the media files for pipeline 1 of all outputs are in a location different from the media files for pipeline 0.\n\nBaseUrlManifest -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlManifest1 -> (string)\n\nOptional. One value per output group. Complete this field only if you are completing Base URL manifest A, and the downstream system has notified you that the child manifest files for pipeline 1 of all outputs are in a location different from the child manifest files for pipeline 0.\n\nCaptionLanguageMappings -> (list)\n\nMapping of up to 4 caption channels to caption languages. Is only meaningful if captionLanguageSetting is set to “insert”.\n\n(structure)\n\nMaps a caption channel to an ISO 693-2 language code (http://www.loc.gov/standards/iso639-2), with an optional description.\n\nCaptionChannel -> (integer)\n\nThe closed caption channel being described by this CaptionLanguageMapping. Each channel mapping must have a unique channel number (maximum of 4)\n\nLanguageCode -> (string)\n\nThree character ISO 639-2 language code (see http://www.loc.gov/standards/iso639-2)\n\nLanguageDescription -> (string)\n\nTextual description of language\n\nCaptionLanguageSetting -> (string)\n\nApplies only to 608 Embedded output captions. insert: Include CLOSED-CAPTIONS lines in the manifest. Specify at least one language in the CC1 Language Code field. One CLOSED-CAPTION line is added for each Language Code you specify. Make sure to specify the languages in the order in which they appear in the original source (if the source is embedded format) or the order of the caption selectors (if the source is other than embedded). Otherwise, languages in the manifest will not match up properly with the output captions. none: Include CLOSED-CAPTIONS=NONE line in the manifest. omit: Omit any CLOSED-CAPTIONS line from the manifest.\n\nClientCache -> (string)\n\nWhen set to “disabled”, sets the #EXT-X-ALLOW-CACHE:no tag in the manifest, which prevents clients from saving media segments for later replay.\n\nCodecSpecification -> (string)\n\nSpecification to use (RFC-6381 or the default RFC-4281) during m3u8 playlist generation.\n\nConstantIv -> (string)\n\nFor use with encryptionType. This is a 128-bit, 16-byte hex value represented by a 32-character text string. If ivSource is set to “explicit” then this parameter is required and is used as the IV for encryption.\n\nDestination -> (structure)\n\nA directory or HTTP destination for the HLS segments, manifest files, and encryption keys (if enabled).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nDirectoryStructure -> (string)\n\nPlace segments in subdirectories.\n\nDiscontinuityTags -> (string)\n\nSpecifies whether to insert EXT-X-DISCONTINUITY tags in the HLS child manifests for this output group. Typically, choose Insert because these tags are required in the manifest (according to the HLS specification) and serve an important purpose. Choose Never Insert only if the downstream system is doing real-time failover (without using the MediaLive automatic failover feature) and only if that downstream system has advised you to exclude the tags.\n\nEncryptionType -> (string)\n\nEncrypts the segments with the given encryption scheme. Exclude this parameter if no encryption is desired.\n\nHlsCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nHlsAkamaiSettings -> (structure)\n\nHls Akamai Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to Akamai. User should contact Akamai to enable this feature.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nSalt -> (string)\n\nSalt for authenticated Akamai.\n\nToken -> (string)\n\nToken parameter for authenticated akamai. If not specified, _gda_ is used.\n\nHlsBasicPutSettings -> (structure)\n\nHls Basic Put Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsMediaStoreSettings -> (structure)\n\nHls Media Store Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nMediaStoreStorageClass -> (string)\n\nWhen set to temporal, output files are stored in non-persistent memory for faster reading and writing.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsS3Settings -> (structure)\n\nHls S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsWebdavSettings -> (structure)\n\nHls Webdav Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to WebDAV.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsId3SegmentTagging -> (string)\n\nState of HLS ID3 Segment Tagging\n\nIFrameOnlyPlaylists -> (string)\n\nDISABLED: Do not create an I-frame-only manifest, but do create the master and media manifests (according to the Output Selection field). STANDARD: Create an I-frame-only manifest for each output that contains video, as well as the other manifests (according to the Output Selection field). The I-frame manifest contains a #EXT-X-I-FRAMES-ONLY tag to indicate it is I-frame only, and one or more #EXT-X-BYTERANGE entries identifying the I-frame position. For example, #EXT-X-BYTERANGE:160364@1461888”\n\nIncompleteSegmentBehavior -> (string)\n\nSpecifies whether to include the final (incomplete) segment in the media output when the pipeline stops producing output because of a channel stop, a channel pause or a loss of input to the pipeline. Auto means that MediaLive decides whether to include the final segment, depending on the channel class and the types of output groups. Suppress means to never include the incomplete segment. We recommend you choose Auto and let MediaLive control the behavior.\n\nIndexNSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the maximum number of segments in the media manifest file. After this maximum, older segments are removed from the media manifest. This number must be smaller than the number in the Keep Segments field.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nIvInManifest -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If set to “include”, IV is listed in the manifest, otherwise the IV is not in the manifest.\n\nIvSource -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If this setting is “followsSegmentNumber”, it will cause the IV to change every segment (to match the segment number). If this is set to “explicit”, you must enter a constantIv value.\n\nKeepSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the number of media segments to retain in the destination directory. This number should be bigger than indexNSegments (Num segments). We recommend (value = (2 x indexNsegments) + 1). If this “keep segments” number is too low, the following might happen: the player is still reading a media manifest file that lists this segment, but that segment has been removed from the destination directory (as directed by indexNSegments). This situation would result in a 404 HTTP error on the player.\n\nKeyFormat -> (string)\n\nThe value specifies how the key is represented in the resource identified by the URI. If parameter is absent, an implicit value of “identity” is used. A reverse DNS string can also be given.\n\nKeyFormatVersions -> (string)\n\nEither a single positive integer version value or a slash delimited list of version values (1/2/3).\n\nKeyProviderSettings -> (structure)\n\nThe key provider settings.\n\nStaticKeySettings -> (structure)\n\nStatic Key Settings\n\nKeyProviderServer -> (structure)\n\nThe URL of the license server used for protecting content.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nStaticKeyValue -> (string)\n\nStatic key value as a 32 character hexadecimal string.\n\nManifestCompression -> (string)\n\nWhen set to gzip, compresses HLS playlist.\n\nManifestDurationFormat -> (string)\n\nIndicates whether the output manifest should use floating point or integer values for segment duration.\n\nMinSegmentLength -> (integer)\n\nWhen set, minimumSegmentLength is enforced by looking ahead and back within the specified range for a nearby avail and extending the segment size if needed.\n\nMode -> (string)\n\nIf “vod”, all segments are indexed and kept permanently in the destination and manifest. If “live”, only the number segments specified in keepSegments and indexNSegments are kept; newer segments replace older segments, which may prevent players from rewinding all the way to the beginning of the event. VOD mode uses HLS EXT-X-PLAYLIST-TYPE of EVENT while the channel is running, converting it to a “VOD” type manifest on completion of the stream.\n\nOutputSelection -> (string)\n\nMANIFESTS_AND_SEGMENTS: Generates manifests (master manifest, if applicable, and media manifests) for this output group. VARIANT_MANIFESTS_AND_SEGMENTS: Generates media manifests for this output group, but not a master manifest. SEGMENTS_ONLY: Does not generate any manifests for this output group.\n\nProgramDateTime -> (string)\n\nIncludes or excludes EXT-X-PROGRAM-DATE-TIME tag in .m3u8 manifest files. The value is calculated as follows: either the program date and time are initialized using the input timecode source, or the time is initialized using the input timecode source and the date is initialized using the timestampOffset.\n\nProgramDateTimePeriod -> (integer)\n\nPeriod of insertion of EXT-X-PROGRAM-DATE-TIME entry, in seconds.\n\nRedundantManifest -> (string)\n\nENABLED: The master manifest (.m3u8 file) for each pipeline includes information about both pipelines: first its own media files, then the media files of the other pipeline. This feature allows playout device that support stale manifest detection to switch from one manifest to the other, when the current manifest seems to be stale. There are still two destinations and two master manifests, but both master manifests reference the media files from both pipelines. DISABLED: The master manifest (.m3u8 file) for each pipeline includes information about its own pipeline only. For an HLS output group with MediaPackage as the destination, the DISABLED behavior is always followed. MediaPackage regenerates the manifests it serves to players so a redundant manifest from MediaLive is irrelevant.\n\nSegmentLength -> (integer)\n\nLength of MPEG-2 Transport Stream segments to create (in seconds). Note that segments will end on the next keyframe after this number of seconds, so actual segment length may be longer.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSegmentsPerSubdirectory -> (integer)\n\nNumber of segments to write to a subdirectory before starting a new one. directoryStructure must be subdirectoryPerStream for this setting to have an effect.\n\nStreamInfResolution -> (string)\n\nInclude or exclude RESOLUTION attribute for video in EXT-X-STREAM-INF tag of variant manifest.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nTimestampDeltaMilliseconds -> (integer)\n\nProvides an extra millisecond delta offset to fine tune the timestamps.\n\nTsFileMode -> (string)\n\nSEGMENTED_FILES: Emit the program as segments - multiple .ts media files. SINGLE_FILE: Applies only if Mode field is VOD. Emit the program as a single .ts media file. The media manifest includes #EXT-X-BYTERANGE tags to index segments for playback. A typical use for this value is when sending the output to AWS Elemental MediaConvert, which can accept only a single media file. Playback while the channel is running is not guaranteed due to HTTP server caching.\n\nMediaPackageGroupSettings -> (structure)\n\nMedia Package Group Settings\n\nDestination -> (structure)\n\nMediaPackage channel destination.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nMsSmoothGroupSettings -> (structure)\n\nMs Smooth Group Settings\n\nAcquisitionPointId -> (string)\n\nThe ID to include in each message in the sparse track. Ignored if sparseTrackType is NONE.\n\nAudioOnlyTimecodeControl -> (string)\n\nIf set to passthrough for an audio-only MS Smooth output, the fragment absolute time will be set to the current timecode. This option does not write timecodes to the audio elementary stream.\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the https certificate chain to a trusted Certificate Authority (CA). This will cause https outputs to self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the IIS server if the connection is lost. Content will be cached during this time and the cache will be be delivered to the IIS server once the connection is re-established.\n\nDestination -> (structure)\n\nSmooth Streaming publish point on an IIS server. Elemental Live acts as a “Push” encoder to IIS.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nEventId -> (string)\n\nMS Smooth event ID to be sent to the IIS server. Should only be specified if eventIdMode is set to useConfigured.\n\nEventIdMode -> (string)\n\nSpecifies whether or not to send an event ID to the IIS server. If no event ID is sent and the same Live Event is used without changing the publishing point, clients might see cached video from the previous run. Options: - “useConfigured” - use the value provided in eventId - “useTimestamp” - generate and send an event ID based on the current timestamp - “noEventId” - do not send an event ID to the IIS server.\n\nEventStopBehavior -> (string)\n\nWhen set to sendEos, send EOS signal to IIS server when stopping the event\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nFragmentLength -> (integer)\n\nLength of mp4 fragments to generate (in seconds). Fragment length must be compatible with GOP size and framerate.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nRestartDelay -> (integer)\n\nNumber of seconds before initiating a restart due to output failure, due to exhausting the numRetries on one segment, or exceeding filecacheDuration.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSendDelayMs -> (integer)\n\nNumber of milliseconds to delay the output from the second pipeline.\n\nSparseTrackType -> (string)\n\nIdentifies the type of data to place in the sparse track: - SCTE35: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame to start a new segment. - SCTE35_WITHOUT_SEGMENTATION: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame but don’t start a new segment. - NONE: Don’t generate a sparse track for any outputs in this output group.\n\nStreamManifestBehavior -> (string)\n\nWhen set to send, send stream manifest so publishing point doesn’t start until all streams start.\n\nTimestampOffset -> (string)\n\nTimestamp offset for the event. Only used if timestampOffsetMode is set to useConfiguredOffset.\n\nTimestampOffsetMode -> (string)\n\nType of timestamp date offset to use. - useEventStartDate: Use the date the event was started as the offset - useConfiguredOffset: Use an explicitly configured date as the offset\n\nMultiplexGroupSettings -> (structure)\n\nMultiplex Group Settings\n\nRtmpGroupSettings -> (structure)\n\nRtmp Group Settings\n\nAdMarkers -> (list)\n\nChoose the ad marker type for this output group. MediaLive will create a message based on the content of each SCTE-35 message, format it for that marker type, and insert it in the datastream.\n\n(string)\n\nRtmp Ad Markers\n\nAuthenticationScheme -> (string)\n\nAuthentication scheme to use when connecting with CDN\n\nCacheFullBehavior -> (string)\n\nControls behavior when content cache fills up. If remote origin server stalls the RTMP connection and does not accept content fast enough the ‘Media Cache’ will fill up. When the cache reaches the duration specified by cacheLength the cache will stop accepting new content. If set to disconnectImmediately, the RTMP output will force a disconnect. Clear the media cache, and reconnect after restartDelay seconds. If set to waitForServer, the RTMP output will wait up to 5 minutes to allow the origin server to begin accepting data again.\n\nCacheLength -> (integer)\n\nCache length, in seconds, is used to calculate buffer size.\n\nCaptionData -> (string)\n\nControls the types of data that passes to onCaptionInfo outputs. If set to ‘all’ then 608 and 708 carried DTVCC data will be passed. If set to ‘field1AndField2608’ then DTVCC data will be stripped out, but 608 data from both fields will be passed. If set to ‘field1608’ then only the data carried in 608 from field 1 video will be passed.\n\nInputLossAction -> (string)\n\nControls the behavior of this RTMP group if input becomes unavailable. - emitOutput: Emit a slate until input returns. - pauseOutput: Stop transmitting data until input returns. This does not close the underlying RTMP connection.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nUdpGroupSettings -> (structure)\n\nUdp Group Settings\n\nInputLossAction -> (string)\n\nSpecifies behavior of last resort when input video is lost, and no more backup inputs are available. When dropTs is selected the entire transport stream will stop being emitted. When dropProgram is selected the program can be dropped from the transport stream (and replaced with null packets to meet the TS bitrate requirement). Or, when emitProgram is chosen the transport stream will continue to be produced normally with repeat frames, black frames, or slate frames substituted for the absent input video.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nOutputs -> (list)\n\nPlaceholder documentation for __listOfOutput\n\n(structure)\n\nOutput settings. There can be multiple outputs within a group.\n\nAudioDescriptionNames -> (list)\n\nThe names of the AudioDescriptions used as audio sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nCaptionDescriptionNames -> (list)\n\nThe names of the CaptionDescriptions used as caption sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nOutputName -> (string)\n\nThe name used to identify an output.\n\nOutputSettings -> (structure)\n\nOutput type-specific settings.\n\nArchiveOutputSettings -> (structure)\n\nArchive Output Settings\n\nContainerSettings -> (structure)\n\nSettings specific to the container type of the file.\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nRawSettings -> (structure)\n\nRaw Settings\n\nExtension -> (string)\n\nOutput file extension. If excluded, this will be auto-selected from the container type.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nFrameCaptureOutputSettings -> (structure)\n\nFrame Capture Output Settings\n\nNameModifier -> (string)\n\nRequired if the output group contains more than one output. This modifier forms part of the output file name.\n\nHlsOutputSettings -> (structure)\n\nHls Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nHlsSettings -> (structure)\n\nSettings regarding the underlying stream. These settings are different for audio-only outputs.\n\nAudioOnlyHlsSettings -> (structure)\n\nAudio Only Hls Settings\n\nAudioGroupId -> (string)\n\nSpecifies the group to which the audio Rendition belongs.\n\nAudioOnlyImage -> (structure)\n\nOptional. Specifies the .jpg or .png image to use as the cover art for an audio-only output. We recommend a low bit-size file because the image increases the output audio bandwidth. The image is attached to the audio as an ID3 tag, frame type APIC, picture type 0x10, as per the “ID3 tag version 2.4.0 - Native Frames” standard.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nAudioTrackType -> (string)\n\nFour types of audio-only tracks are supported: Audio-Only Variant Stream The client can play back this audio-only stream instead of video in low-bandwidth scenarios. Represented as an EXT-X-STREAM-INF in the HLS manifest. Alternate Audio, Auto Select, Default Alternate rendition that the client should try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=YES, AUTOSELECT=YES Alternate Audio, Auto Select, Not Default Alternate rendition that the client may try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=YES Alternate Audio, not Auto Select Alternate rendition that the client will not try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=NO\n\nSegmentType -> (string)\n\nSpecifies the segment type.\n\nFmp4HlsSettings -> (structure)\n\nFmp4 Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nFrameCaptureHlsSettings -> (structure)\n\nFrame Capture Hls Settings\n\nStandardHlsSettings -> (structure)\n\nStandard Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nM3u8Settings -> (structure)\n\nSettings information for the .m3u8 container\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values.\n\nEcmPid -> (string)\n\nThis parameter is unused and deprecated.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock References (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value.\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nScte35Behavior -> (string)\n\nIf set to passthrough, passes any SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Accepts “Format Identifiers”:#formatIdentifierParameters.\n\nSegmentModifier -> (string)\n\nString concatenated to end of segment filenames.\n\nMediaPackageOutputSettings -> (structure)\n\nMedia Package Output Settings\n\nMsSmoothOutputSettings -> (structure)\n\nMs Smooth Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nMultiplexOutputSettings -> (structure)\n\nMultiplex Output Settings\n\nDestination -> (structure)\n\nDestination is a Multiplex.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRtmpOutputSettings -> (structure)\n\nRtmp Output Settings\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the tls certificate chain to a trusted Certificate Authority (CA). This will cause rtmps outputs with self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying a connection to the Flash Media server if the connection is lost.\n\nDestination -> (structure)\n\nThe RTMP endpoint excluding the stream name (eg. rtmp://host/appname). For connection to Akamai, a username and password must be supplied. URI fields accept format identifiers.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nUdpOutputSettings -> (structure)\n\nUdp Output Settings\n\nBufferMsec -> (integer)\n\nUDP output buffering in milliseconds. Larger values increase latency through the transcoder but simultaneously assist the transcoder in maintaining a constant, low-jitter UDP/RTP output while accommodating clock recovery, input switching, input disruptions, picture reordering, etc.\n\nContainerSettings -> (structure)\n\nUdp Container Settings\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nDestination -> (structure)\n\nDestination address and port number for RTP or UDP packets. Can be unicast or multicast RTP or UDP (eg. rtp://239.10.10.10:5001 or udp://10.100.100.100:5002).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFecOutputSettings -> (structure)\n\nSettings for enabling and adjusting Forward Error Correction on UDP outputs.\n\nColumnDepth -> (integer)\n\nParameter D from SMPTE 2022-1. The height of the FEC protection matrix. The number of transport stream packets per column error correction packet. Must be between 4 and 20, inclusive.\n\nIncludeFec -> (string)\n\nEnables column only or column and row based FEC\n\nRowLength -> (integer)\n\nParameter L from SMPTE 2022-1. The width of the FEC protection matrix. Must be between 1 and 20, inclusive. If only Column FEC is used, then larger values increase robustness. If Row FEC is used, then this is the number of transport stream packets per row error correction packet, and the value must be between 4 and 20, inclusive, if includeFec is columnAndRow. If includeFec is column, this value must be 1 to 20, inclusive.\n\nVideoDescriptionName -> (string)\n\nThe name of the VideoDescription used as the source for this output.\n\nTimecodeConfig -> (structure)\n\nContains settings used to acquire and adjust timecode information from inputs.\n\nSource -> (string)\n\nIdentifies the source for the timecode that will be associated with the events outputs. -Embedded (embedded): Initialize the output timecode with timecode from the the source. If no embedded timecode is detected in the source, the system falls back to using “Start at 0” (zerobased). -System Clock (systemclock): Use the UTC time. -Start at 0 (zerobased): The time of the first frame of the event will be 00:00:00:00.\n\nSyncThreshold -> (integer)\n\nThreshold in frames beyond which output timecode is resynchronized to the input timecode. Discrepancies below this threshold are permitted to avoid unnecessary discontinuities in the output timecode. No timecode sync when this is not specified.\n\nVideoDescriptions -> (list)\n\nPlaceholder documentation for __listOfVideoDescription\n\n(structure)\n\nVideo settings for this stream.\n\nCodecSettings -> (structure)\n\nVideo codec settings.\n\nFrameCaptureSettings -> (structure)\n\nFrame Capture Settings\n\nCaptureInterval -> (integer)\n\nThe frequency at which to capture frames for inclusion in the output. May be specified in either seconds or milliseconds, as specified by captureIntervalUnits.\n\nCaptureIntervalUnits -> (string)\n\nUnit for the frame capture interval.\n\nH264Settings -> (structure)\n\nH264 Settings\n\nAdaptiveQuantization -> (string)\n\nEnables or disables adaptive quantization, which is a technique MediaLive can apply to video on a frame-by-frame basis to produce more compression without losing quality. There are three types of adaptive quantization: flicker, spatial, and temporal. Set the field in one of these ways: Set to Auto. Recommended. For each type of AQ, MediaLive will determine if AQ is needed, and if so, the appropriate strength. Set a strength (a value other than Auto or Disable). This strength will apply to any of the AQ fields that you choose to enable. Set to Disabled to disable all types of adaptive quantization.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufFillPct -> (integer)\n\nPercentage of the buffer that should initially be filled (HRD buffer model).\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nEntropyEncoding -> (string)\n\nEntropy encoding mode. Use cabac (must be in Main or High profile) or cavlc.\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nFlicker AQ makes adjustments within each frame to reduce flicker or ‘pop’ on I-frames. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if flicker AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply flicker AQ using the specified strength. Disabled: MediaLive won’t apply flicker AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply flicker AQ.\n\nForceFieldPictures -> (string)\n\nThis setting applies only when scan type is “interlaced.” It controls whether coding is performed on a field basis or on a frame basis. (When the video is progressive, the coding is always performed on a frame basis.) enabled: Force MediaLive to code on a field basis, so that odd and even sets of fields are coded separately. disabled: Code the two sets of fields separately (on a field basis) or together (on a frame basis using PAFF), depending on what is most appropriate for the content.\n\nFramerateControl -> (string)\n\nThis field indicates how the output video frame rate is specified. If “specified” is selected then the output video frame rate is determined by framerateNumerator and framerateDenominator, else if “initializeFromSource” is selected then the output video frame rate will be set equal to the input video frame rate of the first input.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopBReference -> (string)\n\nDocumentation update needed\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopNumBFrames -> (integer)\n\nNumber of B-frames between reference frames.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.264 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level For VBR: Set the maximum bitrate in order to accommodate expected spikes in the complexity of the video.\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nNumRefFrames -> (integer)\n\nNumber of reference frames to use. The encoder may use more than requested if using B-frames and/or interlaced encoding.\n\nParControl -> (string)\n\nThis field indicates how the output pixel aspect ratio is specified. If “specified” is selected then the output video pixel aspect ratio is determined by parNumerator and parDenominator, else if “initializeFromSource” is selected then the output pixsel aspect ratio will be set equal to the input video pixel aspect ratio of the first input.\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.264 Profile.\n\nQualityLevel -> (string)\n\nLeave as STANDARD_QUALITY or choose a different value (which might result in additional costs to run the channel). - ENHANCED_QUALITY: Produces a slightly better video quality without an increase in the bitrate. Has an effect only when the Rate control mode is QVBR or CBR. If this channel is in a MediaLive multiplex, the value must be ENHANCED_QUALITY. - STANDARD_QUALITY: Valid for any Rate control mode.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. You can set a target quality or you can let MediaLive determine the best quality. To set a target quality, enter values in the QVBR quality level field and the Max bitrate field. Enter values that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M To let MediaLive decide, leave the QVBR quality level field empty, and in Max bitrate enter the maximum rate you want in the video. For more information, see the section called “Video - rate control mode” in the MediaLive user guide\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. VBR: Quality and bitrate vary, depending on the video complexity. Recommended instead of QVBR if you want to maintain a specific average bitrate over the duration of the channel. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection. - On: inserts I-frames when scene change is detected. - Off: does not force an I-frame when scene change is detected.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nSoftness -> (integer)\n\nSoftness. Selects quantizer matrix, larger values reduce high-frequency content in the encoded image. If not set to zero, must be greater than 15.\n\nSpatialAq -> (string)\n\nSpatial AQ makes adjustments within each frame based on spatial variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if spatial AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply spatial AQ using the specified strength. Disabled: MediaLive won’t apply spatial AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply spatial AQ.\n\nSubgopLength -> (string)\n\nIf set to fixed, use gopNumBFrames B-frames per sub-GOP. If set to dynamic, optimize the number of B-frames used for each sub-GOP to improve visual quality.\n\nSyntax -> (string)\n\nProduces a bitstream compliant with SMPTE RP-2027.\n\nTemporalAq -> (string)\n\nTemporal makes adjustments within each frame based on temporal variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if temporal AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply temporal AQ using the specified strength. Disabled: MediaLive won’t apply temporal AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply temporal AQ.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nH265Settings -> (structure)\n\nH265 Settings\n\nAdaptiveQuantization -> (string)\n\nAdaptive quantization. Allows intra-frame quantizers to vary to improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nAlternativeTransferFunction -> (string)\n\nWhether or not EML should insert an Alternative Transfer Function SEI message to support backwards compatibility with non-HDR decoders and displays.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nIf set to enabled, adjust quantization within each frame to reduce flicker or ‘pop’ on I-frames.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.265 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.265 Profile.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. Set values for the QVBR quality level field and Max bitrate field that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nTier -> (string)\n\nH.265 Tier.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nMpeg2Settings -> (structure)\n\nMpeg2 Settings\n\nAdaptiveQuantization -> (string)\n\nChoose Off to disable adaptive quantization. Or choose another value to enable the quantizer and set its strength. The strengths are: Auto, Off, Low, Medium, High. When you enable this field, MediaLive allows intra-frame quantizers to vary, which might improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates the AFD values that MediaLive will write into the video encode. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose AUTO. AUTO: MediaLive will try to preserve the input AFD value (in cases where multiple AFD values are valid). FIXED: MediaLive will use the value you specify in fixedAFD.\n\nColorMetadata -> (string)\n\nSpecifies whether to include the color space metadata. The metadata describes the color space that applies to the video (the colorSpace field). We recommend that you insert the metadata.\n\nColorSpace -> (string)\n\nChoose the type of color space conversion to apply to the output. For detailed information on setting up both the input and the output to obtain the desired color space in the output, see the section on “MediaLive Features - Video - color space” in the MediaLive User Guide. PASSTHROUGH: Keep the color space of the input content - do not convert it. AUTO:Convert all content that is SD to rec 601, and convert all content that is HD to rec 709.\n\nDisplayAspectRatio -> (string)\n\nSets the pixel aspect ratio for the encode.\n\nFilterSettings -> (structure)\n\nOptionally specify a noise reduction filter, which can improve quality of compressed content. If you do not choose a filter, no filter will be applied. TEMPORAL: This filter is useful for both source content that is noisy (when it has excessive digital artifacts) and source content that is clean. When the content is noisy, the filter cleans up the source content before the encoding phase, with these two effects: First, it improves the output video quality because the content has been cleaned up. Secondly, it decreases the bandwidth because MediaLive does not waste bits on encoding noise. When the content is reasonably clean, the filter tends to decrease the bitrate.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nComplete this field only when afdSignaling is set to FIXED. Enter the AFD value (4 bits) to write on all frames of the video encode.\n\nFramerateDenominator -> (integer)\n\ndescription”: “The framerate denominator. For example, 1001. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nFramerateNumerator -> (integer)\n\nThe framerate numerator. For example, 24000. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nGopClosedCadence -> (integer)\n\nMPEG2: default is open GOP.\n\nGopNumBFrames -> (integer)\n\nRelates to the GOP structure. The number of B-frames between reference frames. If you do not know what a B-frame is, use the default.\n\nGopSize -> (double)\n\nRelates to the GOP structure. The GOP size (keyframe interval) in the units specified in gopSizeUnits. If you do not know what GOP is, use the default. If gopSizeUnits is frames, then the gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, the gopSize must be greater than 0, but does not need to be an integer.\n\nGopSizeUnits -> (string)\n\nRelates to the GOP structure. Specifies whether the gopSize is specified in frames or seconds. If you do not plan to change the default gopSize, leave the default. If you specify SECONDS, MediaLive will internally convert the gop size to a frame count.\n\nScanType -> (string)\n\nSet the scan type of the output to PROGRESSIVE or INTERLACED (top field first).\n\nSubgopLength -> (string)\n\nRelates to the GOP structure. If you do not know what GOP is, use the default. FIXED: Set the number of B-frames in each sub-GOP to the value in gopNumBFrames. DYNAMIC: Let MediaLive optimize the number of B-frames in each sub-GOP, to improve visual quality.\n\nTimecodeInsertion -> (string)\n\nDetermines how MediaLive inserts timecodes in the output video. For detailed information about setting up the input and the output for a timecode, see the section on “MediaLive Features - Timecode configuration” in the MediaLive User Guide. DISABLED: do not include timecodes. GOP_TIMECODE: Include timecode metadata in the GOP header.\n\nHeight -> (integer)\n\nOutput video height, in pixels. Must be an even number. For most codecs, you can leave this field and width blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nName -> (string)\n\nThe name of this VideoDescription. Outputs will use this name to uniquely identify this Description. Description names should be unique within this Live Event.\n\nRespondToAfd -> (string)\n\nIndicates how MediaLive will respond to the AFD values that might be in the input video. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose PASSTHROUGH. RESPOND: MediaLive clips the input video using a formula that uses the AFD values (configured in afdSignaling ), the input display aspect ratio, and the output display aspect ratio. MediaLive also includes the AFD values in the output, unless the codec for this encode is FRAME_CAPTURE. PASSTHROUGH: MediaLive ignores the AFD values and does not clip the video. But MediaLive does include the values in the output. NONE: MediaLive does not clip the input video and does not include the AFD values in the output\n\nScalingBehavior -> (string)\n\nSTRETCH_TO_OUTPUT configures the output position to stretch the video to the specified output resolution (height and width). This option will override any position value. DEFAULT may insert black boxes (pillar boxes or letter boxes) around the video to provide the specified output resolution.\n\nSharpness -> (integer)\n\nChanges the strength of the anti-alias filter used for scaling. 0 is the softest setting, 100 is the sharpest. A setting of 50 is recommended for most content.\n\nWidth -> (integer)\n\nOutput video width, in pixels. Must be an even number. For most codecs, you can leave this field and height blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nId -> (string)\n\nThe unique id of the channel.\n\nInputAttachments -> (list)\n\nList of input attachments for channel.\n\n(structure)\n\nPlaceholder documentation for InputAttachment\n\nAutomaticInputFailoverSettings -> (structure)\n\nUser-specified settings for defining what the conditions are for declaring the input unhealthy and failing over to a different input.\n\nErrorClearTimeMsec -> (integer)\n\nThis clear time defines the requirement a recovered input must meet to be considered healthy. The input must have no failover conditions for this length of time. Enter a time in milliseconds. This value is particularly important if the input_preference for the failover pair is set to PRIMARY_INPUT_PREFERRED, because after this time, MediaLive will switch back to the primary input.\n\nFailoverConditions -> (list)\n\nA list of failover conditions. If any of these conditions occur, MediaLive will perform a failover to the other input.\n\n(structure)\n\nFailover Condition settings. There can be multiple failover conditions inside AutomaticInputFailoverSettings.\n\nFailoverConditionSettings -> (structure)\n\nFailover condition type-specific settings.\n\nAudioSilenceSettings -> (structure)\n\nMediaLive will perform a failover if the specified audio selector is silent for the specified period.\n\nAudioSelectorName -> (string)\n\nThe name of the audio selector in the input that MediaLive should monitor to detect silence. Select your most important rendition. If you didn’t create an audio selector in this input, leave blank.\n\nAudioSilenceThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be silent before automatic input failover occurs. Silence is defined as audio loss or audio quieter than -50 dBFS.\n\nInputLossSettings -> (structure)\n\nMediaLive will perform a failover if content is not detected in this input for the specified period.\n\nInputLossThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that no input is detected. After that time, an input failover will occur.\n\nVideoBlackSettings -> (structure)\n\nMediaLive will perform a failover if content is considered black for the specified period.\n\nBlackDetectThreshold -> (double)\n\nA value used in calculating the threshold below which MediaLive considers a pixel to be ‘black’. For the input to be considered black, every pixel in a frame must be below this threshold. The threshold is calculated as a percentage (expressed as a decimal) of white. Therefore .1 means 10% white (or 90% black). Note how the formula works for any color depth. For example, if you set this field to 0.1 in 10-bit color depth: (1023*0.1=102.3), which means a pixel value of 102 or less is ‘black’. If you set this field to .1 in an 8-bit color depth: (255*0.1=25.5), which means a pixel value of 25 or less is ‘black’. The range is 0.0 to 1.0, with any number of decimal places.\n\nVideoBlackThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be black before automatic input failover occurs.\n\nInputPreference -> (string)\n\nInput preference when deciding which input to make active when a previously failed input has recovered.\n\nSecondaryInputId -> (string)\n\nThe input ID of the secondary input in the automatic input failover pair.\n\nInputAttachmentName -> (string)\n\nUser-specified name for the attachment. This is required if the user wants to use this input in an input switch action.\n\nInputId -> (string)\n\nThe ID of the input\n\nInputSettings -> (structure)\n\nSettings of an input (caption selector, etc.)\n\nAudioSelectors -> (list)\n\nUsed to select the audio stream to decode for inputs that have multiple available.\n\n(structure)\n\nAudio Selector\n\nName -> (string)\n\nThe name of this AudioSelector. AudioDescriptions will use this name to uniquely identify this Selector. Selector names should be unique per input.\n\nSelectorSettings -> (structure)\n\nThe audio selector settings.\n\nAudioHlsRenditionSelection -> (structure)\n\nAudio Hls Rendition Selection\n\nGroupId -> (string)\n\nSpecifies the GROUP-ID in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nName -> (string)\n\nSpecifies the NAME in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nAudioLanguageSelection -> (structure)\n\nAudio Language Selection\n\nLanguageCode -> (string)\n\nSelects a specific three-letter language code from within an audio source.\n\nLanguageSelectionPolicy -> (string)\n\nWhen set to “strict”, the transport stream demux strictly identifies audio streams by their language descriptor. If a PMT update occurs such that an audio stream matching the initially selected language is no longer present then mute will be encoded until the language returns. If “loose”, then on a PMT update the demux will choose another audio stream in the program with the same stream type if it can’t find one with the same language.\n\nAudioPidSelection -> (structure)\n\nAudio Pid Selection\n\nPid -> (integer)\n\nSelects a specific PID from within a source.\n\nAudioTrackSelection -> (structure)\n\nAudio Track Selection\n\nTracks -> (list)\n\nSelects one or more unique audio tracks from within a source.\n\n(structure)\n\nAudio Track\n\nTrack -> (integer)\n\n1-based integer value that maps to a specific audio track\n\nCaptionSelectors -> (list)\n\nUsed to select the caption input to use for inputs that have multiple available.\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nLanguageCode -> (string)\n\nWhen specified this field indicates the three letter language code of the caption track to extract from the source.\n\nName -> (string)\n\nName identifier for a caption selector. This name is used to associate this caption selector with one or more caption descriptions. Names must be unique within an event.\n\nSelectorSettings -> (structure)\n\nCaption selector settings.\n\nAncillarySourceSettings -> (structure)\n\nAncillary Source Settings\n\nSourceAncillaryChannelNumber -> (integer)\n\nSpecifies the number (1 to 4) of the captions channel you want to extract from the ancillary captions. If you plan to convert the ancillary captions to another format, complete this field. If you plan to choose Embedded as the captions destination in the output (to pass through all the channels in the ancillary captions), leave this field blank because MediaLive ignores the field.\n\nAribSourceSettings -> (structure)\n\nArib Source Settings\n\nDvbSubSourceSettings -> (structure)\n\nDvb Sub Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nWhen using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through, regardless of selectors.\n\nEmbeddedSourceSettings -> (structure)\n\nEmbedded Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nScte20Detection -> (string)\n\nSet to “auto” to handle streams with intermittent and/or non-aligned SCTE-20 and Embedded captions.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nSource608TrackNumber -> (integer)\n\nThis field is unused and deprecated.\n\nScte20SourceSettings -> (structure)\n\nScte20 Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nScte27SourceSettings -> (structure)\n\nScte27 Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nThe pid field is used in conjunction with the caption selector languageCode field as follows: - Specify PID and Language: Extracts captions from that PID; the language is “informational”. - Specify PID and omit Language: Extracts the specified PID. - Omit PID and specify Language: Extracts the specified language, whichever PID that happens to be. - Omit PID and omit Language: Valid only if source is DVB-Sub that is being passed through; all languages will be passed through.\n\nTeletextSourceSettings -> (structure)\n\nTeletext Source Settings\n\nOutputRectangle -> (structure)\n\nOptionally defines a region where TTML style captions will be displayed\n\nHeight -> (double)\n\nSee the description in leftOffset. For height, specify the entire height of the rectangle as a percentage of the underlying frame height. For example, “80” means the rectangle height is 80% of the underlying frame height. The topOffset and rectangleHeight must add up to 100% or less. This field corresponds to tts:extent - Y in the TTML standard.\n\nLeftOffset -> (double)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. (Make sure to leave the default if you don’t have either of these formats in the output.) You can define a display rectangle for the captions that is smaller than the underlying video frame. You define the rectangle by specifying the position of the left edge, top edge, bottom edge, and right edge of the rectangle, all within the underlying video frame. The units for the measurements are percentages. If you specify a value for one of these fields, you must specify a value for all of them. For leftOffset, specify the position of the left edge of the rectangle, as a percentage of the underlying frame width, and relative to the left edge of the frame. For example, “10” means the measurement is 10% of the underlying frame width. The rectangle left edge starts at that position from the left edge of the frame. This field corresponds to tts:origin - X in the TTML standard.\n\nTopOffset -> (double)\n\nSee the description in leftOffset. For topOffset, specify the position of the top edge of the rectangle, as a percentage of the underlying frame height, and relative to the top edge of the frame. For example, “10” means the measurement is 10% of the underlying frame height. The rectangle top edge starts at that position from the top edge of the frame. This field corresponds to tts:origin - Y in the TTML standard.\n\nWidth -> (double)\n\nSee the description in leftOffset. For width, specify the entire width of the rectangle as a percentage of the underlying frame width. For example, “80” means the rectangle width is 80% of the underlying frame width. The leftOffset and rectangleWidth must add up to 100% or less. This field corresponds to tts:extent - X in the TTML standard.\n\nPageNumber -> (string)\n\nSpecifies the teletext page number within the data stream from which to extract captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should be specified as a hexadecimal string with no “0x” prefix.\n\nDeblockFilter -> (string)\n\nEnable or disable the deblock filter when filtering.\n\nDenoiseFilter -> (string)\n\nEnable or disable the denoise filter when filtering.\n\nFilterStrength -> (integer)\n\nAdjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).\n\nInputFilter -> (string)\n\nTurns on the filter for this input. MPEG-2 inputs have the deblocking filter enabled by default. 1) auto - filtering will be applied depending on input type/quality 2) disabled - no filtering will be applied to the input 3) forced - filtering will be applied regardless of input type\n\nNetworkInputSettings -> (structure)\n\nInput settings.\n\nHlsInputSettings -> (structure)\n\nSpecifies HLS input settings when the uri is for a HLS manifest.\n\nBandwidth -> (integer)\n\nWhen specified the HLS stream with the m3u8 BANDWIDTH that most closely matches this value will be chosen, otherwise the highest bandwidth stream in the m3u8 will be chosen. The bitrate is specified in bits per second, as in an HLS manifest.\n\nBufferSegments -> (integer)\n\nWhen specified, reading of the HLS input will begin this many buffer segments from the end (most recently written segment). When not specified, the HLS input will begin with the first segment specified in the m3u8.\n\nRetries -> (integer)\n\nThe number of consecutive times that attempts to read a manifest or segment must fail before the input is considered unavailable.\n\nRetryInterval -> (integer)\n\nThe number of seconds between retries when an attempt to read a manifest or segment fails.\n\nScte35Source -> (string)\n\nIdentifies the source for the SCTE-35 messages that MediaLive will ingest. Messages can be ingested from the content segments (in the stream) or from tags in the playlist (the HLS manifest). MediaLive ignores SCTE-35 information in the source that is not selected.\n\nServerValidation -> (string)\n\nCheck HTTPS server certificates. When set to checkCryptographyOnly, cryptography in the certificate will be checked, but not the server’s name. Certain subdomains (notably S3 buckets that use dots in the bucket name) do not strictly match the corresponding certificate’s wildcard pattern and would otherwise cause the event to error. This setting is ignored for protocols that do not use https.\n\nSmpte2038DataPreference -> (string)\n\nSpecifies whether to extract applicable ancillary data from a SMPTE-2038 source in this input. Applicable data types are captions, timecode, AFD, and SCTE-104 messages. - PREFER: Extract from SMPTE-2038 if present in this input, otherwise extract from another source (if any). - IGNORE: Never extract any ancillary data from SMPTE-2038.\n\nSourceEndBehavior -> (string)\n\nLoop input if it is a file. This allows a file input to be streamed indefinitely.\n\nVideoSelector -> (structure)\n\nInforms which video elementary stream to decode for input types that have multiple available.\n\nColorSpace -> (string)\n\nSpecifies the color space of an input. This setting works in tandem with colorSpaceUsage and a video description’s colorSpaceSettingsChoice to determine if any conversion will be performed.\n\nColorSpaceSettings -> (structure)\n\nColor space settings\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nColorSpaceUsage -> (string)\n\nApplies only if colorSpace is a value other than follow. This field controls how the value in the colorSpace field will be used. fallback means that when the input does include color space data, that data will be used, but when the input has no color space data, the value in colorSpace will be used. Choose fallback if your input is sometimes missing color space data, but when it does have color space data, that data is correct. force means to always use the value in colorSpace. Choose force if your input usually has no color space data or might have unreliable color space data.\n\nSelectorSettings -> (structure)\n\nThe video selector settings.\n\nVideoSelectorPid -> (structure)\n\nVideo Selector Pid\n\nPid -> (integer)\n\nSelects a specific PID from within a video source.\n\nVideoSelectorProgramId -> (structure)\n\nVideo Selector Program Id\n\nProgramId -> (integer)\n\nSelects a specific program from within a multi-program transport stream. If the program doesn’t exist, the first program within the transport stream will be selected by default.\n\nInputSpecification -> (structure)\n\nSpecification of network and file inputs for this channel\n\nCodec -> (string)\n\nInput codec\n\nMaximumBitrate -> (string)\n\nMaximum input bitrate, categorized coarsely\n\nResolution -> (string)\n\nInput resolution, categorized coarsely\n\nLogLevel -> (string)\n\nThe log level being written to CloudWatch Logs.\n\nName -> (string)\n\nThe name of the channel. (user-mutable)\n\nPipelineDetails -> (list)\n\nRuntime details for the pipelines of a running channel.\n\n(structure)\n\nRuntime details of a pipeline when a channel is running.\n\nActiveInputAttachmentName -> (string)\n\nThe name of the active input attachment currently being ingested by this pipeline.\n\nActiveInputSwitchActionName -> (string)\n\nThe name of the input switch schedule action that occurred most recently and that resulted in the switch to the current input attachment for this pipeline.\n\nActiveMotionGraphicsActionName -> (string)\n\nThe name of the motion graphics activate action that occurred most recently and that resulted in the current graphics URI for this pipeline.\n\nActiveMotionGraphicsUri -> (string)\n\nThe current URI being used for HTML5 motion graphics for this pipeline.\n\nPipelineId -> (string)\n\nPipeline ID\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role assumed when running the Channel.\n\nState -> (string)\n\nPlaceholder documentation for ChannelState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nVpc -> (structure)\n\nSettings for VPC output\n\nAvailabilityZones -> (list)\n\nThe Availability Zones where the vpc subnets are located. The first Availability Zone applies to the first subnet in the list of subnets. The second Availability Zone applies to the second subnet.\n\n(string)\n\nPlaceholder documentation for __string\n\nNetworkInterfaceIds -> (list)\n\nA list of Elastic Network Interfaces created by MediaLive in the customer’s VPC\n\n(string)\n\nPlaceholder documentation for __string\n\nSecurityGroupIds -> (list)\n\nA list of up EC2 VPC security group IDs attached to the Output VPC network interfaces.\n\n(string)\n\nPlaceholder documentation for __string\n\nSubnetIds -> (list)\n\nA list of VPC subnet IDs from the same VPC. If STANDARD channel, subnet IDs must be mapped to two unique availability zones (AZ).\n\n(string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "update-channel-class",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/update-channel-class.html",
      "command_description": "Description\n\nChanges the class of the channel.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-channel-class\n--channel-class <value>\n--channel-id <value>\n[--destinations <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-class <value>",
        "--channel-id <value>",
        "[--destinations <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-class (string) The channel class that you wish to update this channel to use.\n\nPossible values:\n\nSTANDARD\n\nSINGLE_PIPELINE\n\n--channel-id (string) Channel Id of the channel whose class should be updated.\n\n--destinations (list) A list of output destinations for this channel.(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nShorthand Syntax:\n\nId=string,MediaPackageSettings=[{ChannelId=string},{ChannelId=string}],MultiplexSettings={MultiplexId=string,ProgramName=string},Settings=[{PasswordParam=string,StreamName=string,Url=string,Username=string},{PasswordParam=string,StreamName=string,Url=string,Username=string}] ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Id\": \"string\",\n    \"MediaPackageSettings\": [\n      {\n        \"ChannelId\": \"string\"\n      }\n      ...\n    ],\n    \"MultiplexSettings\": {\n      \"MultiplexId\": \"string\",\n      \"ProgramName\": \"string\"\n    },\n    \"Settings\": [\n      {\n        \"PasswordParam\": \"string\",\n        \"StreamName\": \"string\",\n        \"Url\": \"string\",\n        \"Username\": \"string\"\n      }\n      ...\n    ]\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nChannel -> (structure)\n\nPlaceholder documentation for Channel\n\nArn -> (string)\n\nThe unique arn of the channel.\n\nCdiInputSpecification -> (structure)\n\nSpecification of CDI inputs for this channel\n\nResolution -> (string)\n\nMaximum CDI input resolution\n\nChannelClass -> (string)\n\nThe class for this channel. STANDARD for a channel with two pipelines or SINGLE_PIPELINE for a channel with one pipeline.\n\nDestinations -> (list)\n\nA list of destinations of the channel. For UDP outputs, there is one destination per output. For other types (HLS, for example), there is one destination per packager.\n\n(structure)\n\nPlaceholder documentation for OutputDestination\n\nId -> (string)\n\nUser-specified id. This is used in an output group or an output.\n\nMediaPackageSettings -> (list)\n\nDestination settings for a MediaPackage output; one destination for both encoders.\n\n(structure)\n\nMediaPackage Output Destination Settings\n\nChannelId -> (string)\n\nID of the channel in MediaPackage that is the destination for this output group. You do not need to specify the individual inputs in MediaPackage; MediaLive will handle the connection of the two MediaLive pipelines to the two MediaPackage inputs. The MediaPackage channel and MediaLive channel must be in the same region.\n\nMultiplexSettings -> (structure)\n\nDestination settings for a Multiplex output; one destination for both encoders.\n\nMultiplexId -> (string)\n\nThe ID of the Multiplex that the encoder is providing output to. You do not need to specify the individual inputs to the Multiplex; MediaLive will handle the connection of the two MediaLive pipelines to the two Multiplex instances. The Multiplex must be in the same region as the Channel.\n\nProgramName -> (string)\n\nThe program name of the Multiplex program that the encoder is providing output to.\n\nSettings -> (list)\n\nDestination settings for a standard output; one destination for each redundant encoder.\n\n(structure)\n\nPlaceholder documentation for OutputDestinationSettings\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nStreamName -> (string)\n\nStream name for RTMP destinations (URLs of type rtmp://)\n\nUrl -> (string)\n\nA URL specifying a destination\n\nUsername -> (string)\n\nusername for destination\n\nEgressEndpoints -> (list)\n\nThe endpoints where outgoing connections initiate from\n\n(structure)\n\nPlaceholder documentation for ChannelEgressEndpoint\n\nSourceIp -> (string)\n\nPublic IP of where a channel’s output comes from\n\nEncoderSettings -> (structure)\n\nEncoder Settings\n\nAudioDescriptions -> (list)\n\nPlaceholder documentation for __listOfAudioDescription\n\n(structure)\n\nAudio Description\n\nAudioNormalizationSettings -> (structure)\n\nAdvanced audio normalization settings.\n\nAlgorithm -> (string)\n\nAudio normalization algorithm to use. itu17701 conforms to the CALM Act specification, itu17702 conforms to the EBU R-128 specification.\n\nAlgorithmControl -> (string)\n\nWhen set to correctAudio the output audio is corrected using the chosen algorithm. If set to measureOnly, the audio will be measured but not adjusted.\n\nTargetLkfs -> (double)\n\nTarget LKFS(loudness) to adjust volume to. If no value is entered, a default value will be used according to the chosen algorithm. The CALM Act (1770-1) recommends a target of -24 LKFS. The EBU R-128 specification (1770-2) recommends a target of -23 LKFS.\n\nAudioSelectorName -> (string)\n\nThe name of the AudioSelector used as the source for this AudioDescription.\n\nAudioType -> (string)\n\nApplies only if audioTypeControl is useConfigured. The values for audioType are defined in ISO-IEC 13818-1.\n\nAudioTypeControl -> (string)\n\nDetermines how audio type is determined. followInput: If the input contains an ISO 639 audioType, then that value is passed through to the output. If the input contains no ISO 639 audioType, the value in Audio Type is included in the output. useConfigured: The value in Audio Type is included in the output. Note that this field and audioType are both ignored if inputType is broadcasterMixedAd.\n\nAudioWatermarkingSettings -> (structure)\n\nSettings to configure one or more solutions that insert audio watermarks in the audio encode\n\nNielsenWatermarksSettings -> (structure)\n\nSettings to configure Nielsen Watermarks in the audio encode\n\nNielsenCbetSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen CBET\n\nCbetCheckDigitString -> (string)\n\nEnter the CBET check digits to use in the watermark.\n\nCbetStepaside -> (string)\n\nDetermines the method of CBET insertion mode when prior encoding is detected on the same layer.\n\nCsid -> (string)\n\nEnter the CBET Source ID (CSID) to use in the watermark\n\nNielsenDistributionType -> (string)\n\nChoose the distribution types that you want to assign to the watermarks: - PROGRAM_CONTENT - FINAL_DISTRIBUTOR\n\nNielsenNaesIiNwSettings -> (structure)\n\nComplete these fields only if you want to insert watermarks of type Nielsen NAES II (N2) and Nielsen NAES VI (NW).\n\nCheckDigitString -> (string)\n\nEnter the check digit string for the watermark\n\nSid -> (double)\n\nEnter the Nielsen Source ID (SID) to include in the watermark\n\nCodecSettings -> (structure)\n\nAudio codec settings.\n\nAacSettings -> (structure)\n\nAac Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid values depend on rate control mode and profile.\n\nCodingMode -> (string)\n\nMono, Stereo, or 5.1 channel layout. Valid values depend on rate control mode and profile. The adReceiverMix setting receives a stereo description plus control track and emits a mono AAC encode of the description track, with control data emitted in the PES header as per ETSI TS 101 154 Annex E.\n\nInputType -> (string)\n\nSet to “broadcasterMixedAd” when input contains pre-mixed main audio + AD (narration) as a stereo pair. The Audio Type field (audioType) will be set to 3, which signals to downstream systems that this stream contains “broadcaster mixed AD”. Note that the input received by the encoder must contain pre-mixed audio; the encoder does not perform the mixing. The values in audioTypeControl and audioType (in AudioDescription) are ignored when set to broadcasterMixedAd. Leave set to “normal” when input does not contain pre-mixed audio + AD.\n\nProfile -> (string)\n\nAAC Profile.\n\nRateControlMode -> (string)\n\nRate Control Mode.\n\nRawFormat -> (string)\n\nSets LATM / LOAS AAC output for raw containers.\n\nSampleRate -> (double)\n\nSample rate in Hz. Valid values depend on rate control mode and profile.\n\nSpec -> (string)\n\nUse MPEG-2 AAC audio instead of MPEG-4 AAC audio for raw or MPEG-2 Transport Stream containers.\n\nVbrQuality -> (string)\n\nVBR Quality Level - Only used if rateControlMode is VBR.\n\nAc3Settings -> (structure)\n\nAc3 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted AC-3 stream. See ATSC A/52-2012 for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital coding mode. Determines number of channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If excluded and input audio is Dolby Digital, dialnorm will be passed through.\n\nDrcProfile -> (string)\n\nIf set to filmStandard, adds dynamic range compression signaling to the output bitstream as defined in the Dolby Digital specification.\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid in codingMode32Lfe mode.\n\nMetadataControl -> (string)\n\nWhen set to “followInput”, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nEac3Settings -> (structure)\n\nEac3 Settings\n\nAttenuationControl -> (string)\n\nWhen set to attenuate3Db, applies a 3 dB attenuation to the surround channels. Only used for 3/2 coding mode.\n\nBitrate -> (double)\n\nAverage bitrate in bits/second. Valid bitrates depend on the coding mode.\n\nBitstreamMode -> (string)\n\nSpecifies the bitstream mode (bsmod) for the emitted E-AC-3 stream. See ATSC A/52-2012 (Annex E) for background on these values.\n\nCodingMode -> (string)\n\nDolby Digital Plus coding mode. Determines number of channels.\n\nDcFilter -> (string)\n\nWhen set to enabled, activates a DC highpass filter for all input channels.\n\nDialnorm -> (integer)\n\nSets the dialnorm for the output. If blank and input audio is Dolby Digital Plus, dialnorm will be passed through.\n\nDrcLine -> (string)\n\nSets the Dolby dynamic range compression profile.\n\nDrcRf -> (string)\n\nSets the profile for heavy Dolby dynamic range compression, ensures that the instantaneous signal peaks do not exceed specified levels.\n\nLfeControl -> (string)\n\nWhen encoding 3/2 audio, setting to lfe enables the LFE channel\n\nLfeFilter -> (string)\n\nWhen set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to encoding. Only valid with codingMode32 coding mode.\n\nLoRoCenterMixLevel -> (double)\n\nLeft only/Right only center mix level. Only used for 3/2 coding mode.\n\nLoRoSurroundMixLevel -> (double)\n\nLeft only/Right only surround mix level. Only used for 3/2 coding mode.\n\nLtRtCenterMixLevel -> (double)\n\nLeft total/Right total center mix level. Only used for 3/2 coding mode.\n\nLtRtSurroundMixLevel -> (double)\n\nLeft total/Right total surround mix level. Only used for 3/2 coding mode.\n\nMetadataControl -> (string)\n\nWhen set to followInput, encoder metadata will be sourced from the DD, DD+, or DolbyE decoder that supplied this audio data. If audio was not supplied from one of these streams, then the static metadata settings will be used.\n\nPassthroughControl -> (string)\n\nWhen set to whenPossible, input DD+ audio will be passed through if it is present on the input. This detection is dynamic over the life of the transcode. Inputs that alternate between DD+ and non-DD+ content will have a consistent DD+ output as the system alternates between passthrough and encoding.\n\nPhaseControl -> (string)\n\nWhen set to shift90Degrees, applies a 90-degree phase shift to the surround channels. Only used for 3/2 coding mode.\n\nStereoDownmix -> (string)\n\nStereo downmix preference. Only used for 3/2 coding mode.\n\nSurroundExMode -> (string)\n\nWhen encoding 3/2 audio, sets whether an extra center back surround channel is matrix encoded into the left and right surround channels.\n\nSurroundMode -> (string)\n\nWhen encoding 2/0 audio, sets whether Dolby Surround is matrix encoded into the two channels.\n\nMp2Settings -> (structure)\n\nMp2 Settings\n\nBitrate -> (double)\n\nAverage bitrate in bits/second.\n\nCodingMode -> (string)\n\nThe MPEG2 Audio coding mode. Valid values are codingMode10 (for mono) or codingMode20 (for stereo).\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nPassThroughSettings -> (structure)\n\nPass Through Settings\n\nWavSettings -> (structure)\n\nWav Settings\n\nBitDepth -> (double)\n\nBits per sample.\n\nCodingMode -> (string)\n\nThe audio coding mode for the WAV audio. The mode determines the number of channels in the audio.\n\nSampleRate -> (double)\n\nSample rate in Hz.\n\nLanguageCode -> (string)\n\nRFC 5646 language code representing the language of the audio output track. Only used if languageControlMode is useConfigured, or there is no ISO 639 language code specified in the input.\n\nLanguageCodeControl -> (string)\n\nChoosing followInput will cause the ISO 639 language code of the output to follow the ISO 639 language code of the input. The languageCode will be used when useConfigured is set, or when followInput is selected but there is no ISO 639 language code specified by the input.\n\nName -> (string)\n\nThe name of this AudioDescription. Outputs will use this name to uniquely identify this AudioDescription. Description names should be unique within this Live Event.\n\nRemixSettings -> (structure)\n\nSettings that control how input audio channels are remixed into the output audio channels.\n\nChannelMappings -> (list)\n\nMapping of input channels to output channels, with appropriate gain adjustments.\n\n(structure)\n\nAudio Channel Mapping\n\nInputChannelLevels -> (list)\n\nIndices and gain values for each input channel that should be remixed into this output channel.\n\n(structure)\n\nInput Channel Level\n\nGain -> (integer)\n\nRemixing value. Units are in dB and acceptable values are within the range from -60 (mute) and 6 dB.\n\nInputChannel -> (integer)\n\nThe index of the input channel used as a source.\n\nOutputChannel -> (integer)\n\nThe index of the output channel being produced.\n\nChannelsIn -> (integer)\n\nNumber of input channels to be used.\n\nChannelsOut -> (integer)\n\nNumber of output channels to be produced. Valid values: 1, 2, 4, 6, 8\n\nStreamName -> (string)\n\nUsed for MS Smooth and Apple HLS outputs. Indicates the name displayed by the player (eg. English, or Director Commentary).\n\nAvailBlanking -> (structure)\n\nSettings for ad avail blanking.\n\nAvailBlankingImage -> (structure)\n\nBlanking image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when insertion metadata is added.\n\nAvailConfiguration -> (structure)\n\nEvent-wide configuration settings for ad avail insertion.\n\nAvailSettings -> (structure)\n\nAd avail settings.\n\nScte35SpliceInsert -> (structure)\n\nScte35 Splice Insert\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nScte35TimeSignalApos -> (structure)\n\nScte35 Time Signal Apos\n\nAdAvailOffset -> (integer)\n\nWhen specified, this offset (in milliseconds) is added to the input Ad Avail PTS time. This only applies to embedded SCTE 104/35 messages and does not apply to OOB messages.\n\nNoRegionalBlackoutFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nWebDeliveryAllowedFlag -> (string)\n\nWhen set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0 will no longer trigger blackouts or Ad Avail slates\n\nBlackoutSlate -> (structure)\n\nSettings for blackout slate.\n\nBlackoutSlateImage -> (structure)\n\nBlackout slate image to be used. Leave empty for solid black. Only bmp and png images are supported.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkEndBlackout -> (string)\n\nSetting to enabled causes the encoder to blackout the video, audio, and captions, and raise the “Network Blackout Image” slate when an SCTE104/35 Network End Segmentation Descriptor is encountered. The blackout will be lifted when the Network Start Segmentation Descriptor is encountered. The Network End and Network Start descriptors must contain a network ID that matches the value entered in “Network ID”.\n\nNetworkEndBlackoutImage -> (structure)\n\nPath to local file to use as Network End Blackout image. Image will be scaled to fill the entire output raster.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nNetworkId -> (string)\n\nProvides Network ID that matches EIDR ID format (e.g., “10.XXXX/XXXX-XXXX-XXXX-XXXX-XXXX-C”).\n\nState -> (string)\n\nWhen set to enabled, causes video, audio and captions to be blanked when indicated by program metadata.\n\nCaptionDescriptions -> (list)\n\nSettings for caption decriptions\n\n(structure)\n\nCaption Description\n\nCaptionSelectorName -> (string)\n\nSpecifies which input caption selector to use as a caption source when generating output captions. This field should match a captionSelector name.\n\nDestinationSettings -> (structure)\n\nAdditional settings for captions destination that depend on the destination type.\n\nAribDestinationSettings -> (structure)\n\nArib Destination Settings\n\nBurnInDestinationSettings -> (structure)\n\nBurn In Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to ‘auto’ fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter out is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. All burn-in and DVB-Sub font settings must match.\n\nDvbSubDestinationSettings -> (structure)\n\nDvb Sub Destination Settings\n\nAlignment -> (string)\n\nIf no explicit xPosition or yPosition is provided, setting alignment to centered will place the captions at the bottom center of the output. Similarly, setting a left alignment will align captions to the bottom left of the output. If x and y positions are given in conjunction with the alignment parameter, the font will be justified (either left or centered) relative to those coordinates. Selecting “smart” justification will left-justify live subtitles and center-justify pre-recorded subtitles. This option is not valid for source captions that are STL or 608/embedded. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nBackgroundColor -> (string)\n\nSpecifies the color of the rectangle behind the captions. All burn-in and DVB-Sub font settings must match.\n\nBackgroundOpacity -> (integer)\n\nSpecifies the opacity of the background rectangle. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nFont -> (structure)\n\nExternal font file used for caption burn-in. File extension must be ‘ttf’ or ‘tte’. Although the user can select output fonts for many different types of input captions, embedded, STL and teletext sources use a strict grid system. Using external fonts with these caption sources could cause unexpected display of proportional fonts. All burn-in and DVB-Sub font settings must match.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nFontColor -> (string)\n\nSpecifies the color of the burned-in captions. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nFontOpacity -> (integer)\n\nSpecifies the opacity of the burned-in captions. 255 is opaque; 0 is transparent. All burn-in and DVB-Sub font settings must match.\n\nFontResolution -> (integer)\n\nFont resolution in DPI (dots per inch); default is 96 dpi. All burn-in and DVB-Sub font settings must match.\n\nFontSize -> (string)\n\nWhen set to auto fontSize will scale depending on the size of the output. Giving a positive integer will specify the exact font size in points. All burn-in and DVB-Sub font settings must match.\n\nOutlineColor -> (string)\n\nSpecifies font outline color. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nOutlineSize -> (integer)\n\nSpecifies font outline size in pixels. This option is not valid for source captions that are either 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nShadowColor -> (string)\n\nSpecifies the color of the shadow cast by the captions. All burn-in and DVB-Sub font settings must match.\n\nShadowOpacity -> (integer)\n\nSpecifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving this parameter blank is equivalent to setting it to 0 (transparent). All burn-in and DVB-Sub font settings must match.\n\nShadowXOffset -> (integer)\n\nSpecifies the horizontal offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All burn-in and DVB-Sub font settings must match.\n\nShadowYOffset -> (integer)\n\nSpecifies the vertical offset of the shadow relative to the captions in pixels. A value of -2 would result in a shadow offset 2 pixels above the text. All burn-in and DVB-Sub font settings must match.\n\nTeletextGridControl -> (string)\n\nControls whether a fixed grid size will be used to generate the output subtitles bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.\n\nXPosition -> (integer)\n\nSpecifies the horizontal position of the caption relative to the left side of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the left of the output. If no explicit xPosition is provided, the horizontal caption position will be determined by the alignment parameter. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nYPosition -> (integer)\n\nSpecifies the vertical position of the caption relative to the top of the output in pixels. A value of 10 would result in the captions starting 10 pixels from the top of the output. If no explicit yPosition is provided, the caption will be positioned towards the bottom of the output. This option is not valid for source captions that are STL, 608/embedded or teletext. These source settings are already pre-defined by the caption stream. All burn-in and DVB-Sub font settings must match.\n\nEbuTtDDestinationSettings -> (structure)\n\nEbu Tt DDestination Settings\n\nCopyrightHolder -> (string)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. Complete this field if you want to include the name of the copyright holder in the copyright metadata tag in the TTML\n\nFillLineGap -> (string)\n\nSpecifies how to handle the gap between the lines (in multi-line captions). - enabled: Fill with the captions background color (as specified in the input captions). - disabled: Leave the gap unfilled.\n\nFontFamily -> (string)\n\nSpecifies the font family to include in the font data attached to the EBU-TT captions. Valid only if styleControl is set to include. If you leave this field empty, the font family is set to “monospaced”. (If styleControl is set to exclude, the font family is always set to “monospaced”.) You specify only the font family. All other style information (color, bold, position and so on) is copied from the input captions. The size is always set to 100% to allow the downstream player to choose the size. - Enter a list of font families, as a comma-separated list of font names, in order of preference. The name can be a font family (such as “Arial”), or a generic font family (such as “serif”), or “default” (to let the downstream player choose the font). - Leave blank to set the family to “monospace”.\n\nStyleControl -> (string)\n\nSpecifies the style information (font color, font position, and so on) to include in the font data that is attached to the EBU-TT captions. - include: Take the style information (font color, font position, and so on) from the source captions and include that information in the font data attached to the EBU-TT captions. This option is valid only if the source captions are Embedded or Teletext. - exclude: In the font data attached to the EBU-TT captions, set the font family to “monospaced”. Do not include any other style information.\n\nEmbeddedDestinationSettings -> (structure)\n\nEmbedded Destination Settings\n\nEmbeddedPlusScte20DestinationSettings -> (structure)\n\nEmbedded Plus Scte20 Destination Settings\n\nRtmpCaptionInfoDestinationSettings -> (structure)\n\nRtmp Caption Info Destination Settings\n\nScte20PlusEmbeddedDestinationSettings -> (structure)\n\nScte20 Plus Embedded Destination Settings\n\nScte27DestinationSettings -> (structure)\n\nScte27 Destination Settings\n\nSmpteTtDestinationSettings -> (structure)\n\nSmpte Tt Destination Settings\n\nTeletextDestinationSettings -> (structure)\n\nTeletext Destination Settings\n\nTtmlDestinationSettings -> (structure)\n\nTtml Destination Settings\n\nStyleControl -> (string)\n\nWhen set to passthrough, passes through style and position information from a TTML-like input source (TTML, SMPTE-TT, CFF-TT) to the CFF-TT output or TTML output.\n\nWebvttDestinationSettings -> (structure)\n\nWebvtt Destination Settings\n\nStyleControl -> (string)\n\nControls whether the color and position of the source captions is passed through to the WebVTT output captions. PASSTHROUGH - Valid only if the source captions are EMBEDDED or TELETEXT. NO_STYLE_DATA - Don’t pass through the style. The output captions will not contain any font styling information.\n\nLanguageCode -> (string)\n\nISO 639-2 three-digit code: http://www.loc.gov/standards/iso639-2/\n\nLanguageDescription -> (string)\n\nHuman readable information to indicate captions available for players (eg. English, or Spanish).\n\nName -> (string)\n\nName of the caption description. Used to associate a caption description with an output. Names must be unique within an event.\n\nFeatureActivations -> (structure)\n\nFeature Activations\n\nInputPrepareScheduleActions -> (string)\n\nEnables the Input Prepare feature. You can create Input Prepare actions in the schedule only if this feature is enabled. If you disable the feature on an existing schedule, make sure that you first delete all input prepare actions from the schedule.\n\nGlobalConfiguration -> (structure)\n\nConfiguration settings that apply to the event as a whole.\n\nInitialAudioGain -> (integer)\n\nValue to set the initial audio gain for the Live Event.\n\nInputEndAction -> (string)\n\nIndicates the action to take when the current input completes (e.g. end-of-file). When switchAndLoopInputs is configured the encoder will restart at the beginning of the first input. When “none” is configured the encoder will transcode either black, a solid color, or a user specified slate images per the “Input Loss Behavior” configuration until the next input switch occurs (which is controlled through the Channel Schedule API).\n\nInputLossBehavior -> (structure)\n\nSettings for system actions when input is lost.\n\nBlackFrameMsec -> (integer)\n\nDocumentation update needed\n\nInputLossImageColor -> (string)\n\nWhen input loss image type is “color” this field specifies the color to use. Value: 6 hex characters representing the values of RGB.\n\nInputLossImageSlate -> (structure)\n\nWhen input loss image type is “slate” these fields specify the parameters for accessing the slate.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nInputLossImageType -> (string)\n\nIndicates whether to substitute a solid color or a slate into the output after input loss exceeds blackFrameMsec.\n\nRepeatFrameMsec -> (integer)\n\nDocumentation update needed\n\nOutputLockingMode -> (string)\n\nIndicates how MediaLive pipelines are synchronized. PIPELINE_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the other. EPOCH_LOCKING - MediaLive will attempt to synchronize the output of each pipeline to the Unix epoch.\n\nOutputTimingSource -> (string)\n\nIndicates whether the rate of frames emitted by the Live encoder should be paced by its system clock (which optionally may be locked to another source via NTP) or should be locked to the clock of the source that is providing the input stream.\n\nSupportLowFramerateInputs -> (string)\n\nAdjusts video input buffer for streams with very low video framerates. This is commonly set to enabled for music channels with less than one video frame per second.\n\nMotionGraphicsConfiguration -> (structure)\n\nSettings for motion graphics.\n\nMotionGraphicsInsertion -> (string)\n\nMotion Graphics Insertion\n\nMotionGraphicsSettings -> (structure)\n\nMotion Graphics Settings\n\nHtmlMotionGraphicsSettings -> (structure)\n\nHtml Motion Graphics Settings\n\nNielsenConfiguration -> (structure)\n\nNielsen configuration settings.\n\nDistributorId -> (string)\n\nEnter the Distributor ID assigned to your organization by Nielsen.\n\nNielsenPcmToId3Tagging -> (string)\n\nEnables Nielsen PCM to ID3 tagging\n\nOutputGroups -> (list)\n\nPlaceholder documentation for __listOfOutputGroup\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nName -> (string)\n\nCustom output group name optionally defined by the user. Only letters, numbers, and the underscore character allowed; only 32 characters allowed.\n\nOutputGroupSettings -> (structure)\n\nSettings associated with the output group.\n\nArchiveGroupSettings -> (structure)\n\nArchive Group Settings\n\nArchiveCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nArchiveS3Settings -> (structure)\n\nArchive S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nDestination -> (structure)\n\nA directory and base filename where archive files should be written.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRolloverInterval -> (integer)\n\nNumber of seconds to write to archive file before closing and starting a new one.\n\nFrameCaptureGroupSettings -> (structure)\n\nFrame Capture Group Settings\n\nDestination -> (structure)\n\nThe destination for the frame capture files. Either the URI for an Amazon S3 bucket and object, plus a file name prefix (for example, s3ssl://sportsDelivery/highlights/20180820/curling-) or the URI for a MediaStore container, plus a file name prefix (for example, mediastoressl://sportsDelivery/20180820/curling-). The final file names consist of the prefix from the destination field (for example, “curling-“) + name modifier + the counter (5 digits, starting from 00001) + extension (which is always .jpg). For example, curling-low.00001.jpg\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFrameCaptureCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nFrameCaptureS3Settings -> (structure)\n\nFrame Capture S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsGroupSettings -> (structure)\n\nHls Group Settings\n\nAdMarkers -> (list)\n\nChoose one or more ad marker types to pass SCTE35 signals through to this group of Apple HLS outputs.\n\n(string)\n\nHls Ad Markers\n\nBaseUrlContent -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlContent1 -> (string)\n\nOptional. One value per output group. This field is required only if you are completing Base URL content A, and the downstream system has notified you that the media files for pipeline 1 of all outputs are in a location different from the media files for pipeline 0.\n\nBaseUrlManifest -> (string)\n\nA partial URI prefix that will be prepended to each output in the media .m3u8 file. Can be used if base manifest is delivered from a different URL than the main .m3u8 file.\n\nBaseUrlManifest1 -> (string)\n\nOptional. One value per output group. Complete this field only if you are completing Base URL manifest A, and the downstream system has notified you that the child manifest files for pipeline 1 of all outputs are in a location different from the child manifest files for pipeline 0.\n\nCaptionLanguageMappings -> (list)\n\nMapping of up to 4 caption channels to caption languages. Is only meaningful if captionLanguageSetting is set to “insert”.\n\n(structure)\n\nMaps a caption channel to an ISO 693-2 language code (http://www.loc.gov/standards/iso639-2), with an optional description.\n\nCaptionChannel -> (integer)\n\nThe closed caption channel being described by this CaptionLanguageMapping. Each channel mapping must have a unique channel number (maximum of 4)\n\nLanguageCode -> (string)\n\nThree character ISO 639-2 language code (see http://www.loc.gov/standards/iso639-2)\n\nLanguageDescription -> (string)\n\nTextual description of language\n\nCaptionLanguageSetting -> (string)\n\nApplies only to 608 Embedded output captions. insert: Include CLOSED-CAPTIONS lines in the manifest. Specify at least one language in the CC1 Language Code field. One CLOSED-CAPTION line is added for each Language Code you specify. Make sure to specify the languages in the order in which they appear in the original source (if the source is embedded format) or the order of the caption selectors (if the source is other than embedded). Otherwise, languages in the manifest will not match up properly with the output captions. none: Include CLOSED-CAPTIONS=NONE line in the manifest. omit: Omit any CLOSED-CAPTIONS line from the manifest.\n\nClientCache -> (string)\n\nWhen set to “disabled”, sets the #EXT-X-ALLOW-CACHE:no tag in the manifest, which prevents clients from saving media segments for later replay.\n\nCodecSpecification -> (string)\n\nSpecification to use (RFC-6381 or the default RFC-4281) during m3u8 playlist generation.\n\nConstantIv -> (string)\n\nFor use with encryptionType. This is a 128-bit, 16-byte hex value represented by a 32-character text string. If ivSource is set to “explicit” then this parameter is required and is used as the IV for encryption.\n\nDestination -> (structure)\n\nA directory or HTTP destination for the HLS segments, manifest files, and encryption keys (if enabled).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nDirectoryStructure -> (string)\n\nPlace segments in subdirectories.\n\nDiscontinuityTags -> (string)\n\nSpecifies whether to insert EXT-X-DISCONTINUITY tags in the HLS child manifests for this output group. Typically, choose Insert because these tags are required in the manifest (according to the HLS specification) and serve an important purpose. Choose Never Insert only if the downstream system is doing real-time failover (without using the MediaLive automatic failover feature) and only if that downstream system has advised you to exclude the tags.\n\nEncryptionType -> (string)\n\nEncrypts the segments with the given encryption scheme. Exclude this parameter if no encryption is desired.\n\nHlsCdnSettings -> (structure)\n\nParameters that control interactions with the CDN.\n\nHlsAkamaiSettings -> (structure)\n\nHls Akamai Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to Akamai. User should contact Akamai to enable this feature.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nSalt -> (string)\n\nSalt for authenticated Akamai.\n\nToken -> (string)\n\nToken parameter for authenticated akamai. If not specified, _gda_ is used.\n\nHlsBasicPutSettings -> (structure)\n\nHls Basic Put Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsMediaStoreSettings -> (structure)\n\nHls Media Store Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nMediaStoreStorageClass -> (string)\n\nWhen set to temporal, output files are stored in non-persistent memory for faster reading and writing.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsS3Settings -> (structure)\n\nHls S3 Settings\n\nCannedAcl -> (string)\n\nSpecify the canned ACL to apply to each S3 request. Defaults to none.\n\nHlsWebdavSettings -> (structure)\n\nHls Webdav Settings\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the CDN if the connection is lost.\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nHttpTransferMode -> (string)\n\nSpecify whether or not to use chunked transfer encoding to WebDAV.\n\nNumRetries -> (integer)\n\nNumber of retry attempts that will be made before the Live Event is put into an error state.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nHlsId3SegmentTagging -> (string)\n\nState of HLS ID3 Segment Tagging\n\nIFrameOnlyPlaylists -> (string)\n\nDISABLED: Do not create an I-frame-only manifest, but do create the master and media manifests (according to the Output Selection field). STANDARD: Create an I-frame-only manifest for each output that contains video, as well as the other manifests (according to the Output Selection field). The I-frame manifest contains a #EXT-X-I-FRAMES-ONLY tag to indicate it is I-frame only, and one or more #EXT-X-BYTERANGE entries identifying the I-frame position. For example, #EXT-X-BYTERANGE:160364@1461888”\n\nIncompleteSegmentBehavior -> (string)\n\nSpecifies whether to include the final (incomplete) segment in the media output when the pipeline stops producing output because of a channel stop, a channel pause or a loss of input to the pipeline. Auto means that MediaLive decides whether to include the final segment, depending on the channel class and the types of output groups. Suppress means to never include the incomplete segment. We recommend you choose Auto and let MediaLive control the behavior.\n\nIndexNSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the maximum number of segments in the media manifest file. After this maximum, older segments are removed from the media manifest. This number must be smaller than the number in the Keep Segments field.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nIvInManifest -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If set to “include”, IV is listed in the manifest, otherwise the IV is not in the manifest.\n\nIvSource -> (string)\n\nFor use with encryptionType. The IV (Initialization Vector) is a 128-bit number used in conjunction with the key for encrypting blocks. If this setting is “followsSegmentNumber”, it will cause the IV to change every segment (to match the segment number). If this is set to “explicit”, you must enter a constantIv value.\n\nKeepSegments -> (integer)\n\nApplies only if Mode field is LIVE. Specifies the number of media segments to retain in the destination directory. This number should be bigger than indexNSegments (Num segments). We recommend (value = (2 x indexNsegments) + 1). If this “keep segments” number is too low, the following might happen: the player is still reading a media manifest file that lists this segment, but that segment has been removed from the destination directory (as directed by indexNSegments). This situation would result in a 404 HTTP error on the player.\n\nKeyFormat -> (string)\n\nThe value specifies how the key is represented in the resource identified by the URI. If parameter is absent, an implicit value of “identity” is used. A reverse DNS string can also be given.\n\nKeyFormatVersions -> (string)\n\nEither a single positive integer version value or a slash delimited list of version values (1/2/3).\n\nKeyProviderSettings -> (structure)\n\nThe key provider settings.\n\nStaticKeySettings -> (structure)\n\nStatic Key Settings\n\nKeyProviderServer -> (structure)\n\nThe URL of the license server used for protecting content.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nStaticKeyValue -> (string)\n\nStatic key value as a 32 character hexadecimal string.\n\nManifestCompression -> (string)\n\nWhen set to gzip, compresses HLS playlist.\n\nManifestDurationFormat -> (string)\n\nIndicates whether the output manifest should use floating point or integer values for segment duration.\n\nMinSegmentLength -> (integer)\n\nWhen set, minimumSegmentLength is enforced by looking ahead and back within the specified range for a nearby avail and extending the segment size if needed.\n\nMode -> (string)\n\nIf “vod”, all segments are indexed and kept permanently in the destination and manifest. If “live”, only the number segments specified in keepSegments and indexNSegments are kept; newer segments replace older segments, which may prevent players from rewinding all the way to the beginning of the event. VOD mode uses HLS EXT-X-PLAYLIST-TYPE of EVENT while the channel is running, converting it to a “VOD” type manifest on completion of the stream.\n\nOutputSelection -> (string)\n\nMANIFESTS_AND_SEGMENTS: Generates manifests (master manifest, if applicable, and media manifests) for this output group. VARIANT_MANIFESTS_AND_SEGMENTS: Generates media manifests for this output group, but not a master manifest. SEGMENTS_ONLY: Does not generate any manifests for this output group.\n\nProgramDateTime -> (string)\n\nIncludes or excludes EXT-X-PROGRAM-DATE-TIME tag in .m3u8 manifest files. The value is calculated as follows: either the program date and time are initialized using the input timecode source, or the time is initialized using the input timecode source and the date is initialized using the timestampOffset.\n\nProgramDateTimePeriod -> (integer)\n\nPeriod of insertion of EXT-X-PROGRAM-DATE-TIME entry, in seconds.\n\nRedundantManifest -> (string)\n\nENABLED: The master manifest (.m3u8 file) for each pipeline includes information about both pipelines: first its own media files, then the media files of the other pipeline. This feature allows playout device that support stale manifest detection to switch from one manifest to the other, when the current manifest seems to be stale. There are still two destinations and two master manifests, but both master manifests reference the media files from both pipelines. DISABLED: The master manifest (.m3u8 file) for each pipeline includes information about its own pipeline only. For an HLS output group with MediaPackage as the destination, the DISABLED behavior is always followed. MediaPackage regenerates the manifests it serves to players so a redundant manifest from MediaLive is irrelevant.\n\nSegmentLength -> (integer)\n\nLength of MPEG-2 Transport Stream segments to create (in seconds). Note that segments will end on the next keyframe after this number of seconds, so actual segment length may be longer.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSegmentsPerSubdirectory -> (integer)\n\nNumber of segments to write to a subdirectory before starting a new one. directoryStructure must be subdirectoryPerStream for this setting to have an effect.\n\nStreamInfResolution -> (string)\n\nInclude or exclude RESOLUTION attribute for video in EXT-X-STREAM-INF tag of variant manifest.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nTimestampDeltaMilliseconds -> (integer)\n\nProvides an extra millisecond delta offset to fine tune the timestamps.\n\nTsFileMode -> (string)\n\nSEGMENTED_FILES: Emit the program as segments - multiple .ts media files. SINGLE_FILE: Applies only if Mode field is VOD. Emit the program as a single .ts media file. The media manifest includes #EXT-X-BYTERANGE tags to index segments for playback. A typical use for this value is when sending the output to AWS Elemental MediaConvert, which can accept only a single media file. Playback while the channel is running is not guaranteed due to HTTP server caching.\n\nMediaPackageGroupSettings -> (structure)\n\nMedia Package Group Settings\n\nDestination -> (structure)\n\nMediaPackage channel destination.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nMsSmoothGroupSettings -> (structure)\n\nMs Smooth Group Settings\n\nAcquisitionPointId -> (string)\n\nThe ID to include in each message in the sparse track. Ignored if sparseTrackType is NONE.\n\nAudioOnlyTimecodeControl -> (string)\n\nIf set to passthrough for an audio-only MS Smooth output, the fragment absolute time will be set to the current timecode. This option does not write timecodes to the audio elementary stream.\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the https certificate chain to a trusted Certificate Authority (CA). This will cause https outputs to self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying connection to the IIS server if the connection is lost. Content will be cached during this time and the cache will be be delivered to the IIS server once the connection is re-established.\n\nDestination -> (structure)\n\nSmooth Streaming publish point on an IIS server. Elemental Live acts as a “Push” encoder to IIS.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nEventId -> (string)\n\nMS Smooth event ID to be sent to the IIS server. Should only be specified if eventIdMode is set to useConfigured.\n\nEventIdMode -> (string)\n\nSpecifies whether or not to send an event ID to the IIS server. If no event ID is sent and the same Live Event is used without changing the publishing point, clients might see cached video from the previous run. Options: - “useConfigured” - use the value provided in eventId - “useTimestamp” - generate and send an event ID based on the current timestamp - “noEventId” - do not send an event ID to the IIS server.\n\nEventStopBehavior -> (string)\n\nWhen set to sendEos, send EOS signal to IIS server when stopping the event\n\nFilecacheDuration -> (integer)\n\nSize in seconds of file cache for streaming outputs.\n\nFragmentLength -> (integer)\n\nLength of mp4 fragments to generate (in seconds). Fragment length must be compatible with GOP size and framerate.\n\nInputLossAction -> (string)\n\nParameter that control output group behavior on input loss.\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nRestartDelay -> (integer)\n\nNumber of seconds before initiating a restart due to output failure, due to exhausting the numRetries on one segment, or exceeding filecacheDuration.\n\nSegmentationMode -> (string)\n\nuseInputSegmentation has been deprecated. The configured segment size is always used.\n\nSendDelayMs -> (integer)\n\nNumber of milliseconds to delay the output from the second pipeline.\n\nSparseTrackType -> (string)\n\nIdentifies the type of data to place in the sparse track: - SCTE35: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame to start a new segment. - SCTE35_WITHOUT_SEGMENTATION: Insert SCTE-35 messages from the source content. With each message, insert an IDR frame but don’t start a new segment. - NONE: Don’t generate a sparse track for any outputs in this output group.\n\nStreamManifestBehavior -> (string)\n\nWhen set to send, send stream manifest so publishing point doesn’t start until all streams start.\n\nTimestampOffset -> (string)\n\nTimestamp offset for the event. Only used if timestampOffsetMode is set to useConfiguredOffset.\n\nTimestampOffsetMode -> (string)\n\nType of timestamp date offset to use. - useEventStartDate: Use the date the event was started as the offset - useConfiguredOffset: Use an explicitly configured date as the offset\n\nMultiplexGroupSettings -> (structure)\n\nMultiplex Group Settings\n\nRtmpGroupSettings -> (structure)\n\nRtmp Group Settings\n\nAdMarkers -> (list)\n\nChoose the ad marker type for this output group. MediaLive will create a message based on the content of each SCTE-35 message, format it for that marker type, and insert it in the datastream.\n\n(string)\n\nRtmp Ad Markers\n\nAuthenticationScheme -> (string)\n\nAuthentication scheme to use when connecting with CDN\n\nCacheFullBehavior -> (string)\n\nControls behavior when content cache fills up. If remote origin server stalls the RTMP connection and does not accept content fast enough the ‘Media Cache’ will fill up. When the cache reaches the duration specified by cacheLength the cache will stop accepting new content. If set to disconnectImmediately, the RTMP output will force a disconnect. Clear the media cache, and reconnect after restartDelay seconds. If set to waitForServer, the RTMP output will wait up to 5 minutes to allow the origin server to begin accepting data again.\n\nCacheLength -> (integer)\n\nCache length, in seconds, is used to calculate buffer size.\n\nCaptionData -> (string)\n\nControls the types of data that passes to onCaptionInfo outputs. If set to ‘all’ then 608 and 708 carried DTVCC data will be passed. If set to ‘field1AndField2608’ then DTVCC data will be stripped out, but 608 data from both fields will be passed. If set to ‘field1608’ then only the data carried in 608 from field 1 video will be passed.\n\nInputLossAction -> (string)\n\nControls the behavior of this RTMP group if input becomes unavailable. - emitOutput: Emit a slate until input returns. - pauseOutput: Stop transmitting data until input returns. This does not close the underlying RTMP connection.\n\nRestartDelay -> (integer)\n\nIf a streaming output fails, number of seconds to wait until a restart is initiated. A value of 0 means never restart.\n\nUdpGroupSettings -> (structure)\n\nUdp Group Settings\n\nInputLossAction -> (string)\n\nSpecifies behavior of last resort when input video is lost, and no more backup inputs are available. When dropTs is selected the entire transport stream will stop being emitted. When dropProgram is selected the program can be dropped from the transport stream (and replaced with null packets to meet the TS bitrate requirement). Or, when emitProgram is chosen the transport stream will continue to be produced normally with repeat frames, black frames, or slate frames substituted for the absent input video.\n\nTimedMetadataId3Frame -> (string)\n\nIndicates ID3 frame that has the timecode.\n\nTimedMetadataId3Period -> (integer)\n\nTimed Metadata interval in seconds.\n\nOutputs -> (list)\n\nPlaceholder documentation for __listOfOutput\n\n(structure)\n\nOutput settings. There can be multiple outputs within a group.\n\nAudioDescriptionNames -> (list)\n\nThe names of the AudioDescriptions used as audio sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nCaptionDescriptionNames -> (list)\n\nThe names of the CaptionDescriptions used as caption sources for this output.\n\n(string)\n\nPlaceholder documentation for __string\n\nOutputName -> (string)\n\nThe name used to identify an output.\n\nOutputSettings -> (structure)\n\nOutput type-specific settings.\n\nArchiveOutputSettings -> (structure)\n\nArchive Output Settings\n\nContainerSettings -> (structure)\n\nSettings specific to the container type of the file.\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nRawSettings -> (structure)\n\nRaw Settings\n\nExtension -> (string)\n\nOutput file extension. If excluded, this will be auto-selected from the container type.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nFrameCaptureOutputSettings -> (structure)\n\nFrame Capture Output Settings\n\nNameModifier -> (string)\n\nRequired if the output group contains more than one output. This modifier forms part of the output file name.\n\nHlsOutputSettings -> (structure)\n\nHls Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nHlsSettings -> (structure)\n\nSettings regarding the underlying stream. These settings are different for audio-only outputs.\n\nAudioOnlyHlsSettings -> (structure)\n\nAudio Only Hls Settings\n\nAudioGroupId -> (string)\n\nSpecifies the group to which the audio Rendition belongs.\n\nAudioOnlyImage -> (structure)\n\nOptional. Specifies the .jpg or .png image to use as the cover art for an audio-only output. We recommend a low bit-size file because the image increases the output audio bandwidth. The image is attached to the audio as an ID3 tag, frame type APIC, picture type 0x10, as per the “ID3 tag version 2.4.0 - Native Frames” standard.\n\nPasswordParam -> (string)\n\nkey used to extract the password from EC2 Parameter store\n\nUri -> (string)\n\nUniform Resource Identifier - This should be a path to a file accessible to the Live system (eg. a http:// URI) depending on the output type. For example, a RTMP destination should have a uri simliar to: “rtmp://fmsserver/live”.\n\nUsername -> (string)\n\nDocumentation update needed\n\nAudioTrackType -> (string)\n\nFour types of audio-only tracks are supported: Audio-Only Variant Stream The client can play back this audio-only stream instead of video in low-bandwidth scenarios. Represented as an EXT-X-STREAM-INF in the HLS manifest. Alternate Audio, Auto Select, Default Alternate rendition that the client should try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=YES, AUTOSELECT=YES Alternate Audio, Auto Select, Not Default Alternate rendition that the client may try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=YES Alternate Audio, not Auto Select Alternate rendition that the client will not try to play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=NO\n\nSegmentType -> (string)\n\nSpecifies the segment type.\n\nFmp4HlsSettings -> (structure)\n\nFmp4 Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nFrameCaptureHlsSettings -> (structure)\n\nFrame Capture Hls Settings\n\nStandardHlsSettings -> (structure)\n\nStandard Hls Settings\n\nAudioRenditionSets -> (string)\n\nList all the audio groups that are used with the video output stream. Input all the audio GROUP-IDs that are associated to the video, separate by ‘,’.\n\nM3u8Settings -> (structure)\n\nSettings information for the .m3u8 container\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values.\n\nEcmPid -> (string)\n\nThis parameter is unused and deprecated.\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock References (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value.\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. A value of “0” writes out the PMT once per segment file.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nScte35Behavior -> (string)\n\nIf set to passthrough, passes any SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata is passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Accepts “Format Identifiers”:#formatIdentifierParameters.\n\nSegmentModifier -> (string)\n\nString concatenated to end of segment filenames.\n\nMediaPackageOutputSettings -> (structure)\n\nMedia Package Output Settings\n\nMsSmoothOutputSettings -> (structure)\n\nMs Smooth Output Settings\n\nH265PackagingType -> (string)\n\nOnly applicable when this output is referencing an H.265 video description. Specifies whether MP4 segments should be packaged as HEV1 or HVC1.\n\nNameModifier -> (string)\n\nString concatenated to the end of the destination filename. Required for multiple outputs of the same type.\n\nMultiplexOutputSettings -> (structure)\n\nMultiplex Output Settings\n\nDestination -> (structure)\n\nDestination is a Multiplex.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nRtmpOutputSettings -> (structure)\n\nRtmp Output Settings\n\nCertificateMode -> (string)\n\nIf set to verifyAuthenticity, verify the tls certificate chain to a trusted Certificate Authority (CA). This will cause rtmps outputs with self-signed certificates to fail.\n\nConnectionRetryInterval -> (integer)\n\nNumber of seconds to wait before retrying a connection to the Flash Media server if the connection is lost.\n\nDestination -> (structure)\n\nThe RTMP endpoint excluding the stream name (eg. rtmp://host/appname). For connection to Akamai, a username and password must be supplied. URI fields accept format identifiers.\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nNumRetries -> (integer)\n\nNumber of retry attempts.\n\nUdpOutputSettings -> (structure)\n\nUdp Output Settings\n\nBufferMsec -> (integer)\n\nUDP output buffering in milliseconds. Larger values increase latency through the transcoder but simultaneously assist the transcoder in maintaining a constant, low-jitter UDP/RTP output while accommodating clock recovery, input switching, input disruptions, picture reordering, etc.\n\nContainerSettings -> (structure)\n\nUdp Container Settings\n\nM2tsSettings -> (structure)\n\nM2ts Settings\n\nAbsentInputAudioBehavior -> (string)\n\nWhen set to drop, output audio streams will be removed from the program if the selected input audio stream is removed from the input. This allows the output audio configuration to dynamically change based on input configuration. If this is set to encodeSilence, all output audio streams will output encoded silence when not connected to an active input stream.\n\nArib -> (string)\n\nWhen set to enabled, uses ARIB-compliant field muxing and removes video descriptor.\n\nAribCaptionsPid -> (string)\n\nPacket Identifier (PID) for ARIB Captions in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nAribCaptionsPidControl -> (string)\n\nIf set to auto, pid number used for ARIB Captions will be auto-selected from unused pids. If set to useConfigured, ARIB Captions will be on the configured pid number.\n\nAudioBufferModel -> (string)\n\nWhen set to dvb, uses DVB buffer model for Dolby Digital audio. When set to atsc, the ATSC model is used.\n\nAudioFramesPerPes -> (integer)\n\nThe number of audio frames to insert for each PES packet.\n\nAudioPids -> (string)\n\nPacket Identifier (PID) of the elementary audio stream(s) in the transport stream. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nAudioStreamType -> (string)\n\nWhen set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for EAC3. When set to dvb, uses stream type = 0x06.\n\nBitrate -> (integer)\n\nThe output bitrate of the transport stream in bits per second. Setting to 0 lets the muxer automatically determine the appropriate bitrate.\n\nBufferModel -> (string)\n\nControls the timing accuracy for output network traffic. Leave as MULTIPLEX to ensure accurate network packet timing. Or set to NONE, which might result in lower latency but will result in more variability in output network packet timing. This variability might cause interruptions, jitter, or bursty behavior in your playback or receiving devices.\n\nCcDescriptor -> (string)\n\nWhen set to enabled, generates captionServiceDescriptor in PMT.\n\nDvbNitSettings -> (structure)\n\nInserts DVB Network Information Table (NIT) at the specified table repetition interval.\n\nNetworkId -> (integer)\n\nThe numeric value placed in the Network Information Table (NIT).\n\nNetworkName -> (string)\n\nThe network name text placed in the networkNameDescriptor inside the Network Information Table. Maximum length is 256 characters.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbSdtSettings -> (structure)\n\nInserts DVB Service Description Table (SDT) at the specified table repetition interval.\n\nOutputSdt -> (string)\n\nSelects method of inserting SDT information into output stream. The sdtFollow setting copies SDT information from input stream to output stream. The sdtFollowIfPresent setting copies SDT information from input stream to output stream if SDT information is present in the input, otherwise it will fall back on the user-defined values. The sdtManual setting means user will enter the SDT information. The sdtNone setting means output stream will not contain SDT information.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nServiceName -> (string)\n\nThe service name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nServiceProviderName -> (string)\n\nThe service provider name placed in the serviceDescriptor in the Service Description Table. Maximum length is 256 characters.\n\nDvbSubPids -> (string)\n\nPacket Identifier (PID) for input source DVB Subtitle data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nDvbTdtSettings -> (structure)\n\nInserts DVB Time and Date Table (TDT) at the specified table repetition interval.\n\nRepInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream.\n\nDvbTeletextPid -> (string)\n\nPacket Identifier (PID) for input source DVB Teletext data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEbif -> (string)\n\nIf set to passthrough, passes any EBIF data from the input source to this output.\n\nEbpAudioInterval -> (string)\n\nWhen videoAndFixedIntervals is selected, audio EBP markers will be added to partitions 3 and 4. The interval between these additional markers will be fixed, and will be slightly shorter than the video EBP marker interval. Only available when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will always follow the video interval.\n\nEbpLookaheadMs -> (integer)\n\nWhen set, enforces that Encoder Boundary Points do not come within the specified time interval of each other by looking ahead at input video. If another EBP is going to come in within the specified time interval, the current EBP is not emitted, and the segment is “stretched” to the next marker. The lookahead value does not add latency to the system. The Live Event must be configured elsewhere to create sufficient latency to make the lookahead accurate.\n\nEbpPlacement -> (string)\n\nControls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP markers will be placed on the video PID and all audio PIDs. If set to videoPid, EBP markers will be placed on only the video PID.\n\nEcmPid -> (string)\n\nThis field is unused and deprecated.\n\nEsRateInPes -> (string)\n\nInclude or exclude the ES Rate field in the PES header.\n\nEtvPlatformPid -> (string)\n\nPacket Identifier (PID) for input source ETV Platform data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nEtvSignalPid -> (string)\n\nPacket Identifier (PID) for input source ETV Signal data to this output. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nFragmentTime -> (double)\n\nThe length in seconds of each fragment. Only used with EBP markers.\n\nKlv -> (string)\n\nIf set to passthrough, passes any KLV data from the input source to this output.\n\nKlvDataPids -> (string)\n\nPacket Identifier (PID) for input source KLV data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nNielsenId3Behavior -> (string)\n\nIf set to passthrough, Nielsen inaudible tones for media tracking will be detected in the input audio and an equivalent ID3 tag will be inserted in the output.\n\nNullPacketBitrate -> (double)\n\nValue in bits per second of extra null packets to insert into the transport stream. This can be used if a downstream encryption system requires periodic null packets.\n\nPatInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPcrControl -> (string)\n\nWhen set to pcrEveryPesPacket, a Program Clock Reference value is inserted for every Packetized Elementary Stream (PES) header. This parameter is effective only when the PCR PID is the same as the video or audio elementary stream.\n\nPcrPeriod -> (integer)\n\nMaximum time in milliseconds between Program Clock Reference (PCRs) inserted into the transport stream.\n\nPcrPid -> (string)\n\nPacket Identifier (PID) of the Program Clock Reference (PCR) in the transport stream. When no value is given, the encoder will assign the same value as the Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nPmtInterval -> (integer)\n\nThe number of milliseconds between instances of this table in the output transport stream. Valid values are 0, 10..1000.\n\nPmtPid -> (string)\n\nPacket Identifier (PID) for the Program Map Table (PMT) in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nProgramNum -> (integer)\n\nThe value of the program number field in the Program Map Table.\n\nRateMode -> (string)\n\nWhen vbr, does not insert null packets into transport stream to fill specified bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.\n\nScte27Pids -> (string)\n\nPacket Identifier (PID) for input source SCTE-27 data to this output. Multiple values are accepted, and can be entered in ranges and/or by comma separation. Can be entered as decimal or hexadecimal values. Each PID specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).\n\nScte35Control -> (string)\n\nOptionally pass SCTE-35 signals from the input source to this output.\n\nScte35Pid -> (string)\n\nPacket Identifier (PID) of the SCTE-35 stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nSegmentationMarkers -> (string)\n\nInserts segmentation markers at each segmentationTime period. raiSegstart sets the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI bit and adds the current timecode in the private data bytes. psiSegstart inserts PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point information to the adaptation field as per OpenCable specification OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the adaptation field using a legacy proprietary format.\n\nSegmentationStyle -> (string)\n\nThe segmentation style parameter controls how segmentation markers are inserted into the transport stream. With avails, it is possible that segments may be truncated, which can influence where future segmentation markers are inserted. When a segmentation style of “resetCadence” is selected and a segment is truncated due to an avail, we will reset the segmentation cadence. This means the subsequent segment will have a duration of $segmentationTime seconds. When a segmentation style of “maintainCadence” is selected and a segment is truncated due to an avail, we will not reset the segmentation cadence. This means the subsequent segment will likely be truncated as well. However, all segments after that will have a duration of $segmentationTime seconds. Note that EBP lookahead is a slight exception to this rule.\n\nSegmentationTime -> (double)\n\nThe length in seconds of each segment. Required unless markers is set to _none_.\n\nTimedMetadataBehavior -> (string)\n\nWhen set to passthrough, timed metadata will be passed through from input to output.\n\nTimedMetadataPid -> (string)\n\nPacket Identifier (PID) of the timed metadata stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nTransportStreamId -> (integer)\n\nThe value of the transport stream ID field in the Program Map Table.\n\nVideoPid -> (string)\n\nPacket Identifier (PID) of the elementary video stream in the transport stream. Can be entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182 (or 0x1ff6).\n\nDestination -> (structure)\n\nDestination address and port number for RTP or UDP packets. Can be unicast or multicast RTP or UDP (eg. rtp://239.10.10.10:5001 or udp://10.100.100.100:5002).\n\nDestinationRefId -> (string)\n\nPlaceholder documentation for __string\n\nFecOutputSettings -> (structure)\n\nSettings for enabling and adjusting Forward Error Correction on UDP outputs.\n\nColumnDepth -> (integer)\n\nParameter D from SMPTE 2022-1. The height of the FEC protection matrix. The number of transport stream packets per column error correction packet. Must be between 4 and 20, inclusive.\n\nIncludeFec -> (string)\n\nEnables column only or column and row based FEC\n\nRowLength -> (integer)\n\nParameter L from SMPTE 2022-1. The width of the FEC protection matrix. Must be between 1 and 20, inclusive. If only Column FEC is used, then larger values increase robustness. If Row FEC is used, then this is the number of transport stream packets per row error correction packet, and the value must be between 4 and 20, inclusive, if includeFec is columnAndRow. If includeFec is column, this value must be 1 to 20, inclusive.\n\nVideoDescriptionName -> (string)\n\nThe name of the VideoDescription used as the source for this output.\n\nTimecodeConfig -> (structure)\n\nContains settings used to acquire and adjust timecode information from inputs.\n\nSource -> (string)\n\nIdentifies the source for the timecode that will be associated with the events outputs. -Embedded (embedded): Initialize the output timecode with timecode from the the source. If no embedded timecode is detected in the source, the system falls back to using “Start at 0” (zerobased). -System Clock (systemclock): Use the UTC time. -Start at 0 (zerobased): The time of the first frame of the event will be 00:00:00:00.\n\nSyncThreshold -> (integer)\n\nThreshold in frames beyond which output timecode is resynchronized to the input timecode. Discrepancies below this threshold are permitted to avoid unnecessary discontinuities in the output timecode. No timecode sync when this is not specified.\n\nVideoDescriptions -> (list)\n\nPlaceholder documentation for __listOfVideoDescription\n\n(structure)\n\nVideo settings for this stream.\n\nCodecSettings -> (structure)\n\nVideo codec settings.\n\nFrameCaptureSettings -> (structure)\n\nFrame Capture Settings\n\nCaptureInterval -> (integer)\n\nThe frequency at which to capture frames for inclusion in the output. May be specified in either seconds or milliseconds, as specified by captureIntervalUnits.\n\nCaptureIntervalUnits -> (string)\n\nUnit for the frame capture interval.\n\nH264Settings -> (structure)\n\nH264 Settings\n\nAdaptiveQuantization -> (string)\n\nEnables or disables adaptive quantization, which is a technique MediaLive can apply to video on a frame-by-frame basis to produce more compression without losing quality. There are three types of adaptive quantization: flicker, spatial, and temporal. Set the field in one of these ways: Set to Auto. Recommended. For each type of AQ, MediaLive will determine if AQ is needed, and if so, the appropriate strength. Set a strength (a value other than Auto or Disable). This strength will apply to any of the AQ fields that you choose to enable. Set to Disabled to disable all types of adaptive quantization.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufFillPct -> (integer)\n\nPercentage of the buffer that should initially be filled (HRD buffer model).\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nEntropyEncoding -> (string)\n\nEntropy encoding mode. Use cabac (must be in Main or High profile) or cavlc.\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nFlicker AQ makes adjustments within each frame to reduce flicker or ‘pop’ on I-frames. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if flicker AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply flicker AQ using the specified strength. Disabled: MediaLive won’t apply flicker AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply flicker AQ.\n\nForceFieldPictures -> (string)\n\nThis setting applies only when scan type is “interlaced.” It controls whether coding is performed on a field basis or on a frame basis. (When the video is progressive, the coding is always performed on a frame basis.) enabled: Force MediaLive to code on a field basis, so that odd and even sets of fields are coded separately. disabled: Code the two sets of fields separately (on a field basis) or together (on a frame basis using PAFF), depending on what is most appropriate for the content.\n\nFramerateControl -> (string)\n\nThis field indicates how the output video frame rate is specified. If “specified” is selected then the output video frame rate is determined by framerateNumerator and framerateDenominator, else if “initializeFromSource” is selected then the output video frame rate will be set equal to the input video frame rate of the first input.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopBReference -> (string)\n\nDocumentation update needed\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopNumBFrames -> (integer)\n\nNumber of B-frames between reference frames.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.264 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level For VBR: Set the maximum bitrate in order to accommodate expected spikes in the complexity of the video.\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nNumRefFrames -> (integer)\n\nNumber of reference frames to use. The encoder may use more than requested if using B-frames and/or interlaced encoding.\n\nParControl -> (string)\n\nThis field indicates how the output pixel aspect ratio is specified. If “specified” is selected then the output video pixel aspect ratio is determined by parNumerator and parDenominator, else if “initializeFromSource” is selected then the output pixsel aspect ratio will be set equal to the input video pixel aspect ratio of the first input.\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.264 Profile.\n\nQualityLevel -> (string)\n\nLeave as STANDARD_QUALITY or choose a different value (which might result in additional costs to run the channel). - ENHANCED_QUALITY: Produces a slightly better video quality without an increase in the bitrate. Has an effect only when the Rate control mode is QVBR or CBR. If this channel is in a MediaLive multiplex, the value must be ENHANCED_QUALITY. - STANDARD_QUALITY: Valid for any Rate control mode.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. You can set a target quality or you can let MediaLive determine the best quality. To set a target quality, enter values in the QVBR quality level field and the Max bitrate field. Enter values that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M To let MediaLive decide, leave the QVBR quality level field empty, and in Max bitrate enter the maximum rate you want in the video. For more information, see the section called “Video - rate control mode” in the MediaLive user guide\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. VBR: Quality and bitrate vary, depending on the video complexity. Recommended instead of QVBR if you want to maintain a specific average bitrate over the duration of the channel. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection. - On: inserts I-frames when scene change is detected. - Off: does not force an I-frame when scene change is detected.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nSoftness -> (integer)\n\nSoftness. Selects quantizer matrix, larger values reduce high-frequency content in the encoded image. If not set to zero, must be greater than 15.\n\nSpatialAq -> (string)\n\nSpatial AQ makes adjustments within each frame based on spatial variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if spatial AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply spatial AQ using the specified strength. Disabled: MediaLive won’t apply spatial AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply spatial AQ.\n\nSubgopLength -> (string)\n\nIf set to fixed, use gopNumBFrames B-frames per sub-GOP. If set to dynamic, optimize the number of B-frames used for each sub-GOP to improve visual quality.\n\nSyntax -> (string)\n\nProduces a bitstream compliant with SMPTE RP-2027.\n\nTemporalAq -> (string)\n\nTemporal makes adjustments within each frame based on temporal variation of content complexity. The value to enter in this field depends on the value in the Adaptive quantization field: If you have set the Adaptive quantization field to Auto, MediaLive ignores any value in this field. MediaLive will determine if temporal AQ is appropriate and will apply the appropriate strength. If you have set the Adaptive quantization field to a strength, you can set this field to Enabled or Disabled. Enabled: MediaLive will apply temporal AQ using the specified strength. Disabled: MediaLive won’t apply temporal AQ. If you have set the Adaptive quantization to Disabled, MediaLive ignores any value in this field and doesn’t apply temporal AQ.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nH265Settings -> (structure)\n\nH265 Settings\n\nAdaptiveQuantization -> (string)\n\nAdaptive quantization. Allows intra-frame quantizers to vary to improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates that AFD values will be written into the output stream. If afdSignaling is “auto”, the system will try to preserve the input AFD value (in cases where multiple AFD values are valid). If set to “fixed”, the AFD value will be the value configured in the fixedAfd parameter.\n\nAlternativeTransferFunction -> (string)\n\nWhether or not EML should insert an Alternative Transfer Function SEI message to support backwards compatibility with non-HDR decoders and displays.\n\nBitrate -> (integer)\n\nAverage bitrate in bits/second. Required when the rate control mode is VBR or CBR. Not used for QVBR. In an MS Smooth output group, each output must have a unique value when its bitrate is rounded down to the nearest multiple of 1000.\n\nBufSize -> (integer)\n\nSize of buffer (HRD buffer model) in bits.\n\nColorMetadata -> (string)\n\nIncludes colorspace metadata in the output.\n\nColorSpaceSettings -> (structure)\n\nColor Space settings\n\nColorSpacePassthroughSettings -> (structure)\n\nPassthrough applies no color space conversion to the output\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nRec601Settings -> (structure)\n\nRec601 Settings\n\nRec709Settings -> (structure)\n\nRec709 Settings\n\nFilterSettings -> (structure)\n\nOptional filters that you can apply to an encode.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nFour bit AFD value to write on all frames of video in the output stream. Only valid when afdSignaling is set to ‘Fixed’.\n\nFlickerAq -> (string)\n\nIf set to enabled, adjust quantization within each frame to reduce flicker or ‘pop’ on I-frames.\n\nFramerateDenominator -> (integer)\n\nFramerate denominator.\n\nFramerateNumerator -> (integer)\n\nFramerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.\n\nGopClosedCadence -> (integer)\n\nFrequency of closed GOPs. In streaming applications, it is recommended that this be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly as possible. Setting this value to 0 will break output segmenting.\n\nGopSize -> (double)\n\nGOP size (keyframe interval) in units of either frames or seconds per gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater than 0, but need not be an integer.\n\nGopSizeUnits -> (string)\n\nIndicates if the gopSize is specified in frames or seconds. If seconds the system will convert the gopSize into a frame count at run time.\n\nLevel -> (string)\n\nH.265 Level.\n\nLookAheadRateControl -> (string)\n\nAmount of lookahead. A value of low can decrease latency and memory usage, while high can produce better quality for certain content.\n\nMaxBitrate -> (integer)\n\nFor QVBR: See the tooltip for Quality level\n\nMinIInterval -> (integer)\n\nOnly meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if multiplex rate control is used. Enforces separation between repeated (cadence) I-frames and I-frames inserted by Scene Change Detection. If a scene change I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk and/or stretched to the scene change I-frame. GOP stretch requires enabling lookahead as well as setting I-interval. The normal cadence resumes for the next GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1\n\nParDenominator -> (integer)\n\nPixel Aspect Ratio denominator.\n\nParNumerator -> (integer)\n\nPixel Aspect Ratio numerator.\n\nProfile -> (string)\n\nH.265 Profile.\n\nQvbrQualityLevel -> (integer)\n\nControls the target quality for the video encode. Applies only when the rate control mode is QVBR. Set values for the QVBR quality level field and Max bitrate field that suit your most important viewing devices. Recommended values are: - Primary screen: Quality level: 8 to 10. Max bitrate: 4M - PC or tablet: Quality level: 7. Max bitrate: 1.5M to 3M - Smartphone: Quality level: 6. Max bitrate: 1M to 1.5M\n\nRateControlMode -> (string)\n\nRate control mode. QVBR: Quality will match the specified quality level except when it is constrained by the maximum bitrate. Recommended if you or your viewers pay for bandwidth. CBR: Quality varies, depending on the video complexity. Recommended only if you distribute your assets to devices that cannot handle variable bitrates. Multiplex: This rate control mode is only supported (and is required) when the video is being delivered to a MediaLive Multiplex in which case the rate control configuration is controlled by the properties within the Multiplex Program.\n\nScanType -> (string)\n\nSets the scan type of the output to progressive or top-field-first interlaced.\n\nSceneChangeDetect -> (string)\n\nScene change detection.\n\nSlices -> (integer)\n\nNumber of slices per picture. Must be less than or equal to the number of macroblock rows for progressive pictures, and less than or equal to half the number of macroblock rows for interlaced pictures. This field is optional; when no value is specified the encoder will choose the number of slices based on encode resolution.\n\nTier -> (string)\n\nH.265 Tier.\n\nTimecodeInsertion -> (string)\n\nDetermines how timecodes should be inserted into the video elementary stream. - ‘disabled’: Do not include timecodes - ‘picTimingSei’: Pass through picture timing SEI messages from the source specified in Timecode Config\n\nMpeg2Settings -> (structure)\n\nMpeg2 Settings\n\nAdaptiveQuantization -> (string)\n\nChoose Off to disable adaptive quantization. Or choose another value to enable the quantizer and set its strength. The strengths are: Auto, Off, Low, Medium, High. When you enable this field, MediaLive allows intra-frame quantizers to vary, which might improve visual quality.\n\nAfdSignaling -> (string)\n\nIndicates the AFD values that MediaLive will write into the video encode. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose AUTO. AUTO: MediaLive will try to preserve the input AFD value (in cases where multiple AFD values are valid). FIXED: MediaLive will use the value you specify in fixedAFD.\n\nColorMetadata -> (string)\n\nSpecifies whether to include the color space metadata. The metadata describes the color space that applies to the video (the colorSpace field). We recommend that you insert the metadata.\n\nColorSpace -> (string)\n\nChoose the type of color space conversion to apply to the output. For detailed information on setting up both the input and the output to obtain the desired color space in the output, see the section on “MediaLive Features - Video - color space” in the MediaLive User Guide. PASSTHROUGH: Keep the color space of the input content - do not convert it. AUTO:Convert all content that is SD to rec 601, and convert all content that is HD to rec 709.\n\nDisplayAspectRatio -> (string)\n\nSets the pixel aspect ratio for the encode.\n\nFilterSettings -> (structure)\n\nOptionally specify a noise reduction filter, which can improve quality of compressed content. If you do not choose a filter, no filter will be applied. TEMPORAL: This filter is useful for both source content that is noisy (when it has excessive digital artifacts) and source content that is clean. When the content is noisy, the filter cleans up the source content before the encoding phase, with these two effects: First, it improves the output video quality because the content has been cleaned up. Secondly, it decreases the bandwidth because MediaLive does not waste bits on encoding noise. When the content is reasonably clean, the filter tends to decrease the bitrate.\n\nTemporalFilterSettings -> (structure)\n\nTemporal Filter Settings\n\nPostFilterSharpening -> (string)\n\nIf you enable this filter, the results are the following: - If the source content is noisy (it contains excessive digital artifacts), the filter cleans up the source. - If the source content is already clean, the filter tends to decrease the bitrate, especially when the rate control mode is QVBR.\n\nStrength -> (string)\n\nChoose a filter strength. We recommend a strength of 1 or 2. A higher strength might take out good information, resulting in an image that is overly soft.\n\nFixedAfd -> (string)\n\nComplete this field only when afdSignaling is set to FIXED. Enter the AFD value (4 bits) to write on all frames of the video encode.\n\nFramerateDenominator -> (integer)\n\ndescription”: “The framerate denominator. For example, 1001. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nFramerateNumerator -> (integer)\n\nThe framerate numerator. For example, 24000. The framerate is the numerator divided by the denominator. For example, 24000 / 1001 = 23.976 FPS.\n\nGopClosedCadence -> (integer)\n\nMPEG2: default is open GOP.\n\nGopNumBFrames -> (integer)\n\nRelates to the GOP structure. The number of B-frames between reference frames. If you do not know what a B-frame is, use the default.\n\nGopSize -> (double)\n\nRelates to the GOP structure. The GOP size (keyframe interval) in the units specified in gopSizeUnits. If you do not know what GOP is, use the default. If gopSizeUnits is frames, then the gopSize must be an integer and must be greater than or equal to 1. If gopSizeUnits is seconds, the gopSize must be greater than 0, but does not need to be an integer.\n\nGopSizeUnits -> (string)\n\nRelates to the GOP structure. Specifies whether the gopSize is specified in frames or seconds. If you do not plan to change the default gopSize, leave the default. If you specify SECONDS, MediaLive will internally convert the gop size to a frame count.\n\nScanType -> (string)\n\nSet the scan type of the output to PROGRESSIVE or INTERLACED (top field first).\n\nSubgopLength -> (string)\n\nRelates to the GOP structure. If you do not know what GOP is, use the default. FIXED: Set the number of B-frames in each sub-GOP to the value in gopNumBFrames. DYNAMIC: Let MediaLive optimize the number of B-frames in each sub-GOP, to improve visual quality.\n\nTimecodeInsertion -> (string)\n\nDetermines how MediaLive inserts timecodes in the output video. For detailed information about setting up the input and the output for a timecode, see the section on “MediaLive Features - Timecode configuration” in the MediaLive User Guide. DISABLED: do not include timecodes. GOP_TIMECODE: Include timecode metadata in the GOP header.\n\nHeight -> (integer)\n\nOutput video height, in pixels. Must be an even number. For most codecs, you can leave this field and width blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nName -> (string)\n\nThe name of this VideoDescription. Outputs will use this name to uniquely identify this Description. Description names should be unique within this Live Event.\n\nRespondToAfd -> (string)\n\nIndicates how MediaLive will respond to the AFD values that might be in the input video. If you do not know what AFD signaling is, or if your downstream system has not given you guidance, choose PASSTHROUGH. RESPOND: MediaLive clips the input video using a formula that uses the AFD values (configured in afdSignaling ), the input display aspect ratio, and the output display aspect ratio. MediaLive also includes the AFD values in the output, unless the codec for this encode is FRAME_CAPTURE. PASSTHROUGH: MediaLive ignores the AFD values and does not clip the video. But MediaLive does include the values in the output. NONE: MediaLive does not clip the input video and does not include the AFD values in the output\n\nScalingBehavior -> (string)\n\nSTRETCH_TO_OUTPUT configures the output position to stretch the video to the specified output resolution (height and width). This option will override any position value. DEFAULT may insert black boxes (pillar boxes or letter boxes) around the video to provide the specified output resolution.\n\nSharpness -> (integer)\n\nChanges the strength of the anti-alias filter used for scaling. 0 is the softest setting, 100 is the sharpest. A setting of 50 is recommended for most content.\n\nWidth -> (integer)\n\nOutput video width, in pixels. Must be an even number. For most codecs, you can leave this field and height blank in order to use the height and width (resolution) from the source. Note, however, that leaving blank is not recommended. For the Frame Capture codec, height and width are required.\n\nId -> (string)\n\nThe unique id of the channel.\n\nInputAttachments -> (list)\n\nList of input attachments for channel.\n\n(structure)\n\nPlaceholder documentation for InputAttachment\n\nAutomaticInputFailoverSettings -> (structure)\n\nUser-specified settings for defining what the conditions are for declaring the input unhealthy and failing over to a different input.\n\nErrorClearTimeMsec -> (integer)\n\nThis clear time defines the requirement a recovered input must meet to be considered healthy. The input must have no failover conditions for this length of time. Enter a time in milliseconds. This value is particularly important if the input_preference for the failover pair is set to PRIMARY_INPUT_PREFERRED, because after this time, MediaLive will switch back to the primary input.\n\nFailoverConditions -> (list)\n\nA list of failover conditions. If any of these conditions occur, MediaLive will perform a failover to the other input.\n\n(structure)\n\nFailover Condition settings. There can be multiple failover conditions inside AutomaticInputFailoverSettings.\n\nFailoverConditionSettings -> (structure)\n\nFailover condition type-specific settings.\n\nAudioSilenceSettings -> (structure)\n\nMediaLive will perform a failover if the specified audio selector is silent for the specified period.\n\nAudioSelectorName -> (string)\n\nThe name of the audio selector in the input that MediaLive should monitor to detect silence. Select your most important rendition. If you didn’t create an audio selector in this input, leave blank.\n\nAudioSilenceThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be silent before automatic input failover occurs. Silence is defined as audio loss or audio quieter than -50 dBFS.\n\nInputLossSettings -> (structure)\n\nMediaLive will perform a failover if content is not detected in this input for the specified period.\n\nInputLossThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that no input is detected. After that time, an input failover will occur.\n\nVideoBlackSettings -> (structure)\n\nMediaLive will perform a failover if content is considered black for the specified period.\n\nBlackDetectThreshold -> (double)\n\nA value used in calculating the threshold below which MediaLive considers a pixel to be ‘black’. For the input to be considered black, every pixel in a frame must be below this threshold. The threshold is calculated as a percentage (expressed as a decimal) of white. Therefore .1 means 10% white (or 90% black). Note how the formula works for any color depth. For example, if you set this field to 0.1 in 10-bit color depth: (1023*0.1=102.3), which means a pixel value of 102 or less is ‘black’. If you set this field to .1 in an 8-bit color depth: (255*0.1=25.5), which means a pixel value of 25 or less is ‘black’. The range is 0.0 to 1.0, with any number of decimal places.\n\nVideoBlackThresholdMsec -> (integer)\n\nThe amount of time (in milliseconds) that the active input must be black before automatic input failover occurs.\n\nInputPreference -> (string)\n\nInput preference when deciding which input to make active when a previously failed input has recovered.\n\nSecondaryInputId -> (string)\n\nThe input ID of the secondary input in the automatic input failover pair.\n\nInputAttachmentName -> (string)\n\nUser-specified name for the attachment. This is required if the user wants to use this input in an input switch action.\n\nInputId -> (string)\n\nThe ID of the input\n\nInputSettings -> (structure)\n\nSettings of an input (caption selector, etc.)\n\nAudioSelectors -> (list)\n\nUsed to select the audio stream to decode for inputs that have multiple available.\n\n(structure)\n\nAudio Selector\n\nName -> (string)\n\nThe name of this AudioSelector. AudioDescriptions will use this name to uniquely identify this Selector. Selector names should be unique per input.\n\nSelectorSettings -> (structure)\n\nThe audio selector settings.\n\nAudioHlsRenditionSelection -> (structure)\n\nAudio Hls Rendition Selection\n\nGroupId -> (string)\n\nSpecifies the GROUP-ID in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nName -> (string)\n\nSpecifies the NAME in the #EXT-X-MEDIA tag of the target HLS audio rendition.\n\nAudioLanguageSelection -> (structure)\n\nAudio Language Selection\n\nLanguageCode -> (string)\n\nSelects a specific three-letter language code from within an audio source.\n\nLanguageSelectionPolicy -> (string)\n\nWhen set to “strict”, the transport stream demux strictly identifies audio streams by their language descriptor. If a PMT update occurs such that an audio stream matching the initially selected language is no longer present then mute will be encoded until the language returns. If “loose”, then on a PMT update the demux will choose another audio stream in the program with the same stream type if it can’t find one with the same language.\n\nAudioPidSelection -> (structure)\n\nAudio Pid Selection\n\nPid -> (integer)\n\nSelects a specific PID from within a source.\n\nAudioTrackSelection -> (structure)\n\nAudio Track Selection\n\nTracks -> (list)\n\nSelects one or more unique audio tracks from within a source.\n\n(structure)\n\nAudio Track\n\nTrack -> (integer)\n\n1-based integer value that maps to a specific audio track\n\nCaptionSelectors -> (list)\n\nUsed to select the caption input to use for inputs that have multiple available.\n\n(structure)\n\nOutput groups for this Live Event. Output groups contain information about where streams should be distributed.\n\nLanguageCode -> (string)\n\nWhen specified this field indicates the three letter language code of the caption track to extract from the source.\n\nName -> (string)\n\nName identifier for a caption selector. This name is used to associate this caption selector with one or more caption descriptions. Names must be unique within an event.\n\nSelectorSettings -> (structure)\n\nCaption selector settings.\n\nAncillarySourceSettings -> (structure)\n\nAncillary Source Settings\n\nSourceAncillaryChannelNumber -> (integer)\n\nSpecifies the number (1 to 4) of the captions channel you want to extract from the ancillary captions. If you plan to convert the ancillary captions to another format, complete this field. If you plan to choose Embedded as the captions destination in the output (to pass through all the channels in the ancillary captions), leave this field blank because MediaLive ignores the field.\n\nAribSourceSettings -> (structure)\n\nArib Source Settings\n\nDvbSubSourceSettings -> (structure)\n\nDvb Sub Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nWhen using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through, regardless of selectors.\n\nEmbeddedSourceSettings -> (structure)\n\nEmbedded Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nScte20Detection -> (string)\n\nSet to “auto” to handle streams with intermittent and/or non-aligned SCTE-20 and Embedded captions.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nSource608TrackNumber -> (integer)\n\nThis field is unused and deprecated.\n\nScte20SourceSettings -> (structure)\n\nScte20 Source Settings\n\nConvert608To708 -> (string)\n\nIf upconvert, 608 data is both passed through via the “608 compatibility bytes” fields of the 708 wrapper as well as translated into 708. 708 data present in the source content will be discarded.\n\nSource608ChannelNumber -> (integer)\n\nSpecifies the 608/708 channel number within the video track from which to extract captions. Unused for passthrough.\n\nScte27SourceSettings -> (structure)\n\nScte27 Source Settings\n\nOcrLanguage -> (string)\n\nIf you will configure a WebVTT caption description that references this caption selector, use this field to provide the language to consider when translating the image-based source to text.\n\nPid -> (integer)\n\nThe pid field is used in conjunction with the caption selector languageCode field as follows: - Specify PID and Language: Extracts captions from that PID; the language is “informational”. - Specify PID and omit Language: Extracts the specified PID. - Omit PID and specify Language: Extracts the specified language, whichever PID that happens to be. - Omit PID and omit Language: Valid only if source is DVB-Sub that is being passed through; all languages will be passed through.\n\nTeletextSourceSettings -> (structure)\n\nTeletext Source Settings\n\nOutputRectangle -> (structure)\n\nOptionally defines a region where TTML style captions will be displayed\n\nHeight -> (double)\n\nSee the description in leftOffset. For height, specify the entire height of the rectangle as a percentage of the underlying frame height. For example, “80” means the rectangle height is 80% of the underlying frame height. The topOffset and rectangleHeight must add up to 100% or less. This field corresponds to tts:extent - Y in the TTML standard.\n\nLeftOffset -> (double)\n\nApplies only if you plan to convert these source captions to EBU-TT-D or TTML in an output. (Make sure to leave the default if you don’t have either of these formats in the output.) You can define a display rectangle for the captions that is smaller than the underlying video frame. You define the rectangle by specifying the position of the left edge, top edge, bottom edge, and right edge of the rectangle, all within the underlying video frame. The units for the measurements are percentages. If you specify a value for one of these fields, you must specify a value for all of them. For leftOffset, specify the position of the left edge of the rectangle, as a percentage of the underlying frame width, and relative to the left edge of the frame. For example, “10” means the measurement is 10% of the underlying frame width. The rectangle left edge starts at that position from the left edge of the frame. This field corresponds to tts:origin - X in the TTML standard.\n\nTopOffset -> (double)\n\nSee the description in leftOffset. For topOffset, specify the position of the top edge of the rectangle, as a percentage of the underlying frame height, and relative to the top edge of the frame. For example, “10” means the measurement is 10% of the underlying frame height. The rectangle top edge starts at that position from the top edge of the frame. This field corresponds to tts:origin - Y in the TTML standard.\n\nWidth -> (double)\n\nSee the description in leftOffset. For width, specify the entire width of the rectangle as a percentage of the underlying frame width. For example, “80” means the rectangle width is 80% of the underlying frame width. The leftOffset and rectangleWidth must add up to 100% or less. This field corresponds to tts:extent - X in the TTML standard.\n\nPageNumber -> (string)\n\nSpecifies the teletext page number within the data stream from which to extract captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should be specified as a hexadecimal string with no “0x” prefix.\n\nDeblockFilter -> (string)\n\nEnable or disable the deblock filter when filtering.\n\nDenoiseFilter -> (string)\n\nEnable or disable the denoise filter when filtering.\n\nFilterStrength -> (integer)\n\nAdjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).\n\nInputFilter -> (string)\n\nTurns on the filter for this input. MPEG-2 inputs have the deblocking filter enabled by default. 1) auto - filtering will be applied depending on input type/quality 2) disabled - no filtering will be applied to the input 3) forced - filtering will be applied regardless of input type\n\nNetworkInputSettings -> (structure)\n\nInput settings.\n\nHlsInputSettings -> (structure)\n\nSpecifies HLS input settings when the uri is for a HLS manifest.\n\nBandwidth -> (integer)\n\nWhen specified the HLS stream with the m3u8 BANDWIDTH that most closely matches this value will be chosen, otherwise the highest bandwidth stream in the m3u8 will be chosen. The bitrate is specified in bits per second, as in an HLS manifest.\n\nBufferSegments -> (integer)\n\nWhen specified, reading of the HLS input will begin this many buffer segments from the end (most recently written segment). When not specified, the HLS input will begin with the first segment specified in the m3u8.\n\nRetries -> (integer)\n\nThe number of consecutive times that attempts to read a manifest or segment must fail before the input is considered unavailable.\n\nRetryInterval -> (integer)\n\nThe number of seconds between retries when an attempt to read a manifest or segment fails.\n\nScte35Source -> (string)\n\nIdentifies the source for the SCTE-35 messages that MediaLive will ingest. Messages can be ingested from the content segments (in the stream) or from tags in the playlist (the HLS manifest). MediaLive ignores SCTE-35 information in the source that is not selected.\n\nServerValidation -> (string)\n\nCheck HTTPS server certificates. When set to checkCryptographyOnly, cryptography in the certificate will be checked, but not the server’s name. Certain subdomains (notably S3 buckets that use dots in the bucket name) do not strictly match the corresponding certificate’s wildcard pattern and would otherwise cause the event to error. This setting is ignored for protocols that do not use https.\n\nSmpte2038DataPreference -> (string)\n\nSpecifies whether to extract applicable ancillary data from a SMPTE-2038 source in this input. Applicable data types are captions, timecode, AFD, and SCTE-104 messages. - PREFER: Extract from SMPTE-2038 if present in this input, otherwise extract from another source (if any). - IGNORE: Never extract any ancillary data from SMPTE-2038.\n\nSourceEndBehavior -> (string)\n\nLoop input if it is a file. This allows a file input to be streamed indefinitely.\n\nVideoSelector -> (structure)\n\nInforms which video elementary stream to decode for input types that have multiple available.\n\nColorSpace -> (string)\n\nSpecifies the color space of an input. This setting works in tandem with colorSpaceUsage and a video description’s colorSpaceSettingsChoice to determine if any conversion will be performed.\n\nColorSpaceSettings -> (structure)\n\nColor space settings\n\nHdr10Settings -> (structure)\n\nHdr10 Settings\n\nMaxCll -> (integer)\n\nMaximum Content Light Level An integer metadata value defining the maximum light level, in nits, of any single pixel within an encoded HDR video stream or file.\n\nMaxFall -> (integer)\n\nMaximum Frame Average Light Level An integer metadata value defining the maximum average light level, in nits, for any single frame within an encoded HDR video stream or file.\n\nColorSpaceUsage -> (string)\n\nApplies only if colorSpace is a value other than follow. This field controls how the value in the colorSpace field will be used. fallback means that when the input does include color space data, that data will be used, but when the input has no color space data, the value in colorSpace will be used. Choose fallback if your input is sometimes missing color space data, but when it does have color space data, that data is correct. force means to always use the value in colorSpace. Choose force if your input usually has no color space data or might have unreliable color space data.\n\nSelectorSettings -> (structure)\n\nThe video selector settings.\n\nVideoSelectorPid -> (structure)\n\nVideo Selector Pid\n\nPid -> (integer)\n\nSelects a specific PID from within a video source.\n\nVideoSelectorProgramId -> (structure)\n\nVideo Selector Program Id\n\nProgramId -> (integer)\n\nSelects a specific program from within a multi-program transport stream. If the program doesn’t exist, the first program within the transport stream will be selected by default.\n\nInputSpecification -> (structure)\n\nSpecification of network and file inputs for this channel\n\nCodec -> (string)\n\nInput codec\n\nMaximumBitrate -> (string)\n\nMaximum input bitrate, categorized coarsely\n\nResolution -> (string)\n\nInput resolution, categorized coarsely\n\nLogLevel -> (string)\n\nThe log level being written to CloudWatch Logs.\n\nName -> (string)\n\nThe name of the channel. (user-mutable)\n\nPipelineDetails -> (list)\n\nRuntime details for the pipelines of a running channel.\n\n(structure)\n\nRuntime details of a pipeline when a channel is running.\n\nActiveInputAttachmentName -> (string)\n\nThe name of the active input attachment currently being ingested by this pipeline.\n\nActiveInputSwitchActionName -> (string)\n\nThe name of the input switch schedule action that occurred most recently and that resulted in the switch to the current input attachment for this pipeline.\n\nActiveMotionGraphicsActionName -> (string)\n\nThe name of the motion graphics activate action that occurred most recently and that resulted in the current graphics URI for this pipeline.\n\nActiveMotionGraphicsUri -> (string)\n\nThe current URI being used for HTML5 motion graphics for this pipeline.\n\nPipelineId -> (string)\n\nPipeline ID\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role assumed when running the Channel.\n\nState -> (string)\n\nPlaceholder documentation for ChannelState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nVpc -> (structure)\n\nSettings for VPC output\n\nAvailabilityZones -> (list)\n\nThe Availability Zones where the vpc subnets are located. The first Availability Zone applies to the first subnet in the list of subnets. The second Availability Zone applies to the second subnet.\n\n(string)\n\nPlaceholder documentation for __string\n\nNetworkInterfaceIds -> (list)\n\nA list of Elastic Network Interfaces created by MediaLive in the customer’s VPC\n\n(string)\n\nPlaceholder documentation for __string\n\nSecurityGroupIds -> (list)\n\nA list of up EC2 VPC security group IDs attached to the Output VPC network interfaces.\n\n(string)\n\nPlaceholder documentation for __string\n\nSubnetIds -> (list)\n\nA list of VPC subnet IDs from the same VPC. If STANDARD channel, subnet IDs must be mapped to two unique availability zones (AZ).\n\n(string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "update-input",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/update-input.html",
      "command_description": "Description\n\nUpdates an input.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-input\n[--destinations <value>]\n[--input-devices <value>]\n--input-id <value>\n[--input-security-groups <value>]\n[--media-connect-flows <value>]\n[--name <value>]\n[--role-arn <value>]\n[--sources <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--destinations <value>]",
        "[--input-devices <value>]",
        "--input-id <value>",
        "[--input-security-groups <value>]",
        "[--media-connect-flows <value>]",
        "[--name <value>]",
        "[--role-arn <value>]",
        "[--sources <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--destinations (list) Destination settings for PUSH type inputs.(structure)\n\nEndpoint settings for a PUSH type input.\n\nStreamName -> (string)\n\nA unique name for the location the RTMP stream is being pushed to.\n\nShorthand Syntax:\n\nStreamName=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"StreamName\": \"string\"\n  }\n  ...\n]\n\n\n--input-devices (list) Settings for the devices.(structure)\n\nSettings for an input device.\n\nId -> (string)\n\nThe unique ID for the device.\n\nShorthand Syntax:\n\nId=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Id\": \"string\"\n  }\n  ...\n]\n\n\n--input-id (string) Unique ID of the input.\n\n--input-security-groups (list) A list of security groups referenced by IDs to attach to the input.(string)\n\nPlaceholder documentation for __string\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--media-connect-flows (list) A list of the MediaConnect Flow ARNs that you want to use as the source of the input. You can specify as few as one Flow and presently, as many as two. The only requirement is when you have more than one is that each Flow is in a separate Availability Zone as this ensures your EML input is redundant to AZ issues. (structure)\n\nThe settings for a MediaConnect Flow.\n\nFlowArn -> (string)\n\nThe ARN of the MediaConnect Flow that you want to use as a source.\n\nShorthand Syntax:\n\nFlowArn=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"FlowArn\": \"string\"\n  }\n  ...\n]\n\n\n--name (string) Name of the input.\n\n--role-arn (string) The Amazon Resource Name (ARN) of the role this input assumes during and after creation.\n\n--sources (list) The source URLs for a PULL-type input. Every PULL type input needs exactly two source URLs for redundancy. Only specify sources for PULL type Inputs. Leave Destinations empty. (structure)\n\nSettings for for a PULL type input.\n\nPasswordParam -> (string)\n\nThe key used to extract the password from EC2 Parameter store.\n\nUrl -> (string)\n\nThis represents the customer’s source URL where stream is pulled from.\n\nUsername -> (string)\n\nThe username for the input source.\n\nShorthand Syntax:\n\nPasswordParam=string,Url=string,Username=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"PasswordParam\": \"string\",\n    \"Url\": \"string\",\n    \"Username\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nInput -> (structure)\n\nPlaceholder documentation for Input\n\nArn -> (string)\n\nThe Unique ARN of the input (generated, immutable).\n\nAttachedChannels -> (list)\n\nA list of channel IDs that that input is attached to (currently an input can only be attached to one channel).\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the destinations of the input (PUSH-type).\n\n(structure)\n\nThe settings for a PUSH type input.\n\nIp -> (string)\n\nThe system-generated static IP address of endpoint. It remains fixed for the lifetime of the input.\n\nPort -> (string)\n\nThe port number for the input.\n\nUrl -> (string)\n\nThis represents the endpoint that the customer stream will be pushed to.\n\nVpc -> (structure)\n\nThe properties for a VPC type input destination.\n\nAvailabilityZone -> (string)\n\nThe availability zone of the Input destination.\n\nNetworkInterfaceId -> (string)\n\nThe network interface ID of the Input destination in the VPC.\n\nId -> (string)\n\nThe generated ID of the input (unique for user account, immutable).\n\nInputClass -> (string)\n\nSTANDARD - MediaLive expects two sources to be connected to this input. If the channel is also STANDARD, both sources will be ingested. If the channel is SINGLE_PIPELINE, only the first source will be ingested; the second source will always be ignored, even if the first source fails. SINGLE_PIPELINE - You can connect only one source to this input. If the ChannelClass is also SINGLE_PIPELINE, this value is valid. If the ChannelClass is STANDARD, this value is not valid because the channel requires two sources in the input.\n\nInputDevices -> (list)\n\nSettings for the input devices.\n\n(structure)\n\nSettings for an input device.\n\nId -> (string)\n\nThe unique ID for the device.\n\nInputPartnerIds -> (list)\n\nA list of IDs for all Inputs which are partners of this one.\n\n(string)\n\nPlaceholder documentation for __string\n\nInputSourceType -> (string)\n\nCertain pull input sources can be dynamic, meaning that they can have their URL’s dynamically changes during input switch actions. Presently, this functionality only works with MP4_FILE and TS_FILE inputs.\n\nMediaConnectFlows -> (list)\n\nA list of MediaConnect Flows for this input.\n\n(structure)\n\nThe settings for a MediaConnect Flow.\n\nFlowArn -> (string)\n\nThe unique ARN of the MediaConnect Flow being used as a source.\n\nName -> (string)\n\nThe user-assigned name (This is a mutable value).\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the role this input assumes during and after creation.\n\nSecurityGroups -> (list)\n\nA list of IDs for all the Input Security Groups attached to the input.\n\n(string)\n\nPlaceholder documentation for __string\n\nSources -> (list)\n\nA list of the sources of the input (PULL-type).\n\n(structure)\n\nThe settings for a PULL type input.\n\nPasswordParam -> (string)\n\nThe key used to extract the password from EC2 Parameter store.\n\nUrl -> (string)\n\nThis represents the customer’s source URL where stream is pulled from.\n\nUsername -> (string)\n\nThe username for the input source.\n\nState -> (string)\n\nPlaceholder documentation for InputState\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nType -> (string)\n\nThe different types of inputs that AWS Elemental MediaLive supports."
    },
    {
      "command_name": "update-input-device",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/update-input-device.html",
      "command_description": "Description\n\nUpdates the parameters for the input device.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-input-device\n[--hd-device-settings <value>]\n--input-device-id <value>\n[--name <value>]\n[--uhd-device-settings <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--hd-device-settings <value>]",
        "--input-device-id <value>",
        "[--name <value>]",
        "[--uhd-device-settings <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--hd-device-settings (structure) The settings that you want to apply to the HD input device.ConfiguredInput -> (string)\n\nThe input source that you want to use. If the device has a source connected to only one of its input ports, or if you don’t care which source the device sends, specify Auto. If the device has sources connected to both its input ports, and you want to use a specific source, specify the source.\n\nMaxBitrate -> (integer)\n\nThe maximum bitrate in bits per second. Set a value here to throttle the bitrate of the source video.\n\nShorthand Syntax:\n\nConfiguredInput=string,MaxBitrate=integer\n\n\nJSON Syntax:\n\n{\n  \"ConfiguredInput\": \"AUTO\"|\"HDMI\"|\"SDI\",\n  \"MaxBitrate\": integer\n}\n\n\n--input-device-id (string) The unique ID of the input device. For example, hd-123456789abcdef.\n\n--name (string) The name that you assigned to this input device (not the unique ID).\n\n--uhd-device-settings (structure) The settings that you want to apply to the UHD input device.ConfiguredInput -> (string)\n\nThe input source that you want to use. If the device has a source connected to only one of its input ports, or if you don’t care which source the device sends, specify Auto. If the device has sources connected to both its input ports, and you want to use a specific source, specify the source.\n\nMaxBitrate -> (integer)\n\nThe maximum bitrate in bits per second. Set a value here to throttle the bitrate of the source video.\n\nShorthand Syntax:\n\nConfiguredInput=string,MaxBitrate=integer\n\n\nJSON Syntax:\n\n{\n  \"ConfiguredInput\": \"AUTO\"|\"HDMI\"|\"SDI\",\n  \"MaxBitrate\": integer\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nArn -> (string)\n\nThe unique ARN of the input device.\n\nConnectionState -> (string)\n\nThe state of the connection between the input device and AWS.\n\nDeviceSettingsSyncState -> (string)\n\nThe status of the action to synchronize the device configuration. If you change the configuration of the input device (for example, the maximum bitrate), MediaLive sends the new data to the device. The device might not update itself immediately. SYNCED means the device has updated its configuration. SYNCING means that it has not updated its configuration.\n\nDeviceUpdateStatus -> (string)\n\nThe status of software on the input device.\n\nHdDeviceSettings -> (structure)\n\nSettings that describe an input device that is type HD.\n\nActiveInput -> (string)\n\nIf you specified Auto as the configured input, specifies which of the sources is currently active (SDI or HDMI).\n\nConfiguredInput -> (string)\n\nThe source at the input device that is currently active. You can specify this source.\n\nDeviceState -> (string)\n\nThe state of the input device.\n\nFramerate -> (double)\n\nThe frame rate of the video source.\n\nHeight -> (integer)\n\nThe height of the video source, in pixels.\n\nMaxBitrate -> (integer)\n\nThe current maximum bitrate for ingesting this source, in bits per second. You can specify this maximum.\n\nScanType -> (string)\n\nThe scan type of the video source.\n\nWidth -> (integer)\n\nThe width of the video source, in pixels.\n\nId -> (string)\n\nThe unique ID of the input device.\n\nMacAddress -> (string)\n\nThe network MAC address of the input device.\n\nName -> (string)\n\nA name that you specify for the input device.\n\nNetworkSettings -> (structure)\n\nThe network settings for the input device.\n\nDnsAddresses -> (list)\n\nThe DNS addresses of the input device.\n\n(string)\n\nPlaceholder documentation for __string\n\nGateway -> (string)\n\nThe network gateway IP address.\n\nIpAddress -> (string)\n\nThe IP address of the input device.\n\nIpScheme -> (string)\n\nSpecifies whether the input device has been configured (outside of MediaLive) to use a dynamic IP address assignment (DHCP) or a static IP address.\n\nSubnetMask -> (string)\n\nThe subnet mask of the input device.\n\nSerialNumber -> (string)\n\nThe unique serial number of the input device.\n\nType -> (string)\n\nThe type of the input device.\n\nUhdDeviceSettings -> (structure)\n\nSettings that describe an input device that is type UHD.\n\nActiveInput -> (string)\n\nIf you specified Auto as the configured input, specifies which of the sources is currently active (SDI or HDMI).\n\nConfiguredInput -> (string)\n\nThe source at the input device that is currently active. You can specify this source.\n\nDeviceState -> (string)\n\nThe state of the input device.\n\nFramerate -> (double)\n\nThe frame rate of the video source.\n\nHeight -> (integer)\n\nThe height of the video source, in pixels.\n\nMaxBitrate -> (integer)\n\nThe current maximum bitrate for ingesting this source, in bits per second. You can specify this maximum.\n\nScanType -> (string)\n\nThe scan type of the video source.\n\nWidth -> (integer)\n\nThe width of the video source, in pixels."
    },
    {
      "command_name": "update-input-security-group",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/update-input-security-group.html",
      "command_description": "Description\n\nUpdate an Input Security Group’s Whilelists.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-input-security-group\n--input-security-group-id <value>\n[--tags <value>]\n[--whitelist-rules <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--input-security-group-id <value>",
        "[--tags <value>]",
        "[--whitelist-rules <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--input-security-group-id (string) The id of the Input Security Group to update.\n\n--tags (map) A collection of key-value pairs.key -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--whitelist-rules (list) List of IPv4 CIDR addresses to whitelist(structure)\n\nAn IPv4 CIDR to whitelist.\n\nCidr -> (string)\n\nThe IPv4 CIDR to whitelist.\n\nShorthand Syntax:\n\nCidr=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Cidr\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nSecurityGroup -> (structure)\n\nAn Input Security Group\n\nArn -> (string)\n\nUnique ARN of Input Security Group\n\nId -> (string)\n\nThe Id of the Input Security Group\n\nInputs -> (list)\n\nThe list of inputs currently using this Input Security Group.\n\n(string)\n\nPlaceholder documentation for __string\n\nState -> (string)\n\nThe current state of the Input Security Group.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nWhitelistRules -> (list)\n\nWhitelist rules and their sync status\n\n(structure)\n\nWhitelist rule\n\nCidr -> (string)\n\nThe IPv4 CIDR that’s whitelisted."
    },
    {
      "command_name": "update-multiplex",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/update-multiplex.html",
      "command_description": "Description\n\nUpdates a multiplex.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-multiplex\n--multiplex-id <value>\n[--multiplex-settings <value>]\n[--name <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--multiplex-id <value>",
        "[--multiplex-settings <value>]",
        "[--name <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--multiplex-id (string) ID of the multiplex to update.\n\n--multiplex-settings (structure) The new settings for a multiplex.MaximumVideoBufferDelayMilliseconds -> (integer)\n\nMaximum video buffer delay in milliseconds.\n\nTransportStreamBitrate -> (integer)\n\nTransport stream bit rate.\n\nTransportStreamId -> (integer)\n\nTransport stream ID.\n\nTransportStreamReservedBitrate -> (integer)\n\nTransport stream reserved bit rate.\n\nShorthand Syntax:\n\nMaximumVideoBufferDelayMilliseconds=integer,TransportStreamBitrate=integer,TransportStreamId=integer,TransportStreamReservedBitrate=integer\n\n\nJSON Syntax:\n\n{\n  \"MaximumVideoBufferDelayMilliseconds\": integer,\n  \"TransportStreamBitrate\": integer,\n  \"TransportStreamId\": integer,\n  \"TransportStreamReservedBitrate\": integer\n}\n\n\n--name (string) Name of the multiplex.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nMultiplex -> (structure)\n\nThe updated multiplex.\n\nArn -> (string)\n\nThe unique arn of the multiplex.\n\nAvailabilityZones -> (list)\n\nA list of availability zones for the multiplex.\n\n(string)\n\nPlaceholder documentation for __string\n\nDestinations -> (list)\n\nA list of the multiplex output destinations.\n\n(structure)\n\nMultiplex output destination settings\n\nMediaConnectSettings -> (structure)\n\nMultiplex MediaConnect output destination settings.\n\nEntitlementArn -> (string)\n\nThe MediaConnect entitlement ARN available as a Flow source.\n\nId -> (string)\n\nThe unique id of the multiplex.\n\nMultiplexSettings -> (structure)\n\nConfiguration for a multiplex event.\n\nMaximumVideoBufferDelayMilliseconds -> (integer)\n\nMaximum video buffer delay in milliseconds.\n\nTransportStreamBitrate -> (integer)\n\nTransport stream bit rate.\n\nTransportStreamId -> (integer)\n\nTransport stream ID.\n\nTransportStreamReservedBitrate -> (integer)\n\nTransport stream reserved bit rate.\n\nName -> (string)\n\nThe name of the multiplex.\n\nPipelinesRunningCount -> (integer)\n\nThe number of currently healthy pipelines.\n\nProgramCount -> (integer)\n\nThe number of programs in the multiplex.\n\nState -> (string)\n\nThe current state of the multiplex.\n\nTags -> (map)\n\nA collection of key-value pairs.\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string"
    },
    {
      "command_name": "update-multiplex-program",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/update-multiplex-program.html",
      "command_description": "Description\n\nUpdate a program in a multiplex.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-multiplex-program\n--multiplex-id <value>\n[--multiplex-program-settings <value>]\n--program-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--multiplex-id <value>",
        "[--multiplex-program-settings <value>]",
        "--program-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--multiplex-id (string) The ID of the multiplex of the program to update.\n\n--multiplex-program-settings (structure) The new settings for a multiplex program.PreferredChannelPipeline -> (string)\n\nIndicates which pipeline is preferred by the multiplex for program ingest.\n\nProgramNumber -> (integer)\n\nUnique program number.\n\nServiceDescriptor -> (structure)\n\nTransport stream service descriptor configuration for the Multiplex program.\n\nProviderName -> (string)\n\nName of the provider.\n\nServiceName -> (string)\n\nName of the service.\n\nVideoSettings -> (structure)\n\nProgram video settings configuration.\n\nConstantBitrate -> (integer)\n\nThe constant bitrate configuration for the video encode. When this field is defined, StatmuxSettings must be undefined.\n\nStatmuxSettings -> (structure)\n\nStatmux rate control settings. When this field is defined, ConstantBitrate must be undefined.\n\nMaximumBitrate -> (integer)\n\nMaximum statmux bitrate.\n\nMinimumBitrate -> (integer)\n\nMinimum statmux bitrate.\n\nPriority -> (integer)\n\nThe purpose of the priority is to use a combination of thenmultiplex rate control algorithm and the QVBR capability of thenencoder to prioritize the video quality of some channels in anmultiplex over others. Channels that have a higher priority willnget higher video quality at the expense of the video quality ofnother channels in the multiplex with lower priority.\n\nShorthand Syntax:\n\nPreferredChannelPipeline=string,ProgramNumber=integer,ServiceDescriptor={ProviderName=string,ServiceName=string},VideoSettings={ConstantBitrate=integer,StatmuxSettings={MaximumBitrate=integer,MinimumBitrate=integer,Priority=integer}}\n\n\nJSON Syntax:\n\n{\n  \"PreferredChannelPipeline\": \"CURRENTLY_ACTIVE\"|\"PIPELINE_0\"|\"PIPELINE_1\",\n  \"ProgramNumber\": integer,\n  \"ServiceDescriptor\": {\n    \"ProviderName\": \"string\",\n    \"ServiceName\": \"string\"\n  },\n  \"VideoSettings\": {\n    \"ConstantBitrate\": integer,\n    \"StatmuxSettings\": {\n      \"MaximumBitrate\": integer,\n      \"MinimumBitrate\": integer,\n      \"Priority\": integer\n    }\n  }\n}\n\n\n--program-name (string) The name of the program to update.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nMultiplexProgram -> (structure)\n\nThe updated multiplex program.\n\nChannelId -> (string)\n\nThe MediaLive channel associated with the program.\n\nMultiplexProgramSettings -> (structure)\n\nThe settings for this multiplex program.\n\nPreferredChannelPipeline -> (string)\n\nIndicates which pipeline is preferred by the multiplex for program ingest.\n\nProgramNumber -> (integer)\n\nUnique program number.\n\nServiceDescriptor -> (structure)\n\nTransport stream service descriptor configuration for the Multiplex program.\n\nProviderName -> (string)\n\nName of the provider.\n\nServiceName -> (string)\n\nName of the service.\n\nVideoSettings -> (structure)\n\nProgram video settings configuration.\n\nConstantBitrate -> (integer)\n\nThe constant bitrate configuration for the video encode. When this field is defined, StatmuxSettings must be undefined.\n\nStatmuxSettings -> (structure)\n\nStatmux rate control settings. When this field is defined, ConstantBitrate must be undefined.\n\nMaximumBitrate -> (integer)\n\nMaximum statmux bitrate.\n\nMinimumBitrate -> (integer)\n\nMinimum statmux bitrate.\n\nPriority -> (integer)\n\nThe purpose of the priority is to use a combination of thenmultiplex rate control algorithm and the QVBR capability of thenencoder to prioritize the video quality of some channels in anmultiplex over others. Channels that have a higher priority willnget higher video quality at the expense of the video quality ofnother channels in the multiplex with lower priority.\n\nPacketIdentifiersMap -> (structure)\n\nThe packet identifier map for this multiplex program.\n\nAudioPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nDvbSubPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nDvbTeletextPid -> (integer)\n\nPlaceholder documentation for __integer\n\nEtvPlatformPid -> (integer)\n\nPlaceholder documentation for __integer\n\nEtvSignalPid -> (integer)\n\nPlaceholder documentation for __integer\n\nKlvDataPids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nPcrPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPmtPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPrivateMetadataPid -> (integer)\n\nPlaceholder documentation for __integer\n\nScte27Pids -> (list)\n\nPlaceholder documentation for __listOf__integer\n\n(integer)\n\nPlaceholder documentation for __integer\n\nScte35Pid -> (integer)\n\nPlaceholder documentation for __integer\n\nTimedMetadataPid -> (integer)\n\nPlaceholder documentation for __integer\n\nVideoPid -> (integer)\n\nPlaceholder documentation for __integer\n\nPipelineDetails -> (list)\n\nContains information about the current sources for the specified program in the specified multiplex. Keep in mind that each multiplex pipeline connects to both pipelines in a given source channel (the channel identified by the program). But only one of those channel pipelines is ever active at one time.\n\n(structure)\n\nThe current source for one of the pipelines in the multiplex.\n\nActiveChannelPipeline -> (string)\n\nIdentifies the channel pipeline that is currently active for the pipeline (identified by PipelineId) in the multiplex.\n\nPipelineId -> (string)\n\nIdentifies a specific pipeline in the multiplex.\n\nProgramName -> (string)\n\nThe name of the multiplex program."
    },
    {
      "command_name": "update-reservation",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/update-reservation.html",
      "command_description": "Description\n\nUpdate reservation.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-reservation\n[--name <value>]\n--reservation-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--name <value>]",
        "--reservation-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--name (string) Name of the reservation\n\n--reservation-id (string) Unique reservation ID, e.g. ‘1234567’\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nReservation -> (structure)\n\nReserved resources available to use\n\nArn -> (string)\n\nUnique reservation ARN, e.g. ‘arn:aws:medialive:us-west-2:123456789012:reservation:1234567’\n\nCount -> (integer)\n\nNumber of reserved resources\n\nCurrencyCode -> (string)\n\nCurrency code for usagePrice and fixedPrice in ISO-4217 format, e.g. ‘USD’\n\nDuration -> (integer)\n\nLease duration, e.g. ‘12’\n\nDurationUnits -> (string)\n\nUnits for duration, e.g. ‘MONTHS’\n\nEnd -> (string)\n\nReservation UTC end date and time in ISO-8601 format, e.g. ‘2019-03-01T00:00:00’\n\nFixedPrice -> (double)\n\nOne-time charge for each reserved resource, e.g. ‘0.0’ for a NO_UPFRONT offering\n\nName -> (string)\n\nUser specified reservation name\n\nOfferingDescription -> (string)\n\nOffering description, e.g. ‘HD AVC output at 10-20 Mbps, 30 fps, and standard VQ in US West (Oregon)’\n\nOfferingId -> (string)\n\nUnique offering ID, e.g. ‘87654321’\n\nOfferingType -> (string)\n\nOffering type, e.g. ‘NO_UPFRONT’\n\nRegion -> (string)\n\nAWS region, e.g. ‘us-west-2’\n\nReservationId -> (string)\n\nUnique reservation ID, e.g. ‘1234567’\n\nResourceSpecification -> (structure)\n\nResource configuration details\n\nChannelClass -> (string)\n\nChannel class, e.g. ‘STANDARD’\n\nCodec -> (string)\n\nCodec, e.g. ‘AVC’\n\nMaximumBitrate -> (string)\n\nMaximum bitrate, e.g. ‘MAX_20_MBPS’\n\nMaximumFramerate -> (string)\n\nMaximum framerate, e.g. ‘MAX_30_FPS’ (Outputs only)\n\nResolution -> (string)\n\nResolution, e.g. ‘HD’\n\nResourceType -> (string)\n\nResource type, ‘INPUT’, ‘OUTPUT’, ‘MULTIPLEX’, or ‘CHANNEL’\n\nSpecialFeature -> (string)\n\nSpecial feature, e.g. ‘AUDIO_NORMALIZATION’ (Channels only)\n\nVideoQuality -> (string)\n\nVideo quality, e.g. ‘STANDARD’ (Outputs only)\n\nStart -> (string)\n\nReservation UTC start date and time in ISO-8601 format, e.g. ‘2018-03-01T00:00:00’\n\nState -> (string)\n\nCurrent state of reservation, e.g. ‘ACTIVE’\n\nTags -> (map)\n\nA collection of key-value pairs\n\nkey -> (string)\n\nPlaceholder documentation for __string\n\nvalue -> (string)\n\nPlaceholder documentation for __string\n\nUsagePrice -> (double)\n\nRecurring usage charge for each reserved resource, e.g. ‘157.0’"
    },
    {
      "command_name": "wait",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/medialive/wait/index.html",
      "command_description": "Description\n\nWait until a particular condition is satisfied. Each subcommand polls an API until the listed requirement is met.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_options": []
    }
  ],
  "service_description": "Description\n\nAPI for AWS Elemental MediaLive"
}