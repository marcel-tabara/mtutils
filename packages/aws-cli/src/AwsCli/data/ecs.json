{
  "service_name": "ecs",
  "service_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/index.html",
  "service_commands": [
    {
      "command_name": "create-capacity-provider",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/create-capacity-provider.html",
      "command_description": "Description\n\nCreates a new capacity provider. Capacity providers are associated with an Amazon ECS cluster and are used in capacity provider strategies to facilitate cluster auto scaling.\n\nOnly capacity providers using an Auto Scaling group can be created. Amazon ECS tasks on Fargate use the FARGATE and FARGATE_SPOT capacity providers which are already created and available to all accounts in Regions supported by Fargate.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-capacity-provider\n--name <value>\n--auto-scaling-group-provider <value>\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--name <value>",
        "--auto-scaling-group-provider <value>",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--name (string)\n\nThe name of the capacity provider. Up to 255 characters are allowed, including letters (upper and lowercase), numbers, underscores, and hyphens. The name cannot be prefixed with “aws “, “ecs “, or “fargate “.\n\n--auto-scaling-group-provider (structure)\n\nThe details of the Auto Scaling group for the capacity provider.\n\nautoScalingGroupArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the Auto Scaling group.\n\nmanagedScaling -> (structure)\n\nThe managed scaling settings for the Auto Scaling group capacity provider.\n\nstatus -> (string)\n\nWhether or not to enable managed scaling for the capacity provider.\n\ntargetCapacity -> (integer)\n\nThe target capacity value for the capacity provider. The specified value must be greater than 0 and less than or equal to 100 . A value of 100 will result in the Amazon EC2 instances in your Auto Scaling group being completely utilized.\n\nminimumScalingStepSize -> (integer)\n\nThe minimum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 1 is used.\n\nmaximumScalingStepSize -> (integer)\n\nThe maximum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 10000 is used.\n\ninstanceWarmupPeriod -> (integer)\n\nThe period of time, in seconds, after a newly launched Amazon EC2 instance can contribute to CloudWatch metrics for Auto Scaling group. If this parameter is omitted, the default value of 300 seconds is used.\n\nmanagedTerminationProtection -> (string)\n\nThe managed termination protection setting to use for the Auto Scaling group capacity provider. This determines whether the Auto Scaling group has managed termination protection.\n\nWarning\n\nWhen using managed termination protection, managed scaling must also be used otherwise managed termination protection will not work.\n\nWhen managed termination protection is enabled, Amazon ECS prevents the Amazon EC2 instances in an Auto Scaling group that contain tasks from being terminated during a scale-in action. The Auto Scaling group and each instance in the Auto Scaling group must have instance protection from scale-in actions enabled as well. For more information, see Instance Protection in the Auto Scaling User Guide .\n\nWhen managed termination protection is disabled, your Amazon EC2 instances are not protected from termination when the Auto Scaling group scales in.\n\nShorthand Syntax:\n\nautoScalingGroupArn=string,managedScaling={status=string,targetCapacity=integer,minimumScalingStepSize=integer,maximumScalingStepSize=integer,instanceWarmupPeriod=integer},managedTerminationProtection=string\n\n\nJSON Syntax:\n\n{\n  \"autoScalingGroupArn\": \"string\",\n  \"managedScaling\": {\n    \"status\": \"ENABLED\"|\"DISABLED\",\n    \"targetCapacity\": integer,\n    \"minimumScalingStepSize\": integer,\n    \"maximumScalingStepSize\": integer,\n    \"instanceWarmupPeriod\": integer\n  },\n  \"managedTerminationProtection\": \"ENABLED\"|\"DISABLED\"\n}\n\n\n--tags (list)\n\nThe metadata that you apply to the capacity provider to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncapacityProvider -> (structure)\n\nThe full description of the new capacity provider.\n\ncapacityProviderArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the capacity provider.\n\nname -> (string)\n\nThe name of the capacity provider.\n\nstatus -> (string)\n\nThe current status of the capacity provider. Only capacity providers in an ACTIVE state can be used in a cluster. When a capacity provider is successfully deleted, it will have an INACTIVE status.\n\nautoScalingGroupProvider -> (structure)\n\nThe Auto Scaling group settings for the capacity provider.\n\nautoScalingGroupArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the Auto Scaling group.\n\nmanagedScaling -> (structure)\n\nThe managed scaling settings for the Auto Scaling group capacity provider.\n\nstatus -> (string)\n\nWhether or not to enable managed scaling for the capacity provider.\n\ntargetCapacity -> (integer)\n\nThe target capacity value for the capacity provider. The specified value must be greater than 0 and less than or equal to 100 . A value of 100 will result in the Amazon EC2 instances in your Auto Scaling group being completely utilized.\n\nminimumScalingStepSize -> (integer)\n\nThe minimum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 1 is used.\n\nmaximumScalingStepSize -> (integer)\n\nThe maximum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 10000 is used.\n\ninstanceWarmupPeriod -> (integer)\n\nThe period of time, in seconds, after a newly launched Amazon EC2 instance can contribute to CloudWatch metrics for Auto Scaling group. If this parameter is omitted, the default value of 300 seconds is used.\n\nmanagedTerminationProtection -> (string)\n\nThe managed termination protection setting to use for the Auto Scaling group capacity provider. This determines whether the Auto Scaling group has managed termination protection.\n\nWarning\n\nWhen using managed termination protection, managed scaling must also be used otherwise managed termination protection will not work.\n\nWhen managed termination protection is enabled, Amazon ECS prevents the Amazon EC2 instances in an Auto Scaling group that contain tasks from being terminated during a scale-in action. The Auto Scaling group and each instance in the Auto Scaling group must have instance protection from scale-in actions enabled as well. For more information, see Instance Protection in the Auto Scaling User Guide .\n\nWhen managed termination protection is disabled, your Amazon EC2 instances are not protected from termination when the Auto Scaling group scales in.\n\nupdateStatus -> (string)\n\nThe update status of the capacity provider. The following are the possible states that will be returned.\n\nDELETE_IN_PROGRESS\n\nThe capacity provider is in the process of being deleted.\n\nDELETE_COMPLETE\n\nThe capacity provider has been successfully deleted and will have an INACTIVE status.\n\nDELETE_FAILED\n\nThe capacity provider was unable to be deleted. The update status reason will provide further details about why the delete failed.\n\nupdateStatusReason -> (string)\n\nThe update status reason. This provides further details about the update status for the capacity provider.\n\ntags -> (list)\n\nThe metadata that you apply to the capacity provider to help you categorize and organize it. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nTo create a capacity provider\n\nThe following create-capacity-provider example creates a capacity provider that uses an Auto Scaling group named MyAutoScalingGroup, has managed scaling and managed termination protection enabled. This configuration is used for Amazon ECS cluster auto scaling.\n\naws ecs create-capacity-provider \\\n    --name \"MyCapacityProvider\" \\\n    --auto-scaling-group-provider autoScalingGroupArn=arn:aws:autoscaling:us-west-2:123456789012:autoScalingGroup:a1b2c3d4-5678-90ab-cdef-EXAMPLE11111:autoScalingGroupName/MyAutoScalingGroup,managedScaling={status=ENABLED,targetCapacity=100,minimumScalingStepSize=1,maximumScalingStepSize=100},managedTerminationProtection=ENABLED\n\n\nOutput:\n\n{\n    \"capacityProvider\": {\n        \"capacityProviderArn\": \"arn:aws:ecs:us-west-2:123456789012:capacity-provider/MyCapacityProvider\",\n        \"name\": \"MyCapacityProvider\",\n        \"status\": \"ACTIVE\",\n        \"autoScalingGroupProvider\": {\n            \"autoScalingGroupArn\": \"arn:aws:autoscaling:us-west-2:123456789012:autoScalingGroup:a1b2c3d4-5678-90ab-cdef-EXAMPLE11111:autoScalingGroupName/MyAutoScalingGroup\",\n            \"managedScaling\": {\n                \"status\": \"ENABLED\",\n                \"targetCapacity\": 100,\n                \"minimumScalingStepSize\": 1,\n                \"maximumScalingStepSize\": 100\n            },\n            \"managedTerminationProtection\": \"ENABLED\"\n        },\n        \"tags\": []\n    }\n}\n\n\nFor more information, see Cluster auto scaling in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "create-cluster",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/create-cluster.html",
      "command_description": "Description\n\nCreates a new Amazon ECS cluster. By default, your account receives a default cluster when you launch your first container instance. However, you can create your own cluster with a unique name with the CreateCluster action.\n\nNote\n\nWhen you call the CreateCluster API operation, Amazon ECS attempts to create the Amazon ECS service-linked role for your account so that required resources in other Amazon Web Services services can be managed on your behalf. However, if the IAM user that makes the call does not have permissions to create the service-linked role, it is not created. For more information, see Using Service-Linked Roles for Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-cluster\n[--cluster-name <value>]\n[--tags <value>]\n[--settings <value>]\n[--configuration <value>]\n[--capacity-providers <value>]\n[--default-capacity-provider-strategy <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster-name <value>]",
        "[--tags <value>]",
        "[--settings <value>]",
        "[--configuration <value>]",
        "[--capacity-providers <value>]",
        "[--default-capacity-provider-strategy <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster-name (string)\n\nThe name of your cluster. If you do not specify a name for your cluster, you create a cluster named default . Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed.\n\n--tags (list)\n\nThe metadata that you apply to the cluster to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--settings (list)\n\nThe setting to use when creating a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster. If this value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\n(structure)\n\nThe settings to use when creating a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster.\n\nname -> (string)\n\nThe name of the cluster setting. The only supported value is containerInsights .\n\nvalue -> (string)\n\nThe value to set for the cluster setting. The supported values are enabled and disabled . If enabled is specified, CloudWatch Container Insights will be enabled for the cluster, otherwise it will be disabled unless the containerInsights account setting is enabled. If a cluster value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\nShorthand Syntax:\n\nname=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"name\": \"containerInsights\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--configuration (structure)\n\nThe execute command configuration for the cluster.\n\nexecuteCommandConfiguration -> (structure)\n\nThe details of the execute command configuration.\n\nkmsKeyId -> (string)\n\nSpecify an Key Management Service key ID to encrypt the data between the local client and the container.\n\nlogging -> (string)\n\nThe log setting to use for redirecting logs for your execute command results. The following log settings are available.\n\nNONE : The execute command session is not logged.\n\nDEFAULT : The awslogs configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no awslogs log driver is configured in the task definition, the output won’t be logged.\n\nOVERRIDE : Specify the logging details as a part of logConfiguration . If the OVERRIDE logging option is specified, the logConfiguration is required.\n\nlogConfiguration -> (structure)\n\nThe log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When logging=OVERRIDE is specified, a logConfiguration must be provided.\n\ncloudWatchLogGroupName -> (string)\n\nThe name of the CloudWatch log group to send logs to.\n\nNote\n\nThe CloudWatch log group must already be created.\n\ncloudWatchEncryptionEnabled -> (boolean)\n\nWhether or not to enable encryption on the CloudWatch logs. If not specified, encryption will be disabled.\n\ns3BucketName -> (string)\n\nThe name of the S3 bucket to send logs to.\n\nNote\n\nThe S3 bucket must already be created.\n\ns3EncryptionEnabled -> (boolean)\n\nWhether or not to use encryption on the S3 logs. If not specified, encryption is not used.\n\ns3KeyPrefix -> (string)\n\nAn optional folder in the S3 bucket to place logs in.\n\nShorthand Syntax:\n\nexecuteCommandConfiguration={kmsKeyId=string,logging=string,logConfiguration={cloudWatchLogGroupName=string,cloudWatchEncryptionEnabled=boolean,s3BucketName=string,s3EncryptionEnabled=boolean,s3KeyPrefix=string}}\n\n\nJSON Syntax:\n\n{\n  \"executeCommandConfiguration\": {\n    \"kmsKeyId\": \"string\",\n    \"logging\": \"NONE\"|\"DEFAULT\"|\"OVERRIDE\",\n    \"logConfiguration\": {\n      \"cloudWatchLogGroupName\": \"string\",\n      \"cloudWatchEncryptionEnabled\": true|false,\n      \"s3BucketName\": \"string\",\n      \"s3EncryptionEnabled\": true|false,\n      \"s3KeyPrefix\": \"string\"\n    }\n  }\n}\n\n\n--capacity-providers (list)\n\nThe short name of one or more capacity providers to associate with the cluster. A capacity provider must be associated with a cluster before it can be included as part of the default capacity provider strategy of the cluster or used in a capacity provider strategy when calling the CreateService or RunTask actions.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created and not already associated with another cluster. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used.\n\nThe PutClusterCapacityProviders API operation is used to update the list of available capacity providers for a cluster after the cluster is created.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--default-capacity-provider-strategy (list)\n\nThe capacity provider strategy to set as the default for the cluster. When a default capacity provider strategy is set for a cluster, when calling the RunTask or CreateService APIs with no capacity provider strategy or launch type specified, the default capacity provider strategy for the cluster is used.\n\nIf a default capacity provider strategy is not defined for a cluster during creation, it can be defined later with the PutClusterCapacityProviders API operation.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nShorthand Syntax:\n\ncapacityProvider=string,weight=integer,base=integer ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"capacityProvider\": \"string\",\n    \"weight\": integer,\n    \"base\": integer\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncluster -> (structure)\n\nThe full description of your new cluster.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the cluster. The ARN contains the arn:aws:ecs namespace, followed by the Region of the cluster, the Amazon Web Services account ID of the cluster owner, the cluster namespace, and then the cluster name. For example, arn:aws:ecs:region:012345678910:cluster/test .\n\nclusterName -> (string)\n\nA user-generated string that you use to identify your cluster.\n\nconfiguration -> (structure)\n\nThe execute command configuration for the cluster.\n\nexecuteCommandConfiguration -> (structure)\n\nThe details of the execute command configuration.\n\nkmsKeyId -> (string)\n\nSpecify an Key Management Service key ID to encrypt the data between the local client and the container.\n\nlogging -> (string)\n\nThe log setting to use for redirecting logs for your execute command results. The following log settings are available.\n\nNONE : The execute command session is not logged.\n\nDEFAULT : The awslogs configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no awslogs log driver is configured in the task definition, the output won’t be logged.\n\nOVERRIDE : Specify the logging details as a part of logConfiguration . If the OVERRIDE logging option is specified, the logConfiguration is required.\n\nlogConfiguration -> (structure)\n\nThe log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When logging=OVERRIDE is specified, a logConfiguration must be provided.\n\ncloudWatchLogGroupName -> (string)\n\nThe name of the CloudWatch log group to send logs to.\n\nNote\n\nThe CloudWatch log group must already be created.\n\ncloudWatchEncryptionEnabled -> (boolean)\n\nWhether or not to enable encryption on the CloudWatch logs. If not specified, encryption will be disabled.\n\ns3BucketName -> (string)\n\nThe name of the S3 bucket to send logs to.\n\nNote\n\nThe S3 bucket must already be created.\n\ns3EncryptionEnabled -> (boolean)\n\nWhether or not to use encryption on the S3 logs. If not specified, encryption is not used.\n\ns3KeyPrefix -> (string)\n\nAn optional folder in the S3 bucket to place logs in.\n\nstatus -> (string)\n\nThe status of the cluster. The following are the possible states that will be returned.\n\nACTIVE\n\nThe cluster is ready to accept tasks and if applicable you can register container instances with the cluster.\n\nPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being created.\n\nDEPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being deleted.\n\nFAILED\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider have failed to create.\n\nINACTIVE\n\nThe cluster has been deleted. Clusters with an INACTIVE status may remain discoverable in your account for a period of time. However, this behavior is subject to change in the future, so you should not rely on INACTIVE clusters persisting.\n\nregisteredContainerInstancesCount -> (integer)\n\nThe number of container instances registered into the cluster. This includes container instances in both ACTIVE and DRAINING status.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the RUNNING state.\n\npendingTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the PENDING state.\n\nactiveServicesCount -> (integer)\n\nThe number of services that are running on the cluster in an ACTIVE state. You can view these services with ListServices .\n\nstatistics -> (list)\n\nAdditional information about your clusters that are separated by launch type, including:\n\nrunningEC2TasksCount\n\nRunningFargateTasksCount\n\npendingEC2TasksCount\n\npendingFargateTasksCount\n\nactiveEC2ServiceCount\n\nactiveFargateServiceCount\n\ndrainingEC2ServiceCount\n\ndrainingFargateServiceCount\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the cluster to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nsettings -> (list)\n\nThe settings for the cluster. This parameter indicates whether CloudWatch Container Insights is enabled or disabled for a cluster.\n\n(structure)\n\nThe settings to use when creating a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster.\n\nname -> (string)\n\nThe name of the cluster setting. The only supported value is containerInsights .\n\nvalue -> (string)\n\nThe value to set for the cluster setting. The supported values are enabled and disabled . If enabled is specified, CloudWatch Container Insights will be enabled for the cluster, otherwise it will be disabled unless the containerInsights account setting is enabled. If a cluster value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\ncapacityProviders -> (list)\n\nThe capacity providers associated with the cluster.\n\n(string)\n\ndefaultCapacityProviderStrategy -> (list)\n\nThe default capacity provider strategy for the cluster. When services or tasks are run in the cluster with no launch type or capacity provider strategy specified, the default capacity provider strategy is used.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nattachments -> (list)\n\nThe resources attached to a cluster. When using a capacity provider with a cluster, the Auto Scaling plan that is created will be returned as a cluster attachment.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nattachmentsStatus -> (string)\n\nThe status of the capacity providers associated with the cluster. The following are the states that will be returned:\n\nUPDATE_IN_PROGRESS\n\nThe available capacity providers for the cluster are updating. This occurs when the Auto Scaling plan is provisioning or deprovisioning.\n\nUPDATE_COMPLETE\n\nThe capacity providers have successfully updated.\n\nUPDATE_FAILED\n\nThe capacity provider updates failed.",
      "command_examples": "Examples\n\nExample 1: To create a new cluster\n\nThe following create-cluster example creates a cluster.\n\naws ecs create-cluster \\\n    --cluster-name MyCluster\n\n\nOutput:\n\n{\n    \"cluster\": {\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"clusterName\": \"MyCluster\",\n        \"status\": \"ACTIVE\",\n        \"registeredContainerInstancesCount\": 0,\n        \"pendingTasksCount\": 0,\n        \"runningTasksCount\": 0,\n        \"activeServicesCount\": 0,\n        \"statistics\": [],\n        \"tags\": []\n    }\n}\n\n\nFor more information, see Creating a Cluster in the Amazon ECS Developer Guide.\n\nExample 2: To create a new cluster using capacity providers\n\nThe following create-cluster example creates a cluster and associates two existing capacity providers with it. The create-capacity-provider command is used to create a capacity provider. Specifying a default capacity provider strategy is optional, but recommended. In this example, we create a cluster named MyCluster and associate the MyCapacityProvider1 and MyCapacityProvider2 capacity providers with it. A default capacity provider strategy is specified that spreads the tasks evenly across both capacity providers.\n\naws ecs create-cluster\n\n–cluster-name MyCluster –capacity-providers MyCapacityProvider1 MyCapacityProvider2 –default-capacity-provider-strategy capacityProvider=MyCapacityProvider1,weight=1 capacityProvider=MyCapacityProvider2,weight=1\n\nOutput:\n\n{\n    \"cluster\": {\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"clusterName\": \"MyCluster\",\n        \"status\": \"PROVISIONING\",\n        \"registeredContainerInstancesCount\": 0,\n        \"pendingTasksCount\": 0,\n        \"runningTasksCount\": 0,\n        \"activeServicesCount\": 0,\n        \"statistics\": [],\n        \"settings\": [\n            {\n                \"name\": \"containerInsights\",\n                \"value\": \"enabled\"\n            }\n        ],\n        \"capacityProviders\": [\n            \"MyCapacityProvider1\",\n            \"MyCapacityProvider2\"\n        ],\n        \"defaultCapacityProviderStrategy\": [\n            {\n                \"capacityProvider\": \"MyCapacityProvider1\",\n                \"weight\": 1,\n                \"base\": 0\n            },\n            {\n                \"capacityProvider\": \"MyCapacityProvider2\",\n                \"weight\": 1,\n                \"base\": 0\n            }\n        ],\n        \"attachments\": [\n           {\n                \"id\": \"0fb0c8f4-6edd-4de1-9b09-17e470ee1918\",\n                \"type\": \"asp\",\n                \"status\": \"PRECREATED\",\n                \"details\": [\n                    {\n                        \"name\": \"capacityProviderName\",\n                        \"value\": \"MyCapacityProvider1\"\n                    },\n                    {\n                        \"name\": \"scalingPlanName\",\n                        \"value\": \"ECSManagedAutoScalingPlan-a1b2c3d4-5678-90ab-cdef-EXAMPLE11111\"\n                    }\n                ]\n            },\n            {\n                \"id\": \"ae592060-2382-4663-9476-b015c685593c\",\n                \"type\": \"asp\",\n                \"status\": \"PRECREATED\",\n                \"details\": [\n                    {\n                        \"name\": \"capacityProviderName\",\n                        \"value\": \"MyCapacityProvider2\"\n                    },\n                    {\n                        \"name\": \"scalingPlanName\",\n                        \"value\": \"ECSManagedAutoScalingPlan-a1b2c3d4-5678-90ab-cdef-EXAMPLE22222\"\n                    }\n                ]\n            }\n        ],\n        \"attachmentsStatus\": \"UPDATE_IN_PROGRESS\"\n    }\n}\n\n\nFor more information, see Cluster capacity providers in the Amazon ECS Developer Guide.\n\nExample 3: To create a new cluster with multiple tags\n\nThe following create-cluster example creates a cluster with multiple tags. For more information about adding tags using shorthand syntax, see Using Shorthand Syntax with the AWS Command Line Interface in the AWS CLI User Guide.\n\naws ecs create-cluster \\\n    --cluster-name MyCluster \\\n    --tags key=key1,value=value1 key=key2,value=value2 key=key3,value=value3\n\n\nOutput:\n\n{\n    \"cluster\": {\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"clusterName\": \"MyCluster\",\n        \"status\": \"ACTIVE\",\n        \"registeredContainerInstancesCount\": 0,\n        \"pendingTasksCount\": 0,\n        \"runningTasksCount\": 0,\n        \"activeServicesCount\": 0,\n        \"statistics\": [],\n        \"tags\": [\n            {\n                \"key\": \"key1\",\n                \"value\": \"value1\"\n            },\n            {\n                \"key\": \"key2\",\n                \"value\": \"value2\"\n            },\n            {\n                \"key\": \"key3\",\n                \"value\": \"value3\"\n            }\n        ]\n    }\n}\n\n\nFor more information, see Creating a Cluster in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "create-service",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/create-service.html",
      "command_description": "Description\n\nRuns and maintains a desired number of tasks from a specified task definition. If the number of tasks running in a service drops below the desiredCount , Amazon ECS runs another copy of the task in the specified cluster. To update an existing service, see the UpdateService action.\n\nIn addition to maintaining the desired count of tasks in your service, you can optionally run your service behind one or more load balancers. The load balancers distribute traffic across the tasks that are associated with the service. For more information, see Service Load Balancing in the Amazon Elastic Container Service Developer Guide .\n\nTasks for services that do not use a load balancer are considered healthy if they’re in the RUNNING state. Tasks for services that do use a load balancer are considered healthy if they’re in the RUNNING state and the container instance that they’re hosted on is reported as healthy by the load balancer.\n\nThere are two service scheduler strategies available:\n\nREPLICA - The replica scheduling strategy places and maintains the desired number of tasks across your cluster. By default, the service scheduler spreads tasks across Availability Zones. You can use task placement strategies and constraints to customize task placement decisions. For more information, see Service Scheduler Concepts in the Amazon Elastic Container Service Developer Guide .\n\nDAEMON - The daemon scheduling strategy deploys exactly one task on each active container instance that meets all of the task placement constraints that you specify in your cluster. The service scheduler also evaluates the task placement constraints for running tasks and will stop tasks that do not meet the placement constraints. When using this strategy, you don’t need to specify a desired number of tasks, a task placement strategy, or use Service Auto Scaling policies. For more information, see Service Scheduler Concepts in the Amazon Elastic Container Service Developer Guide .\n\nYou can optionally specify a deployment configuration for your service. The deployment is triggered by changing properties, such as the task definition or the desired count of a service, with an UpdateService operation. The default value for a replica service for minimumHealthyPercent is 100%. The default value for a daemon service for minimumHealthyPercent is 0%.\n\nIf a service is using the ECS deployment controller, the minimum healthy percent represents a lower limit on the number of tasks in a service that must remain in the RUNNING state during a deployment, as a percentage of the desired number of tasks (rounded up to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a desired number of four tasks and a minimum healthy percent of 50%, the scheduler might stop two existing tasks to free up cluster capacity before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they’re in the RUNNING state. Tasks for services that do use a load balancer are considered healthy if they’re in the RUNNING state and they’re reported as healthy by the load balancer. The default value for minimum healthy percent is 100%.\n\nIf a service is using the ECS deployment controller, the maximum percent parameter represents an upper limit on the number of tasks in a service that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desired number of tasks (rounded down to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to define the deployment batch size. For example, if your service has a desired number of four tasks and a maximum percent value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default value for maximum percent is 200%.\n\nIf a service is using either the CODE_DEPLOY or EXTERNAL deployment controller types and tasks that use the EC2 launch type, the minimum healthy percent and maximum percent values are used only to define the lower and upper limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the minimum healthy percent and maximum percent values aren’t used, although they’re currently visible when describing your service.\n\nWhen creating a service that uses the EXTERNAL deployment controller, you can specify only parameters that aren’t controlled at the task set level. The only required parameter is the service name. You control your services using the CreateTaskSet operation. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide .\n\nWhen the service scheduler launches new tasks, it determines task placement in your cluster using the following logic:\n\nDetermine which of the container instances in your cluster can support your service’s task definition (for example, they have the required CPU, memory, ports, and container instance attributes).\n\nBy default, the service scheduler attempts to balance tasks across Availability Zones in this manner (although you can choose a different placement strategy) with the placementStrategy parameter):\n\nSort the valid container instances, giving priority to instances that have the fewest number of running tasks for this service in their respective Availability Zone. For example, if zone A has one running service task and zones B and C each have zero, valid container instances in either zone B or C are considered optimal for placement.\n\nPlace the new service task on a valid container instance in an optimal Availability Zone (based on the previous steps), favoring container instances with the fewest number of running tasks for this service.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-service\n[--cluster <value>]\n--service-name <value>\n[--task-definition <value>]\n[--load-balancers <value>]\n[--service-registries <value>]\n[--desired-count <value>]\n[--client-token <value>]\n[--launch-type <value>]\n[--capacity-provider-strategy <value>]\n[--platform-version <value>]\n[--role <value>]\n[--deployment-configuration <value>]\n[--placement-constraints <value>]\n[--placement-strategy <value>]\n[--network-configuration <value>]\n[--health-check-grace-period-seconds <value>]\n[--scheduling-strategy <value>]\n[--deployment-controller <value>]\n[--tags <value>]\n[--enable-ecs-managed-tags | --no-enable-ecs-managed-tags]\n[--propagate-tags <value>]\n[--enable-execute-command | --disable-execute-command]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--service-name <value>",
        "[--task-definition <value>]",
        "[--load-balancers <value>]",
        "[--service-registries <value>]",
        "[--desired-count <value>]",
        "[--client-token <value>]",
        "[--launch-type <value>]",
        "[--capacity-provider-strategy <value>]",
        "[--platform-version <value>]",
        "[--role <value>]",
        "[--deployment-configuration <value>]",
        "[--placement-constraints <value>]",
        "[--placement-strategy <value>]",
        "[--network-configuration <value>]",
        "[--health-check-grace-period-seconds <value>]",
        "[--scheduling-strategy <value>]",
        "[--deployment-controller <value>]",
        "[--tags <value>]",
        "[--enable-ecs-managed-tags | --no-enable-ecs-managed-tags]",
        "[--propagate-tags <value>]",
        "[--enable-execute-command | --disable-execute-command]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster on which to run your service. If you do not specify a cluster, the default cluster is assumed.\n\n--service-name (string)\n\nThe name of your service. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. Service names must be unique within a cluster, but you can have similarly named services in multiple clusters within a Region or across multiple Regions.\n\n--task-definition (string)\n\nThe family and revision (family:revision ) or full ARN of the task definition to run in your service. If a revision is not specified, the latest ACTIVE revision is used.\n\nA task definition must be specified if the service is using either the ECS or CODE_DEPLOY deployment controllers.\n\n--load-balancers (list)\n\nA load balancer object representing the load balancers to use with your service. For more information, see Service Load Balancing in the Amazon Elastic Container Service Developer Guide .\n\nIf the service is using the rolling update (ECS ) deployment controller and using either an Application Load Balancer or Network Load Balancer, you must specify one or more target group ARNs to attach to the service. The service-linked role is required for services that make use of multiple target groups. For more information, see Using service-linked roles for Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\nIf the service is using the CODE_DEPLOY deployment controller, the service is required to use either an Application Load Balancer or Network Load Balancer. When creating an CodeDeploy deployment group, you specify two target groups (referred to as a targetGroupPair ). During a deployment, CodeDeploy determines which task set in your service has the status PRIMARY and associates one target group with it, and then associates the other target group with the replacement task set. The load balancer can also have up to two listeners: a required listener for production traffic and an optional listener that allows you perform validation tests with Lambda functions before routing production traffic to it.\n\nAfter you create a service using the ECS deployment controller, the load balancer name or target group ARN, container name, and container port specified in the service definition are immutable. If you are using the CODE_DEPLOY deployment controller, these values can be changed when updating the service.\n\nFor Application Load Balancers and Network Load Balancers, this object must contain the load balancer target group ARN, the container name (as it appears in a container definition), and the container port to access from the load balancer. The load balancer name parameter must be omitted. When a task from this service is placed on a container instance, the container instance and port combination is registered as a target in the target group specified here.\n\nFor Classic Load Balancers, this object must contain the load balancer name, the container name (as it appears in a container definition), and the container port to access from the load balancer. The target group ARN parameter must be omitted. When a task from this service is placed on a container instance, the container instance is registered with the load balancer specified here.\n\nServices with tasks that use the awsvpc network mode (for example, those with the Fargate launch type) only support Application Load Balancers and Network Load Balancers. Classic Load Balancers are not supported. Also, when you create any target groups for these services, you must choose ip as the target type, not instance , because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nShorthand Syntax:\n\ntargetGroupArn=string,loadBalancerName=string,containerName=string,containerPort=integer ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"targetGroupArn\": \"string\",\n    \"loadBalancerName\": \"string\",\n    \"containerName\": \"string\",\n    \"containerPort\": integer\n  }\n  ...\n]\n\n\n--service-registries (list)\n\nThe details of the service discovery registry to associate with this service. For more information, see Service discovery .\n\nNote\n\nEach service may be associated with one service registry. Multiple service registries per service isn’t supported.\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nShorthand Syntax:\n\nregistryArn=string,port=integer,containerName=string,containerPort=integer ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"registryArn\": \"string\",\n    \"port\": integer,\n    \"containerName\": \"string\",\n    \"containerPort\": integer\n  }\n  ...\n]\n\n\n--desired-count (integer)\n\nThe number of instantiations of the specified task definition to place and keep running on your cluster.\n\nThis is required if schedulingStrategy is REPLICA or is not specified. If schedulingStrategy is DAEMON then this is not required.\n\n--client-token (string)\n\nUnique, case-sensitive identifier that you provide to ensure the idempotency of the request. Up to 32 ASCII characters are allowed.\n\n--launch-type (string)\n\nThe infrastructure on which to run your service. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\nThe FARGATE launch type runs your tasks on Fargate On-Demand infrastructure.\n\nNote\n\nFargate Spot infrastructure is available for use but a capacity provider strategy must be used. For more information, see Fargate capacity providers in the Amazon ECS User Guide for Fargate .\n\nThe EC2 launch type runs your tasks on Amazon EC2 instances registered to your cluster.\n\nThe EXTERNAL launch type runs your tasks on your on-premise server or virtual machine (VM) capacity registered to your cluster.\n\nA service can use either a launch type or a capacity provider strategy. If a launchType is specified, the capacityProviderStrategy parameter must be omitted.\n\nPossible values:\n\nEC2\n\nFARGATE\n\nEXTERNAL\n\n--capacity-provider-strategy (list)\n\nThe capacity provider strategy to use for the service.\n\nIf a capacityProviderStrategy is specified, the launchType parameter must be omitted. If no capacityProviderStrategy or launchType is specified, the defaultCapacityProviderStrategy for the cluster is used.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nShorthand Syntax:\n\ncapacityProvider=string,weight=integer,base=integer ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"capacityProvider\": \"string\",\n    \"weight\": integer,\n    \"base\": integer\n  }\n  ...\n]\n\n\n--platform-version (string)\n\nThe platform version that your tasks in the service are running on. A platform version is specified only for tasks using the Fargate launch type. If one isn’t specified, the LATEST platform version is used by default. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\n--role (string)\n\nThe name or full Amazon Resource Name (ARN) of the IAM role that allows Amazon ECS to make calls to your load balancer on your behalf. This parameter is only permitted if you are using a load balancer with your service and your task definition does not use the awsvpc network mode. If you specify the role parameter, you must also specify a load balancer object with the loadBalancers parameter.\n\nWarning\n\nIf your account has already created the Amazon ECS service-linked role, that role is used by default for your service unless you specify a role here. The service-linked role is required if your task definition uses the awsvpc network mode or if the service is configured to use service discovery, an external deployment controller, multiple target groups, or Elastic Inference accelerators in which case you should not specify a role here. For more information, see Using service-linked roles for Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\nIf your specified role has a path other than / , then you must either specify the full role ARN (this is recommended) or prefix the role name with the path. For example, if a role with the name bar has a path of /foo/ then you would specify /foo/bar as the role name. For more information, see Friendly names and paths in the IAM User Guide .\n\n--deployment-configuration (structure)\n\nOptional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.\n\ndeploymentCircuitBreaker -> (structure)\n\nNote\n\nThe deployment circuit breaker can only be used for services using the rolling update (ECS ) deployment type.\n\nThe deployment circuit breaker determines whether a service deployment will fail if the service can’t reach a steady state. If deployment circuit breaker is enabled, a service deployment will transition to a failed state and stop launching new tasks. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nenable -> (boolean)\n\nWhether to enable the deployment circuit breaker logic for the service.\n\nrollback -> (boolean)\n\nWhether to enable Amazon ECS to roll back the service if a service deployment fails. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nmaximumPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the maximum percent parameter represents an upper limit on the number of tasks in a service that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desired number of tasks (rounded down to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to define the deployment batch size. For example, if your service has a desired number of four tasks and a maximum percent value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default value for maximum percent is 200%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the maximum percent value is set to the default value and is used to define the upper limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the maximum percent value is not used, although it is returned when describing your service.\n\nminimumHealthyPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the minimum healthy percent represents a lower limit on the number of tasks in a service that must remain in the RUNNING state during a deployment, as a percentage of the desired number of tasks (rounded up to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a desired number of four tasks and a minimum healthy percent of 50%, the scheduler may stop two existing tasks to free up cluster capacity before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state; tasks for services that do use a load balancer are considered healthy if they are in the RUNNING state and they are reported as healthy by the load balancer. The default value for minimum healthy percent is 100%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the minimum healthy percent value is set to the default value and is used to define the lower limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the minimum healthy percent value is not used, although it is returned when describing your service.\n\nShorthand Syntax:\n\ndeploymentCircuitBreaker={enable=boolean,rollback=boolean},maximumPercent=integer,minimumHealthyPercent=integer\n\n\nJSON Syntax:\n\n{\n  \"deploymentCircuitBreaker\": {\n    \"enable\": true|false,\n    \"rollback\": true|false\n  },\n  \"maximumPercent\": integer,\n  \"minimumHealthyPercent\": integer\n}\n\n\n--placement-constraints (list)\n\nAn array of placement constraint objects to use for tasks in your service. You can specify a maximum of 10 constraints per task (this limit includes constraints in the task definition and those specified at runtime).\n\n(structure)\n\nAn object representing a constraint on task placement. For more information, see Task Placement Constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you are using the Fargate launch type, task placement constraints are not supported.\n\ntype -> (string)\n\nThe type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. The expression can have a maximum length of 2000 characters. You can’t specify an expression if the constraint type is distinctInstance . For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\nShorthand Syntax:\n\ntype=string,expression=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"type\": \"distinctInstance\"|\"memberOf\",\n    \"expression\": \"string\"\n  }\n  ...\n]\n\n\n--placement-strategy (list)\n\nThe placement strategy objects to use for tasks in your service. You can specify a maximum of 5 strategy rules per service.\n\n(structure)\n\nThe task placement strategy for a task or service. For more information, see Task Placement Strategies in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).\n\nfield -> (string)\n\nThe field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host , which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone . For the binpack placement strategy, valid values are cpu and memory . For the random placement strategy, this field is not used.\n\nShorthand Syntax:\n\ntype=string,field=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"type\": \"random\"|\"spread\"|\"binpack\",\n    \"field\": \"string\"\n  }\n  ...\n]\n\n\n--network-configuration (structure)\n\nThe network configuration for the service. This parameter is required for task definitions that use the awsvpc network mode to receive their own elastic network interface, and it is not supported for other network modes. For more information, see Task networking in the Amazon Elastic Container Service Developer Guide .\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nShorthand Syntax:\n\nawsvpcConfiguration={subnets=[string,string],securityGroups=[string,string],assignPublicIp=string}\n\n\nJSON Syntax:\n\n{\n  \"awsvpcConfiguration\": {\n    \"subnets\": [\"string\", ...],\n    \"securityGroups\": [\"string\", ...],\n    \"assignPublicIp\": \"ENABLED\"|\"DISABLED\"\n  }\n}\n\n\n--health-check-grace-period-seconds (integer)\n\nThe period of time, in seconds, that the Amazon ECS service scheduler should ignore unhealthy Elastic Load Balancing target health checks after a task has first started. This is only used when your service is configured to use a load balancer. If your service has a load balancer defined and you don’t specify a health check grace period value, the default value of 0 is used.\n\nIf your service’s tasks take a while to start and respond to Elastic Load Balancing health checks, you can specify a health check grace period of up to 2,147,483,647 seconds. During that time, the Amazon ECS service scheduler ignores health check status. This grace period can prevent the service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.\n\n--scheduling-strategy (string)\n\nThe scheduling strategy to use for the service. For more information, see Services .\n\nThere are two service scheduler strategies available:\n\nREPLICA -The replica scheduling strategy places and maintains the desired number of tasks across your cluster. By default, the service scheduler spreads tasks across Availability Zones. You can use task placement strategies and constraints to customize task placement decisions. This scheduler strategy is required if the service is using the CODE_DEPLOY or EXTERNAL deployment controller types.\n\nDAEMON -The daemon scheduling strategy deploys exactly one task on each active container instance that meets all of the task placement constraints that you specify in your cluster. The service scheduler also evaluates the task placement constraints for running tasks and will stop tasks that do not meet the placement constraints. When you’re using this strategy, you don’t need to specify a desired number of tasks, a task placement strategy, or use Service Auto Scaling policies.\n\nNote\n\nTasks using the Fargate launch type or the CODE_DEPLOY or EXTERNAL deployment controller types don’t support the DAEMON scheduling strategy.\n\nPossible values:\n\nREPLICA\n\nDAEMON\n\n--deployment-controller (structure)\n\nThe deployment controller to use for the service. If no deployment controller is specified, the default value of ECS is used.\n\ntype -> (string)\n\nThe deployment controller type to use.\n\nThere are three deployment controller types available:\n\nECS\n\nThe rolling update (ECS ) deployment type involves replacing the current running version of the container with the latest version. The number of containers Amazon ECS adds or removes from the service during a rolling update is controlled by adjusting the minimum and maximum number of healthy tasks allowed during a service deployment, as specified in the DeploymentConfiguration .\n\nCODE_DEPLOY\n\nThe blue/green (CODE_DEPLOY ) deployment type uses the blue/green deployment model powered by CodeDeploy, which allows you to verify a new deployment of a service before sending production traffic to it.\n\nEXTERNAL\n\nThe external (EXTERNAL ) deployment type enables you to use any third-party deployment controller for full control over the deployment process for an Amazon ECS service.\n\nShorthand Syntax:\n\ntype=string\n\n\nJSON Syntax:\n\n{\n  \"type\": \"ECS\"|\"CODE_DEPLOY\"|\"EXTERNAL\"\n}\n\n\n--tags (list)\n\nThe metadata that you apply to the service to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. When a service is deleted, the tags are deleted as well.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--enable-ecs-managed-tags | --no-enable-ecs-managed-tags (boolean)\n\nSpecifies whether to enable Amazon ECS managed tags for the tasks within the service. For more information, see Tagging Your Amazon ECS Resources in the Amazon Elastic Container Service Developer Guide .\n\n--propagate-tags (string)\n\nSpecifies whether to propagate the tags from the task definition or the service to the tasks in the service. If no value is specified, the tags are not propagated. Tags can only be propagated to the tasks within the service during service creation. To add tags to a task after service creation or task creation, use the TagResource API action.\n\nPossible values:\n\nTASK_DEFINITION\n\nSERVICE\n\n--enable-execute-command | --disable-execute-command (boolean)\n\nWhether or not the execute command functionality is enabled for the service. If true , this enables execute command functionality on all containers in the service tasks.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nservice -> (structure)\n\nThe full description of your service following the create call.\n\nA service will return either a capacityProviderStrategy or launchType parameter, but not both, depending on which one was specified during creation.\n\nIf a service is using the ECS deployment controller, the deploymentController and taskSets parameters will not be returned.\n\nIf the service is using the CODE_DEPLOY deployment controller, the deploymentController , taskSets and deployments parameters will be returned, however the deployments parameter will be an empty list.\n\nserviceArn -> (string)\n\nThe ARN that identifies the service. The ARN contains the arn:aws:ecs namespace, followed by the Region of the service, the Amazon Web Services account ID of the service owner, the service namespace, and then the service name. For example, arn:aws:ecs:region:012345678910:service/my-service .\n\nserviceName -> (string)\n\nThe name of your service. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. Service names must be unique within a cluster, but you can have similarly named services in multiple clusters within a Region or across multiple Regions.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that hosts the service.\n\nloadBalancers -> (list)\n\nA list of Elastic Load Balancing load balancer objects, containing the load balancer name, the container name (as it appears in a container definition), and the container port to access from the load balancer.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this service. For more information, see Service Discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nstatus -> (string)\n\nThe status of the service. The valid values are ACTIVE , DRAINING , or INACTIVE .\n\ndesiredCount -> (integer)\n\nThe desired number of instantiations of the task definition to keep running on the service. This value is specified when the service is created with CreateService , and it can be modified with UpdateService .\n\nrunningCount -> (integer)\n\nThe number of tasks in the cluster that are in the RUNNING state.\n\npendingCount -> (integer)\n\nThe number of tasks in the cluster that are in the PENDING state.\n\nlaunchType -> (string)\n\nThe launch type the service is using. When using the DescribeServices API, this field is omitted if the service was created using a capacity provider strategy.\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy the service is using. When using the DescribeServices API, this field is omitted if the service was created using a launch type.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe platform version on which to run your service. A platform version is only specified for tasks hosted on Fargate. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the service are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX .\n\ntaskDefinition -> (string)\n\nThe task definition to use for tasks in the service. This value is specified when the service is created with CreateService , and it can be modified with UpdateService .\n\ndeploymentConfiguration -> (structure)\n\nOptional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.\n\ndeploymentCircuitBreaker -> (structure)\n\nNote\n\nThe deployment circuit breaker can only be used for services using the rolling update (ECS ) deployment type.\n\nThe deployment circuit breaker determines whether a service deployment will fail if the service can’t reach a steady state. If deployment circuit breaker is enabled, a service deployment will transition to a failed state and stop launching new tasks. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nenable -> (boolean)\n\nWhether to enable the deployment circuit breaker logic for the service.\n\nrollback -> (boolean)\n\nWhether to enable Amazon ECS to roll back the service if a service deployment fails. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nmaximumPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the maximum percent parameter represents an upper limit on the number of tasks in a service that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desired number of tasks (rounded down to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to define the deployment batch size. For example, if your service has a desired number of four tasks and a maximum percent value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default value for maximum percent is 200%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the maximum percent value is set to the default value and is used to define the upper limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the maximum percent value is not used, although it is returned when describing your service.\n\nminimumHealthyPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the minimum healthy percent represents a lower limit on the number of tasks in a service that must remain in the RUNNING state during a deployment, as a percentage of the desired number of tasks (rounded up to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a desired number of four tasks and a minimum healthy percent of 50%, the scheduler may stop two existing tasks to free up cluster capacity before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state; tasks for services that do use a load balancer are considered healthy if they are in the RUNNING state and they are reported as healthy by the load balancer. The default value for minimum healthy percent is 100%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the minimum healthy percent value is set to the default value and is used to define the lower limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the minimum healthy percent value is not used, although it is returned when describing your service.\n\ntaskSets -> (list)\n\nInformation about a set of Amazon ECS tasks in either an CodeDeploy or an EXTERNAL deployment. An Amazon ECS task set includes details such as the desired number of tasks, how many tasks are running, and whether the task set serves production traffic.\n\n(structure)\n\nInformation about a set of Amazon ECS tasks in either an CodeDeploy or an EXTERNAL deployment. An Amazon ECS task set includes details such as the desired number of tasks, how many tasks are running, and whether the task set serves production traffic.\n\nid -> (string)\n\nThe ID of the task set.\n\ntaskSetArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task set.\n\nserviceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service the task set exists in.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that the service that hosts the task set exists in.\n\nstartedBy -> (string)\n\nThe tag specified when a task set is started. If the task set is created by an CodeDeploy deployment, the startedBy parameter is CODE_DEPLOY . For a task set created for an external deployment, the startedBy field isn’t used.\n\nexternalId -> (string)\n\nThe external ID associated with the task set.\n\nIf a task set is created by an CodeDeploy deployment, the externalId parameter contains the CodeDeploy deployment ID.\n\nIf a task set is created for an external deployment and is associated with a service discovery registry, the externalId parameter contains the ECS_TASK_SET_EXTERNAL_ID Cloud Map attribute.\n\nstatus -> (string)\n\nThe status of the task set. The following describes each state:\n\nPRIMARY\n\nThe task set is serving production traffic.\n\nACTIVE\n\nThe task set is not serving production traffic.\n\nDRAINING\n\nThe tasks in the task set are being stopped and their corresponding targets are being deregistered from their target group.\n\ntaskDefinition -> (string)\n\nThe task definition the task set is using.\n\ncomputedDesiredCount -> (integer)\n\nThe computed desired count for the task set. This is calculated by multiplying the service’s desiredCount by the task set’s scale percentage. The result is always rounded up. For example, if the computed desired count is 1.2, it rounds up to 2 tasks.\n\npendingCount -> (integer)\n\nThe number of tasks in the task set that are in the PENDING status during a deployment. A task in the PENDING state is preparing to enter the RUNNING state. A task set enters the PENDING status when it launches for the first time or when it is restarted after being in the STOPPED state.\n\nrunningCount -> (integer)\n\nThe number of tasks in the task set that are in the RUNNING status during a deployment. A task in the RUNNING state is running and ready for use.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was last updated.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the task set are using. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy associated with the task set.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe Fargate platform version on which the tasks in the task set are running. A platform version is only specified for tasks run on Fargate. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the set are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks in the set must have the same value.\n\nnetworkConfiguration -> (structure)\n\nThe network configuration for the task set.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nloadBalancers -> (list)\n\nDetails on a load balancer that is used with a task set.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this task set. For more information, see Service discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nscale -> (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nstabilityStatus -> (string)\n\nThe stability status, which indicates whether the task set has reached a steady state. If the following conditions are met, the task set will be in STEADY_STATE :\n\nThe task runningCount is equal to the computedDesiredCount .\n\nThe pendingCount is 0 .\n\nThere are no tasks running on container instances in the DRAINING status.\n\nAll tasks are reporting a healthy status from the load balancers, service discovery, and container health checks.\n\nIf any of those conditions are not met, the stability status returns STABILIZING .\n\nstabilityStatusAt -> (timestamp)\n\nThe Unix timestamp for when the task set stability status was retrieved.\n\ntags -> (list)\n\nThe metadata that you apply to the task set to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ndeployments -> (list)\n\nThe current state of deployments for the service.\n\n(structure)\n\nThe details of an Amazon ECS service deployment. This is used only when a service uses the ECS deployment controller type.\n\nid -> (string)\n\nThe ID of the deployment.\n\nstatus -> (string)\n\nThe status of the deployment. The following describes each state:\n\nPRIMARY\n\nThe most recent deployment of a service.\n\nACTIVE\n\nA service deployment that still has running tasks, but are in the process of being replaced with a new PRIMARY deployment.\n\nINACTIVE\n\nA deployment that has been completely replaced.\n\ntaskDefinition -> (string)\n\nThe most recent task definition that was specified for the tasks in the service to use.\n\ndesiredCount -> (integer)\n\nThe most recent desired count of tasks that was specified for the service to deploy or maintain.\n\npendingCount -> (integer)\n\nThe number of tasks in the deployment that are in the PENDING status.\n\nrunningCount -> (integer)\n\nThe number of tasks in the deployment that are in the RUNNING status.\n\nfailedTasks -> (integer)\n\nThe number of consecutively failed tasks in the deployment. A task is considered a failure if the service scheduler can’t launch the task, the task doesn’t transition to a RUNNING state, or if it fails any of its defined health checks and is stopped.\n\nNote\n\nOnce a service deployment has one or more successfully running tasks, the failed task count resets to zero and stops being evaluated.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the service deployment was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the service deployment was last updated.\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy that the deployment is using.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the service are using. For more information, see Amazon ECS Launch Types in the Amazon Elastic Container Service Developer Guide .\n\nplatformVersion -> (string)\n\nThe platform version on which your tasks in the service are running. A platform version is only specified for tasks using the Fargate launch type. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the service, or tasks are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX. .\n\nnetworkConfiguration -> (structure)\n\nThe VPC subnet and security group configuration for tasks that receive their own elastic network interface by using the awsvpc networking mode.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nrolloutState -> (string)\n\nNote\n\nThe rolloutState of a service is only returned for services that use the rolling update (ECS ) deployment type that are not behind a Classic Load Balancer.\n\nThe rollout state of the deployment. When a service deployment is started, it begins in an IN_PROGRESS state. When the service reaches a steady state, the deployment will transition to a COMPLETED state. If the service fails to reach a steady state and circuit breaker is enabled, the deployment will transition to a FAILED state. A deployment in FAILED state will launch no new tasks. For more information, see DeploymentCircuitBreaker .\n\nrolloutStateReason -> (string)\n\nA description of the rollout state of a deployment.\n\nroleArn -> (string)\n\nThe ARN of the IAM role associated with the service that allows the Amazon ECS container agent to register container instances with an Elastic Load Balancing load balancer.\n\nevents -> (list)\n\nThe event stream for your service. A maximum of 100 of the latest events are displayed.\n\n(structure)\n\nDetails on an event associated with a service.\n\nid -> (string)\n\nThe ID string of the event.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the event was triggered.\n\nmessage -> (string)\n\nThe event message.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the service was created.\n\nplacementConstraints -> (list)\n\nThe placement constraints for the tasks in the service.\n\n(structure)\n\nAn object representing a constraint on task placement. For more information, see Task Placement Constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you are using the Fargate launch type, task placement constraints are not supported.\n\ntype -> (string)\n\nThe type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. The expression can have a maximum length of 2000 characters. You can’t specify an expression if the constraint type is distinctInstance . For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\nplacementStrategy -> (list)\n\nThe placement strategy that determines how tasks for the service are placed.\n\n(structure)\n\nThe task placement strategy for a task or service. For more information, see Task Placement Strategies in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).\n\nfield -> (string)\n\nThe field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host , which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone . For the binpack placement strategy, valid values are cpu and memory . For the random placement strategy, this field is not used.\n\nnetworkConfiguration -> (structure)\n\nThe VPC subnet and security group configuration for tasks that receive their own elastic network interface by using the awsvpc networking mode.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nhealthCheckGracePeriodSeconds -> (integer)\n\nThe period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started.\n\nschedulingStrategy -> (string)\n\nThe scheduling strategy to use for the service. For more information, see Services .\n\nThere are two service scheduler strategies available:\n\nREPLICA -The replica scheduling strategy places and maintains the desired number of tasks across your cluster. By default, the service scheduler spreads tasks across Availability Zones. You can use task placement strategies and constraints to customize task placement decisions.\n\nDAEMON -The daemon scheduling strategy deploys exactly one task on each active container instance that meets all of the task placement constraints that you specify in your cluster. The service scheduler also evaluates the task placement constraints for running tasks and will stop tasks that do not meet the placement constraints.\n\nNote\n\nFargate tasks do not support the DAEMON scheduling strategy.\n\ndeploymentController -> (structure)\n\nThe deployment controller type the service is using. When using the DescribeServices API, this field is omitted if the service is using the ECS deployment controller type.\n\ntype -> (string)\n\nThe deployment controller type to use.\n\nThere are three deployment controller types available:\n\nECS\n\nThe rolling update (ECS ) deployment type involves replacing the current running version of the container with the latest version. The number of containers Amazon ECS adds or removes from the service during a rolling update is controlled by adjusting the minimum and maximum number of healthy tasks allowed during a service deployment, as specified in the DeploymentConfiguration .\n\nCODE_DEPLOY\n\nThe blue/green (CODE_DEPLOY ) deployment type uses the blue/green deployment model powered by CodeDeploy, which allows you to verify a new deployment of a service before sending production traffic to it.\n\nEXTERNAL\n\nThe external (EXTERNAL ) deployment type enables you to use any third-party deployment controller for full control over the deployment process for an Amazon ECS service.\n\ntags -> (list)\n\nThe metadata that you apply to the service to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ncreatedBy -> (string)\n\nThe principal that created the service.\n\nenableECSManagedTags -> (boolean)\n\nSpecifies whether to enable Amazon ECS managed tags for the tasks in the service. For more information, see Tagging Your Amazon ECS Resources in the Amazon Elastic Container Service Developer Guide .\n\npropagateTags -> (string)\n\nSpecifies whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags are not propagated.\n\nenableExecuteCommand -> (boolean)\n\nWhether or not the execute command functionality is enabled for the service. If true , the execute command functionality is enabled for all containers in tasks as part of the service.",
      "command_examples": "Examples\n\nExample 1: To create a service with a Fargate task\n\nThe following create-service example shows how to create a service using a Fargate task.\n\naws ecs create-service \\\n    --cluster MyCluster \\\n    --service-name MyService \\\n    --task-definition sample-fargate:1 \\\n    --desired-count 2 \\\n    --launch-type FARGATE \\\n    --platform-version LATEST \\\n    --network-configuration \"awsvpcConfiguration={subnets=[subnet-12344321],securityGroups=[sg-12344321],assignPublicIp=ENABLED}\" \\\n    --tags key=key1,value=value1 key=key2,value=value2 key=key3,value=value3\n\n\nOutput:\n\n{\n    \"service\": {\n        \"serviceArn\": \"arn:aws:ecs:us-west-2:123456789012:service/MyCluster/MyService\",\n        \"serviceName\": \"MyService\",\n          \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"loadBalancers\": [],\n        \"serviceRegistries\": [],\n        \"status\": \"ACTIVE\",\n        \"desiredCount\": 2,\n        \"runningCount\": 0,\n        \"pendingCount\": 0,\n        \"launchType\": \"FARGATE\",\n        \"platformVersion\": \"LATEST\",\n        \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sample-fargate:1\",\n        \"deploymentConfiguration\": {\n            \"maximumPercent\": 200,\n            \"minimumHealthyPercent\": 100\n        },\n        \"deployments\": [\n            {\n                \"id\": \"ecs-svc/1234567890123456789\",\n                \"status\": \"PRIMARY\",\n                \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sample-fargate:1\",\n                \"desiredCount\": 2,\n                \"pendingCount\": 0,\n                \"runningCount\": 0,\n                \"createdAt\": 1557119253.821,\n                \"updatedAt\": 1557119253.821,\n                \"launchType\": \"FARGATE\",\n                \"platformVersion\": \"1.3.0\",\n                \"networkConfiguration\": {\n                    \"awsvpcConfiguration\": {\n                        \"subnets\": [\n                            \"subnet-12344321\"\n                        ],\n                        \"securityGroups\": [\n                            \"sg-12344321\"\n                        ],\n                        \"assignPublicIp\": \"ENABLED\"\n                    }\n                }\n            }\n        ],\n        \"roleArn\": \"arn:aws:iam::123456789012:role/aws-service-role/ecs.amazonaws.com/AWSServiceRoleForECS\",\n        \"events\": [],\n        \"createdAt\": 1557119253.821,\n        \"placementConstraints\": [],\n        \"placementStrategy\": [],\n        \"networkConfiguration\": {\n            \"awsvpcConfiguration\": {\n                \"subnets\": [\n                    \"subnet-12344321\"\n                ],\n                \"securityGroups\": [\n                    \"sg-12344321\"\n                ],\n                \"assignPublicIp\": \"ENABLED\"\n            }\n        },\n        \"schedulingStrategy\": \"REPLICA\",\n        \"tags\": [\n            {\n                \"key\": \"key1\",\n                \"value\": \"value1\"\n            },\n            {\n                \"key\": \"key2\",\n                \"value\": \"value2\"\n            },\n            {\n                \"key\": \"key3\",\n                \"value\": \"value3\"\n            }\n        ],\n        \"enableECSManagedTags\": false,\n        \"propagateTags\": \"NONE\"\n    }\n}\n\n\nExample 2: To create a service using the EC2 launch type\n\nThe following create-service example shows how to create a service called ecs-simple-service with a task that uses the EC2 launch type. The service uses the sleep360 task definition and it maintains 1 instantiation of the task.\n\naws ecs create-service \\\n    --cluster MyCluster \\\n    --service-name ecs-simple-service \\\n    --task-definition sleep360:2 \\\n    --desired-count 1\n\n\nOutput:\n\n{\n    \"service\": {\n        \"serviceArn\": \"arn:aws:ecs:us-west-2:123456789012:service/MyCluster/ecs-simple-service\",\n        \"serviceName\": \"ecs-simple-service\",\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"loadBalancers\": [],\n        \"serviceRegistries\": [],\n        \"status\": \"ACTIVE\",\n        \"desiredCount\": 1,\n        \"runningCount\": 0,\n        \"pendingCount\": 0,\n        \"launchType\": \"EC2\",\n        \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sleep360:2\",\n        \"deploymentConfiguration\": {\n            \"maximumPercent\": 200,\n            \"minimumHealthyPercent\": 100\n        },\n        \"deployments\": [\n            {\n                \"id\": \"ecs-svc/1234567890123456789\",\n                \"status\": \"PRIMARY\",\n                \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sleep360:2\",\n                \"desiredCount\": 1,\n                \"pendingCount\": 0,\n                \"runningCount\": 0,\n                \"createdAt\": 1557206498.798,\n                \"updatedAt\": 1557206498.798,\n                \"launchType\": \"EC2\"\n            }\n        ],\n        \"events\": [],\n        \"createdAt\": 1557206498.798,\n        \"placementConstraints\": [],\n        \"placementStrategy\": [],\n        \"schedulingStrategy\": \"REPLICA\",\n        \"enableECSManagedTags\": false,\n        \"propagateTags\": \"NONE\"\n    }\n}\n\n\nExample 3: To create a service that uses an external deployment controller\n\nThe following create-service example creates a service that uses an external deployment controller.\n\naws ecs create-service \\\n    --cluster MyCluster \\\n    --service-name MyService \\\n    --deployment-controller type=EXTERNAL \\\n    --desired-count 1\n\n\nOutput:\n\n{\n    \"service\": {\n        \"serviceArn\": \"arn:aws:ecs:us-west-2:123456789012:service/MyCluster/MyService\",\n        \"serviceName\": \"MyService\",\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"loadBalancers\": [],\n        \"serviceRegistries\": [],\n        \"status\": \"ACTIVE\",\n        \"desiredCount\": 1,\n        \"runningCount\": 0,\n        \"pendingCount\": 0,\n        \"launchType\": \"EC2\",\n        \"deploymentConfiguration\": {\n            \"maximumPercent\": 200,\n            \"minimumHealthyPercent\": 100\n        },\n        \"taskSets\": [],\n        \"deployments\": [],\n        \"roleArn\": \"arn:aws:iam::123456789012:role/aws-service-role/ecs.amazonaws.com/AWSServiceRoleForECS\",\n        \"events\": [],\n        \"createdAt\": 1557128207.101,\n        \"placementConstraints\": [],\n        \"placementStrategy\": [],\n        \"schedulingStrategy\": \"REPLICA\",\n        \"deploymentController\": {\n            \"type\": \"EXTERNAL\"\n        },\n        \"enableECSManagedTags\": false,\n        \"propagateTags\": \"NONE\"\n    }\n}\n\n\nExample 4: To create a new service behind a load balancer\n\nThe following create-service example shows how to create a service that is behind a load balancer. You must have a load balancer configured in the same Region as your container instance. This example uses the --cli-input-json option and a JSON input file called ecs-simple-service-elb.json with the following content:\n\n{\n    \"serviceName\": \"ecs-simple-service-elb\",\n    \"taskDefinition\": \"ecs-demo\",\n    \"loadBalancers\": [\n        {\n            \"loadBalancerName\": \"EC2Contai-EcsElast-123456789012\",\n            \"containerName\": \"simple-demo\",\n            \"containerPort\": 80\n        }\n    ],\n    \"desiredCount\": 10,\n    \"role\": \"ecsServiceRole\"\n}\n\n\nCommand:\n\naws ecs create-service \\\n    --cluster MyCluster \\\n    --service-name ecs-simple-service-elb \\\n    --cli-input-json file://ecs-simple-service-elb.json\n\n\nOutput:\n\n{\n    \"service\": {\n        \"status\": \"ACTIVE\",\n        \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/ecs-demo:1\",\n        \"pendingCount\": 0,\n        \"loadBalancers\": [\n            {\n                \"containerName\": \"ecs-demo\",\n                \"containerPort\": 80,\n                \"loadBalancerName\": \"EC2Contai-EcsElast-123456789012\"\n            }\n        ],\n        \"roleArn\": \"arn:aws:iam::123456789012:role/ecsServiceRole\",\n        \"desiredCount\": 10,\n        \"serviceName\": \"ecs-simple-service-elb\",\n        \"clusterArn\": \"arn:aws:ecs:<us-west-2:123456789012:cluster/MyCluster\",\n        \"serviceArn\": \"arn:aws:ecs:us-west-2:123456789012:service/ecs-simple-service-elb\",\n        \"deployments\": [\n            {\n                \"status\": \"PRIMARY\",\n                \"pendingCount\": 0,\n                \"createdAt\": 1428100239.123,\n                \"desiredCount\": 10,\n                \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/ecs-demo:1\",\n                \"updatedAt\": 1428100239.123,\n                \"id\": \"ecs-svc/1234567890123456789\",\n                \"runningCount\": 0\n            }\n        ],\n        \"events\": [],\n        \"runningCount\": 0\n    }\n}\n\n\nFor more information, see Creating a Service in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "create-task-set",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/create-task-set.html",
      "command_description": "Description\n\nCreate a task set in the specified cluster and service. This is used when a service uses the EXTERNAL deployment controller type. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-task-set\n--service <value>\n--cluster <value>\n[--external-id <value>]\n--task-definition <value>\n[--network-configuration <value>]\n[--load-balancers <value>]\n[--service-registries <value>]\n[--launch-type <value>]\n[--capacity-provider-strategy <value>]\n[--platform-version <value>]\n[--scale <value>]\n[--client-token <value>]\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--service <value>",
        "--cluster <value>",
        "[--external-id <value>]",
        "--task-definition <value>",
        "[--network-configuration <value>]",
        "[--load-balancers <value>]",
        "[--service-registries <value>]",
        "[--launch-type <value>]",
        "[--capacity-provider-strategy <value>]",
        "[--platform-version <value>]",
        "[--scale <value>]",
        "[--client-token <value>]",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--service (string)\n\nThe short name or full Amazon Resource Name (ARN) of the service to create the task set in.\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the service to create the task set in.\n\n--external-id (string)\n\nAn optional non-unique tag that identifies this task set in external systems. If the task set is associated with a service discovery registry, the tasks in this task set will have the ECS_TASK_SET_EXTERNAL_ID Cloud Map attribute set to the provided value.\n\n--task-definition (string)\n\nThe task definition for the tasks in the task set to use.\n\n--network-configuration (structure)\n\nAn object representing the network configuration for a task set.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nShorthand Syntax:\n\nawsvpcConfiguration={subnets=[string,string],securityGroups=[string,string],assignPublicIp=string}\n\n\nJSON Syntax:\n\n{\n  \"awsvpcConfiguration\": {\n    \"subnets\": [\"string\", ...],\n    \"securityGroups\": [\"string\", ...],\n    \"assignPublicIp\": \"ENABLED\"|\"DISABLED\"\n  }\n}\n\n\n--load-balancers (list)\n\nA load balancer object representing the load balancer to use with the task set. The supported load balancer types are either an Application Load Balancer or a Network Load Balancer.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nShorthand Syntax:\n\ntargetGroupArn=string,loadBalancerName=string,containerName=string,containerPort=integer ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"targetGroupArn\": \"string\",\n    \"loadBalancerName\": \"string\",\n    \"containerName\": \"string\",\n    \"containerPort\": integer\n  }\n  ...\n]\n\n\n--service-registries (list)\n\nThe details of the service discovery registries to assign to this task set. For more information, see Service Discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nShorthand Syntax:\n\nregistryArn=string,port=integer,containerName=string,containerPort=integer ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"registryArn\": \"string\",\n    \"port\": integer,\n    \"containerName\": \"string\",\n    \"containerPort\": integer\n  }\n  ...\n]\n\n\n--launch-type (string)\n\nThe launch type that new tasks in the task set will use. For more information, see Amazon ECS Launch Types in the Amazon Elastic Container Service Developer Guide .\n\nIf a launchType is specified, the capacityProviderStrategy parameter must be omitted.\n\nPossible values:\n\nEC2\n\nFARGATE\n\nEXTERNAL\n\n--capacity-provider-strategy (list)\n\nThe capacity provider strategy to use for the task set.\n\nA capacity provider strategy consists of one or more capacity providers along with the base and weight to assign to them. A capacity provider must be associated with the cluster to be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster. Only capacity providers with an ACTIVE or UPDATING status can be used.\n\nIf a capacityProviderStrategy is specified, the launchType parameter must be omitted. If no capacityProviderStrategy or launchType is specified, the defaultCapacityProviderStrategy for the cluster is used.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used.\n\nThe PutClusterCapacityProviders API operation is used to update the list of available capacity providers for a cluster after the cluster is created.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nShorthand Syntax:\n\ncapacityProvider=string,weight=integer,base=integer ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"capacityProvider\": \"string\",\n    \"weight\": integer,\n    \"base\": integer\n  }\n  ...\n]\n\n\n--platform-version (string)\n\nThe platform version that the tasks in the task set should use. A platform version is specified only for tasks using the Fargate launch type. If one isn’t specified, the LATEST platform version is used by default.\n\n--scale (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nShorthand Syntax:\n\nvalue=double,unit=string\n\n\nJSON Syntax:\n\n{\n  \"value\": double,\n  \"unit\": \"PERCENT\"\n}\n\n\n--client-token (string)\n\nUnique, case-sensitive identifier that you provide to ensure the idempotency of the request. Up to 32 ASCII characters are allowed.\n\n--tags (list)\n\nThe metadata that you apply to the task set to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. When a service is deleted, the tags are deleted as well.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntaskSet -> (structure)\n\nInformation about a set of Amazon ECS tasks in either an CodeDeploy or an EXTERNAL deployment. A task set includes details such as the desired number of tasks, how many tasks are running, and whether the task set serves production traffic.\n\nid -> (string)\n\nThe ID of the task set.\n\ntaskSetArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task set.\n\nserviceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service the task set exists in.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that the service that hosts the task set exists in.\n\nstartedBy -> (string)\n\nThe tag specified when a task set is started. If the task set is created by an CodeDeploy deployment, the startedBy parameter is CODE_DEPLOY . For a task set created for an external deployment, the startedBy field isn’t used.\n\nexternalId -> (string)\n\nThe external ID associated with the task set.\n\nIf a task set is created by an CodeDeploy deployment, the externalId parameter contains the CodeDeploy deployment ID.\n\nIf a task set is created for an external deployment and is associated with a service discovery registry, the externalId parameter contains the ECS_TASK_SET_EXTERNAL_ID Cloud Map attribute.\n\nstatus -> (string)\n\nThe status of the task set. The following describes each state:\n\nPRIMARY\n\nThe task set is serving production traffic.\n\nACTIVE\n\nThe task set is not serving production traffic.\n\nDRAINING\n\nThe tasks in the task set are being stopped and their corresponding targets are being deregistered from their target group.\n\ntaskDefinition -> (string)\n\nThe task definition the task set is using.\n\ncomputedDesiredCount -> (integer)\n\nThe computed desired count for the task set. This is calculated by multiplying the service’s desiredCount by the task set’s scale percentage. The result is always rounded up. For example, if the computed desired count is 1.2, it rounds up to 2 tasks.\n\npendingCount -> (integer)\n\nThe number of tasks in the task set that are in the PENDING status during a deployment. A task in the PENDING state is preparing to enter the RUNNING state. A task set enters the PENDING status when it launches for the first time or when it is restarted after being in the STOPPED state.\n\nrunningCount -> (integer)\n\nThe number of tasks in the task set that are in the RUNNING status during a deployment. A task in the RUNNING state is running and ready for use.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was last updated.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the task set are using. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy associated with the task set.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe Fargate platform version on which the tasks in the task set are running. A platform version is only specified for tasks run on Fargate. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the set are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks in the set must have the same value.\n\nnetworkConfiguration -> (structure)\n\nThe network configuration for the task set.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nloadBalancers -> (list)\n\nDetails on a load balancer that is used with a task set.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this task set. For more information, see Service discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nscale -> (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nstabilityStatus -> (string)\n\nThe stability status, which indicates whether the task set has reached a steady state. If the following conditions are met, the task set will be in STEADY_STATE :\n\nThe task runningCount is equal to the computedDesiredCount .\n\nThe pendingCount is 0 .\n\nThere are no tasks running on container instances in the DRAINING status.\n\nAll tasks are reporting a healthy status from the load balancers, service discovery, and container health checks.\n\nIf any of those conditions are not met, the stability status returns STABILIZING .\n\nstabilityStatusAt -> (timestamp)\n\nThe Unix timestamp for when the task set stability status was retrieved.\n\ntags -> (list)\n\nThe metadata that you apply to the task set to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nTo create a task set\n\nThe following create-task-set example creates a task set in a service that uses an external deployment controller.\n\naws ecs create-task-set \\\n    --cluster MyCluster \\\n    --service MyService \\\n    --task-definition MyTaskDefinition:2 \\\n    --network-configuration \"awsvpcConfiguration={subnets=[subnet-12344321],securityGroups=[sg-12344321]}\"\n\n\nOutput:\n\n{\n    \"taskSet\": {\n        \"id\": \"ecs-svc/1234567890123456789\",\n        \"taskSetArn\": \"arn:aws:ecs:us-west-2:123456789012:task-set/MyCluster/MyService/ecs-svc/1234567890123456789\",\n        \"status\": \"ACTIVE\",\n        \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/MyTaskDefinition:2\",\n        \"computedDesiredCount\": 0,\n        \"pendingCount\": 0,\n        \"runningCount\": 0,\n        \"createdAt\": 1557128360.711,\n        \"updatedAt\": 1557128360.711,\n        \"launchType\": \"EC2\",\n        \"networkConfiguration\": {\n            \"awsvpcConfiguration\": {\n                \"subnets\": [\n                    \"subnet-12344321\"\n                ],\n                \"securityGroups\": [\n                    \"sg-12344321\"\n                ],\n                \"assignPublicIp\": \"DISABLED\"\n            }\n        },\n        \"loadBalancers\": [],\n        \"serviceRegistries\": [],\n        \"scale\": {\n            \"value\": 0.0,\n            \"unit\": \"PERCENT\"\n        },\n        \"stabilityStatus\": \"STABILIZING\",\n        \"stabilityStatusAt\": 1557128360.711\n    }\n}\n"
    },
    {
      "command_name": "delete-account-setting",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/delete-account-setting.html",
      "command_description": "Description\n\nDisables an account setting for a specified IAM user, IAM role, or the root user for an account.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-account-setting\n--name <value>\n[--principal-arn <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--name <value>",
        "[--principal-arn <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--name (string)\n\nThe resource name for which to disable the account setting. If serviceLongArnFormat is specified, the ARN for your Amazon ECS services is affected. If taskLongArnFormat is specified, the ARN and resource ID for your Amazon ECS tasks is affected. If containerInstanceLongArnFormat is specified, the ARN and resource ID for your Amazon ECS container instances is affected. If awsvpcTrunking is specified, the ENI limit for your Amazon ECS container instances is affected.\n\nPossible values:\n\nserviceLongArnFormat\n\ntaskLongArnFormat\n\ncontainerInstanceLongArnFormat\n\nawsvpcTrunking\n\ncontainerInsights\n\n--principal-arn (string)\n\nThe ARN of the principal, which can be an IAM user, IAM role, or the root user. If you specify the root user, it disables the account setting for all IAM users, IAM roles, and the root user of the account unless an IAM user or role explicitly overrides these settings. If this field is omitted, the setting is changed only for the authenticated user.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nsetting -> (structure)\n\nThe account setting for the specified principal ARN.\n\nname -> (string)\n\nThe Amazon ECS resource name.\n\nvalue -> (string)\n\nWhether the account setting is enabled or disabled for the specified resource.\n\nprincipalArn -> (string)\n\nThe ARN of the principal, which can be an IAM user, IAM role, or the root user. If this field is omitted, the authenticated user is assumed.",
      "command_examples": "Examples\n\nTo delete the account settings for a specific IAM user or IAM role\n\nThe following example delete-account-setting deletes the account settings for the specific IAM user or IAM role.\n\naws ecs delete-account-setting \\\n    --name serviceLongArnFormat \\\n    --principal-arn arn:aws:iam::123456789012:user/MyUser\n\n\nOutput:\n\n{\n    \"setting\": {\n        \"name\": \"serviceLongArnFormat\",\n        \"value\": \"enabled\",\n        \"principalArn\": \"arn:aws:iam::123456789012:user/MyUser\"\n    }\n}\n\n\nFor more information, see Amazon Resource Names (ARNs) and IDs in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "delete-attributes",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/delete-attributes.html",
      "command_description": "Description\n\nDeletes one or more custom attributes from an Amazon ECS resource.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-attributes\n[--cluster <value>]\n--attributes <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--attributes <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that contains the resource to delete attributes. If you do not specify a cluster, the default cluster is assumed.\n\n--attributes (list)\n\nThe attributes to delete from your resource. You can specify up to 10 attributes per request. For custom attributes, specify the attribute name and target ID, but do not specify the value. If you specify the target ID using the short form, you must also specify the target type.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nShorthand Syntax:\n\nname=string,value=string,targetType=string,targetId=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"name\": \"string\",\n    \"value\": \"string\",\n    \"targetType\": \"container-instance\",\n    \"targetId\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nattributes -> (list)\n\nA list of attribute objects that were successfully deleted from your resource.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).",
      "command_examples": "Examples\n\nTo delete one or more custom attributes from an Amazon ECS resource\n\nThe following delete-attributes deletes an attribute with the name stack from a container instance.\n\naws ecs delete-attributes \\\n    --attributes name=stack,targetId=arn:aws:ecs:us-west-2:130757420319:container-instance/1c3be8ed-df30-47b4-8f1e-6e68ebd01f34\n\n\nOutput:\n\n{\n    \"attributes\": [\n        {\n            \"name\": \"stack\",\n            \"targetId\": \"arn:aws:ecs:us-west-2:130757420319:container-instance/1c3be8ed-df30-47b4-8f1e-6e68ebd01f34\",\n            \"value\": \"production\"\n        }\n    ]\n}\n"
    },
    {
      "command_name": "delete-capacity-provider",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/delete-capacity-provider.html",
      "command_description": "Description\n\nDeletes the specified capacity provider.\n\nNote\n\nThe FARGATE and FARGATE_SPOT capacity providers are reserved and cannot be deleted. You can disassociate them from a cluster using either the PutClusterCapacityProviders API or by deleting the cluster.\n\nPrior to a capacity provider being deleted, the capacity provider must be removed from the capacity provider strategy from all services. The UpdateService API can be used to remove a capacity provider from a service’s capacity provider strategy. When updating a service, the forceNewDeployment option can be used to ensure that any tasks using the Amazon EC2 instance capacity provided by the capacity provider are transitioned to use the capacity from the remaining capacity providers. Only capacity providers that are not associated with a cluster can be deleted. To remove a capacity provider from a cluster, you can either use PutClusterCapacityProviders or delete the cluster.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-capacity-provider\n--capacity-provider <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--capacity-provider <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--capacity-provider (string)\n\nThe short name or full Amazon Resource Name (ARN) of the capacity provider to delete.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncapacityProvider -> (structure)\n\nThe details of the capacity provider.\n\ncapacityProviderArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the capacity provider.\n\nname -> (string)\n\nThe name of the capacity provider.\n\nstatus -> (string)\n\nThe current status of the capacity provider. Only capacity providers in an ACTIVE state can be used in a cluster. When a capacity provider is successfully deleted, it will have an INACTIVE status.\n\nautoScalingGroupProvider -> (structure)\n\nThe Auto Scaling group settings for the capacity provider.\n\nautoScalingGroupArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the Auto Scaling group.\n\nmanagedScaling -> (structure)\n\nThe managed scaling settings for the Auto Scaling group capacity provider.\n\nstatus -> (string)\n\nWhether or not to enable managed scaling for the capacity provider.\n\ntargetCapacity -> (integer)\n\nThe target capacity value for the capacity provider. The specified value must be greater than 0 and less than or equal to 100 . A value of 100 will result in the Amazon EC2 instances in your Auto Scaling group being completely utilized.\n\nminimumScalingStepSize -> (integer)\n\nThe minimum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 1 is used.\n\nmaximumScalingStepSize -> (integer)\n\nThe maximum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 10000 is used.\n\ninstanceWarmupPeriod -> (integer)\n\nThe period of time, in seconds, after a newly launched Amazon EC2 instance can contribute to CloudWatch metrics for Auto Scaling group. If this parameter is omitted, the default value of 300 seconds is used.\n\nmanagedTerminationProtection -> (string)\n\nThe managed termination protection setting to use for the Auto Scaling group capacity provider. This determines whether the Auto Scaling group has managed termination protection.\n\nWarning\n\nWhen using managed termination protection, managed scaling must also be used otherwise managed termination protection will not work.\n\nWhen managed termination protection is enabled, Amazon ECS prevents the Amazon EC2 instances in an Auto Scaling group that contain tasks from being terminated during a scale-in action. The Auto Scaling group and each instance in the Auto Scaling group must have instance protection from scale-in actions enabled as well. For more information, see Instance Protection in the Auto Scaling User Guide .\n\nWhen managed termination protection is disabled, your Amazon EC2 instances are not protected from termination when the Auto Scaling group scales in.\n\nupdateStatus -> (string)\n\nThe update status of the capacity provider. The following are the possible states that will be returned.\n\nDELETE_IN_PROGRESS\n\nThe capacity provider is in the process of being deleted.\n\nDELETE_COMPLETE\n\nThe capacity provider has been successfully deleted and will have an INACTIVE status.\n\nDELETE_FAILED\n\nThe capacity provider was unable to be deleted. The update status reason will provide further details about why the delete failed.\n\nupdateStatusReason -> (string)\n\nThe update status reason. This provides further details about the update status for the capacity provider.\n\ntags -> (list)\n\nThe metadata that you apply to the capacity provider to help you categorize and organize it. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nExample 1: To delete a capacity provider using the Amazon Resource Name (ARN)\n\nThe following delete-capacity-provider example deletes a capacity provider by specifying the Amazon Resource Name (ARN) of the capacity provider. The ARN as well as the status of the capacity provider deletion can be retrieved using the describe-capacity-providers command.\n\naws ecs delete-capacity-provider \\\n    --capacity-provider arn:aws:ecs:us-west-2:123456789012:capacity-provider/ExampleCapacityProvider\n\n\nOutput:\n\n{\n    \"capacityProvider\": {\n        \"capacityProviderArn\": \"arn:aws:ecs:us-west-2:123456789012:capacity-provider/ExampleCapacityProvider\",\n        \"name\": \"ExampleCapacityProvider\",\n        \"status\": \"ACTIVE\",\n        \"autoScalingGroupProvider\": {\n            \"autoScalingGroupArn\": \"arn:aws:autoscaling:us-west-2:123456789012:autoScalingGroup:a1b2c3d4-5678-90ab-cdef-EXAMPLE11111:autoScalingGroupName/MyAutoScalingGroup\",\n            \"managedScaling\": {\n                \"status\": \"ENABLED\",\n                \"targetCapacity\": 100,\n                \"minimumScalingStepSize\": 1,\n                \"maximumScalingStepSize\": 10000\n            },\n            \"managedTerminationProtection\": \"DISABLED\"\n        },\n        \"updateStatus\": \"DELETE_IN_PROGRESS\",\n        \"tags\": []\n    }\n}\n\n\nFor more information, see Cluster capacity providers in the Amazon ECS Developer Guide.\n\nExample 2: To delete a capacity provider using the name\n\nThe following delete-capacity-provider example deletes a capacity provider by specifying the short name of the capacity provider. The short name as well as the status of the capacity provider deletion can be retrieved using the describe-capacity-providers command.\n\naws ecs delete-capacity-provider \\\n    --capacity-provider ExampleCapacityProvider\n\n\nOutput:\n\n{\n    \"capacityProvider\": {\n        \"capacityProviderArn\": \"arn:aws:ecs:us-west-2:123456789012:capacity-provider/ExampleCapacityProvider\",\n        \"name\": \"ExampleCapacityProvider\",\n        \"status\": \"ACTIVE\",\n        \"autoScalingGroupProvider\": {\n            \"autoScalingGroupArn\": \"arn:aws:autoscaling:us-west-2:123456789012:autoScalingGroup:a1b2c3d4-5678-90ab-cdef-EXAMPLE11111:autoScalingGroupName/MyAutoScalingGroup\",\n            \"managedScaling\": {\n                \"status\": \"ENABLED\",\n                \"targetCapacity\": 100,\n                \"minimumScalingStepSize\": 1,\n                \"maximumScalingStepSize\": 10000\n            },\n            \"managedTerminationProtection\": \"DISABLED\"\n        },\n        \"updateStatus\": \"DELETE_IN_PROGRESS\",\n        \"tags\": []\n    }\n}\n\n\nFor more information, see Cluster capacity providers in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "delete-cluster",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/delete-cluster.html",
      "command_description": "Description\n\nDeletes the specified cluster. The cluster will transition to the INACTIVE state. Clusters with an INACTIVE status may remain discoverable in your account for a period of time. However, this behavior is subject to change in the future, so you should not rely on INACTIVE clusters persisting.\n\nYou must deregister all container instances from this cluster before you may delete it. You can list the container instances in a cluster with ListContainerInstances and deregister them with DeregisterContainerInstance .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-cluster\n--cluster <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--cluster <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster to delete.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncluster -> (structure)\n\nThe full description of the deleted cluster.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the cluster. The ARN contains the arn:aws:ecs namespace, followed by the Region of the cluster, the Amazon Web Services account ID of the cluster owner, the cluster namespace, and then the cluster name. For example, arn:aws:ecs:region:012345678910:cluster/test .\n\nclusterName -> (string)\n\nA user-generated string that you use to identify your cluster.\n\nconfiguration -> (structure)\n\nThe execute command configuration for the cluster.\n\nexecuteCommandConfiguration -> (structure)\n\nThe details of the execute command configuration.\n\nkmsKeyId -> (string)\n\nSpecify an Key Management Service key ID to encrypt the data between the local client and the container.\n\nlogging -> (string)\n\nThe log setting to use for redirecting logs for your execute command results. The following log settings are available.\n\nNONE : The execute command session is not logged.\n\nDEFAULT : The awslogs configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no awslogs log driver is configured in the task definition, the output won’t be logged.\n\nOVERRIDE : Specify the logging details as a part of logConfiguration . If the OVERRIDE logging option is specified, the logConfiguration is required.\n\nlogConfiguration -> (structure)\n\nThe log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When logging=OVERRIDE is specified, a logConfiguration must be provided.\n\ncloudWatchLogGroupName -> (string)\n\nThe name of the CloudWatch log group to send logs to.\n\nNote\n\nThe CloudWatch log group must already be created.\n\ncloudWatchEncryptionEnabled -> (boolean)\n\nWhether or not to enable encryption on the CloudWatch logs. If not specified, encryption will be disabled.\n\ns3BucketName -> (string)\n\nThe name of the S3 bucket to send logs to.\n\nNote\n\nThe S3 bucket must already be created.\n\ns3EncryptionEnabled -> (boolean)\n\nWhether or not to use encryption on the S3 logs. If not specified, encryption is not used.\n\ns3KeyPrefix -> (string)\n\nAn optional folder in the S3 bucket to place logs in.\n\nstatus -> (string)\n\nThe status of the cluster. The following are the possible states that will be returned.\n\nACTIVE\n\nThe cluster is ready to accept tasks and if applicable you can register container instances with the cluster.\n\nPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being created.\n\nDEPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being deleted.\n\nFAILED\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider have failed to create.\n\nINACTIVE\n\nThe cluster has been deleted. Clusters with an INACTIVE status may remain discoverable in your account for a period of time. However, this behavior is subject to change in the future, so you should not rely on INACTIVE clusters persisting.\n\nregisteredContainerInstancesCount -> (integer)\n\nThe number of container instances registered into the cluster. This includes container instances in both ACTIVE and DRAINING status.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the RUNNING state.\n\npendingTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the PENDING state.\n\nactiveServicesCount -> (integer)\n\nThe number of services that are running on the cluster in an ACTIVE state. You can view these services with ListServices .\n\nstatistics -> (list)\n\nAdditional information about your clusters that are separated by launch type, including:\n\nrunningEC2TasksCount\n\nRunningFargateTasksCount\n\npendingEC2TasksCount\n\npendingFargateTasksCount\n\nactiveEC2ServiceCount\n\nactiveFargateServiceCount\n\ndrainingEC2ServiceCount\n\ndrainingFargateServiceCount\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the cluster to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nsettings -> (list)\n\nThe settings for the cluster. This parameter indicates whether CloudWatch Container Insights is enabled or disabled for a cluster.\n\n(structure)\n\nThe settings to use when creating a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster.\n\nname -> (string)\n\nThe name of the cluster setting. The only supported value is containerInsights .\n\nvalue -> (string)\n\nThe value to set for the cluster setting. The supported values are enabled and disabled . If enabled is specified, CloudWatch Container Insights will be enabled for the cluster, otherwise it will be disabled unless the containerInsights account setting is enabled. If a cluster value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\ncapacityProviders -> (list)\n\nThe capacity providers associated with the cluster.\n\n(string)\n\ndefaultCapacityProviderStrategy -> (list)\n\nThe default capacity provider strategy for the cluster. When services or tasks are run in the cluster with no launch type or capacity provider strategy specified, the default capacity provider strategy is used.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nattachments -> (list)\n\nThe resources attached to a cluster. When using a capacity provider with a cluster, the Auto Scaling plan that is created will be returned as a cluster attachment.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nattachmentsStatus -> (string)\n\nThe status of the capacity providers associated with the cluster. The following are the states that will be returned:\n\nUPDATE_IN_PROGRESS\n\nThe available capacity providers for the cluster are updating. This occurs when the Auto Scaling plan is provisioning or deprovisioning.\n\nUPDATE_COMPLETE\n\nThe capacity providers have successfully updated.\n\nUPDATE_FAILED\n\nThe capacity provider updates failed.",
      "command_examples": "Examples\n\nTo delete an empty cluster\n\nThe following delete-cluster example deletes the specified empty cluster.\n\naws ecs delete-cluster --cluster MyCluster\n\n\nOutput:\n\n{\n    \"cluster\": {\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"status\": \"INACTIVE\",\n        \"clusterName\": \"MyCluster\",\n        \"registeredContainerInstancesCount\": 0,\n        \"pendingTasksCount\": 0,\n        \"runningTasksCount\": 0,\n        \"activeServicesCount\": 0\n        \"statistics\": [],\n        \"tags\": []\n    }\n}\n\n\nFor more information, see Deleting a Cluster in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "delete-service",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/delete-service.html",
      "command_description": "Description\n\nDeletes a specified service within a cluster. You can delete a service if you have no running tasks in it and the desired task count is zero. If the service is actively maintaining tasks, you cannot delete it, and you must update the service to a desired task count of zero. For more information, see UpdateService .\n\nNote\n\nWhen you delete a service, if there are still running tasks that require cleanup, the service status moves from ACTIVE to DRAINING , and the service is no longer visible in the console or in the ListServices API operation. After all tasks have transitioned to either STOPPING or STOPPED status, the service status moves from DRAINING to INACTIVE . Services in the DRAINING or INACTIVE status can still be viewed with the DescribeServices API operation. However, in the future, INACTIVE services may be cleaned up and purged from Amazon ECS record keeping, and DescribeServices calls on those services return a ServiceNotFoundException error.\n\nWarning\n\nIf you attempt to create a new service with the same name as an existing service in either ACTIVE or DRAINING status, you receive an error.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-service\n[--cluster <value>]\n--service <value>\n[--force | --no-force]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--service <value>",
        "[--force | --no-force]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the service to delete. If you do not specify a cluster, the default cluster is assumed.\n\n--service (string)\n\nThe name of the service to delete.\n\n--force | --no-force (boolean)\n\nIf true , allows you to delete a service even if it has not been scaled down to zero tasks. It is only necessary to use this if the service is using the REPLICA scheduling strategy.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nservice -> (structure)\n\nThe full description of the deleted service.\n\nserviceArn -> (string)\n\nThe ARN that identifies the service. The ARN contains the arn:aws:ecs namespace, followed by the Region of the service, the Amazon Web Services account ID of the service owner, the service namespace, and then the service name. For example, arn:aws:ecs:region:012345678910:service/my-service .\n\nserviceName -> (string)\n\nThe name of your service. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. Service names must be unique within a cluster, but you can have similarly named services in multiple clusters within a Region or across multiple Regions.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that hosts the service.\n\nloadBalancers -> (list)\n\nA list of Elastic Load Balancing load balancer objects, containing the load balancer name, the container name (as it appears in a container definition), and the container port to access from the load balancer.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this service. For more information, see Service Discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nstatus -> (string)\n\nThe status of the service. The valid values are ACTIVE , DRAINING , or INACTIVE .\n\ndesiredCount -> (integer)\n\nThe desired number of instantiations of the task definition to keep running on the service. This value is specified when the service is created with CreateService , and it can be modified with UpdateService .\n\nrunningCount -> (integer)\n\nThe number of tasks in the cluster that are in the RUNNING state.\n\npendingCount -> (integer)\n\nThe number of tasks in the cluster that are in the PENDING state.\n\nlaunchType -> (string)\n\nThe launch type the service is using. When using the DescribeServices API, this field is omitted if the service was created using a capacity provider strategy.\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy the service is using. When using the DescribeServices API, this field is omitted if the service was created using a launch type.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe platform version on which to run your service. A platform version is only specified for tasks hosted on Fargate. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the service are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX .\n\ntaskDefinition -> (string)\n\nThe task definition to use for tasks in the service. This value is specified when the service is created with CreateService , and it can be modified with UpdateService .\n\ndeploymentConfiguration -> (structure)\n\nOptional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.\n\ndeploymentCircuitBreaker -> (structure)\n\nNote\n\nThe deployment circuit breaker can only be used for services using the rolling update (ECS ) deployment type.\n\nThe deployment circuit breaker determines whether a service deployment will fail if the service can’t reach a steady state. If deployment circuit breaker is enabled, a service deployment will transition to a failed state and stop launching new tasks. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nenable -> (boolean)\n\nWhether to enable the deployment circuit breaker logic for the service.\n\nrollback -> (boolean)\n\nWhether to enable Amazon ECS to roll back the service if a service deployment fails. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nmaximumPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the maximum percent parameter represents an upper limit on the number of tasks in a service that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desired number of tasks (rounded down to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to define the deployment batch size. For example, if your service has a desired number of four tasks and a maximum percent value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default value for maximum percent is 200%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the maximum percent value is set to the default value and is used to define the upper limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the maximum percent value is not used, although it is returned when describing your service.\n\nminimumHealthyPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the minimum healthy percent represents a lower limit on the number of tasks in a service that must remain in the RUNNING state during a deployment, as a percentage of the desired number of tasks (rounded up to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a desired number of four tasks and a minimum healthy percent of 50%, the scheduler may stop two existing tasks to free up cluster capacity before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state; tasks for services that do use a load balancer are considered healthy if they are in the RUNNING state and they are reported as healthy by the load balancer. The default value for minimum healthy percent is 100%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the minimum healthy percent value is set to the default value and is used to define the lower limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the minimum healthy percent value is not used, although it is returned when describing your service.\n\ntaskSets -> (list)\n\nInformation about a set of Amazon ECS tasks in either an CodeDeploy or an EXTERNAL deployment. An Amazon ECS task set includes details such as the desired number of tasks, how many tasks are running, and whether the task set serves production traffic.\n\n(structure)\n\nInformation about a set of Amazon ECS tasks in either an CodeDeploy or an EXTERNAL deployment. An Amazon ECS task set includes details such as the desired number of tasks, how many tasks are running, and whether the task set serves production traffic.\n\nid -> (string)\n\nThe ID of the task set.\n\ntaskSetArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task set.\n\nserviceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service the task set exists in.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that the service that hosts the task set exists in.\n\nstartedBy -> (string)\n\nThe tag specified when a task set is started. If the task set is created by an CodeDeploy deployment, the startedBy parameter is CODE_DEPLOY . For a task set created for an external deployment, the startedBy field isn’t used.\n\nexternalId -> (string)\n\nThe external ID associated with the task set.\n\nIf a task set is created by an CodeDeploy deployment, the externalId parameter contains the CodeDeploy deployment ID.\n\nIf a task set is created for an external deployment and is associated with a service discovery registry, the externalId parameter contains the ECS_TASK_SET_EXTERNAL_ID Cloud Map attribute.\n\nstatus -> (string)\n\nThe status of the task set. The following describes each state:\n\nPRIMARY\n\nThe task set is serving production traffic.\n\nACTIVE\n\nThe task set is not serving production traffic.\n\nDRAINING\n\nThe tasks in the task set are being stopped and their corresponding targets are being deregistered from their target group.\n\ntaskDefinition -> (string)\n\nThe task definition the task set is using.\n\ncomputedDesiredCount -> (integer)\n\nThe computed desired count for the task set. This is calculated by multiplying the service’s desiredCount by the task set’s scale percentage. The result is always rounded up. For example, if the computed desired count is 1.2, it rounds up to 2 tasks.\n\npendingCount -> (integer)\n\nThe number of tasks in the task set that are in the PENDING status during a deployment. A task in the PENDING state is preparing to enter the RUNNING state. A task set enters the PENDING status when it launches for the first time or when it is restarted after being in the STOPPED state.\n\nrunningCount -> (integer)\n\nThe number of tasks in the task set that are in the RUNNING status during a deployment. A task in the RUNNING state is running and ready for use.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was last updated.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the task set are using. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy associated with the task set.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe Fargate platform version on which the tasks in the task set are running. A platform version is only specified for tasks run on Fargate. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the set are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks in the set must have the same value.\n\nnetworkConfiguration -> (structure)\n\nThe network configuration for the task set.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nloadBalancers -> (list)\n\nDetails on a load balancer that is used with a task set.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this task set. For more information, see Service discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nscale -> (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nstabilityStatus -> (string)\n\nThe stability status, which indicates whether the task set has reached a steady state. If the following conditions are met, the task set will be in STEADY_STATE :\n\nThe task runningCount is equal to the computedDesiredCount .\n\nThe pendingCount is 0 .\n\nThere are no tasks running on container instances in the DRAINING status.\n\nAll tasks are reporting a healthy status from the load balancers, service discovery, and container health checks.\n\nIf any of those conditions are not met, the stability status returns STABILIZING .\n\nstabilityStatusAt -> (timestamp)\n\nThe Unix timestamp for when the task set stability status was retrieved.\n\ntags -> (list)\n\nThe metadata that you apply to the task set to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ndeployments -> (list)\n\nThe current state of deployments for the service.\n\n(structure)\n\nThe details of an Amazon ECS service deployment. This is used only when a service uses the ECS deployment controller type.\n\nid -> (string)\n\nThe ID of the deployment.\n\nstatus -> (string)\n\nThe status of the deployment. The following describes each state:\n\nPRIMARY\n\nThe most recent deployment of a service.\n\nACTIVE\n\nA service deployment that still has running tasks, but are in the process of being replaced with a new PRIMARY deployment.\n\nINACTIVE\n\nA deployment that has been completely replaced.\n\ntaskDefinition -> (string)\n\nThe most recent task definition that was specified for the tasks in the service to use.\n\ndesiredCount -> (integer)\n\nThe most recent desired count of tasks that was specified for the service to deploy or maintain.\n\npendingCount -> (integer)\n\nThe number of tasks in the deployment that are in the PENDING status.\n\nrunningCount -> (integer)\n\nThe number of tasks in the deployment that are in the RUNNING status.\n\nfailedTasks -> (integer)\n\nThe number of consecutively failed tasks in the deployment. A task is considered a failure if the service scheduler can’t launch the task, the task doesn’t transition to a RUNNING state, or if it fails any of its defined health checks and is stopped.\n\nNote\n\nOnce a service deployment has one or more successfully running tasks, the failed task count resets to zero and stops being evaluated.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the service deployment was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the service deployment was last updated.\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy that the deployment is using.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the service are using. For more information, see Amazon ECS Launch Types in the Amazon Elastic Container Service Developer Guide .\n\nplatformVersion -> (string)\n\nThe platform version on which your tasks in the service are running. A platform version is only specified for tasks using the Fargate launch type. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the service, or tasks are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX. .\n\nnetworkConfiguration -> (structure)\n\nThe VPC subnet and security group configuration for tasks that receive their own elastic network interface by using the awsvpc networking mode.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nrolloutState -> (string)\n\nNote\n\nThe rolloutState of a service is only returned for services that use the rolling update (ECS ) deployment type that are not behind a Classic Load Balancer.\n\nThe rollout state of the deployment. When a service deployment is started, it begins in an IN_PROGRESS state. When the service reaches a steady state, the deployment will transition to a COMPLETED state. If the service fails to reach a steady state and circuit breaker is enabled, the deployment will transition to a FAILED state. A deployment in FAILED state will launch no new tasks. For more information, see DeploymentCircuitBreaker .\n\nrolloutStateReason -> (string)\n\nA description of the rollout state of a deployment.\n\nroleArn -> (string)\n\nThe ARN of the IAM role associated with the service that allows the Amazon ECS container agent to register container instances with an Elastic Load Balancing load balancer.\n\nevents -> (list)\n\nThe event stream for your service. A maximum of 100 of the latest events are displayed.\n\n(structure)\n\nDetails on an event associated with a service.\n\nid -> (string)\n\nThe ID string of the event.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the event was triggered.\n\nmessage -> (string)\n\nThe event message.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the service was created.\n\nplacementConstraints -> (list)\n\nThe placement constraints for the tasks in the service.\n\n(structure)\n\nAn object representing a constraint on task placement. For more information, see Task Placement Constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you are using the Fargate launch type, task placement constraints are not supported.\n\ntype -> (string)\n\nThe type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. The expression can have a maximum length of 2000 characters. You can’t specify an expression if the constraint type is distinctInstance . For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\nplacementStrategy -> (list)\n\nThe placement strategy that determines how tasks for the service are placed.\n\n(structure)\n\nThe task placement strategy for a task or service. For more information, see Task Placement Strategies in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).\n\nfield -> (string)\n\nThe field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host , which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone . For the binpack placement strategy, valid values are cpu and memory . For the random placement strategy, this field is not used.\n\nnetworkConfiguration -> (structure)\n\nThe VPC subnet and security group configuration for tasks that receive their own elastic network interface by using the awsvpc networking mode.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nhealthCheckGracePeriodSeconds -> (integer)\n\nThe period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started.\n\nschedulingStrategy -> (string)\n\nThe scheduling strategy to use for the service. For more information, see Services .\n\nThere are two service scheduler strategies available:\n\nREPLICA -The replica scheduling strategy places and maintains the desired number of tasks across your cluster. By default, the service scheduler spreads tasks across Availability Zones. You can use task placement strategies and constraints to customize task placement decisions.\n\nDAEMON -The daemon scheduling strategy deploys exactly one task on each active container instance that meets all of the task placement constraints that you specify in your cluster. The service scheduler also evaluates the task placement constraints for running tasks and will stop tasks that do not meet the placement constraints.\n\nNote\n\nFargate tasks do not support the DAEMON scheduling strategy.\n\ndeploymentController -> (structure)\n\nThe deployment controller type the service is using. When using the DescribeServices API, this field is omitted if the service is using the ECS deployment controller type.\n\ntype -> (string)\n\nThe deployment controller type to use.\n\nThere are three deployment controller types available:\n\nECS\n\nThe rolling update (ECS ) deployment type involves replacing the current running version of the container with the latest version. The number of containers Amazon ECS adds or removes from the service during a rolling update is controlled by adjusting the minimum and maximum number of healthy tasks allowed during a service deployment, as specified in the DeploymentConfiguration .\n\nCODE_DEPLOY\n\nThe blue/green (CODE_DEPLOY ) deployment type uses the blue/green deployment model powered by CodeDeploy, which allows you to verify a new deployment of a service before sending production traffic to it.\n\nEXTERNAL\n\nThe external (EXTERNAL ) deployment type enables you to use any third-party deployment controller for full control over the deployment process for an Amazon ECS service.\n\ntags -> (list)\n\nThe metadata that you apply to the service to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ncreatedBy -> (string)\n\nThe principal that created the service.\n\nenableECSManagedTags -> (boolean)\n\nSpecifies whether to enable Amazon ECS managed tags for the tasks in the service. For more information, see Tagging Your Amazon ECS Resources in the Amazon Elastic Container Service Developer Guide .\n\npropagateTags -> (string)\n\nSpecifies whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags are not propagated.\n\nenableExecuteCommand -> (boolean)\n\nWhether or not the execute command functionality is enabled for the service. If true , the execute command functionality is enabled for all containers in tasks as part of the service.",
      "command_examples": "Examples\n\nTo delete a service\n\nThe following ecs delete-service example deletes the specified service from a cluster. You can include the --force parameter to delete a service even if it has not been scaled to zero tasks.\n\naws ecs delete-service --cluster MyCluster --service MyService1 --force\n\n\nFor more information, see Deleting a Service in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "delete-task-set",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/delete-task-set.html",
      "command_description": "Description\n\nDeletes a specified task set within a service. This is used when a service uses the EXTERNAL deployment controller type. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-task-set\n--cluster <value>\n--service <value>\n--task-set <value>\n[--force | --no-force]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--cluster <value>",
        "--service <value>",
        "--task-set <value>",
        "[--force | --no-force]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the service that the task set exists in to delete.\n\n--service (string)\n\nThe short name or full Amazon Resource Name (ARN) of the service that hosts the task set to delete.\n\n--task-set (string)\n\nThe task set ID or full Amazon Resource Name (ARN) of the task set to delete.\n\n--force | --no-force (boolean)\n\nIf true , this allows you to delete a task set even if it hasn’t been scaled down to zero.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntaskSet -> (structure)\n\nDetails about the task set.\n\nid -> (string)\n\nThe ID of the task set.\n\ntaskSetArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task set.\n\nserviceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service the task set exists in.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that the service that hosts the task set exists in.\n\nstartedBy -> (string)\n\nThe tag specified when a task set is started. If the task set is created by an CodeDeploy deployment, the startedBy parameter is CODE_DEPLOY . For a task set created for an external deployment, the startedBy field isn’t used.\n\nexternalId -> (string)\n\nThe external ID associated with the task set.\n\nIf a task set is created by an CodeDeploy deployment, the externalId parameter contains the CodeDeploy deployment ID.\n\nIf a task set is created for an external deployment and is associated with a service discovery registry, the externalId parameter contains the ECS_TASK_SET_EXTERNAL_ID Cloud Map attribute.\n\nstatus -> (string)\n\nThe status of the task set. The following describes each state:\n\nPRIMARY\n\nThe task set is serving production traffic.\n\nACTIVE\n\nThe task set is not serving production traffic.\n\nDRAINING\n\nThe tasks in the task set are being stopped and their corresponding targets are being deregistered from their target group.\n\ntaskDefinition -> (string)\n\nThe task definition the task set is using.\n\ncomputedDesiredCount -> (integer)\n\nThe computed desired count for the task set. This is calculated by multiplying the service’s desiredCount by the task set’s scale percentage. The result is always rounded up. For example, if the computed desired count is 1.2, it rounds up to 2 tasks.\n\npendingCount -> (integer)\n\nThe number of tasks in the task set that are in the PENDING status during a deployment. A task in the PENDING state is preparing to enter the RUNNING state. A task set enters the PENDING status when it launches for the first time or when it is restarted after being in the STOPPED state.\n\nrunningCount -> (integer)\n\nThe number of tasks in the task set that are in the RUNNING status during a deployment. A task in the RUNNING state is running and ready for use.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was last updated.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the task set are using. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy associated with the task set.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe Fargate platform version on which the tasks in the task set are running. A platform version is only specified for tasks run on Fargate. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the set are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks in the set must have the same value.\n\nnetworkConfiguration -> (structure)\n\nThe network configuration for the task set.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nloadBalancers -> (list)\n\nDetails on a load balancer that is used with a task set.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this task set. For more information, see Service discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nscale -> (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nstabilityStatus -> (string)\n\nThe stability status, which indicates whether the task set has reached a steady state. If the following conditions are met, the task set will be in STEADY_STATE :\n\nThe task runningCount is equal to the computedDesiredCount .\n\nThe pendingCount is 0 .\n\nThere are no tasks running on container instances in the DRAINING status.\n\nAll tasks are reporting a healthy status from the load balancers, service discovery, and container health checks.\n\nIf any of those conditions are not met, the stability status returns STABILIZING .\n\nstabilityStatusAt -> (timestamp)\n\nThe Unix timestamp for when the task set stability status was retrieved.\n\ntags -> (list)\n\nThe metadata that you apply to the task set to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nTo delete a task set\n\nThe following delete-task-set example shows how to delete a task set. You can include the --force parameter to delete a task set even if it has not been scaled to zero.\n\naws ecs delete-task-set \\\n    --cluster MyCluster \\\n    --service MyService \\\n    --task-set arn:aws:ecs:us-west-2:123456789012:task-set/MyCluster/MyService/ecs-svc/1234567890123456789 \\\n    --force\n\n\nOutput:\n\n{\n    \"taskSet\": {\n        \"id\": \"ecs-svc/1234567890123456789\",\n        \"taskSetArn\": \"arn:aws:ecs:us-west-2:123456789012:task-set/MyCluster/MyService/ecs-svc/1234567890123456789\",\n        \"status\": \"DRAINING\",\n        \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sample-fargate:2\",\n        \"computedDesiredCount\": 0,\n        \"pendingCount\": 0,\n        \"runningCount\": 0,\n        \"createdAt\": 1557130260.276,\n        \"updatedAt\": 1557130290.707,\n        \"launchType\": \"EC2\",\n        \"networkConfiguration\": {\n            \"awsvpcConfiguration\": {\n                \"subnets\": [\n                    \"subnet-12345678\"\n                ],\n                \"securityGroups\": [\n                    \"sg-12345678\"\n                ],\n                \"assignPublicIp\": \"DISABLED\"\n            }\n        },\n        \"loadBalancers\": [],\n        \"serviceRegistries\": [],\n        \"scale\": {\n            \"value\": 0.0,\n            \"unit\": \"PERCENT\"\n        },\n        \"stabilityStatus\": \"STABILIZING\",\n        \"stabilityStatusAt\": 1557130290.707\n    }\n}\n"
    },
    {
      "command_name": "deploy",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/deploy.html",
      "command_description": "Description\n\nDeploys a new task definition to the specified ECS service. Only services that use CodeDeploy for deployments are supported. This command will register a new task definition, update the CodeDeploy appspec with the new task definition revision, create a CodeDeploy deployment, and wait for the deployment to successfully complete. This command will exit with a return code of 255 if the deployment does not succeed within 30 minutes by default or up to 10 minutes more than your deployment group’s configured wait time (max of 6 hours).\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  deploy\n--service <value>\n--task-definition <value>\n--codedeploy-appspec <value>\n[--cluster <value>]\n[--codedeploy-application <value>]\n[--codedeploy-deployment-group <value>]\n",
      "command_options": [
        "--service <value>",
        "--task-definition <value>",
        "--codedeploy-appspec <value>",
        "[--cluster <value>]",
        "[--codedeploy-application <value>]",
        "[--codedeploy-deployment-group <value>]"
      ],
      "command_options_description": "Options\n\n--service (string) The short name or full Amazon Resource Name (ARN) of the service to update\n\n--task-definition (string) The file path where your task definition file is located. The format of the file must be the same as the JSON output of:\n\naws ecs register-task-definition --generate-cli-skeleton\n\n\n--codedeploy-appspec (string) The file path where your AWS CodeDeploy appspec file is located. The appspec file may be in JSON or YAML format. The TaskDefinition property will be updated within the appspec with the newly registered task definition ARN, overwriting any placeholder values in the file.\n\n--cluster (string) The short name or full Amazon Resource Name (ARN) of the cluster that your service is running within. If you do not specify a cluster, the “default” cluster is assumed.\n\n--codedeploy-application (string) The name of the AWS CodeDeploy application to use for the deployment. The specified application must use the ‘ECS’ compute platform. If you do not specify an application, the application name AppECS-[CLUSTER_NAME]-[SERVICE_NAME] is assumed.\n\n--codedeploy-deployment-group (string) The name of the AWS CodeDeploy deployment group to use for the deployment. The specified deployment group must be associated with the specified ECS service and cluster. If you do not specify a deployment group, the deployment group name DgpECS-[CLUSTER_NAME]-[SERVICE_NAME] is assumed.\n\nSee ‘aws help’ for descriptions of global parameters."
    },
    {
      "command_name": "deregister-container-instance",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/deregister-container-instance.html",
      "command_description": "Description\n\nDeregisters an Amazon ECS container instance from the specified cluster. This instance is no longer available to run tasks.\n\nIf you intend to use the container instance for some other purpose after deregistration, you should stop all of the tasks running on the container instance before deregistration. That prevents any orphaned tasks from consuming resources.\n\nDeregistering a container instance removes the instance from a cluster, but it does not terminate the EC2 instance. If you are finished using the instance, be sure to terminate it in the Amazon EC2 console to stop billing.\n\nNote\n\nIf you terminate a running container instance, Amazon ECS automatically deregisters the instance from your cluster (stopped container instances or instances with disconnected agents are not automatically deregistered when terminated).\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  deregister-container-instance\n[--cluster <value>]\n--container-instance <value>\n[--force | --no-force]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--container-instance <value>",
        "[--force | --no-force]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the container instance to deregister. If you do not specify a cluster, the default cluster is assumed.\n\n--container-instance (string)\n\nThe container instance ID or full ARN of the container instance to deregister. The ARN contains the arn:aws:ecs namespace, followed by the Region of the container instance, the Amazon Web Services account ID of the container instance owner, the container-instance namespace, and then the container instance ID. For example, arn:aws:ecs:region:aws_account_id:container-instance/container_instance_ID .\n\n--force | --no-force (boolean)\n\nForces the deregistration of the container instance. If you have tasks running on the container instance when you deregister it with the force option, these tasks remain running until you terminate the instance or the tasks stop through some other means, but they are orphaned (no longer monitored or accounted for by Amazon ECS). If an orphaned task on your container instance is part of an Amazon ECS service, then the service scheduler starts another copy of that task, on a different container instance if possible.\n\nAny containers in orphaned service tasks that are registered with a Classic Load Balancer or an Application Load Balancer target group are deregistered. They begin connection draining according to the settings on the load balancer or target group.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncontainerInstance -> (structure)\n\nThe container instance that was deregistered.\n\ncontainerInstanceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the container instance. The ARN contains the arn:aws:ecs namespace, followed by the Region of the container instance, the Amazon Web Services account ID of the container instance owner, the container-instance namespace, and then the container instance ID. For example, arn:aws:ecs:region:aws_account_id:container-instance/container_instance_ID .\n\nec2InstanceId -> (string)\n\nThe ID of the container instance. For Amazon EC2 instances, this value is the Amazon EC2 instance ID. For external instances, this value is the Amazon Web Services Systems Manager managed instance ID.\n\ncapacityProviderName -> (string)\n\nThe capacity provider associated with the container instance.\n\nversion -> (long)\n\nThe version counter for the container instance. Every time a container instance experiences a change that triggers a CloudWatch event, the version counter is incremented. If you are replicating your Amazon ECS container instance state with CloudWatch Events, you can compare the version of a container instance reported by the Amazon ECS APIs with the version reported in CloudWatch Events for the container instance (inside the detail object) to verify that the version in your event stream is current.\n\nversionInfo -> (structure)\n\nThe version information for the Amazon ECS container agent and Docker daemon running on the container instance.\n\nagentVersion -> (string)\n\nThe version number of the Amazon ECS container agent.\n\nagentHash -> (string)\n\nThe Git commit hash for the Amazon ECS container agent build on the amazon-ecs-agent GitHub repository.\n\ndockerVersion -> (string)\n\nThe Docker version running on the container instance.\n\nremainingResources -> (list)\n\nFor CPU and memory resource types, this parameter describes the remaining CPU and memory that has not already been allocated to tasks and is therefore available for new tasks. For port resource types, this parameter describes the ports that were reserved by the Amazon ECS container agent (at instance registration time) and any task containers that have reserved port mappings on the host (with the host or bridge network mode). Any port that is not specified here is available for new tasks.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nregisteredResources -> (list)\n\nFor CPU and memory resource types, this parameter describes the amount of each resource that was available on the container instance when the container agent registered it with Amazon ECS. This value represents the total amount of CPU and memory that can be allocated on this container instance to tasks. For port resource types, this parameter describes the ports that were reserved by the Amazon ECS container agent when it registered the container instance with Amazon ECS.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nstatus -> (string)\n\nThe status of the container instance. The valid values are REGISTERING , REGISTRATION_FAILED , ACTIVE , INACTIVE , DEREGISTERING , or DRAINING .\n\nIf your account has opted in to the awsvpcTrunking account setting, then any newly registered container instance will transition to a REGISTERING status while the trunk elastic network interface is provisioned for the instance. If the registration fails, the instance will transition to a REGISTRATION_FAILED status. You can describe the container instance and see the reason for failure in the statusReason parameter. Once the container instance is terminated, the instance transitions to a DEREGISTERING status while the trunk elastic network interface is deprovisioned. The instance then transitions to an INACTIVE status.\n\nThe ACTIVE status indicates that the container instance can accept tasks. The DRAINING indicates that new tasks are not placed on the container instance and any service tasks running on the container instance are removed if possible. For more information, see Container Instance Draining in the Amazon Elastic Container Service Developer Guide .\n\nstatusReason -> (string)\n\nThe reason that the container instance reached its current status.\n\nagentConnected -> (boolean)\n\nThis parameter returns true if the agent is connected to Amazon ECS. Registered instances with an agent that may be unhealthy or stopped return false . Only instances connected to an agent can accept placement requests.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks on the container instance that are in the RUNNING status.\n\npendingTasksCount -> (integer)\n\nThe number of tasks on the container instance that are in the PENDING status.\n\nagentUpdateStatus -> (string)\n\nThe status of the most recent agent update. If an update has never been requested, this value is NULL .\n\nattributes -> (list)\n\nThe attributes set for the container instance, either by the Amazon ECS container agent at instance registration or manually with the PutAttributes operation.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nregisteredAt -> (timestamp)\n\nThe Unix timestamp for when the container instance was registered.\n\nattachments -> (list)\n\nThe resources attached to a container instance, such as elastic network interfaces.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the container instance to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nTo deregister a container instance from a cluster\n\nThe following deregister-container-instance example deregisters a container instance from the specified cluster. If there are still tasks running in the container instance, you must either stop those tasks before deregistering, or use the --force option.\n\naws ecs deregister-container-instance \\\n    --cluster arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster \\\n    --container-instance arn:aws:ecs:us-west-2:123456789012:container-instance/a1b2c3d4-5678-90ab-cdef-11111EXAMPLE \\\n    --force\n\n\nOutput:\n\n{\n    \"containerInstance\": {\n        \"remainingResources\": [\n            {\n                \"integerValue\": 1024,\n                \"doubleValue\": 0.0,\n                \"type\": \"INTEGER\",\n                \"longValue\": 0,\n                \"name\": \"CPU\"\n            },\n            {\n                \"integerValue\": 985,\n                \"doubleValue\": 0.0,\n                \"type\": \"INTEGER\",\n                \"longValue\": 0,\n                \"name\": \"MEMORY\"\n            },\n            {\n                \"type\": \"STRINGSET\",\n                \"integerValue\": 0,\n                \"name\": \"PORTS\",\n                \"stringSetValue\": [\n                    \"22\",\n                    \"2376\",\n                    \"2375\",\n                    \"51678\",\n                    \"51679\"\n                ],\n                \"longValue\": 0,\n                \"doubleValue\": 0.0\n            },\n            {\n                \"type\": \"STRINGSET\",\n                \"integerValue\": 0,\n                \"name\": \"PORTS_UDP\",\n                \"stringSetValue\": [],\n                \"longValue\": 0,\n                \"doubleValue\": 0.0\n            }\n        ],\n        \"agentConnected\": true,\n        \"attributes\": [\n            {\n                \"name\": \"ecs.capability.secrets.asm.environment-variables\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.logging-driver.syslog\"\n            },\n            {\n                \"value\": \"ami-01a82c3fce2c3ba58\",\n                \"name\": \"ecs.ami-id\"\n            },\n            {\n                \"name\": \"ecs.capability.secrets.asm.bootstrap.log-driver\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.logging-driver.none\"\n            },\n            {\n                \"name\": \"ecs.capability.ecr-endpoint\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.logging-driver.json-file\"\n            },\n            {\n                \"value\": \"vpc-1234567890123467\",\n                \"name\": \"ecs.vpc-id\"\n            },\n            {\n                \"name\": \"ecs.capability.execution-role-awslogs\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.17\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.18\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.19\"\n            },\n            {\n                \"name\": \"ecs.capability.docker-plugin.local\"\n            },\n            {\n                \"name\": \"ecs.capability.task-eni\"\n            },\n            {\n                \"name\": \"ecs.capability.task-cpu-mem-limit\"\n            },\n            {\n                \"name\": \"ecs.capability.secrets.ssm.bootstrap.log-driver\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.30\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.31\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.32\"\n            },\n            {\n                \"name\": \"ecs.capability.execution-role-ecr-pull\"\n            },\n            {\n                \"name\": \"ecs.capability.container-health-check\"\n            },\n            {\n                \"value\": \"subnet-1234567890123467\",\n                \"name\": \"ecs.subnet-id\"\n            },\n            {\n                \"value\": \"us-west-2a\",\n                \"name\": \"ecs.availability-zone\"\n            },\n            {\n                \"value\": \"t2.micro\",\n                \"name\": \"ecs.instance-type\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.task-iam-role-network-host\"\n            },\n            {\n                \"name\": \"ecs.capability.aws-appmesh\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.logging-driver.awslogs\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.24\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.25\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.26\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.27\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.privileged-container\"\n            },\n            {\n                \"name\": \"ecs.capability.container-ordering\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.28\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.29\"\n            },\n            {\n                \"value\": \"x86_64\",\n                \"name\": \"ecs.cpu-architecture\"\n            },\n            {\n                \"value\": \"93f43776-2018.10.0\",\n                \"name\": \"ecs.capability.cni-plugin-version\"\n            },\n            {\n                \"name\": \"ecs.capability.secrets.ssm.environment-variables\"\n            },\n            {\n                \"name\": \"ecs.capability.pid-ipc-namespace-sharing\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.ecr-auth\"\n            },\n            {\n                \"value\": \"linux\",\n                \"name\": \"ecs.os-type\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.20\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.21\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.22\"\n            },\n            {\n                \"name\": \"ecs.capability.task-eia\"\n            },\n            {\n                \"name\": \"ecs.capability.private-registry-authentication.secretsmanager\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.task-iam-role\"\n            },\n            {\n                \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.23\"\n            }\n        ],\n        \"pendingTasksCount\": 0,\n        \"tags\": [],\n        \"containerInstanceArn\": \"arn:aws:ecs:us-west-2:123456789012:container-instance/a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\",\n        \"registeredResources\": [\n            {\n                \"integerValue\": 1024,\n                \"doubleValue\": 0.0,\n                \"type\": \"INTEGER\",\n                \"longValue\": 0,\n                \"name\": \"CPU\"\n            },\n            {\n                \"integerValue\": 985,\n                \"doubleValue\": 0.0,\n                \"type\": \"INTEGER\",\n                \"longValue\": 0,\n                \"name\": \"MEMORY\"\n            },\n            {\n                \"type\": \"STRINGSET\",\n                \"integerValue\": 0,\n                \"name\": \"PORTS\",\n                \"stringSetValue\": [\n                    \"22\",\n                    \"2376\",\n                    \"2375\",\n                    \"51678\",\n                    \"51679\"\n                ],\n                \"longValue\": 0,\n                \"doubleValue\": 0.0\n            },\n            {\n                \"type\": \"STRINGSET\",\n                \"integerValue\": 0,\n                \"name\": \"PORTS_UDP\",\n                \"stringSetValue\": [],\n                \"longValue\": 0,\n                \"doubleValue\": 0.0\n            }\n        ],\n        \"status\": \"INACTIVE\",\n        \"registeredAt\": 1557768075.681,\n        \"version\": 4,\n        \"versionInfo\": {\n            \"agentVersion\": \"1.27.0\",\n            \"agentHash\": \"aabe65ee\",\n            \"dockerVersion\": \"DockerVersion: 18.06.1-ce\"\n        },\n        \"attachments\": [],\n        \"runningTasksCount\": 0,\n        \"ec2InstanceId\": \"i-12345678901234678\"\n    }\n}\n\n\nFor more information, see Deregister a Container Instance in the ECS Developer Guide."
    },
    {
      "command_name": "deregister-task-definition",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/deregister-task-definition.html",
      "command_description": "Description\n\nDeregisters the specified task definition by family and revision. Upon deregistration, the task definition is marked as INACTIVE . Existing tasks and services that reference an INACTIVE task definition continue to run without disruption. Existing services that reference an INACTIVE task definition can still scale up or down by modifying the service’s desired count.\n\nYou cannot use an INACTIVE task definition to run new tasks or create new services, and you cannot update an existing service to reference an INACTIVE task definition. However, there may be up to a 10-minute window following deregistration where these restrictions have not yet taken effect.\n\nNote\n\nAt this time, INACTIVE task definitions remain discoverable in your account indefinitely. However, this behavior is subject to change in the future, so you should not rely on INACTIVE task definitions persisting beyond the lifecycle of any associated tasks and services.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  deregister-task-definition\n--task-definition <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--task-definition <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--task-definition (string)\n\nThe family and revision (family:revision ) or full Amazon Resource Name (ARN) of the task definition to deregister. You must specify a revision .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntaskDefinition -> (structure)\n\nThe full description of the deregistered task.\n\ntaskDefinitionArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the task definition.\n\ncontainerDefinitions -> (list)\n\nA list of container definitions in JSON format that describe the different containers that make up your task. For more information about container definition parameters and defaults, see Amazon ECS Task Definitions in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nContainer definitions are used in task definitions to describe the different containers that are launched as part of a task.\n\nname -> (string)\n\nThe name of a container. If you are linking multiple containers together in a task definition, the name of one container can be entered in the links of another container to connect the containers. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This parameter maps to name in the Create a container section of the Docker Remote API and the --name option to docker run .\n\nimage -> (string)\n\nThe image used to start a container. This string is passed directly to the Docker daemon. Images in the Docker Hub registry are available by default. Other repositories are specified with either `` repository-url /image :tag `` or `` repository-url /image @*digest* `` . Up to 255 letters (uppercase and lowercase), numbers, hyphens, underscores, colons, periods, forward slashes, and number signs are allowed. This parameter maps to Image in the Create a container section of the Docker Remote API and the IMAGE parameter of docker run .\n\nWhen a new task starts, the Amazon ECS container agent pulls the latest version of the specified image and tag for the container to use. However, subsequent updates to a repository image are not propagated to already running tasks.\n\nImages in Amazon ECR repositories can be specified by either using the full registry/repository:tag or registry/repository@digest . For example, 012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>:latest or 012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>@sha256:94afd1f2e64d908bc90dbca0035a5b567EXAMPLE .\n\nImages in official repositories on Docker Hub use a single name (for example, ubuntu or mongo ).\n\nImages in other repositories on Docker Hub are qualified with an organization name (for example, amazon/amazon-ecs-agent ).\n\nImages in other online repositories are qualified further by a domain name (for example, quay.io/assemblyline/ubuntu ).\n\nrepositoryCredentials -> (structure)\n\nThe private repository authentication credentials to use.\n\ncredentialsParameter -> (string)\n\nThe Amazon Resource Name (ARN) of the secret containing the private repository credentials.\n\nNote\n\nWhen you are using the Amazon ECS API, CLI, or Amazon Web Services SDK, if the secret exists in the same Region as the task that you are launching then you can use either the full ARN or the name of the secret. When you are using the Amazon Web Services Management Console, you must specify the full ARN of the secret.\n\ncpu -> (integer)\n\nThe number of cpu units reserved for the container. This parameter maps to CpuShares in the Create a container section of the Docker Remote API and the --cpu-shares option to docker run .\n\nThis field is optional for tasks using the Fargate launch type, and the only requirement is that the total amount of CPU reserved for all containers within a task be lower than the task-level cpu value.\n\nNote\n\nYou can determine the number of CPU units that are available per EC2 instance type by multiplying the vCPUs listed for that instance type on the Amazon EC2 Instances detail page by 1,024.\n\nLinux containers share unallocated CPU units with other containers on the container instance with the same ratio as their allocated amount. For example, if you run a single-container task on a single-core instance type with 512 CPU units specified for that container, and that is the only task running on the container instance, that container could use the full 1,024 CPU unit share at any given time. However, if you launched another copy of the same task on that container instance, each task would be guaranteed a minimum of 512 CPU units when needed, and each container could float to higher CPU usage if the other container was not using it, but if both tasks were 100% active all of the time, they would be limited to 512 CPU units.\n\nOn Linux container instances, the Docker daemon on the container instance uses the CPU value to calculate the relative CPU share ratios for running containers. For more information, see CPU share constraint in the Docker documentation. The minimum valid CPU share value that the Linux kernel allows is 2. However, the CPU parameter is not required, and you can use CPU values below 2 in your container definitions. For CPU values below 2 (including null), the behavior varies based on your Amazon ECS container agent version:\n\nAgent versions less than or equal to 1.1.0: Null and zero CPU values are passed to Docker as 0, which Docker then converts to 1,024 CPU shares. CPU values of 1 are passed to Docker as 1, which the Linux kernel converts to two CPU shares.\n\nAgent versions greater than or equal to 1.2.0: Null, zero, and CPU values of 1 are passed to Docker as 2.\n\nOn Windows container instances, the CPU limit is enforced as an absolute limit, or a quota. Windows containers only have access to the specified amount of CPU that is described in the task definition. A null or zero CPU value is passed to Docker as 0 , which Windows interprets as 1% of one CPU.\n\nmemory -> (integer)\n\nThe amount (in MiB) of memory to present to the container. If your container attempts to exceed the memory specified here, the container is killed. The total amount of memory reserved for all containers within a task must be lower than the task memory value, if one is specified. This parameter maps to Memory in the Create a container section of the Docker Remote API and the --memory option to docker run .\n\nIf using the Fargate launch type, this parameter is optional.\n\nIf using the EC2 launch type, you must specify either a task-level memory value or a container-level memory value. If you specify both a container-level memory and memoryReservation value, memory must be greater than memoryReservation . If you specify memoryReservation , then that value is subtracted from the available memory resources for the container instance on which the container is placed. Otherwise, the value of memory is used.\n\nThe Docker daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.\n\nmemoryReservation -> (integer)\n\nThe soft limit (in MiB) of memory to reserve for the container. When system memory is under heavy contention, Docker attempts to keep the container memory to this soft limit. However, your container can consume more memory when it needs to, up to either the hard limit specified with the memory parameter (if applicable), or all of the available memory on the container instance, whichever comes first. This parameter maps to MemoryReservation in the Create a container section of the Docker Remote API and the --memory-reservation option to docker run .\n\nIf a task-level memory value is not specified, you must specify a non-zero integer for one or both of memory or memoryReservation in a container definition. If you specify both, memory must be greater than memoryReservation . If you specify memoryReservation , then that value is subtracted from the available memory resources for the container instance on which the container is placed. Otherwise, the value of memory is used.\n\nFor example, if your container normally uses 128 MiB of memory, but occasionally bursts to 256 MiB of memory for short periods of time, you can set a memoryReservation of 128 MiB, and a memory hard limit of 300 MiB. This configuration would allow the container to only reserve 128 MiB of memory from the remaining resources on the container instance, but also allow the container to consume more memory resources when needed.\n\nThe Docker daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.\n\nlinks -> (list)\n\nThe links parameter allows containers to communicate with each other without the need for port mappings. This parameter is only supported if the network mode of a task definition is bridge . The name:internalName construct is analogous to name:alias in Docker links. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. For more information about linking Docker containers, go to Legacy container links in the Docker documentation. This parameter maps to Links in the Create a container section of the Docker Remote API and the --link option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nWarning\n\nContainers that are collocated on a single container instance may be able to communicate with each other without requiring links or host port mappings. Network isolation is achieved on the container instance using security groups and VPC settings.\n\n(string)\n\nportMappings -> (list)\n\nThe list of port mappings for the container. Port mappings allow containers to access ports on the host container instance to send or receive traffic.\n\nFor task definitions that use the awsvpc network mode, you should only specify the containerPort . The hostPort can be left blank or it must be the same value as the containerPort .\n\nPort mappings on Windows use the NetNAT gateway address rather than localhost . There is no loopback for port mappings on Windows, so you cannot access a container’s mapped port from the host itself.\n\nThis parameter maps to PortBindings in the Create a container section of the Docker Remote API and the --publish option to docker run . If the network mode of a task definition is set to none , then you can’t specify port mappings. If the network mode of a task definition is set to host , then host ports must either be undefined or they must match the container port in the port mapping.\n\nNote\n\nAfter a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the Network Bindings section of a container description for a selected task in the Amazon ECS console. The assignments are also visible in the networkBindings section DescribeTasks responses.\n\n(structure)\n\nPort mappings allow containers to access ports on the host container instance to send or receive traffic. Port mappings are specified as part of the container definition.\n\nIf you are using containers in a task with the awsvpc or host network mode, exposed ports should be specified using containerPort . The hostPort can be left blank or it must be the same value as the containerPort .\n\nNote\n\nYou cannot expose the same container port for multiple protocols. An error will be returned if this is attempted\n\nAfter a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the networkBindings section of DescribeTasks API responses.\n\ncontainerPort -> (integer)\n\nThe port number on the container that is bound to the user-specified or automatically assigned host port.\n\nIf you are using containers in a task with the awsvpc or host network mode, exposed ports should be specified using containerPort .\n\nIf you are using containers in a task with the bridge network mode and you specify a container port and not a host port, your container automatically receives a host port in the ephemeral port range. For more information, see hostPort . Port mappings that are automatically assigned in this way do not count toward the 100 reserved ports limit of a container instance.\n\nhostPort -> (integer)\n\nThe port number on the container instance to reserve for your container.\n\nIf you are using containers in a task with the awsvpc or host network mode, the hostPort can either be left blank or set to the same value as the containerPort .\n\nIf you are using containers in a task with the bridge network mode, you can specify a non-reserved host port for your container port mapping, or you can omit the hostPort (or set it to 0 ) while specifying a containerPort and your container automatically receives a port in the ephemeral port range for your container instance operating system and Docker version.\n\nThe default ephemeral port range for Docker version 1.6.0 and later is listed on the instance under /proc/sys/net/ipv4/ip_local_port_range . If this kernel parameter is unavailable, the default ephemeral port range from 49153 through 65535 is used. Do not attempt to specify a host port in the ephemeral port range as these are reserved for automatic assignment. In general, ports below 32768 are outside of the ephemeral port range.\n\nNote\n\nThe default ephemeral port range from 49153 through 65535 is always used for Docker versions before 1.6.0.\n\nThe default reserved ports are 22 for SSH, the Docker ports 2375 and 2376, and the Amazon ECS container agent ports 51678-51680. Any host port that was previously specified in a running task is also reserved while the task is running (after a task stops, the host port is released). The current reserved ports are displayed in the remainingResources of DescribeContainerInstances output. A container instance can have up to 100 reserved ports at a time, including the default reserved ports. Automatically assigned ports don’t count toward the 100 reserved ports limit.\n\nprotocol -> (string)\n\nThe protocol used for the port mapping. Valid values are tcp and udp . The default is tcp .\n\nessential -> (boolean)\n\nIf the essential parameter of a container is marked as true , and that container fails or stops for any reason, all other containers that are part of the task are stopped. If the essential parameter of a container is marked as false , then its failure does not affect the rest of the containers in a task. If this parameter is omitted, a container is assumed to be essential.\n\nAll tasks must have at least one essential container. If you have an application that is composed of multiple containers, you should group containers that are used for a common purpose into components, and separate the different components into multiple task definitions. For more information, see Application Architecture in the Amazon Elastic Container Service Developer Guide .\n\nentryPoint -> (list)\n\nWarning\n\nEarly versions of the Amazon ECS container agent do not properly handle entryPoint parameters. If you have problems using entryPoint , update your container agent or enter your commands and arguments as command array items instead.\n\nThe entry point that is passed to the container. This parameter maps to Entrypoint in the Create a container section of the Docker Remote API and the --entrypoint option to docker run . For more information, see https://docs.docker.com/engine/reference/builder/#entrypoint .\n\n(string)\n\ncommand -> (list)\n\nThe command that is passed to the container. This parameter maps to Cmd in the Create a container section of the Docker Remote API and the COMMAND parameter to docker run . For more information, see https://docs.docker.com/engine/reference/builder/#cmd . If there are multiple arguments, each argument should be a separated string in the array.\n\n(string)\n\nenvironment -> (list)\n\nThe environment variables to pass to a container. This parameter maps to Env in the Create a container section of the Docker Remote API and the --env option to docker run .\n\nWarning\n\nWe do not recommend using plaintext environment variables for sensitive information, such as credential data.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nenvironmentFiles -> (list)\n\nA list of files containing the environment variables to pass to a container. This parameter maps to the --env-file option to docker run .\n\nYou can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying Environment Variables in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nA list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying environment variables in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nvalue -> (string)\n\nThe Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\ntype -> (string)\n\nThe file type to use. The only supported value is s3 .\n\nmountPoints -> (list)\n\nThe mount points for data volumes in your container.\n\nThis parameter maps to Volumes in the Create a container section of the Docker Remote API and the --volume option to docker run .\n\nWindows containers can mount whole directories on the same drive as $env:ProgramData . Windows containers cannot mount directories on a different drive, and mount point cannot be across drives.\n\n(structure)\n\nDetails on a volume mount point that is used in a container definition.\n\nsourceVolume -> (string)\n\nThe name of the volume to mount. Must be a volume name referenced in the name parameter of task definition volume .\n\ncontainerPath -> (string)\n\nThe path on the container to mount the host volume at.\n\nreadOnly -> (boolean)\n\nIf this value is true , the container has read-only access to the volume. If this value is false , then the container can write to the volume. The default value is false .\n\nvolumesFrom -> (list)\n\nData volumes to mount from another container. This parameter maps to VolumesFrom in the Create a container section of the Docker Remote API and the --volumes-from option to docker run .\n\n(structure)\n\nDetails on a data volume from another container in the same task definition.\n\nsourceContainer -> (string)\n\nThe name of another container within the same task definition from which to mount volumes.\n\nreadOnly -> (boolean)\n\nIf this value is true , the container has read-only access to the volume. If this value is false , then the container can write to the volume. The default value is false .\n\nlinuxParameters -> (structure)\n\nLinux-specific modifications that are applied to the container, such as Linux kernel capabilities. For more information see KernelCapabilities .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\ncapabilities -> (structure)\n\nThe Linux capabilities for the container that are added to or dropped from the default configuration provided by Docker.\n\nNote\n\nFor tasks that use the Fargate launch type, capabilities is supported for all platform versions but the add parameter is only supported if using platform version 1.4.0 or later.\n\nadd -> (list)\n\nThe Linux capabilities for the container that have been added to the default configuration provided by Docker. This parameter maps to CapAdd in the Create a container section of the Docker Remote API and the --cap-add option to docker run .\n\nNote\n\nTasks launched on Fargate only support adding the SYS_PTRACE kernel capability.\n\nValid values: \"ALL\" | \"AUDIT_CONTROL\" | \"AUDIT_WRITE\" | \"BLOCK_SUSPEND\" | \"CHOWN\" | \"DAC_OVERRIDE\" | \"DAC_READ_SEARCH\" | \"FOWNER\" | \"FSETID\" | \"IPC_LOCK\" | \"IPC_OWNER\" | \"KILL\" | \"LEASE\" | \"LINUX_IMMUTABLE\" | \"MAC_ADMIN\" | \"MAC_OVERRIDE\" | \"MKNOD\" | \"NET_ADMIN\" | \"NET_BIND_SERVICE\" | \"NET_BROADCAST\" | \"NET_RAW\" | \"SETFCAP\" | \"SETGID\" | \"SETPCAP\" | \"SETUID\" | \"SYS_ADMIN\" | \"SYS_BOOT\" | \"SYS_CHROOT\" | \"SYS_MODULE\" | \"SYS_NICE\" | \"SYS_PACCT\" | \"SYS_PTRACE\" | \"SYS_RAWIO\" | \"SYS_RESOURCE\" | \"SYS_TIME\" | \"SYS_TTY_CONFIG\" | \"SYSLOG\" | \"WAKE_ALARM\"\n\n(string)\n\ndrop -> (list)\n\nThe Linux capabilities for the container that have been removed from the default configuration provided by Docker. This parameter maps to CapDrop in the Create a container section of the Docker Remote API and the --cap-drop option to docker run .\n\nValid values: \"ALL\" | \"AUDIT_CONTROL\" | \"AUDIT_WRITE\" | \"BLOCK_SUSPEND\" | \"CHOWN\" | \"DAC_OVERRIDE\" | \"DAC_READ_SEARCH\" | \"FOWNER\" | \"FSETID\" | \"IPC_LOCK\" | \"IPC_OWNER\" | \"KILL\" | \"LEASE\" | \"LINUX_IMMUTABLE\" | \"MAC_ADMIN\" | \"MAC_OVERRIDE\" | \"MKNOD\" | \"NET_ADMIN\" | \"NET_BIND_SERVICE\" | \"NET_BROADCAST\" | \"NET_RAW\" | \"SETFCAP\" | \"SETGID\" | \"SETPCAP\" | \"SETUID\" | \"SYS_ADMIN\" | \"SYS_BOOT\" | \"SYS_CHROOT\" | \"SYS_MODULE\" | \"SYS_NICE\" | \"SYS_PACCT\" | \"SYS_PTRACE\" | \"SYS_RAWIO\" | \"SYS_RESOURCE\" | \"SYS_TIME\" | \"SYS_TTY_CONFIG\" | \"SYSLOG\" | \"WAKE_ALARM\"\n\n(string)\n\ndevices -> (list)\n\nAny host devices to expose to the container. This parameter maps to Devices in the Create a container section of the Docker Remote API and the --device option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the devices parameter is not supported.\n\n(structure)\n\nAn object representing a container instance host device.\n\nhostPath -> (string)\n\nThe path for the device on the host container instance.\n\ncontainerPath -> (string)\n\nThe path inside the container at which to expose the host device.\n\npermissions -> (list)\n\nThe explicit permissions to provide to the container for the device. By default, the container has permissions for read , write , and mknod for the device.\n\n(string)\n\ninitProcessEnabled -> (boolean)\n\nRun an init process inside the container that forwards signals and reaps processes. This parameter maps to the --init option to docker run . This parameter requires version 1.25 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nsharedMemorySize -> (integer)\n\nThe value for the size (in MiB) of the /dev/shm volume. This parameter maps to the --shm-size option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the sharedMemorySize parameter is not supported.\n\ntmpfs -> (list)\n\nThe container path, mount options, and size (in MiB) of the tmpfs mount. This parameter maps to the --tmpfs option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the tmpfs parameter is not supported.\n\n(structure)\n\nThe container path, mount options, and size of the tmpfs mount.\n\ncontainerPath -> (string)\n\nThe absolute file path where the tmpfs volume is to be mounted.\n\nsize -> (integer)\n\nThe maximum size (in MiB) of the tmpfs volume.\n\nmountOptions -> (list)\n\nThe list of tmpfs volume mount options.\n\nValid values: \"defaults\" | \"ro\" | \"rw\" | \"suid\" | \"nosuid\" | \"dev\" | \"nodev\" | \"exec\" | \"noexec\" | \"sync\" | \"async\" | \"dirsync\" | \"remount\" | \"mand\" | \"nomand\" | \"atime\" | \"noatime\" | \"diratime\" | \"nodiratime\" | \"bind\" | \"rbind\" | \"unbindable\" | \"runbindable\" | \"private\" | \"rprivate\" | \"shared\" | \"rshared\" | \"slave\" | \"rslave\" | \"relatime\" | \"norelatime\" | \"strictatime\" | \"nostrictatime\" | \"mode\" | \"uid\" | \"gid\" | \"nr_inodes\" | \"nr_blocks\" | \"mpol\"\n\n(string)\n\nmaxSwap -> (integer)\n\nThe total amount of swap memory (in MiB) a container can use. This parameter will be translated to the --memory-swap option to docker run where the value would be the sum of the container memory plus the maxSwap value.\n\nIf a maxSwap value of 0 is specified, the container will not use swap. Accepted values are 0 or any positive integer. If the maxSwap parameter is omitted, the container will use the swap configuration for the container instance it is running on. A maxSwap value must be set for the swappiness parameter to be used.\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the maxSwap parameter is not supported.\n\nswappiness -> (integer)\n\nThis allows you to tune a container’s memory swappiness behavior. A swappiness value of 0 will cause swapping to not happen unless absolutely necessary. A swappiness value of 100 will cause pages to be swapped very aggressively. Accepted values are whole numbers between 0 and 100 . If the swappiness parameter is not specified, a default value of 60 is used. If a value is not specified for maxSwap then this parameter is ignored. This parameter maps to the --memory-swappiness option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the swappiness parameter is not supported.\n\nsecrets -> (list)\n\nThe secrets to pass to the container. For more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nAn object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:\n\nTo inject sensitive data into your containers as environment variables, use the secrets container definition parameter.\n\nTo reference sensitive information in the log configuration of a container, use the secretOptions container definition parameter.\n\nFor more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the secret.\n\nvalueFrom -> (string)\n\nThe secret to expose to the container. The supported values are either the full ARN of the Secrets Manager secret or the full ARN of the parameter in the SSM Parameter Store.\n\nNote\n\nIf the SSM Parameter Store parameter exists in the same Region as the task you are launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.\n\ndependsOn -> (list)\n\nThe dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.\n\nFor tasks using the EC2 launch type, the container instances require at least version 1.26.0 of the container agent to enable container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\n(structure)\n\nThe dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.\n\nYour Amazon ECS container instances require at least version 1.26.0 of the container agent to enable container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\ncontainerName -> (string)\n\nThe name of a container.\n\ncondition -> (string)\n\nThe dependency condition of the container. The following are the available conditions and their behavior:\n\nSTART - This condition emulates the behavior of links and volumes today. It validates that a dependent container is started before permitting other containers to start.\n\nCOMPLETE - This condition validates that a dependent container runs to completion (exits) before permitting other containers to start. This can be useful for nonessential containers that run a script and then exit. This condition cannot be set on an essential container.\n\nSUCCESS - This condition is the same as COMPLETE , but it also requires that the container exits with a zero status. This condition cannot be set on an essential container.\n\nHEALTHY - This condition validates that the dependent container passes its Docker health check before permitting other containers to start. This requires that the dependent container has health checks configured. This condition is confirmed only at task startup.\n\nstartTimeout -> (integer)\n\nTime duration (in seconds) to wait before giving up on resolving dependencies for a container. For example, you specify two containers in a task definition with containerA having a dependency on containerB reaching a COMPLETE , SUCCESS , or HEALTHY status. If a startTimeout value is specified for containerB and it does not reach the desired status within that time then containerA will give up and not start. This results in the task transitioning to a STOPPED state.\n\nNote\n\nWhen the ECS_CONTAINER_START_TIMEOUT container agent configuration variable is used, it is enforced indendently from this start timeout value.\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nFor tasks using the EC2 launch type, your container instances require at least version 1.26.0 of the container agent to enable a container start timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nstopTimeout -> (integer)\n\nTime duration (in seconds) to wait before the container is forcefully killed if it doesn’t exit normally on its own.\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nThe max stop timeout value is 120 seconds and if the parameter is not specified, the default value of 30 seconds is used.\n\nFor tasks using the EC2 launch type, if the stopTimeout parameter is not specified, the value set for the Amazon ECS container agent configuration variable ECS_CONTAINER_STOP_TIMEOUT is used by default. If neither the stopTimeout parameter or the ECS_CONTAINER_STOP_TIMEOUT agent configuration variable are set, then the default values of 30 seconds for Linux containers and 30 seconds on Windows containers are used. Your container instances require at least version 1.26.0 of the container agent to enable a container stop timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nhostname -> (string)\n\nThe hostname to use for your container. This parameter maps to Hostname in the Create a container section of the Docker Remote API and the --hostname option to docker run .\n\nNote\n\nThe hostname parameter is not supported if you are using the awsvpc network mode.\n\nuser -> (string)\n\nThe user to use inside the container. This parameter maps to User in the Create a container section of the Docker Remote API and the --user option to docker run .\n\nWarning\n\nWhen running tasks using the host network mode, you should not run containers using the root user (UID 0). It is considered best practice to use a non-root user.\n\nYou can specify the user using the following formats. If specifying a UID or GID, you must specify it as a positive integer.\n\nuser\n\nuser:group\n\nuid\n\nuid:gid\n\nuser:gid\n\nuid:group\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nworkingDirectory -> (string)\n\nThe working directory in which to run commands inside the container. This parameter maps to WorkingDir in the Create a container section of the Docker Remote API and the --workdir option to docker run .\n\ndisableNetworking -> (boolean)\n\nWhen this parameter is true, networking is disabled within the container. This parameter maps to NetworkDisabled in the Create a container section of the Docker Remote API .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nprivileged -> (boolean)\n\nWhen this parameter is true, the container is given elevated privileges on the host container instance (similar to the root user). This parameter maps to Privileged in the Create a container section of the Docker Remote API and the --privileged option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nreadonlyRootFilesystem -> (boolean)\n\nWhen this parameter is true, the container is given read-only access to its root file system. This parameter maps to ReadonlyRootfs in the Create a container section of the Docker Remote API and the --read-only option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\ndnsServers -> (list)\n\nA list of DNS servers that are presented to the container. This parameter maps to Dns in the Create a container section of the Docker Remote API and the --dns option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(string)\n\ndnsSearchDomains -> (list)\n\nA list of DNS search domains that are presented to the container. This parameter maps to DnsSearch in the Create a container section of the Docker Remote API and the --dns-search option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(string)\n\nextraHosts -> (list)\n\nA list of hostnames and IP address mappings to append to the /etc/hosts file on the container. This parameter maps to ExtraHosts in the Create a container section of the Docker Remote API and the --add-host option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks that use the awsvpc network mode.\n\n(structure)\n\nHostnames and IP address entries that are added to the /etc/hosts file of a container via the extraHosts parameter of its ContainerDefinition .\n\nhostname -> (string)\n\nThe hostname to use in the /etc/hosts entry.\n\nipAddress -> (string)\n\nThe IP address to use in the /etc/hosts entry.\n\ndockerSecurityOptions -> (list)\n\nA list of strings to provide custom labels for SELinux and AppArmor multi-level security systems. This field is not valid for containers in tasks using the Fargate launch type.\n\nWith Windows containers, this parameter can be used to reference a credential spec file when configuring a container for Active Directory authentication. For more information, see Using gMSAs for Windows Containers in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter maps to SecurityOpt in the Create a container section of the Docker Remote API and the --security-opt option to docker run .\n\nNote\n\nThe Amazon ECS container agent running on a container instance must register with the ECS_SELINUX_CAPABLE=true or ECS_APPARMOR_CAPABLE=true environment variables before containers placed on that instance can use these security options. For more information, see Amazon ECS Container Agent Configuration in the Amazon Elastic Container Service Developer Guide .\n\nFor more information about valid values, see Docker Run Security Configuration .\n\nValid values: “no-new-privileges” | “apparmor:PROFILE” | “label:value” | “credentialspec:CredentialSpecFilePath”\n\n(string)\n\ninteractive -> (boolean)\n\nWhen this parameter is true , this allows you to deploy containerized applications that require stdin or a tty to be allocated. This parameter maps to OpenStdin in the Create a container section of the Docker Remote API and the --interactive option to docker run .\n\npseudoTerminal -> (boolean)\n\nWhen this parameter is true , a TTY is allocated. This parameter maps to Tty in the Create a container section of the Docker Remote API and the --tty option to docker run .\n\ndockerLabels -> (map)\n\nA key/value map of labels to add to the container. This parameter maps to Labels in the Create a container section of the Docker Remote API and the --label option to docker run . This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nkey -> (string)\n\nvalue -> (string)\n\nulimits -> (list)\n\nA list of ulimits to set in the container. If a ulimit value is specified in a task definition, it will override the default values set by Docker. This parameter maps to Ulimits in the Create a container section of the Docker Remote API and the --ulimit option to docker run . Valid naming values are displayed in the Ulimit data type.\n\nAmazon ECS tasks hosted on Fargate use the default resource limit values set by the operating system with the exception of the nofile resource limit parameter which Fargate overrides. The nofile resource limit sets a restriction on the number of open files that a container can use. The default nofile soft limit is 1024 and hard limit is 4096 .\n\nThis parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(structure)\n\nThe ulimit settings to pass to the container.\n\nAmazon ECS tasks hosted on Fargate use the default resource limit values set by the operating system with the exception of the nofile resource limit parameter which Fargate overrides. The nofile resource limit sets a restriction on the number of open files that a container can use. The default nofile soft limit is 1024 and hard limit is 4096 .\n\nname -> (string)\n\nThe type of the ulimit .\n\nsoftLimit -> (integer)\n\nThe soft limit for the ulimit type.\n\nhardLimit -> (integer)\n\nThe hard limit for the ulimit type.\n\nlogConfiguration -> (structure)\n\nThe log configuration specification for the container.\n\nThis parameter maps to LogConfig in the Create a container section of the Docker Remote API and the --log-driver option to docker run . By default, containers use the same logging driver that the Docker daemon uses. However the container may use a different logging driver than the Docker daemon by specifying a log driver with this parameter in the container definition. To use a different logging driver for a container, the log system must be configured properly on the container instance (or on a different log server for remote logging options). For more information on the options for different supported log drivers, see Configure logging drivers in the Docker documentation.\n\nNote\n\nAmazon ECS currently supports a subset of the logging drivers available to the Docker daemon (shown in the LogConfiguration data type). Additional log drivers may be available in future releases of the Amazon ECS container agent.\n\nThis parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nNote\n\nThe Amazon ECS container agent running on a container instance must register the logging drivers available on that instance with the ECS_AVAILABLE_LOGGING_DRIVERS environment variable before containers placed on that instance can use these log configuration options. For more information, see Amazon ECS Container Agent Configuration in the Amazon Elastic Container Service Developer Guide .\n\nlogDriver -> (string)\n\nThe log driver to use for the container.\n\nFor tasks on Fargate, the supported log drivers are awslogs , splunk , and awsfirelens .\n\nFor tasks hosted on Amazon EC2 instances, the supported log drivers are awslogs , fluentd , gelf , json-file , journald , logentries ,``syslog`` , splunk , and awsfirelens .\n\nFor more information about using the awslogs log driver, see Using the awslogs log driver in the Amazon Elastic Container Service Developer Guide .\n\nFor more information about using the awsfirelens log driver, see Custom log routing in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you have a custom driver that is not listed, you can fork the Amazon ECS container agent project that is available on GitHub and customize it to work with that driver. We encourage you to submit pull requests for changes that you would like to have included. However, we do not currently provide support for running modified copies of this software.\n\noptions -> (map)\n\nThe configuration options to send to the log driver. This parameter requires version 1.19 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nkey -> (string)\n\nvalue -> (string)\n\nsecretOptions -> (list)\n\nThe secrets to pass to the log configuration. For more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nAn object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:\n\nTo inject sensitive data into your containers as environment variables, use the secrets container definition parameter.\n\nTo reference sensitive information in the log configuration of a container, use the secretOptions container definition parameter.\n\nFor more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the secret.\n\nvalueFrom -> (string)\n\nThe secret to expose to the container. The supported values are either the full ARN of the Secrets Manager secret or the full ARN of the parameter in the SSM Parameter Store.\n\nNote\n\nIf the SSM Parameter Store parameter exists in the same Region as the task you are launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.\n\nhealthCheck -> (structure)\n\nThe container health check command and associated configuration parameters for the container. This parameter maps to HealthCheck in the Create a container section of the Docker Remote API and the HEALTHCHECK parameter of docker run .\n\ncommand -> (list)\n\nA string array representing the command that the container runs to determine if it is healthy. The string array must start with CMD to execute the command arguments directly, or CMD-SHELL to run the command with the container’s default shell.\n\nWhen you use the Amazon Web Services Management Console JSON panel, the Command Line Interface, or the APIs, you should enclose the list of commands in brackets, as shown below.\n\n[ \"CMD-SHELL\", \"curl -f http://localhost/ || exit 1\" ]\n\nYou do not need to include the brackets when you use the Amazon Web Services Management Consoleas shown below.\n\n\"CMD-SHELL\", \"curl -f http://localhost/ || exit 1\"\n\nAn exit code of 0 indicates success, and non-zero exit code indicates failure. For more information, see HealthCheck in the Create a container section of the Docker Remote API .\n\n(string)\n\ninterval -> (integer)\n\nThe time period in seconds between each health check execution. You may specify between 5 and 300 seconds. The default value is 30 seconds.\n\ntimeout -> (integer)\n\nThe time period in seconds to wait for a health check to succeed before it is considered a failure. You may specify between 2 and 60 seconds. The default value is 5.\n\nretries -> (integer)\n\nThe number of times to retry a failed health check before the container is considered unhealthy. You may specify between 1 and 10 retries. The default value is 3.\n\nstartPeriod -> (integer)\n\nThe optional grace period within which to provide containers time to bootstrap before failed health checks count towards the maximum number of retries. You may specify between 0 and 300 seconds. The startPeriod is disabled by default.\n\nNote\n\nIf a health check succeeds within the startPeriod , then the container is considered healthy and any subsequent failures count toward the maximum number of retries.\n\nsystemControls -> (list)\n\nA list of namespaced kernel parameters to set in the container. This parameter maps to Sysctls in the Create a container section of the Docker Remote API and the --sysctl option to docker run .\n\nNote\n\nIt is not recommended that you specify network-related systemControls parameters for multiple containers in a single task that also uses either the awsvpc or host network modes. For tasks that use the awsvpc network mode, the container that is started last determines which systemControls parameters take effect. For tasks that use the host network mode, it changes the container instance’s namespaced kernel parameters as well as the containers.\n\n(structure)\n\nA list of namespaced kernel parameters to set in the container. This parameter maps to Sysctls in the Create a container section of the Docker Remote API and the --sysctl option to docker run .\n\nIt is not recommended that you specify network-related systemControls parameters for multiple containers in a single task that also uses either the awsvpc or host network mode for the following reasons:\n\nFor tasks that use the awsvpc network mode, if you set systemControls for any container, it applies to all containers in the task. If you set different systemControls for multiple containers in a single task, the container that is started last determines which systemControls take effect.\n\nFor tasks that use the host network mode, the systemControls parameter applies to the container instance’s kernel parameter as well as that of all containers of any tasks running on that container instance.\n\nnamespace -> (string)\n\nThe namespaced kernel parameter for which to set a value .\n\nvalue -> (string)\n\nThe value for the namespaced kernel parameter specified in namespace .\n\nresourceRequirements -> (list)\n\nThe type and amount of a resource to assign to a container. The only supported resource is a GPU.\n\n(structure)\n\nThe type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see Working with GPUs on Amazon ECS or Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide\n\nvalue -> (string)\n\nThe value for the specified resource type.\n\nIf the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent will reserve for the container. The number of GPUs reserved for all containers in a task should not exceed the number of available GPUs on the container instance the task is launched on.\n\nIf the InferenceAccelerator type is used, the value should match the deviceName for an InferenceAccelerator specified in a task definition.\n\ntype -> (string)\n\nThe type of resource to assign to a container. The supported values are GPU or InferenceAccelerator .\n\nfirelensConfiguration -> (structure)\n\nThe FireLens configuration for the container. This is used to specify and configure a log router for container logs. For more information, see Custom Log Routing in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe log router to use. The valid values are fluentd or fluentbit .\n\noptions -> (map)\n\nThe options to use when configuring the log router. This field is optional and can be used to specify a custom configuration file or to add additional metadata, such as the task, task definition, cluster, and container instance details to the log event. If specified, the syntax to use is \"options\":{\"enable-ecs-log-metadata\":\"true|false\",\"config-file-type:\"s3|file\",\"config-file-value\":\"arn:aws:s3:::mybucket/fluent.conf|filepath\"} . For more information, see Creating a Task Definition that Uses a FireLens Configuration in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nTasks hosted on Fargate only support the file configuration file type.\n\nkey -> (string)\n\nvalue -> (string)\n\nfamily -> (string)\n\nThe name of a family that this task definition is registered to. Up to 255 letters (uppercase and lowercase), numbers, hyphens, and underscores are allowed.\n\nA family groups multiple versions of a task definition. Amazon ECS gives the first task definition that you registered to a family a revision number of 1. Amazon ECS gives sequential revision numbers to each task definition that you add.\n\ntaskRoleArn -> (string)\n\nThe short name or full Amazon Resource Name (ARN) of the Identity and Access Management role that grants containers in the task permission to call Amazon Web Services APIs on your behalf. For more information, see Amazon ECS Task Role in the Amazon Elastic Container Service Developer Guide .\n\nIAM roles for tasks on Windows require that the -EnableTaskIAMRole option is set when you launch the Amazon ECS-optimized Windows AMI. Your containers must also run some configuration code in order to take advantage of the feature. For more information, see Windows IAM roles for tasks in the Amazon Elastic Container Service Developer Guide .\n\nexecutionRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task execution role that grants the Amazon ECS container agent permission to make Amazon Web Services API calls on your behalf. The task execution IAM role is required depending on the requirements of your task. For more information, see Amazon ECS task execution IAM role in the Amazon Elastic Container Service Developer Guide .\n\nnetworkMode -> (string)\n\nThe Docker networking mode to use for the containers in the task. The valid values are none , bridge , awsvpc , and host . If no network mode is specified, the default is bridge .\n\nFor Amazon ECS tasks on Fargate, the awsvpc network mode is required. For Amazon ECS tasks on Amazon EC2 Linux instances, any network mode can be used. For Amazon ECS tasks on Amazon EC2 Windows instances, <default> or awsvpc can be used. If the network mode is set to none , you cannot specify port mappings in your container definitions, and the tasks containers do not have external connectivity. The host and awsvpc network modes offer the highest networking performance for containers because they use the EC2 network stack instead of the virtualized network stack provided by the bridge mode.\n\nWith the host and awsvpc network modes, exposed container ports are mapped directly to the corresponding host port (for the host network mode) or the attached elastic network interface port (for the awsvpc network mode), so you cannot take advantage of dynamic host port mappings.\n\nWarning\n\nWhen using the host network mode, you should not run containers using the root user (UID 0). It is considered best practice to use a non-root user.\n\nIf the network mode is awsvpc , the task is allocated an elastic network interface, and you must specify a NetworkConfiguration value when you create a service or run a task with the task definition. For more information, see Task Networking in the Amazon Elastic Container Service Developer Guide .\n\nIf the network mode is host , you cannot run multiple instantiations of the same task on a single container instance when port mappings are used.\n\nFor more information, see Network settings in the Docker run reference .\n\nrevision -> (integer)\n\nThe revision of the task in a particular family. The revision is a version number of a task definition in a family. When you register a task definition for the first time, the revision is 1 . Each time that you register a new revision of a task definition in the same family, the revision value always increases by one, even if you have deregistered previous revisions in this family.\n\nvolumes -> (list)\n\nThe list of data volume definitions for the task. For more information, see Using data volumes in tasks in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nThe host and sourcePath parameters are not supported for tasks run on Fargate.\n\n(structure)\n\nA data volume used in a task definition. For tasks that use the Amazon Elastic File System (Amazon EFS), specify an efsVolumeConfiguration . For Windows tasks that use Amazon FSx for Windows File Server file system, specify a fsxWindowsFileServerVolumeConfiguration . For tasks that use a Docker volume, specify a DockerVolumeConfiguration . For tasks that use a bind mount host volume, specify a host and optional sourcePath . For more information, see Using Data Volumes in Tasks .\n\nname -> (string)\n\nThe name of the volume. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This name is referenced in the sourceVolume parameter of container definition mountPoints .\n\nhost -> (structure)\n\nThis parameter is specified when you are using bind mount host volumes. The contents of the host parameter determine whether your bind mount host volume persists on the host container instance and where it is stored. If the host parameter is empty, then the Docker daemon assigns a host path for your data volume. However, the data is not guaranteed to persist after the containers associated with it stop running.\n\nWindows containers can mount whole directories on the same drive as $env:ProgramData . Windows containers cannot mount directories on a different drive, and mount point cannot be across drives. For example, you can mount C:\\my\\path:C:\\my\\path and D:\\:D:\\ , but not D:\\my\\path:C:\\my\\path or D:\\:C:\\my\\path .\n\nsourcePath -> (string)\n\nWhen the host parameter is used, specify a sourcePath to declare the path on the host container instance that is presented to the container. If this parameter is empty, then the Docker daemon has assigned a host path for you. If the host parameter contains a sourcePath file location, then the data volume persists at the specified location on the host container instance until you delete it manually. If the sourcePath value does not exist on the host container instance, the Docker daemon creates it. If the location does exist, the contents of the source path folder are exported.\n\nIf you are using the Fargate launch type, the sourcePath parameter is not supported.\n\ndockerVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using Docker volumes.\n\nWindows containers only support the use of the local driver. To use bind mounts, specify the host parameter instead.\n\nNote\n\nDocker volumes are not supported by tasks run on Fargate.\n\nscope -> (string)\n\nThe scope for the Docker volume that determines its lifecycle. Docker volumes that are scoped to a task are automatically provisioned when the task starts and destroyed when the task stops. Docker volumes that are scoped as shared persist after the task stops.\n\nautoprovision -> (boolean)\n\nIf this value is true , the Docker volume is created if it does not already exist.\n\nNote\n\nThis field is only used if the scope is shared .\n\ndriver -> (string)\n\nThe Docker volume driver to use. The driver value must match the driver name provided by Docker because it is used for task placement. If the driver was installed using the Docker plugin CLI, use docker plugin ls to retrieve the driver name from your container instance. If the driver was installed using another method, use Docker plugin discovery to retrieve the driver name. For more information, see Docker plugin discovery . This parameter maps to Driver in the Create a volume section of the Docker Remote API and the xxdriver option to docker volume create .\n\ndriverOpts -> (map)\n\nA map of Docker driver-specific options passed through. This parameter maps to DriverOpts in the Create a volume section of the Docker Remote API and the xxopt option to docker volume create .\n\nkey -> (string)\n\nvalue -> (string)\n\nlabels -> (map)\n\nCustom metadata to add to your Docker volume. This parameter maps to Labels in the Create a volume section of the Docker Remote API and the xxlabel option to docker volume create .\n\nkey -> (string)\n\nvalue -> (string)\n\nefsVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using an Amazon Elastic File System file system for task storage.\n\nfileSystemId -> (string)\n\nThe Amazon EFS file system ID to use.\n\nrootDirectory -> (string)\n\nThe directory within the Amazon EFS file system to mount as the root directory inside the host. If this parameter is omitted, the root of the Amazon EFS volume will be used. Specifying / will have the same effect as omitting this parameter.\n\nWarning\n\nIf an EFS access point is specified in the authorizationConfig , the root directory parameter must either be omitted or set to / which will enforce the path set on the EFS access point.\n\ntransitEncryption -> (string)\n\nWhether or not to enable encryption for Amazon EFS data in transit between the Amazon ECS host and the Amazon EFS server. Transit encryption must be enabled if Amazon EFS IAM authorization is used. If this parameter is omitted, the default value of DISABLED is used. For more information, see Encrypting Data in Transit in the Amazon Elastic File System User Guide .\n\ntransitEncryptionPort -> (integer)\n\nThe port to use when sending encrypted data between the Amazon ECS host and the Amazon EFS server. If you do not specify a transit encryption port, it will use the port selection strategy that the Amazon EFS mount helper uses. For more information, see EFS Mount Helper in the Amazon Elastic File System User Guide .\n\nauthorizationConfig -> (structure)\n\nThe authorization configuration details for the Amazon EFS file system.\n\naccessPointId -> (string)\n\nThe Amazon EFS access point ID to use. If an access point is specified, the root directory value specified in the EFSVolumeConfiguration must either be omitted or set to / which will enforce the path set on the EFS access point. If an access point is used, transit encryption must be enabled in the EFSVolumeConfiguration . For more information, see Working with Amazon EFS Access Points in the Amazon Elastic File System User Guide .\n\niam -> (string)\n\nWhether or not to use the Amazon ECS task IAM role defined in a task definition when mounting the Amazon EFS file system. If enabled, transit encryption must be enabled in the EFSVolumeConfiguration . If this parameter is omitted, the default value of DISABLED is used. For more information, see Using Amazon EFS Access Points in the Amazon Elastic Container Service Developer Guide .\n\nfsxWindowsFileServerVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using Amazon FSx for Windows File Server file system for task storage.\n\nfileSystemId -> (string)\n\nThe Amazon FSx for Windows File Server file system ID to use.\n\nrootDirectory -> (string)\n\nThe directory within the Amazon FSx for Windows File Server file system to mount as the root directory inside the host.\n\nauthorizationConfig -> (structure)\n\nThe authorization configuration details for the Amazon FSx for Windows File Server file system.\n\ncredentialsParameter -> (string)\n\nThe authorization credential option to use. The authorization credential options can be provided using either the Amazon Resource Name (ARN) of an Secrets Manager secret or SSM Parameter Store parameter. The ARNs refer to the stored credentials.\n\ndomain -> (string)\n\nA fully qualified domain name hosted by an Directory Service Managed Microsoft AD (Active Directory) or self-hosted AD on Amazon EC2.\n\nstatus -> (string)\n\nThe status of the task definition.\n\nrequiresAttributes -> (list)\n\nThe container instance attributes required by your task. When an Amazon EC2 instance is registered to your cluster, the Amazon ECS container agent assigns some standard attributes to the instance. You can apply custom attributes, specified as key-value pairs using the Amazon ECS console or the PutAttributes API. These attributes are used when considering task placement for tasks hosted on Amazon EC2 instances. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nThis parameter is not supported for tasks run on Fargate.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nplacementConstraints -> (list)\n\nAn array of placement constraint objects to use for tasks.\n\nNote\n\nThis parameter is not supported for tasks run on Fargate.\n\n(structure)\n\nAn object representing a constraint on task placement in the task definition. For more information, see Task placement constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nTask placement constraints are not supported for tasks run on Fargate.\n\ntype -> (string)\n\nThe type of constraint. The MemberOf constraint restricts selection to be from a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\ncompatibilities -> (list)\n\nThe task launch types the task definition validated against during task definition registration. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\n(string)\n\nruntimePlatform -> (structure)\n\nThe operating system that your task definitions are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nWhen you specify a task in a service, this value must match the runtimePlatform value of the service.\n\ncpuArchitecture -> (string)\n\nThe CPU architecture.\n\noperatingSystemFamily -> (string)\n\nThe operating system.\n\nrequiresCompatibilities -> (list)\n\nThe task launch types the task definition was validated against. To determine which task launch types the task definition is validated for, see the TaskDefinition$compatibilities parameter.\n\n(string)\n\ncpu -> (string)\n\nThe number of cpu units used by the task. If you are using the EC2 launch type, this field is optional and any value can be used. If you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of valid values for the memory parameter:\n\n256 (.25 vCPU) - Available memory values: 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)\n\n512 (.5 vCPU) - Available memory values: 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)\n\n1024 (1 vCPU) - Available memory values: 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)\n\n2048 (2 vCPU) - Available memory values: Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)\n\n4096 (4 vCPU) - Available memory values: Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)\n\nmemory -> (string)\n\nThe amount (in MiB) of memory used by the task.\n\nIf your tasks will be run on Amazon EC2 instances, you must specify either a task-level memory value or a container-level memory value. This field is optional and any value can be used. If a task-level memory value is specified then the container-level memory value is optional. For more information regarding container-level memory and memory reservation, see ContainerDefinition .\n\nIf your tasks will be run on Fargate, this field is required and you must use one of the following values, which determines your range of valid values for the cpu parameter:\n\n512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)\n\n1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)\n\n2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)\n\nBetween 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)\n\nBetween 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)\n\ninferenceAccelerators -> (list)\n\nThe Elastic Inference accelerator associated with the task.\n\n(structure)\n\nDetails on a Elastic Inference accelerator. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name. The deviceName must also be referenced in a container definition as a ResourceRequirement .\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\npidMode -> (string)\n\nThe process namespace to use for the containers in the task. The valid values are host or task . If host is specified, then all containers within the tasks that specified the host PID mode on the same container instance share the same process namespace with the host Amazon EC2 instance. If task is specified, all containers within the specified task share the same process namespace. If no value is specified, the default is a private namespace. For more information, see PID settings in the Docker run reference .\n\nIf the host PID mode is used, be aware that there is a heightened risk of undesired process namespace expose. For more information, see Docker security .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nipcMode -> (string)\n\nThe IPC resource namespace to use for the containers in the task. The valid values are host , task , or none . If host is specified, then all containers within the tasks that specified the host IPC mode on the same container instance share the same IPC resources with the host Amazon EC2 instance. If task is specified, all containers within the specified task share the same IPC resources. If none is specified, then IPC resources within the containers of a task are private and not shared with other containers in a task or on the container instance. If no value is specified, then the IPC resource namespace sharing depends on the Docker daemon setting on the container instance. For more information, see IPC settings in the Docker run reference .\n\nIf the host IPC mode is used, be aware that there is a heightened risk of undesired IPC namespace expose. For more information, see Docker security .\n\nIf you are setting namespaced kernel parameters using systemControls for the containers in the task, the following will apply to your IPC resource namespace. For more information, see System Controls in the Amazon Elastic Container Service Developer Guide .\n\nFor tasks that use the host IPC mode, IPC namespace related systemControls are not supported.\n\nFor tasks that use the task IPC mode, IPC namespace related systemControls will apply to all containers within a task.\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nproxyConfiguration -> (structure)\n\nThe configuration details for the App Mesh proxy.\n\nYour Amazon ECS container instances require at least version 1.26.0 of the container agent and at least version 1.26.0-1 of the ecs-init package to enable a proxy configuration. If your container instances are launched from the Amazon ECS-optimized AMI version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe proxy type. The only supported value is APPMESH .\n\ncontainerName -> (string)\n\nThe name of the container that will serve as the App Mesh proxy.\n\nproperties -> (list)\n\nThe set of network configuration parameters to provide the Container Network Interface (CNI) plugin, specified as key-value pairs.\n\nIgnoredUID - (Required) The user ID (UID) of the proxy container as defined by the user parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If IgnoredGID is specified, this field can be empty.\n\nIgnoredGID - (Required) The group ID (GID) of the proxy container as defined by the user parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If IgnoredUID is specified, this field can be empty.\n\nAppPorts - (Required) The list of ports that the application uses. Network traffic to these ports is forwarded to the ProxyIngressPort and ProxyEgressPort .\n\nProxyIngressPort - (Required) Specifies the port that incoming traffic to the AppPorts is directed to.\n\nProxyEgressPort - (Required) Specifies the port that outgoing traffic from the AppPorts is directed to.\n\nEgressIgnoredPorts - (Required) The egress traffic going to the specified ports is ignored and not redirected to the ProxyEgressPort . It can be an empty list.\n\nEgressIgnoredIPs - (Required) The egress traffic going to the specified IP addresses is ignored and not redirected to the ProxyEgressPort . It can be an empty list.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nregisteredAt -> (timestamp)\n\nThe Unix timestamp for when the task definition was registered.\n\nderegisteredAt -> (timestamp)\n\nThe Unix timestamp for when the task definition was deregistered.\n\nregisteredBy -> (string)\n\nThe principal that registered the task definition.\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage settings to use for tasks run with the task definition.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.",
      "command_examples": "Examples\n\nTo deregister a task definition\n\nThe following deregister-task-definition example deregisters the first revision of the curler task definition in your default region.\n\naws ecs deregister-task-definition --task-definition curler:1\n\n\nNote that in the resulting output, the task definition status shows INACTIVE:\n\n{\n    \"taskDefinition\": {\n        \"status\": \"INACTIVE\",\n        \"family\": \"curler\",\n        \"volumes\": [],\n        \"taskDefinitionArn\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/curler:1\",\n        \"containerDefinitions\": [\n            {\n                \"environment\": [],\n                \"name\": \"curler\",\n                \"mountPoints\": [],\n                \"image\": \"curl:latest\",\n                \"cpu\": 100,\n                \"portMappings\": [],\n                \"entryPoint\": [],\n                \"memory\": 256,\n                \"command\": [\n                    \"curl -v http://example.com/\"\n                ],\n                \"essential\": true,\n                \"volumesFrom\": []\n            }\n        ],\n        \"revision\": 1\n    }\n}\n\n\nFor more information, see Amazon ECS Task Definitions in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "describe-capacity-providers",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describe-capacity-providers.html",
      "command_description": "Description\n\nDescribes one or more of your capacity providers.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-capacity-providers\n[--capacity-providers <value>]\n[--include <value>]\n[--max-results <value>]\n[--next-token <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--capacity-providers <value>]",
        "[--include <value>]",
        "[--max-results <value>]",
        "[--next-token <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--capacity-providers (list)\n\nThe short name or full Amazon Resource Name (ARN) of one or more capacity providers. Up to 100 capacity providers can be described in an action.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--include (list)\n\nSpecifies whether or not you want to see the resource tags for the capacity provider. If TAGS is specified, the tags are included in the response. If this field is omitted, tags are not included in the response.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  TAGS\n\n\n--max-results (integer)\n\nThe maximum number of account setting results returned by DescribeCapacityProviders in paginated output. When this parameter is used, DescribeCapacityProviders only returns maxResults results in a single page along with a nextToken response element. The remaining results of the initial request can be seen by sending another DescribeCapacityProviders request with the returned nextToken value. This value can be between 1 and 10. If this parameter is not used, then DescribeCapacityProviders returns up to 10 results and a nextToken value if applicable.\n\n--next-token (string)\n\nThe nextToken value returned from a previous paginated DescribeCapacityProviders request where maxResults was used and the results exceeded the value of that parameter. Pagination continues from the end of the previous results that returned the nextToken value.\n\nNote\n\nThis token should be treated as an opaque identifier that is only used to retrieve the next items in a list and not for other programmatic purposes.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncapacityProviders -> (list)\n\nThe list of capacity providers.\n\n(structure)\n\nThe details of a capacity provider.\n\ncapacityProviderArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the capacity provider.\n\nname -> (string)\n\nThe name of the capacity provider.\n\nstatus -> (string)\n\nThe current status of the capacity provider. Only capacity providers in an ACTIVE state can be used in a cluster. When a capacity provider is successfully deleted, it will have an INACTIVE status.\n\nautoScalingGroupProvider -> (structure)\n\nThe Auto Scaling group settings for the capacity provider.\n\nautoScalingGroupArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the Auto Scaling group.\n\nmanagedScaling -> (structure)\n\nThe managed scaling settings for the Auto Scaling group capacity provider.\n\nstatus -> (string)\n\nWhether or not to enable managed scaling for the capacity provider.\n\ntargetCapacity -> (integer)\n\nThe target capacity value for the capacity provider. The specified value must be greater than 0 and less than or equal to 100 . A value of 100 will result in the Amazon EC2 instances in your Auto Scaling group being completely utilized.\n\nminimumScalingStepSize -> (integer)\n\nThe minimum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 1 is used.\n\nmaximumScalingStepSize -> (integer)\n\nThe maximum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 10000 is used.\n\ninstanceWarmupPeriod -> (integer)\n\nThe period of time, in seconds, after a newly launched Amazon EC2 instance can contribute to CloudWatch metrics for Auto Scaling group. If this parameter is omitted, the default value of 300 seconds is used.\n\nmanagedTerminationProtection -> (string)\n\nThe managed termination protection setting to use for the Auto Scaling group capacity provider. This determines whether the Auto Scaling group has managed termination protection.\n\nWarning\n\nWhen using managed termination protection, managed scaling must also be used otherwise managed termination protection will not work.\n\nWhen managed termination protection is enabled, Amazon ECS prevents the Amazon EC2 instances in an Auto Scaling group that contain tasks from being terminated during a scale-in action. The Auto Scaling group and each instance in the Auto Scaling group must have instance protection from scale-in actions enabled as well. For more information, see Instance Protection in the Auto Scaling User Guide .\n\nWhen managed termination protection is disabled, your Amazon EC2 instances are not protected from termination when the Auto Scaling group scales in.\n\nupdateStatus -> (string)\n\nThe update status of the capacity provider. The following are the possible states that will be returned.\n\nDELETE_IN_PROGRESS\n\nThe capacity provider is in the process of being deleted.\n\nDELETE_COMPLETE\n\nThe capacity provider has been successfully deleted and will have an INACTIVE status.\n\nDELETE_FAILED\n\nThe capacity provider was unable to be deleted. The update status reason will provide further details about why the delete failed.\n\nupdateStatusReason -> (string)\n\nThe update status reason. This provides further details about the update status for the capacity provider.\n\ntags -> (list)\n\nThe metadata that you apply to the capacity provider to help you categorize and organize it. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nfailures -> (list)\n\nAny failures associated with the call.\n\n(structure)\n\nA failed resource. For a list of common causes, see API failure reasons in the Amazon Elastic Container Service Developer Guide .\n\narn -> (string)\n\nThe Amazon Resource Name (ARN) of the failed resource.\n\nreason -> (string)\n\nThe reason for the failure.\n\ndetail -> (string)\n\nThe details of the failure.\n\nnextToken -> (string)\n\nThe nextToken value to include in a future DescribeCapacityProviders request. When the results of a DescribeCapacityProviders request exceed maxResults , this value can be used to retrieve the next page of results. This value is null when there are no more results to return.",
      "command_examples": "Examples\n\nExample 1: To describe all capacity providers\n\nThe following describe-capacity-providers example retrieves details about all capacity providers.\n\naws ecs describe-capacity-providers\n\n\nOutput:\n\n{\n    \"capacityProviders\": [\n        {\n            \"capacityProviderArn\": \"arn:aws:ecs:us-west-2:123456789012:capacity-provider/MyCapacityProvider\",\n            \"name\": \"MyCapacityProvider\",\n            \"status\": \"ACTIVE\",\n            \"autoScalingGroupProvider\": {\n                \"autoScalingGroupArn\": \"arn:aws:autoscaling:us-west-2:123456789012:autoScalingGroup:a1b2c3d4-5678-90ab-cdef-EXAMPLE11111:autoScalingGroupName/MyAutoScalingGroup\",\n                \"managedScaling\": {\n                    \"status\": \"ENABLED\",\n                    \"targetCapacity\": 100,\n                    \"minimumScalingStepSize\": 1,\n                    \"maximumScalingStepSize\": 1000\n                },\n                \"managedTerminationProtection\": \"ENABLED\"\n            },\n            \"tags\": []\n        },\n        {\n            \"capacityProviderArn\": \"arn:aws:ecs:us-west-2:123456789012:capacity-provider/FARGATE\",\n            \"name\": \"FARGATE\",\n            \"status\": \"ACTIVE\",\n            \"tags\": []\n        },\n        {\n            \"capacityProviderArn\": \"arn:aws:ecs:us-west-2:123456789012:capacity-provider/FARGATE_SPOT\",\n            \"name\": \"FARGATE_SPOT\",\n            \"status\": \"ACTIVE\",\n            \"tags\": []\n        }\n    ]\n}\n\n\nFor more information, see Cluster capacity providers in the Amazon ECS Developer Guide.\n\nExample 2: To describe a specific capacity providers\n\nThe following describe-capacity-providers example retrieves details about a specific capacity provider. Using the --include TAGS parameter will add the tags associated with the capacity provider to the output.\n\naws ecs describe-capacity-providers \\\n    --capacity-providers MyCapacityProvider \\\n    --include TAGS\n\n\nOutput:\n\n{\n    \"capacityProviders\": [\n        {\n            \"capacityProviderArn\": \"arn:aws:ecs:us-west-2:123456789012:capacity-provider/MyCapacityProvider\",\n            \"name\": \"MyCapacityProvider\",\n            \"status\": \"ACTIVE\",\n            \"autoScalingGroupProvider\": {\n                \"autoScalingGroupArn\": \"arn:aws:autoscaling:us-west-2:123456789012:autoScalingGroup:a1b2c3d4-5678-90ab-cdef-EXAMPLE11111:autoScalingGroupName/MyAutoScalingGroup\",\n                \"managedScaling\": {\n                    \"status\": \"ENABLED\",\n                    \"targetCapacity\": 100,\n                    \"minimumScalingStepSize\": 1,\n                    \"maximumScalingStepSize\": 1000\n                },\n                \"managedTerminationProtection\": \"ENABLED\"\n            },\n            \"tags\": [\n                {\n                    \"key\": \"environment\",\n                    \"value\": \"production\"\n                }\n            ]\n        }\n    ]\n}\n\n\nFor more information, see Cluster capacity providers in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "describe-clusters",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describe-clusters.html",
      "command_description": "Description\n\nDescribes one or more of your clusters.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-clusters\n[--clusters <value>]\n[--include <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--clusters <value>]",
        "[--include <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--clusters (list)\n\nA list of up to 100 cluster names or full cluster Amazon Resource Name (ARN) entries. If you do not specify a cluster, the default cluster is assumed.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--include (list)\n\nWhether to include additional information about the clusters in the response. If this field is omitted, this information isn’t included.\n\nIf ATTACHMENTS is specified, the attachments for the container instances or tasks within the cluster are included.\n\nIf SETTINGS is specified, the settings for the cluster are included.\n\nIf CONFIGURATIONS is specified, the configuration for the cluster is included.\n\nIf STATISTICS is specified, the task and service count is included, separated by launch type.\n\nIf TAGS is specified, the metadata tags associated with the cluster are included.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  ATTACHMENTS\n  CONFIGURATIONS\n  SETTINGS\n  STATISTICS\n  TAGS\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nclusters -> (list)\n\nThe list of clusters.\n\n(structure)\n\nA regional grouping of one or more container instances on which you can run task requests. Each account receives a default cluster the first time you use the Amazon ECS service, but you may also create other clusters. Clusters may contain more than one instance type simultaneously.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the cluster. The ARN contains the arn:aws:ecs namespace, followed by the Region of the cluster, the Amazon Web Services account ID of the cluster owner, the cluster namespace, and then the cluster name. For example, arn:aws:ecs:region:012345678910:cluster/test .\n\nclusterName -> (string)\n\nA user-generated string that you use to identify your cluster.\n\nconfiguration -> (structure)\n\nThe execute command configuration for the cluster.\n\nexecuteCommandConfiguration -> (structure)\n\nThe details of the execute command configuration.\n\nkmsKeyId -> (string)\n\nSpecify an Key Management Service key ID to encrypt the data between the local client and the container.\n\nlogging -> (string)\n\nThe log setting to use for redirecting logs for your execute command results. The following log settings are available.\n\nNONE : The execute command session is not logged.\n\nDEFAULT : The awslogs configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no awslogs log driver is configured in the task definition, the output won’t be logged.\n\nOVERRIDE : Specify the logging details as a part of logConfiguration . If the OVERRIDE logging option is specified, the logConfiguration is required.\n\nlogConfiguration -> (structure)\n\nThe log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When logging=OVERRIDE is specified, a logConfiguration must be provided.\n\ncloudWatchLogGroupName -> (string)\n\nThe name of the CloudWatch log group to send logs to.\n\nNote\n\nThe CloudWatch log group must already be created.\n\ncloudWatchEncryptionEnabled -> (boolean)\n\nWhether or not to enable encryption on the CloudWatch logs. If not specified, encryption will be disabled.\n\ns3BucketName -> (string)\n\nThe name of the S3 bucket to send logs to.\n\nNote\n\nThe S3 bucket must already be created.\n\ns3EncryptionEnabled -> (boolean)\n\nWhether or not to use encryption on the S3 logs. If not specified, encryption is not used.\n\ns3KeyPrefix -> (string)\n\nAn optional folder in the S3 bucket to place logs in.\n\nstatus -> (string)\n\nThe status of the cluster. The following are the possible states that will be returned.\n\nACTIVE\n\nThe cluster is ready to accept tasks and if applicable you can register container instances with the cluster.\n\nPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being created.\n\nDEPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being deleted.\n\nFAILED\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider have failed to create.\n\nINACTIVE\n\nThe cluster has been deleted. Clusters with an INACTIVE status may remain discoverable in your account for a period of time. However, this behavior is subject to change in the future, so you should not rely on INACTIVE clusters persisting.\n\nregisteredContainerInstancesCount -> (integer)\n\nThe number of container instances registered into the cluster. This includes container instances in both ACTIVE and DRAINING status.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the RUNNING state.\n\npendingTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the PENDING state.\n\nactiveServicesCount -> (integer)\n\nThe number of services that are running on the cluster in an ACTIVE state. You can view these services with ListServices .\n\nstatistics -> (list)\n\nAdditional information about your clusters that are separated by launch type, including:\n\nrunningEC2TasksCount\n\nRunningFargateTasksCount\n\npendingEC2TasksCount\n\npendingFargateTasksCount\n\nactiveEC2ServiceCount\n\nactiveFargateServiceCount\n\ndrainingEC2ServiceCount\n\ndrainingFargateServiceCount\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the cluster to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nsettings -> (list)\n\nThe settings for the cluster. This parameter indicates whether CloudWatch Container Insights is enabled or disabled for a cluster.\n\n(structure)\n\nThe settings to use when creating a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster.\n\nname -> (string)\n\nThe name of the cluster setting. The only supported value is containerInsights .\n\nvalue -> (string)\n\nThe value to set for the cluster setting. The supported values are enabled and disabled . If enabled is specified, CloudWatch Container Insights will be enabled for the cluster, otherwise it will be disabled unless the containerInsights account setting is enabled. If a cluster value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\ncapacityProviders -> (list)\n\nThe capacity providers associated with the cluster.\n\n(string)\n\ndefaultCapacityProviderStrategy -> (list)\n\nThe default capacity provider strategy for the cluster. When services or tasks are run in the cluster with no launch type or capacity provider strategy specified, the default capacity provider strategy is used.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nattachments -> (list)\n\nThe resources attached to a cluster. When using a capacity provider with a cluster, the Auto Scaling plan that is created will be returned as a cluster attachment.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nattachmentsStatus -> (string)\n\nThe status of the capacity providers associated with the cluster. The following are the states that will be returned:\n\nUPDATE_IN_PROGRESS\n\nThe available capacity providers for the cluster are updating. This occurs when the Auto Scaling plan is provisioning or deprovisioning.\n\nUPDATE_COMPLETE\n\nThe capacity providers have successfully updated.\n\nUPDATE_FAILED\n\nThe capacity provider updates failed.\n\nfailures -> (list)\n\nAny failures associated with the call.\n\n(structure)\n\nA failed resource. For a list of common causes, see API failure reasons in the Amazon Elastic Container Service Developer Guide .\n\narn -> (string)\n\nThe Amazon Resource Name (ARN) of the failed resource.\n\nreason -> (string)\n\nThe reason for the failure.\n\ndetail -> (string)\n\nThe details of the failure.",
      "command_examples": "Examples\n\nTo describe a cluster\n\nThe following describe-clusters example retrieves details about the specified cluster.\n\naws ecs describe-clusters --cluster default\n\n\nOutput:\n\n{\n    \"clusters\": [\n        {\n            \"status\": \"ACTIVE\",\n            \"clusterName\": \"default\",\n            \"registeredContainerInstancesCount\": 0,\n            \"pendingTasksCount\": 0,\n            \"runningTasksCount\": 0,\n            \"activeServicesCount\": 1,\n            \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/default\"\n        }\n    ],\n    \"failures\": []\n}\n\n\nFor more information, see Amazon ECS Clusters in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "describe-container-instances",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describe-container-instances.html",
      "command_description": "Description\n\nDescribes one or more container instances. Returns metadata about each container instance requested.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-container-instances\n[--cluster <value>]\n--container-instances <value>\n[--include <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--container-instances <value>",
        "[--include <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the container instances to describe. If you do not specify a cluster, the default cluster is assumed. This parameter is required if the container instance or container instances you are describing were launched in any cluster other than the default cluster.\n\n--container-instances (list)\n\nA list of up to 100 container instance IDs or full Amazon Resource Name (ARN) entries.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--include (list)\n\nSpecifies whether you want to see the resource tags for the container instance. If TAGS is specified, the tags are included in the response. If this field is omitted, tags are not included in the response.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  TAGS\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncontainerInstances -> (list)\n\nThe list of container instances.\n\n(structure)\n\nAn EC2 instance that is running the Amazon ECS agent and has been registered with a cluster.\n\ncontainerInstanceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the container instance. The ARN contains the arn:aws:ecs namespace, followed by the Region of the container instance, the Amazon Web Services account ID of the container instance owner, the container-instance namespace, and then the container instance ID. For example, arn:aws:ecs:region:aws_account_id:container-instance/container_instance_ID .\n\nec2InstanceId -> (string)\n\nThe ID of the container instance. For Amazon EC2 instances, this value is the Amazon EC2 instance ID. For external instances, this value is the Amazon Web Services Systems Manager managed instance ID.\n\ncapacityProviderName -> (string)\n\nThe capacity provider associated with the container instance.\n\nversion -> (long)\n\nThe version counter for the container instance. Every time a container instance experiences a change that triggers a CloudWatch event, the version counter is incremented. If you are replicating your Amazon ECS container instance state with CloudWatch Events, you can compare the version of a container instance reported by the Amazon ECS APIs with the version reported in CloudWatch Events for the container instance (inside the detail object) to verify that the version in your event stream is current.\n\nversionInfo -> (structure)\n\nThe version information for the Amazon ECS container agent and Docker daemon running on the container instance.\n\nagentVersion -> (string)\n\nThe version number of the Amazon ECS container agent.\n\nagentHash -> (string)\n\nThe Git commit hash for the Amazon ECS container agent build on the amazon-ecs-agent GitHub repository.\n\ndockerVersion -> (string)\n\nThe Docker version running on the container instance.\n\nremainingResources -> (list)\n\nFor CPU and memory resource types, this parameter describes the remaining CPU and memory that has not already been allocated to tasks and is therefore available for new tasks. For port resource types, this parameter describes the ports that were reserved by the Amazon ECS container agent (at instance registration time) and any task containers that have reserved port mappings on the host (with the host or bridge network mode). Any port that is not specified here is available for new tasks.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nregisteredResources -> (list)\n\nFor CPU and memory resource types, this parameter describes the amount of each resource that was available on the container instance when the container agent registered it with Amazon ECS. This value represents the total amount of CPU and memory that can be allocated on this container instance to tasks. For port resource types, this parameter describes the ports that were reserved by the Amazon ECS container agent when it registered the container instance with Amazon ECS.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nstatus -> (string)\n\nThe status of the container instance. The valid values are REGISTERING , REGISTRATION_FAILED , ACTIVE , INACTIVE , DEREGISTERING , or DRAINING .\n\nIf your account has opted in to the awsvpcTrunking account setting, then any newly registered container instance will transition to a REGISTERING status while the trunk elastic network interface is provisioned for the instance. If the registration fails, the instance will transition to a REGISTRATION_FAILED status. You can describe the container instance and see the reason for failure in the statusReason parameter. Once the container instance is terminated, the instance transitions to a DEREGISTERING status while the trunk elastic network interface is deprovisioned. The instance then transitions to an INACTIVE status.\n\nThe ACTIVE status indicates that the container instance can accept tasks. The DRAINING indicates that new tasks are not placed on the container instance and any service tasks running on the container instance are removed if possible. For more information, see Container Instance Draining in the Amazon Elastic Container Service Developer Guide .\n\nstatusReason -> (string)\n\nThe reason that the container instance reached its current status.\n\nagentConnected -> (boolean)\n\nThis parameter returns true if the agent is connected to Amazon ECS. Registered instances with an agent that may be unhealthy or stopped return false . Only instances connected to an agent can accept placement requests.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks on the container instance that are in the RUNNING status.\n\npendingTasksCount -> (integer)\n\nThe number of tasks on the container instance that are in the PENDING status.\n\nagentUpdateStatus -> (string)\n\nThe status of the most recent agent update. If an update has never been requested, this value is NULL .\n\nattributes -> (list)\n\nThe attributes set for the container instance, either by the Amazon ECS container agent at instance registration or manually with the PutAttributes operation.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nregisteredAt -> (timestamp)\n\nThe Unix timestamp for when the container instance was registered.\n\nattachments -> (list)\n\nThe resources attached to a container instance, such as elastic network interfaces.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the container instance to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nfailures -> (list)\n\nAny failures associated with the call.\n\n(structure)\n\nA failed resource. For a list of common causes, see API failure reasons in the Amazon Elastic Container Service Developer Guide .\n\narn -> (string)\n\nThe Amazon Resource Name (ARN) of the failed resource.\n\nreason -> (string)\n\nThe reason for the failure.\n\ndetail -> (string)\n\nThe details of the failure.",
      "command_examples": "Examples\n\nTo describe container instance\n\nThe following describe-container-instances example retrieves details for a container instance in the update cluster, using the container instance UUID as an identifier.\n\naws ecs describe-container-instances \\\n    --cluster update \\\n    --container-instances a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\n\n\nOutput:\n\n{\n    \"failures\": [],\n    \"containerInstances\": [\n        {\n            \"status\": \"ACTIVE\",\n            \"registeredResources\": [\n                {\n                    \"integerValue\": 2048,\n                    \"longValue\": 0,\n                    \"type\": \"INTEGER\",\n                    \"name\": \"CPU\",\n                    \"doubleValue\": 0.0\n                },\n                {\n                    \"integerValue\": 3955,\n                    \"longValue\": 0,\n                    \"type\": \"INTEGER\",\n                    \"name\": \"MEMORY\",\n                    \"doubleValue\": 0.0\n                },\n                {\n                    \"name\": \"PORTS\",\n                    \"longValue\": 0,\n                    \"doubleValue\": 0.0,\n                    \"stringSetValue\": [\n                        \"22\",\n                        \"2376\",\n                        \"2375\",\n                        \"51678\"\n                    ],\n                    \"type\": \"STRINGSET\",\n                    \"integerValue\": 0\n                }\n            ],\n            \"ec2InstanceId\": \"i-A1B2C3D4\",\n            \"agentConnected\": true,\n            \"containerInstanceArn\": \"arn:aws:ecs:us-west-2:123456789012:container-instance/a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\",\n            \"pendingTasksCount\": 0,\n            \"remainingResources\": [\n                {\n                    \"integerValue\": 2048,\n                    \"longValue\": 0,\n                    \"type\": \"INTEGER\",\n                    \"name\": \"CPU\",\n                    \"doubleValue\": 0.0\n                },\n                {\n                    \"integerValue\": 3955,\n                    \"longValue\": 0,\n                    \"type\": \"INTEGER\",\n                    \"name\": \"MEMORY\",\n                    \"doubleValue\": 0.0\n                },\n                {\n                    \"name\": \"PORTS\",\n                    \"longValue\": 0,\n                    \"doubleValue\": 0.0,\n                    \"stringSetValue\": [\n                        \"22\",\n                        \"2376\",\n                        \"2375\",\n                        \"51678\"\n                    ],\n                    \"type\": \"STRINGSET\",\n                    \"integerValue\": 0\n                }\n            ],\n            \"runningTasksCount\": 0,\n            \"versionInfo\": {\n                \"agentVersion\": \"1.0.0\",\n                \"agentHash\": \"4023248\",\n                \"dockerVersion\": \"DockerVersion: 1.5.0\"\n            }\n        }\n    ]\n}\n\n\nFor more information, see Amazon ECS Container Instances in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "describe-services",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describe-services.html",
      "command_description": "Description\n\nDescribes the specified services running in your cluster.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-services\n[--cluster <value>]\n--services <value>\n[--include <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--services <value>",
        "[--include <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN)the cluster that hosts the service to describe. If you do not specify a cluster, the default cluster is assumed. This parameter is required if the service or services you are describing were launched in any cluster other than the default cluster.\n\n--services (list)\n\nA list of services to describe. You may specify up to 10 services to describe in a single operation.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--include (list)\n\nSpecifies whether you want to see the resource tags for the service. If TAGS is specified, the tags are included in the response. If this field is omitted, tags are not included in the response.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  TAGS\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nservices -> (list)\n\nThe list of services described.\n\n(structure)\n\nDetails on a service within a cluster\n\nserviceArn -> (string)\n\nThe ARN that identifies the service. The ARN contains the arn:aws:ecs namespace, followed by the Region of the service, the Amazon Web Services account ID of the service owner, the service namespace, and then the service name. For example, arn:aws:ecs:region:012345678910:service/my-service .\n\nserviceName -> (string)\n\nThe name of your service. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. Service names must be unique within a cluster, but you can have similarly named services in multiple clusters within a Region or across multiple Regions.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that hosts the service.\n\nloadBalancers -> (list)\n\nA list of Elastic Load Balancing load balancer objects, containing the load balancer name, the container name (as it appears in a container definition), and the container port to access from the load balancer.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this service. For more information, see Service Discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nstatus -> (string)\n\nThe status of the service. The valid values are ACTIVE , DRAINING , or INACTIVE .\n\ndesiredCount -> (integer)\n\nThe desired number of instantiations of the task definition to keep running on the service. This value is specified when the service is created with CreateService , and it can be modified with UpdateService .\n\nrunningCount -> (integer)\n\nThe number of tasks in the cluster that are in the RUNNING state.\n\npendingCount -> (integer)\n\nThe number of tasks in the cluster that are in the PENDING state.\n\nlaunchType -> (string)\n\nThe launch type the service is using. When using the DescribeServices API, this field is omitted if the service was created using a capacity provider strategy.\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy the service is using. When using the DescribeServices API, this field is omitted if the service was created using a launch type.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe platform version on which to run your service. A platform version is only specified for tasks hosted on Fargate. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the service are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX .\n\ntaskDefinition -> (string)\n\nThe task definition to use for tasks in the service. This value is specified when the service is created with CreateService , and it can be modified with UpdateService .\n\ndeploymentConfiguration -> (structure)\n\nOptional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.\n\ndeploymentCircuitBreaker -> (structure)\n\nNote\n\nThe deployment circuit breaker can only be used for services using the rolling update (ECS ) deployment type.\n\nThe deployment circuit breaker determines whether a service deployment will fail if the service can’t reach a steady state. If deployment circuit breaker is enabled, a service deployment will transition to a failed state and stop launching new tasks. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nenable -> (boolean)\n\nWhether to enable the deployment circuit breaker logic for the service.\n\nrollback -> (boolean)\n\nWhether to enable Amazon ECS to roll back the service if a service deployment fails. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nmaximumPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the maximum percent parameter represents an upper limit on the number of tasks in a service that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desired number of tasks (rounded down to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to define the deployment batch size. For example, if your service has a desired number of four tasks and a maximum percent value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default value for maximum percent is 200%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the maximum percent value is set to the default value and is used to define the upper limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the maximum percent value is not used, although it is returned when describing your service.\n\nminimumHealthyPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the minimum healthy percent represents a lower limit on the number of tasks in a service that must remain in the RUNNING state during a deployment, as a percentage of the desired number of tasks (rounded up to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a desired number of four tasks and a minimum healthy percent of 50%, the scheduler may stop two existing tasks to free up cluster capacity before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state; tasks for services that do use a load balancer are considered healthy if they are in the RUNNING state and they are reported as healthy by the load balancer. The default value for minimum healthy percent is 100%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the minimum healthy percent value is set to the default value and is used to define the lower limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the minimum healthy percent value is not used, although it is returned when describing your service.\n\ntaskSets -> (list)\n\nInformation about a set of Amazon ECS tasks in either an CodeDeploy or an EXTERNAL deployment. An Amazon ECS task set includes details such as the desired number of tasks, how many tasks are running, and whether the task set serves production traffic.\n\n(structure)\n\nInformation about a set of Amazon ECS tasks in either an CodeDeploy or an EXTERNAL deployment. An Amazon ECS task set includes details such as the desired number of tasks, how many tasks are running, and whether the task set serves production traffic.\n\nid -> (string)\n\nThe ID of the task set.\n\ntaskSetArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task set.\n\nserviceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service the task set exists in.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that the service that hosts the task set exists in.\n\nstartedBy -> (string)\n\nThe tag specified when a task set is started. If the task set is created by an CodeDeploy deployment, the startedBy parameter is CODE_DEPLOY . For a task set created for an external deployment, the startedBy field isn’t used.\n\nexternalId -> (string)\n\nThe external ID associated with the task set.\n\nIf a task set is created by an CodeDeploy deployment, the externalId parameter contains the CodeDeploy deployment ID.\n\nIf a task set is created for an external deployment and is associated with a service discovery registry, the externalId parameter contains the ECS_TASK_SET_EXTERNAL_ID Cloud Map attribute.\n\nstatus -> (string)\n\nThe status of the task set. The following describes each state:\n\nPRIMARY\n\nThe task set is serving production traffic.\n\nACTIVE\n\nThe task set is not serving production traffic.\n\nDRAINING\n\nThe tasks in the task set are being stopped and their corresponding targets are being deregistered from their target group.\n\ntaskDefinition -> (string)\n\nThe task definition the task set is using.\n\ncomputedDesiredCount -> (integer)\n\nThe computed desired count for the task set. This is calculated by multiplying the service’s desiredCount by the task set’s scale percentage. The result is always rounded up. For example, if the computed desired count is 1.2, it rounds up to 2 tasks.\n\npendingCount -> (integer)\n\nThe number of tasks in the task set that are in the PENDING status during a deployment. A task in the PENDING state is preparing to enter the RUNNING state. A task set enters the PENDING status when it launches for the first time or when it is restarted after being in the STOPPED state.\n\nrunningCount -> (integer)\n\nThe number of tasks in the task set that are in the RUNNING status during a deployment. A task in the RUNNING state is running and ready for use.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was last updated.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the task set are using. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy associated with the task set.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe Fargate platform version on which the tasks in the task set are running. A platform version is only specified for tasks run on Fargate. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the set are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks in the set must have the same value.\n\nnetworkConfiguration -> (structure)\n\nThe network configuration for the task set.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nloadBalancers -> (list)\n\nDetails on a load balancer that is used with a task set.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this task set. For more information, see Service discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nscale -> (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nstabilityStatus -> (string)\n\nThe stability status, which indicates whether the task set has reached a steady state. If the following conditions are met, the task set will be in STEADY_STATE :\n\nThe task runningCount is equal to the computedDesiredCount .\n\nThe pendingCount is 0 .\n\nThere are no tasks running on container instances in the DRAINING status.\n\nAll tasks are reporting a healthy status from the load balancers, service discovery, and container health checks.\n\nIf any of those conditions are not met, the stability status returns STABILIZING .\n\nstabilityStatusAt -> (timestamp)\n\nThe Unix timestamp for when the task set stability status was retrieved.\n\ntags -> (list)\n\nThe metadata that you apply to the task set to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ndeployments -> (list)\n\nThe current state of deployments for the service.\n\n(structure)\n\nThe details of an Amazon ECS service deployment. This is used only when a service uses the ECS deployment controller type.\n\nid -> (string)\n\nThe ID of the deployment.\n\nstatus -> (string)\n\nThe status of the deployment. The following describes each state:\n\nPRIMARY\n\nThe most recent deployment of a service.\n\nACTIVE\n\nA service deployment that still has running tasks, but are in the process of being replaced with a new PRIMARY deployment.\n\nINACTIVE\n\nA deployment that has been completely replaced.\n\ntaskDefinition -> (string)\n\nThe most recent task definition that was specified for the tasks in the service to use.\n\ndesiredCount -> (integer)\n\nThe most recent desired count of tasks that was specified for the service to deploy or maintain.\n\npendingCount -> (integer)\n\nThe number of tasks in the deployment that are in the PENDING status.\n\nrunningCount -> (integer)\n\nThe number of tasks in the deployment that are in the RUNNING status.\n\nfailedTasks -> (integer)\n\nThe number of consecutively failed tasks in the deployment. A task is considered a failure if the service scheduler can’t launch the task, the task doesn’t transition to a RUNNING state, or if it fails any of its defined health checks and is stopped.\n\nNote\n\nOnce a service deployment has one or more successfully running tasks, the failed task count resets to zero and stops being evaluated.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the service deployment was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the service deployment was last updated.\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy that the deployment is using.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the service are using. For more information, see Amazon ECS Launch Types in the Amazon Elastic Container Service Developer Guide .\n\nplatformVersion -> (string)\n\nThe platform version on which your tasks in the service are running. A platform version is only specified for tasks using the Fargate launch type. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the service, or tasks are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX. .\n\nnetworkConfiguration -> (structure)\n\nThe VPC subnet and security group configuration for tasks that receive their own elastic network interface by using the awsvpc networking mode.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nrolloutState -> (string)\n\nNote\n\nThe rolloutState of a service is only returned for services that use the rolling update (ECS ) deployment type that are not behind a Classic Load Balancer.\n\nThe rollout state of the deployment. When a service deployment is started, it begins in an IN_PROGRESS state. When the service reaches a steady state, the deployment will transition to a COMPLETED state. If the service fails to reach a steady state and circuit breaker is enabled, the deployment will transition to a FAILED state. A deployment in FAILED state will launch no new tasks. For more information, see DeploymentCircuitBreaker .\n\nrolloutStateReason -> (string)\n\nA description of the rollout state of a deployment.\n\nroleArn -> (string)\n\nThe ARN of the IAM role associated with the service that allows the Amazon ECS container agent to register container instances with an Elastic Load Balancing load balancer.\n\nevents -> (list)\n\nThe event stream for your service. A maximum of 100 of the latest events are displayed.\n\n(structure)\n\nDetails on an event associated with a service.\n\nid -> (string)\n\nThe ID string of the event.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the event was triggered.\n\nmessage -> (string)\n\nThe event message.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the service was created.\n\nplacementConstraints -> (list)\n\nThe placement constraints for the tasks in the service.\n\n(structure)\n\nAn object representing a constraint on task placement. For more information, see Task Placement Constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you are using the Fargate launch type, task placement constraints are not supported.\n\ntype -> (string)\n\nThe type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. The expression can have a maximum length of 2000 characters. You can’t specify an expression if the constraint type is distinctInstance . For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\nplacementStrategy -> (list)\n\nThe placement strategy that determines how tasks for the service are placed.\n\n(structure)\n\nThe task placement strategy for a task or service. For more information, see Task Placement Strategies in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).\n\nfield -> (string)\n\nThe field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host , which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone . For the binpack placement strategy, valid values are cpu and memory . For the random placement strategy, this field is not used.\n\nnetworkConfiguration -> (structure)\n\nThe VPC subnet and security group configuration for tasks that receive their own elastic network interface by using the awsvpc networking mode.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nhealthCheckGracePeriodSeconds -> (integer)\n\nThe period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started.\n\nschedulingStrategy -> (string)\n\nThe scheduling strategy to use for the service. For more information, see Services .\n\nThere are two service scheduler strategies available:\n\nREPLICA -The replica scheduling strategy places and maintains the desired number of tasks across your cluster. By default, the service scheduler spreads tasks across Availability Zones. You can use task placement strategies and constraints to customize task placement decisions.\n\nDAEMON -The daemon scheduling strategy deploys exactly one task on each active container instance that meets all of the task placement constraints that you specify in your cluster. The service scheduler also evaluates the task placement constraints for running tasks and will stop tasks that do not meet the placement constraints.\n\nNote\n\nFargate tasks do not support the DAEMON scheduling strategy.\n\ndeploymentController -> (structure)\n\nThe deployment controller type the service is using. When using the DescribeServices API, this field is omitted if the service is using the ECS deployment controller type.\n\ntype -> (string)\n\nThe deployment controller type to use.\n\nThere are three deployment controller types available:\n\nECS\n\nThe rolling update (ECS ) deployment type involves replacing the current running version of the container with the latest version. The number of containers Amazon ECS adds or removes from the service during a rolling update is controlled by adjusting the minimum and maximum number of healthy tasks allowed during a service deployment, as specified in the DeploymentConfiguration .\n\nCODE_DEPLOY\n\nThe blue/green (CODE_DEPLOY ) deployment type uses the blue/green deployment model powered by CodeDeploy, which allows you to verify a new deployment of a service before sending production traffic to it.\n\nEXTERNAL\n\nThe external (EXTERNAL ) deployment type enables you to use any third-party deployment controller for full control over the deployment process for an Amazon ECS service.\n\ntags -> (list)\n\nThe metadata that you apply to the service to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ncreatedBy -> (string)\n\nThe principal that created the service.\n\nenableECSManagedTags -> (boolean)\n\nSpecifies whether to enable Amazon ECS managed tags for the tasks in the service. For more information, see Tagging Your Amazon ECS Resources in the Amazon Elastic Container Service Developer Guide .\n\npropagateTags -> (string)\n\nSpecifies whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags are not propagated.\n\nenableExecuteCommand -> (boolean)\n\nWhether or not the execute command functionality is enabled for the service. If true , the execute command functionality is enabled for all containers in tasks as part of the service.\n\nfailures -> (list)\n\nAny failures associated with the call.\n\n(structure)\n\nA failed resource. For a list of common causes, see API failure reasons in the Amazon Elastic Container Service Developer Guide .\n\narn -> (string)\n\nThe Amazon Resource Name (ARN) of the failed resource.\n\nreason -> (string)\n\nThe reason for the failure.\n\ndetail -> (string)\n\nThe details of the failure.",
      "command_examples": "Examples\n\nTo describe a service\n\nThe following describe-services example retrieves details for the my-http-service service in the default cluster.\n\naws ecs describe-services --services my-http-service\n\n\nOutput:\n\n{\n    \"services\": [\n        {\n            \"status\": \"ACTIVE\",\n            \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/amazon-ecs-sample:1\",\n            \"pendingCount\": 0,\n            \"loadBalancers\": [],\n            \"desiredCount\": 10,\n            \"createdAt\": 1466801808.595,\n            \"serviceName\": \"my-http-service\",\n            \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/default\",\n            \"serviceArn\": \"arn:aws:ecs:us-west-2:123456789012:service/my-http-service\",\n            \"deployments\": [\n                {\n                    \"status\": \"PRIMARY\",\n                    \"pendingCount\": 0,\n                    \"createdAt\": 1466801808.595,\n                    \"desiredCount\": 10,\n                    \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/amazon-ecs-sample:1\",\n                    \"updatedAt\": 1428326312.703,\n                    \"id\": \"ecs-svc/1234567890123456789\",\n                    \"runningCount\": 10\n                }\n            ],\n            \"events\": [\n                {\n                    \"message\": \"(service my-http-service) has reached a steady state.\",\n                    \"id\": \"a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\",\n                    \"createdAt\": 1466801812.435\n                }\n            ],\n            \"runningCount\": 10\n        }\n    ],\n    \"failures\": []\n}\n\n\nFor more information, see Services in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "describe-task-definition",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describe-task-definition.html",
      "command_description": "Description\n\nDescribes a task definition. You can specify a family and revision to find information about a specific task definition, or you can simply specify the family to find the latest ACTIVE revision in that family.\n\nNote\n\nYou can only describe INACTIVE task definitions while an active task or service references them.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-task-definition\n--task-definition <value>\n[--include <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--task-definition <value>",
        "[--include <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--task-definition (string)\n\nThe family for the latest ACTIVE revision, family and revision (family:revision ) for a specific revision in the family, or full Amazon Resource Name (ARN) of the task definition to describe.\n\n--include (list)\n\nSpecifies whether to see the resource tags for the task definition. If TAGS is specified, the tags are included in the response. If this field is omitted, tags are not included in the response.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  TAGS\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntaskDefinition -> (structure)\n\nThe full task definition description.\n\ntaskDefinitionArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the task definition.\n\ncontainerDefinitions -> (list)\n\nA list of container definitions in JSON format that describe the different containers that make up your task. For more information about container definition parameters and defaults, see Amazon ECS Task Definitions in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nContainer definitions are used in task definitions to describe the different containers that are launched as part of a task.\n\nname -> (string)\n\nThe name of a container. If you are linking multiple containers together in a task definition, the name of one container can be entered in the links of another container to connect the containers. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This parameter maps to name in the Create a container section of the Docker Remote API and the --name option to docker run .\n\nimage -> (string)\n\nThe image used to start a container. This string is passed directly to the Docker daemon. Images in the Docker Hub registry are available by default. Other repositories are specified with either `` repository-url /image :tag `` or `` repository-url /image @*digest* `` . Up to 255 letters (uppercase and lowercase), numbers, hyphens, underscores, colons, periods, forward slashes, and number signs are allowed. This parameter maps to Image in the Create a container section of the Docker Remote API and the IMAGE parameter of docker run .\n\nWhen a new task starts, the Amazon ECS container agent pulls the latest version of the specified image and tag for the container to use. However, subsequent updates to a repository image are not propagated to already running tasks.\n\nImages in Amazon ECR repositories can be specified by either using the full registry/repository:tag or registry/repository@digest . For example, 012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>:latest or 012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>@sha256:94afd1f2e64d908bc90dbca0035a5b567EXAMPLE .\n\nImages in official repositories on Docker Hub use a single name (for example, ubuntu or mongo ).\n\nImages in other repositories on Docker Hub are qualified with an organization name (for example, amazon/amazon-ecs-agent ).\n\nImages in other online repositories are qualified further by a domain name (for example, quay.io/assemblyline/ubuntu ).\n\nrepositoryCredentials -> (structure)\n\nThe private repository authentication credentials to use.\n\ncredentialsParameter -> (string)\n\nThe Amazon Resource Name (ARN) of the secret containing the private repository credentials.\n\nNote\n\nWhen you are using the Amazon ECS API, CLI, or Amazon Web Services SDK, if the secret exists in the same Region as the task that you are launching then you can use either the full ARN or the name of the secret. When you are using the Amazon Web Services Management Console, you must specify the full ARN of the secret.\n\ncpu -> (integer)\n\nThe number of cpu units reserved for the container. This parameter maps to CpuShares in the Create a container section of the Docker Remote API and the --cpu-shares option to docker run .\n\nThis field is optional for tasks using the Fargate launch type, and the only requirement is that the total amount of CPU reserved for all containers within a task be lower than the task-level cpu value.\n\nNote\n\nYou can determine the number of CPU units that are available per EC2 instance type by multiplying the vCPUs listed for that instance type on the Amazon EC2 Instances detail page by 1,024.\n\nLinux containers share unallocated CPU units with other containers on the container instance with the same ratio as their allocated amount. For example, if you run a single-container task on a single-core instance type with 512 CPU units specified for that container, and that is the only task running on the container instance, that container could use the full 1,024 CPU unit share at any given time. However, if you launched another copy of the same task on that container instance, each task would be guaranteed a minimum of 512 CPU units when needed, and each container could float to higher CPU usage if the other container was not using it, but if both tasks were 100% active all of the time, they would be limited to 512 CPU units.\n\nOn Linux container instances, the Docker daemon on the container instance uses the CPU value to calculate the relative CPU share ratios for running containers. For more information, see CPU share constraint in the Docker documentation. The minimum valid CPU share value that the Linux kernel allows is 2. However, the CPU parameter is not required, and you can use CPU values below 2 in your container definitions. For CPU values below 2 (including null), the behavior varies based on your Amazon ECS container agent version:\n\nAgent versions less than or equal to 1.1.0: Null and zero CPU values are passed to Docker as 0, which Docker then converts to 1,024 CPU shares. CPU values of 1 are passed to Docker as 1, which the Linux kernel converts to two CPU shares.\n\nAgent versions greater than or equal to 1.2.0: Null, zero, and CPU values of 1 are passed to Docker as 2.\n\nOn Windows container instances, the CPU limit is enforced as an absolute limit, or a quota. Windows containers only have access to the specified amount of CPU that is described in the task definition. A null or zero CPU value is passed to Docker as 0 , which Windows interprets as 1% of one CPU.\n\nmemory -> (integer)\n\nThe amount (in MiB) of memory to present to the container. If your container attempts to exceed the memory specified here, the container is killed. The total amount of memory reserved for all containers within a task must be lower than the task memory value, if one is specified. This parameter maps to Memory in the Create a container section of the Docker Remote API and the --memory option to docker run .\n\nIf using the Fargate launch type, this parameter is optional.\n\nIf using the EC2 launch type, you must specify either a task-level memory value or a container-level memory value. If you specify both a container-level memory and memoryReservation value, memory must be greater than memoryReservation . If you specify memoryReservation , then that value is subtracted from the available memory resources for the container instance on which the container is placed. Otherwise, the value of memory is used.\n\nThe Docker daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.\n\nmemoryReservation -> (integer)\n\nThe soft limit (in MiB) of memory to reserve for the container. When system memory is under heavy contention, Docker attempts to keep the container memory to this soft limit. However, your container can consume more memory when it needs to, up to either the hard limit specified with the memory parameter (if applicable), or all of the available memory on the container instance, whichever comes first. This parameter maps to MemoryReservation in the Create a container section of the Docker Remote API and the --memory-reservation option to docker run .\n\nIf a task-level memory value is not specified, you must specify a non-zero integer for one or both of memory or memoryReservation in a container definition. If you specify both, memory must be greater than memoryReservation . If you specify memoryReservation , then that value is subtracted from the available memory resources for the container instance on which the container is placed. Otherwise, the value of memory is used.\n\nFor example, if your container normally uses 128 MiB of memory, but occasionally bursts to 256 MiB of memory for short periods of time, you can set a memoryReservation of 128 MiB, and a memory hard limit of 300 MiB. This configuration would allow the container to only reserve 128 MiB of memory from the remaining resources on the container instance, but also allow the container to consume more memory resources when needed.\n\nThe Docker daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.\n\nlinks -> (list)\n\nThe links parameter allows containers to communicate with each other without the need for port mappings. This parameter is only supported if the network mode of a task definition is bridge . The name:internalName construct is analogous to name:alias in Docker links. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. For more information about linking Docker containers, go to Legacy container links in the Docker documentation. This parameter maps to Links in the Create a container section of the Docker Remote API and the --link option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nWarning\n\nContainers that are collocated on a single container instance may be able to communicate with each other without requiring links or host port mappings. Network isolation is achieved on the container instance using security groups and VPC settings.\n\n(string)\n\nportMappings -> (list)\n\nThe list of port mappings for the container. Port mappings allow containers to access ports on the host container instance to send or receive traffic.\n\nFor task definitions that use the awsvpc network mode, you should only specify the containerPort . The hostPort can be left blank or it must be the same value as the containerPort .\n\nPort mappings on Windows use the NetNAT gateway address rather than localhost . There is no loopback for port mappings on Windows, so you cannot access a container’s mapped port from the host itself.\n\nThis parameter maps to PortBindings in the Create a container section of the Docker Remote API and the --publish option to docker run . If the network mode of a task definition is set to none , then you can’t specify port mappings. If the network mode of a task definition is set to host , then host ports must either be undefined or they must match the container port in the port mapping.\n\nNote\n\nAfter a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the Network Bindings section of a container description for a selected task in the Amazon ECS console. The assignments are also visible in the networkBindings section DescribeTasks responses.\n\n(structure)\n\nPort mappings allow containers to access ports on the host container instance to send or receive traffic. Port mappings are specified as part of the container definition.\n\nIf you are using containers in a task with the awsvpc or host network mode, exposed ports should be specified using containerPort . The hostPort can be left blank or it must be the same value as the containerPort .\n\nNote\n\nYou cannot expose the same container port for multiple protocols. An error will be returned if this is attempted\n\nAfter a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the networkBindings section of DescribeTasks API responses.\n\ncontainerPort -> (integer)\n\nThe port number on the container that is bound to the user-specified or automatically assigned host port.\n\nIf you are using containers in a task with the awsvpc or host network mode, exposed ports should be specified using containerPort .\n\nIf you are using containers in a task with the bridge network mode and you specify a container port and not a host port, your container automatically receives a host port in the ephemeral port range. For more information, see hostPort . Port mappings that are automatically assigned in this way do not count toward the 100 reserved ports limit of a container instance.\n\nhostPort -> (integer)\n\nThe port number on the container instance to reserve for your container.\n\nIf you are using containers in a task with the awsvpc or host network mode, the hostPort can either be left blank or set to the same value as the containerPort .\n\nIf you are using containers in a task with the bridge network mode, you can specify a non-reserved host port for your container port mapping, or you can omit the hostPort (or set it to 0 ) while specifying a containerPort and your container automatically receives a port in the ephemeral port range for your container instance operating system and Docker version.\n\nThe default ephemeral port range for Docker version 1.6.0 and later is listed on the instance under /proc/sys/net/ipv4/ip_local_port_range . If this kernel parameter is unavailable, the default ephemeral port range from 49153 through 65535 is used. Do not attempt to specify a host port in the ephemeral port range as these are reserved for automatic assignment. In general, ports below 32768 are outside of the ephemeral port range.\n\nNote\n\nThe default ephemeral port range from 49153 through 65535 is always used for Docker versions before 1.6.0.\n\nThe default reserved ports are 22 for SSH, the Docker ports 2375 and 2376, and the Amazon ECS container agent ports 51678-51680. Any host port that was previously specified in a running task is also reserved while the task is running (after a task stops, the host port is released). The current reserved ports are displayed in the remainingResources of DescribeContainerInstances output. A container instance can have up to 100 reserved ports at a time, including the default reserved ports. Automatically assigned ports don’t count toward the 100 reserved ports limit.\n\nprotocol -> (string)\n\nThe protocol used for the port mapping. Valid values are tcp and udp . The default is tcp .\n\nessential -> (boolean)\n\nIf the essential parameter of a container is marked as true , and that container fails or stops for any reason, all other containers that are part of the task are stopped. If the essential parameter of a container is marked as false , then its failure does not affect the rest of the containers in a task. If this parameter is omitted, a container is assumed to be essential.\n\nAll tasks must have at least one essential container. If you have an application that is composed of multiple containers, you should group containers that are used for a common purpose into components, and separate the different components into multiple task definitions. For more information, see Application Architecture in the Amazon Elastic Container Service Developer Guide .\n\nentryPoint -> (list)\n\nWarning\n\nEarly versions of the Amazon ECS container agent do not properly handle entryPoint parameters. If you have problems using entryPoint , update your container agent or enter your commands and arguments as command array items instead.\n\nThe entry point that is passed to the container. This parameter maps to Entrypoint in the Create a container section of the Docker Remote API and the --entrypoint option to docker run . For more information, see https://docs.docker.com/engine/reference/builder/#entrypoint .\n\n(string)\n\ncommand -> (list)\n\nThe command that is passed to the container. This parameter maps to Cmd in the Create a container section of the Docker Remote API and the COMMAND parameter to docker run . For more information, see https://docs.docker.com/engine/reference/builder/#cmd . If there are multiple arguments, each argument should be a separated string in the array.\n\n(string)\n\nenvironment -> (list)\n\nThe environment variables to pass to a container. This parameter maps to Env in the Create a container section of the Docker Remote API and the --env option to docker run .\n\nWarning\n\nWe do not recommend using plaintext environment variables for sensitive information, such as credential data.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nenvironmentFiles -> (list)\n\nA list of files containing the environment variables to pass to a container. This parameter maps to the --env-file option to docker run .\n\nYou can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying Environment Variables in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nA list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying environment variables in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nvalue -> (string)\n\nThe Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\ntype -> (string)\n\nThe file type to use. The only supported value is s3 .\n\nmountPoints -> (list)\n\nThe mount points for data volumes in your container.\n\nThis parameter maps to Volumes in the Create a container section of the Docker Remote API and the --volume option to docker run .\n\nWindows containers can mount whole directories on the same drive as $env:ProgramData . Windows containers cannot mount directories on a different drive, and mount point cannot be across drives.\n\n(structure)\n\nDetails on a volume mount point that is used in a container definition.\n\nsourceVolume -> (string)\n\nThe name of the volume to mount. Must be a volume name referenced in the name parameter of task definition volume .\n\ncontainerPath -> (string)\n\nThe path on the container to mount the host volume at.\n\nreadOnly -> (boolean)\n\nIf this value is true , the container has read-only access to the volume. If this value is false , then the container can write to the volume. The default value is false .\n\nvolumesFrom -> (list)\n\nData volumes to mount from another container. This parameter maps to VolumesFrom in the Create a container section of the Docker Remote API and the --volumes-from option to docker run .\n\n(structure)\n\nDetails on a data volume from another container in the same task definition.\n\nsourceContainer -> (string)\n\nThe name of another container within the same task definition from which to mount volumes.\n\nreadOnly -> (boolean)\n\nIf this value is true , the container has read-only access to the volume. If this value is false , then the container can write to the volume. The default value is false .\n\nlinuxParameters -> (structure)\n\nLinux-specific modifications that are applied to the container, such as Linux kernel capabilities. For more information see KernelCapabilities .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\ncapabilities -> (structure)\n\nThe Linux capabilities for the container that are added to or dropped from the default configuration provided by Docker.\n\nNote\n\nFor tasks that use the Fargate launch type, capabilities is supported for all platform versions but the add parameter is only supported if using platform version 1.4.0 or later.\n\nadd -> (list)\n\nThe Linux capabilities for the container that have been added to the default configuration provided by Docker. This parameter maps to CapAdd in the Create a container section of the Docker Remote API and the --cap-add option to docker run .\n\nNote\n\nTasks launched on Fargate only support adding the SYS_PTRACE kernel capability.\n\nValid values: \"ALL\" | \"AUDIT_CONTROL\" | \"AUDIT_WRITE\" | \"BLOCK_SUSPEND\" | \"CHOWN\" | \"DAC_OVERRIDE\" | \"DAC_READ_SEARCH\" | \"FOWNER\" | \"FSETID\" | \"IPC_LOCK\" | \"IPC_OWNER\" | \"KILL\" | \"LEASE\" | \"LINUX_IMMUTABLE\" | \"MAC_ADMIN\" | \"MAC_OVERRIDE\" | \"MKNOD\" | \"NET_ADMIN\" | \"NET_BIND_SERVICE\" | \"NET_BROADCAST\" | \"NET_RAW\" | \"SETFCAP\" | \"SETGID\" | \"SETPCAP\" | \"SETUID\" | \"SYS_ADMIN\" | \"SYS_BOOT\" | \"SYS_CHROOT\" | \"SYS_MODULE\" | \"SYS_NICE\" | \"SYS_PACCT\" | \"SYS_PTRACE\" | \"SYS_RAWIO\" | \"SYS_RESOURCE\" | \"SYS_TIME\" | \"SYS_TTY_CONFIG\" | \"SYSLOG\" | \"WAKE_ALARM\"\n\n(string)\n\ndrop -> (list)\n\nThe Linux capabilities for the container that have been removed from the default configuration provided by Docker. This parameter maps to CapDrop in the Create a container section of the Docker Remote API and the --cap-drop option to docker run .\n\nValid values: \"ALL\" | \"AUDIT_CONTROL\" | \"AUDIT_WRITE\" | \"BLOCK_SUSPEND\" | \"CHOWN\" | \"DAC_OVERRIDE\" | \"DAC_READ_SEARCH\" | \"FOWNER\" | \"FSETID\" | \"IPC_LOCK\" | \"IPC_OWNER\" | \"KILL\" | \"LEASE\" | \"LINUX_IMMUTABLE\" | \"MAC_ADMIN\" | \"MAC_OVERRIDE\" | \"MKNOD\" | \"NET_ADMIN\" | \"NET_BIND_SERVICE\" | \"NET_BROADCAST\" | \"NET_RAW\" | \"SETFCAP\" | \"SETGID\" | \"SETPCAP\" | \"SETUID\" | \"SYS_ADMIN\" | \"SYS_BOOT\" | \"SYS_CHROOT\" | \"SYS_MODULE\" | \"SYS_NICE\" | \"SYS_PACCT\" | \"SYS_PTRACE\" | \"SYS_RAWIO\" | \"SYS_RESOURCE\" | \"SYS_TIME\" | \"SYS_TTY_CONFIG\" | \"SYSLOG\" | \"WAKE_ALARM\"\n\n(string)\n\ndevices -> (list)\n\nAny host devices to expose to the container. This parameter maps to Devices in the Create a container section of the Docker Remote API and the --device option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the devices parameter is not supported.\n\n(structure)\n\nAn object representing a container instance host device.\n\nhostPath -> (string)\n\nThe path for the device on the host container instance.\n\ncontainerPath -> (string)\n\nThe path inside the container at which to expose the host device.\n\npermissions -> (list)\n\nThe explicit permissions to provide to the container for the device. By default, the container has permissions for read , write , and mknod for the device.\n\n(string)\n\ninitProcessEnabled -> (boolean)\n\nRun an init process inside the container that forwards signals and reaps processes. This parameter maps to the --init option to docker run . This parameter requires version 1.25 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nsharedMemorySize -> (integer)\n\nThe value for the size (in MiB) of the /dev/shm volume. This parameter maps to the --shm-size option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the sharedMemorySize parameter is not supported.\n\ntmpfs -> (list)\n\nThe container path, mount options, and size (in MiB) of the tmpfs mount. This parameter maps to the --tmpfs option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the tmpfs parameter is not supported.\n\n(structure)\n\nThe container path, mount options, and size of the tmpfs mount.\n\ncontainerPath -> (string)\n\nThe absolute file path where the tmpfs volume is to be mounted.\n\nsize -> (integer)\n\nThe maximum size (in MiB) of the tmpfs volume.\n\nmountOptions -> (list)\n\nThe list of tmpfs volume mount options.\n\nValid values: \"defaults\" | \"ro\" | \"rw\" | \"suid\" | \"nosuid\" | \"dev\" | \"nodev\" | \"exec\" | \"noexec\" | \"sync\" | \"async\" | \"dirsync\" | \"remount\" | \"mand\" | \"nomand\" | \"atime\" | \"noatime\" | \"diratime\" | \"nodiratime\" | \"bind\" | \"rbind\" | \"unbindable\" | \"runbindable\" | \"private\" | \"rprivate\" | \"shared\" | \"rshared\" | \"slave\" | \"rslave\" | \"relatime\" | \"norelatime\" | \"strictatime\" | \"nostrictatime\" | \"mode\" | \"uid\" | \"gid\" | \"nr_inodes\" | \"nr_blocks\" | \"mpol\"\n\n(string)\n\nmaxSwap -> (integer)\n\nThe total amount of swap memory (in MiB) a container can use. This parameter will be translated to the --memory-swap option to docker run where the value would be the sum of the container memory plus the maxSwap value.\n\nIf a maxSwap value of 0 is specified, the container will not use swap. Accepted values are 0 or any positive integer. If the maxSwap parameter is omitted, the container will use the swap configuration for the container instance it is running on. A maxSwap value must be set for the swappiness parameter to be used.\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the maxSwap parameter is not supported.\n\nswappiness -> (integer)\n\nThis allows you to tune a container’s memory swappiness behavior. A swappiness value of 0 will cause swapping to not happen unless absolutely necessary. A swappiness value of 100 will cause pages to be swapped very aggressively. Accepted values are whole numbers between 0 and 100 . If the swappiness parameter is not specified, a default value of 60 is used. If a value is not specified for maxSwap then this parameter is ignored. This parameter maps to the --memory-swappiness option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the swappiness parameter is not supported.\n\nsecrets -> (list)\n\nThe secrets to pass to the container. For more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nAn object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:\n\nTo inject sensitive data into your containers as environment variables, use the secrets container definition parameter.\n\nTo reference sensitive information in the log configuration of a container, use the secretOptions container definition parameter.\n\nFor more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the secret.\n\nvalueFrom -> (string)\n\nThe secret to expose to the container. The supported values are either the full ARN of the Secrets Manager secret or the full ARN of the parameter in the SSM Parameter Store.\n\nNote\n\nIf the SSM Parameter Store parameter exists in the same Region as the task you are launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.\n\ndependsOn -> (list)\n\nThe dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.\n\nFor tasks using the EC2 launch type, the container instances require at least version 1.26.0 of the container agent to enable container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\n(structure)\n\nThe dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.\n\nYour Amazon ECS container instances require at least version 1.26.0 of the container agent to enable container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\ncontainerName -> (string)\n\nThe name of a container.\n\ncondition -> (string)\n\nThe dependency condition of the container. The following are the available conditions and their behavior:\n\nSTART - This condition emulates the behavior of links and volumes today. It validates that a dependent container is started before permitting other containers to start.\n\nCOMPLETE - This condition validates that a dependent container runs to completion (exits) before permitting other containers to start. This can be useful for nonessential containers that run a script and then exit. This condition cannot be set on an essential container.\n\nSUCCESS - This condition is the same as COMPLETE , but it also requires that the container exits with a zero status. This condition cannot be set on an essential container.\n\nHEALTHY - This condition validates that the dependent container passes its Docker health check before permitting other containers to start. This requires that the dependent container has health checks configured. This condition is confirmed only at task startup.\n\nstartTimeout -> (integer)\n\nTime duration (in seconds) to wait before giving up on resolving dependencies for a container. For example, you specify two containers in a task definition with containerA having a dependency on containerB reaching a COMPLETE , SUCCESS , or HEALTHY status. If a startTimeout value is specified for containerB and it does not reach the desired status within that time then containerA will give up and not start. This results in the task transitioning to a STOPPED state.\n\nNote\n\nWhen the ECS_CONTAINER_START_TIMEOUT container agent configuration variable is used, it is enforced indendently from this start timeout value.\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nFor tasks using the EC2 launch type, your container instances require at least version 1.26.0 of the container agent to enable a container start timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nstopTimeout -> (integer)\n\nTime duration (in seconds) to wait before the container is forcefully killed if it doesn’t exit normally on its own.\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nThe max stop timeout value is 120 seconds and if the parameter is not specified, the default value of 30 seconds is used.\n\nFor tasks using the EC2 launch type, if the stopTimeout parameter is not specified, the value set for the Amazon ECS container agent configuration variable ECS_CONTAINER_STOP_TIMEOUT is used by default. If neither the stopTimeout parameter or the ECS_CONTAINER_STOP_TIMEOUT agent configuration variable are set, then the default values of 30 seconds for Linux containers and 30 seconds on Windows containers are used. Your container instances require at least version 1.26.0 of the container agent to enable a container stop timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nhostname -> (string)\n\nThe hostname to use for your container. This parameter maps to Hostname in the Create a container section of the Docker Remote API and the --hostname option to docker run .\n\nNote\n\nThe hostname parameter is not supported if you are using the awsvpc network mode.\n\nuser -> (string)\n\nThe user to use inside the container. This parameter maps to User in the Create a container section of the Docker Remote API and the --user option to docker run .\n\nWarning\n\nWhen running tasks using the host network mode, you should not run containers using the root user (UID 0). It is considered best practice to use a non-root user.\n\nYou can specify the user using the following formats. If specifying a UID or GID, you must specify it as a positive integer.\n\nuser\n\nuser:group\n\nuid\n\nuid:gid\n\nuser:gid\n\nuid:group\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nworkingDirectory -> (string)\n\nThe working directory in which to run commands inside the container. This parameter maps to WorkingDir in the Create a container section of the Docker Remote API and the --workdir option to docker run .\n\ndisableNetworking -> (boolean)\n\nWhen this parameter is true, networking is disabled within the container. This parameter maps to NetworkDisabled in the Create a container section of the Docker Remote API .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nprivileged -> (boolean)\n\nWhen this parameter is true, the container is given elevated privileges on the host container instance (similar to the root user). This parameter maps to Privileged in the Create a container section of the Docker Remote API and the --privileged option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nreadonlyRootFilesystem -> (boolean)\n\nWhen this parameter is true, the container is given read-only access to its root file system. This parameter maps to ReadonlyRootfs in the Create a container section of the Docker Remote API and the --read-only option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\ndnsServers -> (list)\n\nA list of DNS servers that are presented to the container. This parameter maps to Dns in the Create a container section of the Docker Remote API and the --dns option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(string)\n\ndnsSearchDomains -> (list)\n\nA list of DNS search domains that are presented to the container. This parameter maps to DnsSearch in the Create a container section of the Docker Remote API and the --dns-search option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(string)\n\nextraHosts -> (list)\n\nA list of hostnames and IP address mappings to append to the /etc/hosts file on the container. This parameter maps to ExtraHosts in the Create a container section of the Docker Remote API and the --add-host option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks that use the awsvpc network mode.\n\n(structure)\n\nHostnames and IP address entries that are added to the /etc/hosts file of a container via the extraHosts parameter of its ContainerDefinition .\n\nhostname -> (string)\n\nThe hostname to use in the /etc/hosts entry.\n\nipAddress -> (string)\n\nThe IP address to use in the /etc/hosts entry.\n\ndockerSecurityOptions -> (list)\n\nA list of strings to provide custom labels for SELinux and AppArmor multi-level security systems. This field is not valid for containers in tasks using the Fargate launch type.\n\nWith Windows containers, this parameter can be used to reference a credential spec file when configuring a container for Active Directory authentication. For more information, see Using gMSAs for Windows Containers in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter maps to SecurityOpt in the Create a container section of the Docker Remote API and the --security-opt option to docker run .\n\nNote\n\nThe Amazon ECS container agent running on a container instance must register with the ECS_SELINUX_CAPABLE=true or ECS_APPARMOR_CAPABLE=true environment variables before containers placed on that instance can use these security options. For more information, see Amazon ECS Container Agent Configuration in the Amazon Elastic Container Service Developer Guide .\n\nFor more information about valid values, see Docker Run Security Configuration .\n\nValid values: “no-new-privileges” | “apparmor:PROFILE” | “label:value” | “credentialspec:CredentialSpecFilePath”\n\n(string)\n\ninteractive -> (boolean)\n\nWhen this parameter is true , this allows you to deploy containerized applications that require stdin or a tty to be allocated. This parameter maps to OpenStdin in the Create a container section of the Docker Remote API and the --interactive option to docker run .\n\npseudoTerminal -> (boolean)\n\nWhen this parameter is true , a TTY is allocated. This parameter maps to Tty in the Create a container section of the Docker Remote API and the --tty option to docker run .\n\ndockerLabels -> (map)\n\nA key/value map of labels to add to the container. This parameter maps to Labels in the Create a container section of the Docker Remote API and the --label option to docker run . This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nkey -> (string)\n\nvalue -> (string)\n\nulimits -> (list)\n\nA list of ulimits to set in the container. If a ulimit value is specified in a task definition, it will override the default values set by Docker. This parameter maps to Ulimits in the Create a container section of the Docker Remote API and the --ulimit option to docker run . Valid naming values are displayed in the Ulimit data type.\n\nAmazon ECS tasks hosted on Fargate use the default resource limit values set by the operating system with the exception of the nofile resource limit parameter which Fargate overrides. The nofile resource limit sets a restriction on the number of open files that a container can use. The default nofile soft limit is 1024 and hard limit is 4096 .\n\nThis parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(structure)\n\nThe ulimit settings to pass to the container.\n\nAmazon ECS tasks hosted on Fargate use the default resource limit values set by the operating system with the exception of the nofile resource limit parameter which Fargate overrides. The nofile resource limit sets a restriction on the number of open files that a container can use. The default nofile soft limit is 1024 and hard limit is 4096 .\n\nname -> (string)\n\nThe type of the ulimit .\n\nsoftLimit -> (integer)\n\nThe soft limit for the ulimit type.\n\nhardLimit -> (integer)\n\nThe hard limit for the ulimit type.\n\nlogConfiguration -> (structure)\n\nThe log configuration specification for the container.\n\nThis parameter maps to LogConfig in the Create a container section of the Docker Remote API and the --log-driver option to docker run . By default, containers use the same logging driver that the Docker daemon uses. However the container may use a different logging driver than the Docker daemon by specifying a log driver with this parameter in the container definition. To use a different logging driver for a container, the log system must be configured properly on the container instance (or on a different log server for remote logging options). For more information on the options for different supported log drivers, see Configure logging drivers in the Docker documentation.\n\nNote\n\nAmazon ECS currently supports a subset of the logging drivers available to the Docker daemon (shown in the LogConfiguration data type). Additional log drivers may be available in future releases of the Amazon ECS container agent.\n\nThis parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nNote\n\nThe Amazon ECS container agent running on a container instance must register the logging drivers available on that instance with the ECS_AVAILABLE_LOGGING_DRIVERS environment variable before containers placed on that instance can use these log configuration options. For more information, see Amazon ECS Container Agent Configuration in the Amazon Elastic Container Service Developer Guide .\n\nlogDriver -> (string)\n\nThe log driver to use for the container.\n\nFor tasks on Fargate, the supported log drivers are awslogs , splunk , and awsfirelens .\n\nFor tasks hosted on Amazon EC2 instances, the supported log drivers are awslogs , fluentd , gelf , json-file , journald , logentries ,``syslog`` , splunk , and awsfirelens .\n\nFor more information about using the awslogs log driver, see Using the awslogs log driver in the Amazon Elastic Container Service Developer Guide .\n\nFor more information about using the awsfirelens log driver, see Custom log routing in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you have a custom driver that is not listed, you can fork the Amazon ECS container agent project that is available on GitHub and customize it to work with that driver. We encourage you to submit pull requests for changes that you would like to have included. However, we do not currently provide support for running modified copies of this software.\n\noptions -> (map)\n\nThe configuration options to send to the log driver. This parameter requires version 1.19 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nkey -> (string)\n\nvalue -> (string)\n\nsecretOptions -> (list)\n\nThe secrets to pass to the log configuration. For more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nAn object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:\n\nTo inject sensitive data into your containers as environment variables, use the secrets container definition parameter.\n\nTo reference sensitive information in the log configuration of a container, use the secretOptions container definition parameter.\n\nFor more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the secret.\n\nvalueFrom -> (string)\n\nThe secret to expose to the container. The supported values are either the full ARN of the Secrets Manager secret or the full ARN of the parameter in the SSM Parameter Store.\n\nNote\n\nIf the SSM Parameter Store parameter exists in the same Region as the task you are launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.\n\nhealthCheck -> (structure)\n\nThe container health check command and associated configuration parameters for the container. This parameter maps to HealthCheck in the Create a container section of the Docker Remote API and the HEALTHCHECK parameter of docker run .\n\ncommand -> (list)\n\nA string array representing the command that the container runs to determine if it is healthy. The string array must start with CMD to execute the command arguments directly, or CMD-SHELL to run the command with the container’s default shell.\n\nWhen you use the Amazon Web Services Management Console JSON panel, the Command Line Interface, or the APIs, you should enclose the list of commands in brackets, as shown below.\n\n[ \"CMD-SHELL\", \"curl -f http://localhost/ || exit 1\" ]\n\nYou do not need to include the brackets when you use the Amazon Web Services Management Consoleas shown below.\n\n\"CMD-SHELL\", \"curl -f http://localhost/ || exit 1\"\n\nAn exit code of 0 indicates success, and non-zero exit code indicates failure. For more information, see HealthCheck in the Create a container section of the Docker Remote API .\n\n(string)\n\ninterval -> (integer)\n\nThe time period in seconds between each health check execution. You may specify between 5 and 300 seconds. The default value is 30 seconds.\n\ntimeout -> (integer)\n\nThe time period in seconds to wait for a health check to succeed before it is considered a failure. You may specify between 2 and 60 seconds. The default value is 5.\n\nretries -> (integer)\n\nThe number of times to retry a failed health check before the container is considered unhealthy. You may specify between 1 and 10 retries. The default value is 3.\n\nstartPeriod -> (integer)\n\nThe optional grace period within which to provide containers time to bootstrap before failed health checks count towards the maximum number of retries. You may specify between 0 and 300 seconds. The startPeriod is disabled by default.\n\nNote\n\nIf a health check succeeds within the startPeriod , then the container is considered healthy and any subsequent failures count toward the maximum number of retries.\n\nsystemControls -> (list)\n\nA list of namespaced kernel parameters to set in the container. This parameter maps to Sysctls in the Create a container section of the Docker Remote API and the --sysctl option to docker run .\n\nNote\n\nIt is not recommended that you specify network-related systemControls parameters for multiple containers in a single task that also uses either the awsvpc or host network modes. For tasks that use the awsvpc network mode, the container that is started last determines which systemControls parameters take effect. For tasks that use the host network mode, it changes the container instance’s namespaced kernel parameters as well as the containers.\n\n(structure)\n\nA list of namespaced kernel parameters to set in the container. This parameter maps to Sysctls in the Create a container section of the Docker Remote API and the --sysctl option to docker run .\n\nIt is not recommended that you specify network-related systemControls parameters for multiple containers in a single task that also uses either the awsvpc or host network mode for the following reasons:\n\nFor tasks that use the awsvpc network mode, if you set systemControls for any container, it applies to all containers in the task. If you set different systemControls for multiple containers in a single task, the container that is started last determines which systemControls take effect.\n\nFor tasks that use the host network mode, the systemControls parameter applies to the container instance’s kernel parameter as well as that of all containers of any tasks running on that container instance.\n\nnamespace -> (string)\n\nThe namespaced kernel parameter for which to set a value .\n\nvalue -> (string)\n\nThe value for the namespaced kernel parameter specified in namespace .\n\nresourceRequirements -> (list)\n\nThe type and amount of a resource to assign to a container. The only supported resource is a GPU.\n\n(structure)\n\nThe type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see Working with GPUs on Amazon ECS or Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide\n\nvalue -> (string)\n\nThe value for the specified resource type.\n\nIf the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent will reserve for the container. The number of GPUs reserved for all containers in a task should not exceed the number of available GPUs on the container instance the task is launched on.\n\nIf the InferenceAccelerator type is used, the value should match the deviceName for an InferenceAccelerator specified in a task definition.\n\ntype -> (string)\n\nThe type of resource to assign to a container. The supported values are GPU or InferenceAccelerator .\n\nfirelensConfiguration -> (structure)\n\nThe FireLens configuration for the container. This is used to specify and configure a log router for container logs. For more information, see Custom Log Routing in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe log router to use. The valid values are fluentd or fluentbit .\n\noptions -> (map)\n\nThe options to use when configuring the log router. This field is optional and can be used to specify a custom configuration file or to add additional metadata, such as the task, task definition, cluster, and container instance details to the log event. If specified, the syntax to use is \"options\":{\"enable-ecs-log-metadata\":\"true|false\",\"config-file-type:\"s3|file\",\"config-file-value\":\"arn:aws:s3:::mybucket/fluent.conf|filepath\"} . For more information, see Creating a Task Definition that Uses a FireLens Configuration in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nTasks hosted on Fargate only support the file configuration file type.\n\nkey -> (string)\n\nvalue -> (string)\n\nfamily -> (string)\n\nThe name of a family that this task definition is registered to. Up to 255 letters (uppercase and lowercase), numbers, hyphens, and underscores are allowed.\n\nA family groups multiple versions of a task definition. Amazon ECS gives the first task definition that you registered to a family a revision number of 1. Amazon ECS gives sequential revision numbers to each task definition that you add.\n\ntaskRoleArn -> (string)\n\nThe short name or full Amazon Resource Name (ARN) of the Identity and Access Management role that grants containers in the task permission to call Amazon Web Services APIs on your behalf. For more information, see Amazon ECS Task Role in the Amazon Elastic Container Service Developer Guide .\n\nIAM roles for tasks on Windows require that the -EnableTaskIAMRole option is set when you launch the Amazon ECS-optimized Windows AMI. Your containers must also run some configuration code in order to take advantage of the feature. For more information, see Windows IAM roles for tasks in the Amazon Elastic Container Service Developer Guide .\n\nexecutionRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task execution role that grants the Amazon ECS container agent permission to make Amazon Web Services API calls on your behalf. The task execution IAM role is required depending on the requirements of your task. For more information, see Amazon ECS task execution IAM role in the Amazon Elastic Container Service Developer Guide .\n\nnetworkMode -> (string)\n\nThe Docker networking mode to use for the containers in the task. The valid values are none , bridge , awsvpc , and host . If no network mode is specified, the default is bridge .\n\nFor Amazon ECS tasks on Fargate, the awsvpc network mode is required. For Amazon ECS tasks on Amazon EC2 Linux instances, any network mode can be used. For Amazon ECS tasks on Amazon EC2 Windows instances, <default> or awsvpc can be used. If the network mode is set to none , you cannot specify port mappings in your container definitions, and the tasks containers do not have external connectivity. The host and awsvpc network modes offer the highest networking performance for containers because they use the EC2 network stack instead of the virtualized network stack provided by the bridge mode.\n\nWith the host and awsvpc network modes, exposed container ports are mapped directly to the corresponding host port (for the host network mode) or the attached elastic network interface port (for the awsvpc network mode), so you cannot take advantage of dynamic host port mappings.\n\nWarning\n\nWhen using the host network mode, you should not run containers using the root user (UID 0). It is considered best practice to use a non-root user.\n\nIf the network mode is awsvpc , the task is allocated an elastic network interface, and you must specify a NetworkConfiguration value when you create a service or run a task with the task definition. For more information, see Task Networking in the Amazon Elastic Container Service Developer Guide .\n\nIf the network mode is host , you cannot run multiple instantiations of the same task on a single container instance when port mappings are used.\n\nFor more information, see Network settings in the Docker run reference .\n\nrevision -> (integer)\n\nThe revision of the task in a particular family. The revision is a version number of a task definition in a family. When you register a task definition for the first time, the revision is 1 . Each time that you register a new revision of a task definition in the same family, the revision value always increases by one, even if you have deregistered previous revisions in this family.\n\nvolumes -> (list)\n\nThe list of data volume definitions for the task. For more information, see Using data volumes in tasks in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nThe host and sourcePath parameters are not supported for tasks run on Fargate.\n\n(structure)\n\nA data volume used in a task definition. For tasks that use the Amazon Elastic File System (Amazon EFS), specify an efsVolumeConfiguration . For Windows tasks that use Amazon FSx for Windows File Server file system, specify a fsxWindowsFileServerVolumeConfiguration . For tasks that use a Docker volume, specify a DockerVolumeConfiguration . For tasks that use a bind mount host volume, specify a host and optional sourcePath . For more information, see Using Data Volumes in Tasks .\n\nname -> (string)\n\nThe name of the volume. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This name is referenced in the sourceVolume parameter of container definition mountPoints .\n\nhost -> (structure)\n\nThis parameter is specified when you are using bind mount host volumes. The contents of the host parameter determine whether your bind mount host volume persists on the host container instance and where it is stored. If the host parameter is empty, then the Docker daemon assigns a host path for your data volume. However, the data is not guaranteed to persist after the containers associated with it stop running.\n\nWindows containers can mount whole directories on the same drive as $env:ProgramData . Windows containers cannot mount directories on a different drive, and mount point cannot be across drives. For example, you can mount C:\\my\\path:C:\\my\\path and D:\\:D:\\ , but not D:\\my\\path:C:\\my\\path or D:\\:C:\\my\\path .\n\nsourcePath -> (string)\n\nWhen the host parameter is used, specify a sourcePath to declare the path on the host container instance that is presented to the container. If this parameter is empty, then the Docker daemon has assigned a host path for you. If the host parameter contains a sourcePath file location, then the data volume persists at the specified location on the host container instance until you delete it manually. If the sourcePath value does not exist on the host container instance, the Docker daemon creates it. If the location does exist, the contents of the source path folder are exported.\n\nIf you are using the Fargate launch type, the sourcePath parameter is not supported.\n\ndockerVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using Docker volumes.\n\nWindows containers only support the use of the local driver. To use bind mounts, specify the host parameter instead.\n\nNote\n\nDocker volumes are not supported by tasks run on Fargate.\n\nscope -> (string)\n\nThe scope for the Docker volume that determines its lifecycle. Docker volumes that are scoped to a task are automatically provisioned when the task starts and destroyed when the task stops. Docker volumes that are scoped as shared persist after the task stops.\n\nautoprovision -> (boolean)\n\nIf this value is true , the Docker volume is created if it does not already exist.\n\nNote\n\nThis field is only used if the scope is shared .\n\ndriver -> (string)\n\nThe Docker volume driver to use. The driver value must match the driver name provided by Docker because it is used for task placement. If the driver was installed using the Docker plugin CLI, use docker plugin ls to retrieve the driver name from your container instance. If the driver was installed using another method, use Docker plugin discovery to retrieve the driver name. For more information, see Docker plugin discovery . This parameter maps to Driver in the Create a volume section of the Docker Remote API and the xxdriver option to docker volume create .\n\ndriverOpts -> (map)\n\nA map of Docker driver-specific options passed through. This parameter maps to DriverOpts in the Create a volume section of the Docker Remote API and the xxopt option to docker volume create .\n\nkey -> (string)\n\nvalue -> (string)\n\nlabels -> (map)\n\nCustom metadata to add to your Docker volume. This parameter maps to Labels in the Create a volume section of the Docker Remote API and the xxlabel option to docker volume create .\n\nkey -> (string)\n\nvalue -> (string)\n\nefsVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using an Amazon Elastic File System file system for task storage.\n\nfileSystemId -> (string)\n\nThe Amazon EFS file system ID to use.\n\nrootDirectory -> (string)\n\nThe directory within the Amazon EFS file system to mount as the root directory inside the host. If this parameter is omitted, the root of the Amazon EFS volume will be used. Specifying / will have the same effect as omitting this parameter.\n\nWarning\n\nIf an EFS access point is specified in the authorizationConfig , the root directory parameter must either be omitted or set to / which will enforce the path set on the EFS access point.\n\ntransitEncryption -> (string)\n\nWhether or not to enable encryption for Amazon EFS data in transit between the Amazon ECS host and the Amazon EFS server. Transit encryption must be enabled if Amazon EFS IAM authorization is used. If this parameter is omitted, the default value of DISABLED is used. For more information, see Encrypting Data in Transit in the Amazon Elastic File System User Guide .\n\ntransitEncryptionPort -> (integer)\n\nThe port to use when sending encrypted data between the Amazon ECS host and the Amazon EFS server. If you do not specify a transit encryption port, it will use the port selection strategy that the Amazon EFS mount helper uses. For more information, see EFS Mount Helper in the Amazon Elastic File System User Guide .\n\nauthorizationConfig -> (structure)\n\nThe authorization configuration details for the Amazon EFS file system.\n\naccessPointId -> (string)\n\nThe Amazon EFS access point ID to use. If an access point is specified, the root directory value specified in the EFSVolumeConfiguration must either be omitted or set to / which will enforce the path set on the EFS access point. If an access point is used, transit encryption must be enabled in the EFSVolumeConfiguration . For more information, see Working with Amazon EFS Access Points in the Amazon Elastic File System User Guide .\n\niam -> (string)\n\nWhether or not to use the Amazon ECS task IAM role defined in a task definition when mounting the Amazon EFS file system. If enabled, transit encryption must be enabled in the EFSVolumeConfiguration . If this parameter is omitted, the default value of DISABLED is used. For more information, see Using Amazon EFS Access Points in the Amazon Elastic Container Service Developer Guide .\n\nfsxWindowsFileServerVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using Amazon FSx for Windows File Server file system for task storage.\n\nfileSystemId -> (string)\n\nThe Amazon FSx for Windows File Server file system ID to use.\n\nrootDirectory -> (string)\n\nThe directory within the Amazon FSx for Windows File Server file system to mount as the root directory inside the host.\n\nauthorizationConfig -> (structure)\n\nThe authorization configuration details for the Amazon FSx for Windows File Server file system.\n\ncredentialsParameter -> (string)\n\nThe authorization credential option to use. The authorization credential options can be provided using either the Amazon Resource Name (ARN) of an Secrets Manager secret or SSM Parameter Store parameter. The ARNs refer to the stored credentials.\n\ndomain -> (string)\n\nA fully qualified domain name hosted by an Directory Service Managed Microsoft AD (Active Directory) or self-hosted AD on Amazon EC2.\n\nstatus -> (string)\n\nThe status of the task definition.\n\nrequiresAttributes -> (list)\n\nThe container instance attributes required by your task. When an Amazon EC2 instance is registered to your cluster, the Amazon ECS container agent assigns some standard attributes to the instance. You can apply custom attributes, specified as key-value pairs using the Amazon ECS console or the PutAttributes API. These attributes are used when considering task placement for tasks hosted on Amazon EC2 instances. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nThis parameter is not supported for tasks run on Fargate.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nplacementConstraints -> (list)\n\nAn array of placement constraint objects to use for tasks.\n\nNote\n\nThis parameter is not supported for tasks run on Fargate.\n\n(structure)\n\nAn object representing a constraint on task placement in the task definition. For more information, see Task placement constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nTask placement constraints are not supported for tasks run on Fargate.\n\ntype -> (string)\n\nThe type of constraint. The MemberOf constraint restricts selection to be from a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\ncompatibilities -> (list)\n\nThe task launch types the task definition validated against during task definition registration. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\n(string)\n\nruntimePlatform -> (structure)\n\nThe operating system that your task definitions are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nWhen you specify a task in a service, this value must match the runtimePlatform value of the service.\n\ncpuArchitecture -> (string)\n\nThe CPU architecture.\n\noperatingSystemFamily -> (string)\n\nThe operating system.\n\nrequiresCompatibilities -> (list)\n\nThe task launch types the task definition was validated against. To determine which task launch types the task definition is validated for, see the TaskDefinition$compatibilities parameter.\n\n(string)\n\ncpu -> (string)\n\nThe number of cpu units used by the task. If you are using the EC2 launch type, this field is optional and any value can be used. If you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of valid values for the memory parameter:\n\n256 (.25 vCPU) - Available memory values: 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)\n\n512 (.5 vCPU) - Available memory values: 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)\n\n1024 (1 vCPU) - Available memory values: 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)\n\n2048 (2 vCPU) - Available memory values: Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)\n\n4096 (4 vCPU) - Available memory values: Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)\n\nmemory -> (string)\n\nThe amount (in MiB) of memory used by the task.\n\nIf your tasks will be run on Amazon EC2 instances, you must specify either a task-level memory value or a container-level memory value. This field is optional and any value can be used. If a task-level memory value is specified then the container-level memory value is optional. For more information regarding container-level memory and memory reservation, see ContainerDefinition .\n\nIf your tasks will be run on Fargate, this field is required and you must use one of the following values, which determines your range of valid values for the cpu parameter:\n\n512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)\n\n1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)\n\n2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)\n\nBetween 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)\n\nBetween 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)\n\ninferenceAccelerators -> (list)\n\nThe Elastic Inference accelerator associated with the task.\n\n(structure)\n\nDetails on a Elastic Inference accelerator. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name. The deviceName must also be referenced in a container definition as a ResourceRequirement .\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\npidMode -> (string)\n\nThe process namespace to use for the containers in the task. The valid values are host or task . If host is specified, then all containers within the tasks that specified the host PID mode on the same container instance share the same process namespace with the host Amazon EC2 instance. If task is specified, all containers within the specified task share the same process namespace. If no value is specified, the default is a private namespace. For more information, see PID settings in the Docker run reference .\n\nIf the host PID mode is used, be aware that there is a heightened risk of undesired process namespace expose. For more information, see Docker security .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nipcMode -> (string)\n\nThe IPC resource namespace to use for the containers in the task. The valid values are host , task , or none . If host is specified, then all containers within the tasks that specified the host IPC mode on the same container instance share the same IPC resources with the host Amazon EC2 instance. If task is specified, all containers within the specified task share the same IPC resources. If none is specified, then IPC resources within the containers of a task are private and not shared with other containers in a task or on the container instance. If no value is specified, then the IPC resource namespace sharing depends on the Docker daemon setting on the container instance. For more information, see IPC settings in the Docker run reference .\n\nIf the host IPC mode is used, be aware that there is a heightened risk of undesired IPC namespace expose. For more information, see Docker security .\n\nIf you are setting namespaced kernel parameters using systemControls for the containers in the task, the following will apply to your IPC resource namespace. For more information, see System Controls in the Amazon Elastic Container Service Developer Guide .\n\nFor tasks that use the host IPC mode, IPC namespace related systemControls are not supported.\n\nFor tasks that use the task IPC mode, IPC namespace related systemControls will apply to all containers within a task.\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nproxyConfiguration -> (structure)\n\nThe configuration details for the App Mesh proxy.\n\nYour Amazon ECS container instances require at least version 1.26.0 of the container agent and at least version 1.26.0-1 of the ecs-init package to enable a proxy configuration. If your container instances are launched from the Amazon ECS-optimized AMI version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe proxy type. The only supported value is APPMESH .\n\ncontainerName -> (string)\n\nThe name of the container that will serve as the App Mesh proxy.\n\nproperties -> (list)\n\nThe set of network configuration parameters to provide the Container Network Interface (CNI) plugin, specified as key-value pairs.\n\nIgnoredUID - (Required) The user ID (UID) of the proxy container as defined by the user parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If IgnoredGID is specified, this field can be empty.\n\nIgnoredGID - (Required) The group ID (GID) of the proxy container as defined by the user parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If IgnoredUID is specified, this field can be empty.\n\nAppPorts - (Required) The list of ports that the application uses. Network traffic to these ports is forwarded to the ProxyIngressPort and ProxyEgressPort .\n\nProxyIngressPort - (Required) Specifies the port that incoming traffic to the AppPorts is directed to.\n\nProxyEgressPort - (Required) Specifies the port that outgoing traffic from the AppPorts is directed to.\n\nEgressIgnoredPorts - (Required) The egress traffic going to the specified ports is ignored and not redirected to the ProxyEgressPort . It can be an empty list.\n\nEgressIgnoredIPs - (Required) The egress traffic going to the specified IP addresses is ignored and not redirected to the ProxyEgressPort . It can be an empty list.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nregisteredAt -> (timestamp)\n\nThe Unix timestamp for when the task definition was registered.\n\nderegisteredAt -> (timestamp)\n\nThe Unix timestamp for when the task definition was deregistered.\n\nregisteredBy -> (string)\n\nThe principal that registered the task definition.\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage settings to use for tasks run with the task definition.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\ntags -> (list)\n\nThe metadata that is applied to the task definition to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nTo describe a task definition\n\nThe following describe-task-definition example retrieves the details of a task definition.\n\naws ecs describe-task-definition --task-definition hello_world:8\n\n\nOutput:\n\n{\n    \"taskDefinition\": {\n        \"volumes\": [],\n        \"taskDefinitionArn\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/hello_world:8\",\n        \"containerDefinitions\": [\n            {\n                \"environment\": [],\n                \"name\": \"wordpress\",\n                \"links\": [\n                    \"mysql\"\n                ],\n                \"mountPoints\": [],\n                \"image\": \"wordpress\",\n                \"essential\": true,\n                \"portMappings\": [\n                    {\n                        \"containerPort\": 80,\n                        \"hostPort\": 80\n                    }\n                ],\n                \"memory\": 500,\n                \"cpu\": 10,\n                \"volumesFrom\": []\n            },\n            {\n                \"environment\": [\n                    {\n                        \"name\": \"MYSQL_ROOT_PASSWORD\",\n                        \"value\": \"password\"\n                    }\n                ],\n                \"name\": \"mysql\",\n                \"mountPoints\": [],\n                \"image\": \"mysql\",\n                \"cpu\": 10,\n                \"portMappings\": [],\n                \"memory\": 500,\n                \"essential\": true,\n                \"volumesFrom\": []\n            }\n        ],\n        \"family\": \"hello_world\",\n        \"revision\": 8\n    }\n}\n\n\nFor more information, see Amazon ECS Task Definitions in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "describe-task-sets",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describe-task-sets.html",
      "command_description": "Description\n\nDescribes the task sets in the specified cluster and service. This is used when a service uses the EXTERNAL deployment controller type. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-task-sets\n--cluster <value>\n--service <value>\n[--task-sets <value>]\n[--include <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--cluster <value>",
        "--service <value>",
        "[--task-sets <value>]",
        "[--include <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the service that the task sets exist in.\n\n--service (string)\n\nThe short name or full Amazon Resource Name (ARN) of the service that the task sets exist in.\n\n--task-sets (list)\n\nThe ID or full Amazon Resource Name (ARN) of task sets to describe.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--include (list)\n\nSpecifies whether to see the resource tags for the task set. If TAGS is specified, the tags are included in the response. If this field is omitted, tags are not included in the response.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  TAGS\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntaskSets -> (list)\n\nThe list of task sets described.\n\n(structure)\n\nInformation about a set of Amazon ECS tasks in either an CodeDeploy or an EXTERNAL deployment. An Amazon ECS task set includes details such as the desired number of tasks, how many tasks are running, and whether the task set serves production traffic.\n\nid -> (string)\n\nThe ID of the task set.\n\ntaskSetArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task set.\n\nserviceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service the task set exists in.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that the service that hosts the task set exists in.\n\nstartedBy -> (string)\n\nThe tag specified when a task set is started. If the task set is created by an CodeDeploy deployment, the startedBy parameter is CODE_DEPLOY . For a task set created for an external deployment, the startedBy field isn’t used.\n\nexternalId -> (string)\n\nThe external ID associated with the task set.\n\nIf a task set is created by an CodeDeploy deployment, the externalId parameter contains the CodeDeploy deployment ID.\n\nIf a task set is created for an external deployment and is associated with a service discovery registry, the externalId parameter contains the ECS_TASK_SET_EXTERNAL_ID Cloud Map attribute.\n\nstatus -> (string)\n\nThe status of the task set. The following describes each state:\n\nPRIMARY\n\nThe task set is serving production traffic.\n\nACTIVE\n\nThe task set is not serving production traffic.\n\nDRAINING\n\nThe tasks in the task set are being stopped and their corresponding targets are being deregistered from their target group.\n\ntaskDefinition -> (string)\n\nThe task definition the task set is using.\n\ncomputedDesiredCount -> (integer)\n\nThe computed desired count for the task set. This is calculated by multiplying the service’s desiredCount by the task set’s scale percentage. The result is always rounded up. For example, if the computed desired count is 1.2, it rounds up to 2 tasks.\n\npendingCount -> (integer)\n\nThe number of tasks in the task set that are in the PENDING status during a deployment. A task in the PENDING state is preparing to enter the RUNNING state. A task set enters the PENDING status when it launches for the first time or when it is restarted after being in the STOPPED state.\n\nrunningCount -> (integer)\n\nThe number of tasks in the task set that are in the RUNNING status during a deployment. A task in the RUNNING state is running and ready for use.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was last updated.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the task set are using. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy associated with the task set.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe Fargate platform version on which the tasks in the task set are running. A platform version is only specified for tasks run on Fargate. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the set are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks in the set must have the same value.\n\nnetworkConfiguration -> (structure)\n\nThe network configuration for the task set.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nloadBalancers -> (list)\n\nDetails on a load balancer that is used with a task set.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this task set. For more information, see Service discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nscale -> (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nstabilityStatus -> (string)\n\nThe stability status, which indicates whether the task set has reached a steady state. If the following conditions are met, the task set will be in STEADY_STATE :\n\nThe task runningCount is equal to the computedDesiredCount .\n\nThe pendingCount is 0 .\n\nThere are no tasks running on container instances in the DRAINING status.\n\nAll tasks are reporting a healthy status from the load balancers, service discovery, and container health checks.\n\nIf any of those conditions are not met, the stability status returns STABILIZING .\n\nstabilityStatusAt -> (timestamp)\n\nThe Unix timestamp for when the task set stability status was retrieved.\n\ntags -> (list)\n\nThe metadata that you apply to the task set to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nfailures -> (list)\n\nAny failures associated with the call.\n\n(structure)\n\nA failed resource. For a list of common causes, see API failure reasons in the Amazon Elastic Container Service Developer Guide .\n\narn -> (string)\n\nThe Amazon Resource Name (ARN) of the failed resource.\n\nreason -> (string)\n\nThe reason for the failure.\n\ndetail -> (string)\n\nThe details of the failure.",
      "command_examples": "Examples\n\nTo describe a task set\n\nThe following describe-task-sets example describes a task set in a service that uses an external deployer.\n\naws ecs describe-task-sets \\\n    --cluster MyCluster \\\n    --service MyService \\\n    --task-sets arn:aws:ecs:us-west-2:123456789012:task-set/MyCluster/MyService/ecs-svc/1234567890123456789\n\n\nOutput:\n\n{\n    \"taskSets\": [\n        {\n            \"id\": \"ecs-svc/1234567890123456789\",\n            \"taskSetArn\": \"arn:aws:ecs:us-west-2:123456789012:task-set/MyCluster/MyService/ecs-svc/1234567890123456789\",\n            \"status\": \"ACTIVE\",\n            \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sample-fargate:2\",\n            \"computedDesiredCount\": 0,\n            \"pendingCount\": 0,\n            \"runningCount\": 0,\n            \"createdAt\": 1557207715.195,\n            \"updatedAt\": 1557207740.014,\n            \"launchType\": \"EC2\",\n            \"networkConfiguration\": {\n                \"awsvpcConfiguration\": {\n                    \"subnets\": [\n                        \"subnet-12344321\"\n                    ],\n                    \"securityGroups\": [\n                        \"sg-1234431\"\n                    ],\n                    \"assignPublicIp\": \"DISABLED\"\n                }\n            },\n            \"loadBalancers\": [],\n            \"serviceRegistries\": [],\n            \"scale\": {\n                \"value\": 0.0,\n                \"unit\": \"PERCENT\"\n            },\n            \"stabilityStatus\": \"STEADY_STATE\",\n            \"stabilityStatusAt\": 1557207740.014\n        }\n    ],\n    \"failures\": []\n}\n"
    },
    {
      "command_name": "describe-tasks",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describe-tasks.html",
      "command_description": "Description\n\nDescribes a specified task or tasks.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-tasks\n[--cluster <value>]\n--tasks <value>\n[--include <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--tasks <value>",
        "[--include <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the task or tasks to describe. If you do not specify a cluster, the default cluster is assumed. This parameter is required if the task or tasks you are describing were launched in any cluster other than the default cluster.\n\n--tasks (list)\n\nA list of up to 100 task IDs or full ARN entries.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--include (list)\n\nSpecifies whether you want to see the resource tags for the task. If TAGS is specified, the tags are included in the response. If this field is omitted, tags are not included in the response.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  TAGS\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntasks -> (list)\n\nThe list of tasks.\n\n(structure)\n\nDetails on a task in a cluster.\n\nattachments -> (list)\n\nThe Elastic Network Adapter associated with the task if the task uses the awsvpc network mode.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nattributes -> (list)\n\nThe attributes of the task\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\navailabilityZone -> (string)\n\nThe availability zone of the task.\n\ncapacityProviderName -> (string)\n\nThe capacity provider associated with the task.\n\nclusterArn -> (string)\n\nThe ARN of the cluster that hosts the task.\n\nconnectivity -> (string)\n\nThe connectivity status of a task.\n\nconnectivityAt -> (timestamp)\n\nThe Unix timestamp for when the task last went into CONNECTED status.\n\ncontainerInstanceArn -> (string)\n\nThe ARN of the container instances that host the task.\n\ncontainers -> (list)\n\nThe containers associated with the task.\n\n(structure)\n\nA Docker container that is part of a task.\n\ncontainerArn -> (string)\n\nThe Amazon Resource Name (ARN) of the container.\n\ntaskArn -> (string)\n\nThe ARN of the task.\n\nname -> (string)\n\nThe name of the container.\n\nimage -> (string)\n\nThe image used for the container.\n\nimageDigest -> (string)\n\nThe container image manifest digest.\n\nNote\n\nThe imageDigest is only returned if the container is using an image hosted in Amazon ECR, otherwise it is omitted.\n\nruntimeId -> (string)\n\nThe ID of the Docker container.\n\nlastStatus -> (string)\n\nThe last known status of the container.\n\nexitCode -> (integer)\n\nThe exit code returned from the container.\n\nreason -> (string)\n\nA short (255 max characters) human-readable string to provide additional details about a running or stopped container.\n\nnetworkBindings -> (list)\n\nThe network bindings associated with the container.\n\n(structure)\n\nDetails on the network bindings between a container and its host container instance. After a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the networkBindings section of DescribeTasks API responses.\n\nbindIP -> (string)\n\nThe IP address that the container is bound to on the container instance.\n\ncontainerPort -> (integer)\n\nThe port number on the container that is used with the network binding.\n\nhostPort -> (integer)\n\nThe port number on the host that is used with the network binding.\n\nprotocol -> (string)\n\nThe protocol used for the network binding.\n\nnetworkInterfaces -> (list)\n\nThe network interfaces associated with the container.\n\n(structure)\n\nAn object representing the elastic network interface for tasks that use the awsvpc network mode.\n\nattachmentId -> (string)\n\nThe attachment ID for the network interface.\n\nprivateIpv4Address -> (string)\n\nThe private IPv4 address for the network interface.\n\nipv6Address -> (string)\n\nThe private IPv6 address for the network interface.\n\nhealthStatus -> (string)\n\nThe health status of the container. If health checks are not configured for this container in its task definition, then it reports the health status as UNKNOWN .\n\nmanagedAgents -> (list)\n\nThe details of any Amazon ECS managed agents associated with the container.\n\n(structure)\n\nDetails about the managed agent status for the container.\n\nlastStartedAt -> (timestamp)\n\nThe Unix timestamp for when the managed agent was last started.\n\nname -> (string)\n\nThe name of the managed agent. When the execute command feature is enabled, the managed agent name is ExecuteCommandAgent .\n\nreason -> (string)\n\nThe reason for why the managed agent is in the state it is in.\n\nlastStatus -> (string)\n\nThe last known status of the managed agent.\n\ncpu -> (string)\n\nThe number of CPU units set for the container. The value will be 0 if no value was specified in the container definition when the task definition was registered.\n\nmemory -> (string)\n\nThe hard limit (in MiB) of memory set for the container.\n\nmemoryReservation -> (string)\n\nThe soft limit (in MiB) of memory set for the container.\n\ngpuIds -> (list)\n\nThe IDs of each GPU assigned to the container.\n\n(string)\n\ncpu -> (string)\n\nThe number of CPU units used by the task as expressed in a task definition. It can be expressed as an integer using CPU units, for example 1024 . It can also be expressed as a string using vCPUs, for example 1 vCPU or 1 vcpu . String values are converted to an integer indicating the CPU units when the task definition is registered.\n\nIf you are using the EC2 launch type, this field is optional. Supported values are between 128 CPU units (0.125 vCPUs) and 10240 CPU units (10 vCPUs).\n\nIf you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the memory parameter:\n\n256 (.25 vCPU) - Available memory values: 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)\n\n512 (.5 vCPU) - Available memory values: 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)\n\n1024 (1 vCPU) - Available memory values: 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)\n\n2048 (2 vCPU) - Available memory values: Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)\n\n4096 (4 vCPU) - Available memory values: Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task was created (the task entered the PENDING state).\n\ndesiredStatus -> (string)\n\nThe desired status of the task. For more information, see Task Lifecycle .\n\nenableExecuteCommand -> (boolean)\n\nWhether or not execute command functionality is enabled for this task. If true , this enables execute command functionality on all containers in the task.\n\nexecutionStoppedAt -> (timestamp)\n\nThe Unix timestamp for when the task execution stopped.\n\ngroup -> (string)\n\nThe name of the task group associated with the task.\n\nhealthStatus -> (string)\n\nThe health status for the task, which is determined by the health of the essential containers in the task. If all essential containers in the task are reporting as HEALTHY , then the task status also reports as HEALTHY . If any essential containers in the task are reporting as UNHEALTHY or UNKNOWN , then the task status also reports as UNHEALTHY or UNKNOWN , accordingly.\n\nNote\n\nThe Amazon ECS container agent does not monitor or report on Docker health checks that are embedded in a container image (such as those specified in a parent image or from the image’s Dockerfile) and not specified in the container definition. Health check parameters that are specified in a container definition override any Docker health checks that exist in the container image.\n\ninferenceAccelerators -> (list)\n\nThe Elastic Inference accelerator associated with the task.\n\n(structure)\n\nDetails on a Elastic Inference accelerator. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name. The deviceName must also be referenced in a container definition as a ResourceRequirement .\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nlastStatus -> (string)\n\nThe last known status of the task. For more information, see Task Lifecycle .\n\nlaunchType -> (string)\n\nThe infrastructure on which your task is running. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\nmemory -> (string)\n\nThe amount of memory (in MiB) used by the task as expressed in a task definition. It can be expressed as an integer using MiB, for example 1024 . It can also be expressed as a string using GB, for example 1GB or 1 GB . String values are converted to an integer indicating the MiB when the task definition is registered.\n\nIf you are using the EC2 launch type, this field is optional.\n\nIf you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the cpu parameter:\n\n512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)\n\n1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)\n\n2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)\n\nBetween 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)\n\nBetween 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)\n\noverrides -> (structure)\n\nOne or more container overrides.\n\ncontainerOverrides -> (list)\n\nOne or more container overrides sent to a task.\n\n(structure)\n\nThe overrides that should be sent to a container. An empty container override can be passed in. An example of an empty container override would be {\"containerOverrides\": [ ] } . If a non-empty container override is specified, the name parameter must be included.\n\nname -> (string)\n\nThe name of the container that receives the override. This parameter is required if any override is specified.\n\ncommand -> (list)\n\nThe command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.\n\n(string)\n\nenvironment -> (list)\n\nThe environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nenvironmentFiles -> (list)\n\nA list of files containing the environment variables to pass to a container, instead of the value from the container definition.\n\n(structure)\n\nA list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying environment variables in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nvalue -> (string)\n\nThe Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\ntype -> (string)\n\nThe file type to use. The only supported value is s3 .\n\ncpu -> (integer)\n\nThe number of cpu units reserved for the container, instead of the default value from the task definition. You must also specify a container name.\n\nmemory -> (integer)\n\nThe hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.\n\nmemoryReservation -> (integer)\n\nThe soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.\n\nresourceRequirements -> (list)\n\nThe type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.\n\n(structure)\n\nThe type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see Working with GPUs on Amazon ECS or Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide\n\nvalue -> (string)\n\nThe value for the specified resource type.\n\nIf the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent will reserve for the container. The number of GPUs reserved for all containers in a task should not exceed the number of available GPUs on the container instance the task is launched on.\n\nIf the InferenceAccelerator type is used, the value should match the deviceName for an InferenceAccelerator specified in a task definition.\n\ntype -> (string)\n\nThe type of resource to assign to a container. The supported values are GPU or InferenceAccelerator .\n\ncpu -> (string)\n\nThe cpu override for the task.\n\ninferenceAcceleratorOverrides -> (list)\n\nThe Elastic Inference accelerator override for the task.\n\n(structure)\n\nDetails on an Elastic Inference accelerator task override. This parameter is used to override the Elastic Inference accelerator specified in the task definition. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name to override for the task. This parameter must match a deviceName specified in the task definition.\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nexecutionRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see Amazon ECS task execution IAM role in the Amazon Elastic Container Service Developer Guide .\n\nmemory -> (string)\n\nThe memory override for the task.\n\ntaskRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see IAM Role for Tasks in the Amazon Elastic Container Service Developer Guide .\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage setting override for the task.\n\nNote\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\nplatformVersion -> (string)\n\nThe platform version on which your task is running. A platform version is only specified for tasks using the Fargate launch type. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX. .\n\npullStartedAt -> (timestamp)\n\nThe Unix timestamp for when the container image pull began.\n\npullStoppedAt -> (timestamp)\n\nThe Unix timestamp for when the container image pull completed.\n\nstartedAt -> (timestamp)\n\nThe Unix timestamp for when the task started (the task transitioned from the PENDING state to the RUNNING state).\n\nstartedBy -> (string)\n\nThe tag specified when a task is started. If the task is started by an Amazon ECS service, then the startedBy parameter contains the deployment ID of the service that starts it.\n\nstopCode -> (string)\n\nThe stop code indicating why a task was stopped. The stoppedReason may contain additional details.\n\nstoppedAt -> (timestamp)\n\nThe Unix timestamp for when the task was stopped (the task transitioned from the RUNNING state to the STOPPED state).\n\nstoppedReason -> (string)\n\nThe reason that the task was stopped.\n\nstoppingAt -> (timestamp)\n\nThe Unix timestamp for when the task stops (transitions from the RUNNING state to STOPPED ).\n\ntags -> (list)\n\nThe metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ntaskArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task.\n\ntaskDefinitionArn -> (string)\n\nThe ARN of the task definition that creates the task.\n\nversion -> (long)\n\nThe version counter for the task. Every time a task experiences a change that triggers a CloudWatch event, the version counter is incremented. If you are replicating your Amazon ECS task state with CloudWatch Events, you can compare the version of a task reported by the Amazon ECS API actions with the version reported in CloudWatch Events for the task (inside the detail object) to verify that the version in your event stream is current.\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage settings for the task.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\nfailures -> (list)\n\nAny failures associated with the call.\n\n(structure)\n\nA failed resource. For a list of common causes, see API failure reasons in the Amazon Elastic Container Service Developer Guide .\n\narn -> (string)\n\nThe Amazon Resource Name (ARN) of the failed resource.\n\nreason -> (string)\n\nThe reason for the failure.\n\ndetail -> (string)\n\nThe details of the failure.",
      "command_examples": "Examples\n\nTo describe a task\n\nThe following describe-tasks example retrieves the details of a task. You can specify the task by using either the ID or full ARN of the task.\n\naws ecs describe-tasks \\\n    --cluster MyCluster \\\n    --tasks arn:aws:ecs:us-west-2:123456789012:task/MyCluster/1234567890123456789\n\n\nOutput:\n\n{\n    \"tasks\": [\n        {\n            \"taskArn\": \"arn:aws:ecs:us-west-2:123456789012:task/MyCluster/1234567890123456789\",\n            \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n            \"taskDefinitionArn\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sample-fargate:2\",\n            \"overrides\": {\n                \"containerOverrides\": [\n                    {\n                        \"name\": \"fargate-app\"\n                    }\n                ]\n            },\n            \"lastStatus\": \"RUNNING\",\n            \"desiredStatus\": \"RUNNING\",\n            \"cpu\": \"256\",\n            \"memory\": \"512\",\n            \"containers\": [\n                {\n                    \"containerArn\": \"arn:aws:ecs:us-west-2:123456789012:container/a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\",\n                    \"taskArn\": \"arn:aws:ecs:us-west-2:123456789012:task/MyCluster/1234567890123456789\",\n                    \"name\": \"fargate-app\",\n                    \"lastStatus\": \"RUNNING\",\n                    \"networkBindings\": [],\n                    \"networkInterfaces\": [\n                        {\n                            \"attachmentId\": \"a1b2c3d4-5678-90ab-cdef-22222EXAMPLE\",\n                            \"privateIpv4Address\": \"10.0.0.4\"\n                        }\n                    ],\n                    \"healthStatus\": \"UNKNOWN\",\n                    \"cpu\": \"0\"\n                }\n            ],\n            \"startedBy\": \"ecs-svc/1234567890123456789\",\n            \"version\": 3,\n            \"connectivity\": \"CONNECTED\",\n            \"connectivityAt\": 1557134016.971,\n            \"pullStartedAt\": 1557134025.379,\n            \"pullStoppedAt\": 1557134033.379,\n            \"createdAt\": 1557134011.644,\n            \"startedAt\": 1557134035.379,\n            \"group\": \"service:fargate-service\",\n            \"launchType\": \"FARGATE\",\n            \"platformVersion\": \"1.3.0\",\n            \"attachments\": [\n                {\n                    \"id\": \"a1b2c3d4-5678-90ab-cdef-33333EXAMPLE\",\n                    \"type\": \"ElasticNetworkInterface\",\n                    \"status\": \"ATTACHED\",\n                    \"details\": [\n                        {\n                            \"name\": \"subnetId\",\n                            \"value\": \"subnet-12344321\"\n                        },\n                        {\n                            \"name\": \"networkInterfaceId\",\n                            \"value\": \"eni-12344321\"\n                        },\n                        {\n                            \"name\": \"macAddress\",\n                            \"value\": \"0a:90:09:84:f9:14\"\n                        },\n                        {\n                            \"name\": \"privateIPv4Address\",\n                            \"value\": \"10.0.0.4\"\n                        }\n                    ]\n                }\n            ],\n            \"healthStatus\": \"UNKNOWN\",\n            \"tags\": []\n        }\n    ],\n    \"failures\": []\n}\n\n\nFor more information, see Amazon ECS Task Definitions in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "discover-poll-endpoint",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/discover-poll-endpoint.html",
      "command_description": "Description\n\nNote\n\nThis action is only used by the Amazon ECS agent, and it is not intended for use outside of the agent.\n\nReturns an endpoint for the Amazon ECS agent to poll for updates.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  discover-poll-endpoint\n[--container-instance <value>]\n[--cluster <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--container-instance <value>]",
        "[--cluster <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--container-instance (string)\n\nThe container instance ID or full ARN of the container instance. The ARN contains the arn:aws:ecs namespace, followed by the Region of the container instance, the Amazon Web Services account ID of the container instance owner, the container-instance namespace, and then the container instance ID. For example, arn:aws:ecs:region:aws_account_id:container-instance/container_instance_ID .\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster to which the container instance belongs.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nendpoint -> (string)\n\nThe endpoint for the Amazon ECS agent to poll.\n\ntelemetryEndpoint -> (string)\n\nThe telemetry endpoint for the Amazon ECS agent."
    },
    {
      "command_name": "execute-command",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/execute-command.html",
      "command_description": "Description\n\nRuns a command remotely on a container within a task.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  execute-command\n[--cluster <value>]\n[--container <value>]\n--command <value>\n--interactive | --non-interactive\n--task <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "[--container <value>]",
        "--command <value>",
        "--interactive | --non-interactive",
        "--task <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe Amazon Resource Name (ARN) or short name of the cluster the task is running in. If you do not specify a cluster, the default cluster is assumed.\n\n--container (string)\n\nThe name of the container to execute the command on. A container name only needs to be specified for tasks containing multiple containers.\n\n--command (string)\n\nThe command to run on the container.\n\n--interactive | --non-interactive (boolean)\n\nUse this flag to run your command in interactive mode.\n\n--task (string)\n\nThe Amazon Resource Name (ARN) or ID of the task the container is part of.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "list-account-settings",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list-account-settings.html",
      "command_description": "Description\n\nLists the account settings for a specified principal.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-account-settings is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: settings",
      "command_synopsis": "Synopsis\n  list-account-settings\n[--name <value>]\n[--value <value>]\n[--principal-arn <value>]\n[--effective-settings | --no-effective-settings]\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--name <value>]",
        "[--value <value>]",
        "[--principal-arn <value>]",
        "[--effective-settings | --no-effective-settings]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--name (string)\n\nThe name of the account setting you want to list the settings for.\n\nPossible values:\n\nserviceLongArnFormat\n\ntaskLongArnFormat\n\ncontainerInstanceLongArnFormat\n\nawsvpcTrunking\n\ncontainerInsights\n\n--value (string)\n\nThe value of the account settings with which to filter results. You must also specify an account setting name to use this parameter.\n\n--principal-arn (string)\n\nThe ARN of the principal, which can be an IAM user, IAM role, or the root user. If this field is omitted, the account settings are listed only for the authenticated user.\n\nNote\n\nFederated users assume the account setting of the root user and can’t have explicit account settings set for them.\n\n--effective-settings | --no-effective-settings (boolean)\n\nSpecifies whether to return the effective settings. If true , the account settings for the root user or the default setting for the principalArn are returned. If false , the account settings for the principalArn are returned if they are set. Otherwise, no account settings are returned.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nsettings -> (list)\n\nThe account settings for the resource.\n\n(structure)\n\nThe current account setting for a resource.\n\nname -> (string)\n\nThe Amazon ECS resource name.\n\nvalue -> (string)\n\nWhether the account setting is enabled or disabled for the specified resource.\n\nprincipalArn -> (string)\n\nThe ARN of the principal, which can be an IAM user, IAM role, or the root user. If this field is omitted, the authenticated user is assumed.\n\nnextToken -> (string)\n\nThe nextToken value to include in a future ListAccountSettings request. When the results of a ListAccountSettings request exceed maxResults , this value can be used to retrieve the next page of results. This value is null when there are no more results to return.",
      "command_examples": "Examples\n\nExample 1: To view the account settings for an account\n\nThe following list-account-settings example displays the effective account settings for an account.\n\naws ecs list-account-settings --effective-settings\n\n\nOutput:\n\n{\n    \"settings\": [\n        {\n            \"name\": \"containerInstanceLongArnFormat\",\n            \"value\": \"enabled\",\n            \"principalArn\": \"arn:aws:iam::123456789012:root\"\n        },\n        {\n            \"name\": \"serviceLongArnFormat\",\n            \"value\": \"enabled\",\n            \"principalArn\": \"arn:aws:iam::123456789012:root\"\n        },\n        {\n            \"name\": \"taskLongArnFormat\",\n            \"value\": \"enabled\",\n            \"principalArn\": \"arn:aws:iam::123456789012:root\"\n        }\n    ]\n}\n\n\nExample 2: To view the account settings for a specific IAM user or IAM role\n\nThe following list-account-settings example displays the account settings for the specified IAM user or IAM role.\n\naws ecs list-account-settings --principal-arn arn:aws:iam::123456789012:user/MyUser\n\n\nOutput:\n\n{\n    \"settings\": [\n        {\n            \"name\": \"serviceLongArnFormat\",\n            \"value\": \"enabled\",\n            \"principalArn\": \"arn:aws:iam::123456789012:user/MyUser\"\n        }\n    ]\n}\n\n\nFor more information, see Amazon Resource Names (ARNs) and IDs in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "list-attributes",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list-attributes.html",
      "command_description": "Description\n\nLists the attributes for Amazon ECS resources within a specified target type and cluster. When you specify a target type and cluster, ListAttributes returns a list of attribute objects, one for each attribute on each resource. You can filter the list of results to a single attribute name to only return results that have that name. You can also filter the results by attribute name and value, for example, to see which container instances in a cluster are running a Linux AMI (ecs.os-type=linux ).\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-attributes is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: attributes",
      "command_synopsis": "Synopsis\n  list-attributes\n[--cluster <value>]\n--target-type <value>\n[--attribute-name <value>]\n[--attribute-value <value>]\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--target-type <value>",
        "[--attribute-name <value>]",
        "[--attribute-value <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster to list attributes. If you do not specify a cluster, the default cluster is assumed.\n\n--target-type (string)\n\nThe type of the target with which to list attributes.\n\nPossible values:\n\ncontainer-instance\n\n--attribute-name (string)\n\nThe name of the attribute with which to filter the results.\n\n--attribute-value (string)\n\nThe value of the attribute with which to filter results. You must also specify an attribute name to use this parameter.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nattributes -> (list)\n\nA list of attribute objects that meet the criteria of the request.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nnextToken -> (string)\n\nThe nextToken value to include in a future ListAttributes request. When the results of a ListAttributes request exceed maxResults , this value can be used to retrieve the next page of results. This value is null when there are no more results to return.",
      "command_examples": "Examples\n\nTo list the container instances that contain a specific attribute\n\nThe following example lists the attributes for container instances that have the stack=production attribute in the default cluster.\n\naws ecs list-attributes \\\n    --target-type container-instance \\\n    --attribute-name stack \\\n    --attribute-value production \\\n    --cluster default\n\n\nOutput:\n\n{\n    \"attributes\": [\n        {\n            \"name\": \"stack\",\n            \"targetId\": \"arn:aws:ecs:us-west-2:130757420319:container-instance/1c3be8ed-df30-47b4-8f1e-6e68ebd01f34\",\n            \"value\": \"production\"\n        }\n    ]\n}\n\n\nFor more information, see Amazon ECS Container Agent Configuration in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "list-clusters",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list-clusters.html",
      "command_description": "Description\n\nReturns a list of existing clusters.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-clusters is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: clusterArns",
      "command_synopsis": "Synopsis\n  list-clusters\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nclusterArns -> (list)\n\nThe list of full Amazon Resource Name (ARN) entries for each cluster associated with your account.\n\n(string)\n\nnextToken -> (string)\n\nThe nextToken value to include in a future ListClusters request. When the results of a ListClusters request exceed maxResults , this value can be used to retrieve the next page of results. This value is null when there are no more results to return.",
      "command_examples": "Examples\n\nTo list your available clusters\n\nThe following list-clusters example lists all of the available clusters.\n\naws ecs list-clusters\n\n\nOutput:\n\n{\n    \"clusterArns\": [\n        \"arn:aws:ecs:us-west-2:123456789012:cluster/MyECSCluster1\",\n        \"arn:aws:ecs:us-west-2:123456789012:cluster/AnotherECSCluster\"\n    ]\n}\n\n\nFor more information, see Amazon ECS Clusters in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "list-container-instances",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list-container-instances.html",
      "command_description": "Description\n\nReturns a list of container instances in a specified cluster. You can filter the results of a ListContainerInstances operation with cluster query language statements inside the filter parameter. For more information, see Cluster Query Language in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-container-instances is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: containerInstanceArns",
      "command_synopsis": "Synopsis\n  list-container-instances\n[--cluster <value>]\n[--filter <value>]\n[--status <value>]\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "[--filter <value>]",
        "[--status <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the container instances to list. If you do not specify a cluster, the default cluster is assumed.\n\n--filter (string)\n\nYou can filter the results of a ListContainerInstances operation with cluster query language statements. For more information, see Cluster Query Language in the Amazon Elastic Container Service Developer Guide .\n\n--status (string)\n\nFilters the container instances by status. For example, if you specify the DRAINING status, the results include only container instances that have been set to DRAINING using UpdateContainerInstancesState . If you do not specify this parameter, the default is to include container instances set to all states other than INACTIVE .\n\nPossible values:\n\nACTIVE\n\nDRAINING\n\nREGISTERING\n\nDEREGISTERING\n\nREGISTRATION_FAILED\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncontainerInstanceArns -> (list)\n\nThe list of container instances with full ARN entries for each container instance associated with the specified cluster.\n\n(string)\n\nnextToken -> (string)\n\nThe nextToken value to include in a future ListContainerInstances request. When the results of a ListContainerInstances request exceed maxResults , this value can be used to retrieve the next page of results. This value is null when there are no more results to return.",
      "command_examples": "Examples\n\nTo list the container instances in a cluster\n\nThe following list-container-instances example lists all of the available container instances in a cluster.\n\naws ecs list-container-instances --cluster MyCluster\n\n\nOutput:\n\n{\n    \"containerInstanceArns\": [\n        \"arn:aws:ecs:us-west-2:123456789012:container-instance/MyCluster/a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\",\n        \"arn:aws:ecs:us-west-2:123456789012:container-instance/MyCluster/a1b2c3d4-5678-90ab-cdef-22222EXAMPLE\"\n    ]\n}\n\n\nFor more information, see Amazon ECS Container Instances in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "list-services",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list-services.html",
      "command_description": "Description\n\nReturns a list of services. You can filter the results by cluster, launch type, and scheduling strategy.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-services is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: serviceArns",
      "command_synopsis": "Synopsis\n  list-services\n[--cluster <value>]\n[--launch-type <value>]\n[--scheduling-strategy <value>]\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "[--launch-type <value>]",
        "[--scheduling-strategy <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster to use when filtering the ListServices results. If you do not specify a cluster, the default cluster is assumed.\n\n--launch-type (string)\n\nThe launch type to use when filtering the ListServices results.\n\nPossible values:\n\nEC2\n\nFARGATE\n\nEXTERNAL\n\n--scheduling-strategy (string)\n\nThe scheduling strategy to use when filtering the ListServices results.\n\nPossible values:\n\nREPLICA\n\nDAEMON\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nserviceArns -> (list)\n\nThe list of full ARN entries for each service associated with the specified cluster.\n\n(string)\n\nnextToken -> (string)\n\nThe nextToken value to include in a future ListServices request. When the results of a ListServices request exceed maxResults , this value can be used to retrieve the next page of results. This value is null when there are no more results to return.",
      "command_examples": "Examples\n\nTo list the services in a cluster\n\nThe following list-services example shows how to list the services running in a cluster.\n\naws ecs list-services --cluster MyCluster\n\n\nOutput:\n\n {\n     \"serviceArns\": [\n         \"arn:aws:ecs:us-west-2:123456789012:service/MyCluster/MyService\"\n     ]\n}\n\n\nFor more information, see Services in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "list-tags-for-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list-tags-for-resource.html",
      "command_description": "Description\n\nList the tags for an Amazon ECS resource.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-tags-for-resource\n--resource-arn <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe Amazon Resource Name (ARN) that identifies the resource for which to list the tags. Currently, the supported resources are Amazon ECS tasks, services, task definitions, clusters, and container instances.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntags -> (list)\n\nThe tags for the resource.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nTo list the tags for a resource\n\nThe following list-tags-for-resource example lists the tags for a specific cluster.\n\naws ecs list-tags-for-resource \\\n    --resource-arn arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\n\n\nOutput:\n\n{\n    \"tags\": [\n        {\n            \"key\": \"key1\",\n            \"value\": \"value1\"\n        },\n        {\n            \"key\": \"key2\",\n            \"value\": \"value2\"\n        },\n        {\n            \"key\": \"key3\",\n            \"value\": \"value3\"\n        }\n    ]\n}\n"
    },
    {
      "command_name": "list-task-definition-families",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list-task-definition-families.html",
      "command_description": "Description\n\nReturns a list of task definition families that are registered to your account (which may include task definition families that no longer have any ACTIVE task definition revisions).\n\nYou can filter out task definition families that do not contain any ACTIVE task definition revisions by setting the status parameter to ACTIVE . You can also filter the results with the familyPrefix parameter.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-task-definition-families is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: families",
      "command_synopsis": "Synopsis\n  list-task-definition-families\n[--family-prefix <value>]\n[--status <value>]\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--family-prefix <value>]",
        "[--status <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--family-prefix (string)\n\nThe familyPrefix is a string that is used to filter the results of ListTaskDefinitionFamilies . If you specify a familyPrefix , only task definition family names that begin with the familyPrefix string are returned.\n\n--status (string)\n\nThe task definition family status with which to filter the ListTaskDefinitionFamilies results. By default, both ACTIVE and INACTIVE task definition families are listed. If this parameter is set to ACTIVE , only task definition families that have an ACTIVE task definition revision are returned. If this parameter is set to INACTIVE , only task definition families that do not have any ACTIVE task definition revisions are returned. If you paginate the resulting output, be sure to keep the status value constant in each subsequent request.\n\nPossible values:\n\nACTIVE\n\nINACTIVE\n\nALL\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nfamilies -> (list)\n\nThe list of task definition family names that match the ListTaskDefinitionFamilies request.\n\n(string)\n\nnextToken -> (string)\n\nThe nextToken value to include in a future ListTaskDefinitionFamilies request. When the results of a ListTaskDefinitionFamilies request exceed maxResults , this value can be used to retrieve the next page of results. This value is null when there are no more results to return.",
      "command_examples": "Examples\n\nExample 1: To list the registered task definition families\n\nThe following list-task-definition-families example lists all of the registered task definition families.\n\naws ecs list-task-definition-families\n\n\nOutput:\n\n{\n    \"families\": [\n        \"node-js-app\",\n        \"web-timer\",\n        \"hpcc\",\n        \"hpcc-c4-8xlarge\"\n    ]\n}\n\n\nExample 2: To filter the registered task definition families\n\nThe following list-task-definition-families example lists the task definition revisions that start with “hpcc”.\n\naws ecs list-task-definition-families --family-prefix hpcc\n\n\nOutput:\n\n{\n    \"families\": [\n        \"hpcc\",\n        \"hpcc-c4-8xlarge\"\n    ]\n}\n\n\nFor more information, see Task Definition Parameters in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "list-task-definitions",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list-task-definitions.html",
      "command_description": "Description\n\nReturns a list of task definitions that are registered to your account. You can filter the results by family name with the familyPrefix parameter or by status with the status parameter.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-task-definitions is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: taskDefinitionArns",
      "command_synopsis": "Synopsis\n  list-task-definitions\n[--family-prefix <value>]\n[--status <value>]\n[--sort <value>]\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--family-prefix <value>]",
        "[--status <value>]",
        "[--sort <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--family-prefix (string)\n\nThe full family name with which to filter the ListTaskDefinitions results. Specifying a familyPrefix limits the listed task definitions to task definition revisions that belong to that family.\n\n--status (string)\n\nThe task definition status with which to filter the ListTaskDefinitions results. By default, only ACTIVE task definitions are listed. By setting this parameter to INACTIVE , you can view task definitions that are INACTIVE as long as an active task or service still references them. If you paginate the resulting output, be sure to keep the status value constant in each subsequent request.\n\nPossible values:\n\nACTIVE\n\nINACTIVE\n\n--sort (string)\n\nThe order in which to sort the results. Valid values are ASC and DESC . By default (ASC ), task definitions are listed lexicographically by family name and in ascending numerical order by revision so that the newest task definitions in a family are listed last. Setting this parameter to DESC reverses the sort order on family name and revision so that the newest task definitions in a family are listed first.\n\nPossible values:\n\nASC\n\nDESC\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntaskDefinitionArns -> (list)\n\nThe list of task definition Amazon Resource Name (ARN) entries for the ListTaskDefinitions request.\n\n(string)\n\nnextToken -> (string)\n\nThe nextToken value to include in a future ListTaskDefinitions request. When the results of a ListTaskDefinitions request exceed maxResults , this value can be used to retrieve the next page of results. This value is null when there are no more results to return.",
      "command_examples": "Examples\n\nExample 1: To list the registered task definitions\n\nThe following list-task-definitions example lists all of the registered task definitions.\n\naws ecs list-task-definitions\n\n\nOutput:\n\n{\n    \"taskDefinitionArns\": [\n        \"arn:aws:ecs:us-west-2:123456789012:task-definition/sleep300:2\",\n        \"arn:aws:ecs:us-west-2:123456789012:task-definition/sleep360:1\",\n        \"arn:aws:ecs:us-west-2:123456789012:task-definition/wordpress:3\",\n        \"arn:aws:ecs:us-west-2:123456789012:task-definition/wordpress:4\",\n        \"arn:aws:ecs:us-west-2:123456789012:task-definition/wordpress:5\",\n        \"arn:aws:ecs:us-west-2:123456789012:task-definition/wordpress:6\"\n    ]\n}\n\n\nExample 2: To list the registered task definitions in a family\n\nThe following list-task-definitions example lists the task definition revisions of a specified family.\n\naws ecs list-task-definitions --family-prefix wordpress\n\n\nOutput:\n\n{\n    \"taskDefinitionArns\": [\n        \"arn:aws:ecs:us-west-2:123456789012:task-definition/wordpress:3\",\n        \"arn:aws:ecs:us-west-2:123456789012:task-definition/wordpress:4\",\n        \"arn:aws:ecs:us-west-2:123456789012:task-definition/wordpress:5\",\n        \"arn:aws:ecs:us-west-2:123456789012:task-definition/wordpress:6\"\n    ]\n}\n\n\nFor more information, see Amazon ECS Task Definitions in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "list-tasks",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list-tasks.html",
      "command_description": "Description\n\nReturns a list of tasks. You can filter the results by cluster, task definition family, container instance, launch type, what IAM principal started the task, or by the desired status of the task.\n\nRecently stopped tasks might appear in the returned results. Currently, stopped tasks appear in the returned results for at least one hour.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-tasks is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: taskArns",
      "command_synopsis": "Synopsis\n  list-tasks\n[--cluster <value>]\n[--container-instance <value>]\n[--family <value>]\n[--started-by <value>]\n[--service-name <value>]\n[--desired-status <value>]\n[--launch-type <value>]\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "[--container-instance <value>]",
        "[--family <value>]",
        "[--started-by <value>]",
        "[--service-name <value>]",
        "[--desired-status <value>]",
        "[--launch-type <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster to use when filtering the ListTasks results. If you do not specify a cluster, the default cluster is assumed.\n\n--container-instance (string)\n\nThe container instance ID or full ARN of the container instance to use when filtering the ListTasks results. Specifying a containerInstance limits the results to tasks that belong to that container instance.\n\n--family (string)\n\nThe name of the task definition family to use when filtering the ListTasks results. Specifying a family limits the results to tasks that belong to that family.\n\n--started-by (string)\n\nThe startedBy value with which to filter the task results. Specifying a startedBy value limits the results to tasks that were started with that value.\n\n--service-name (string)\n\nThe name of the service to use when filtering the ListTasks results. Specifying a serviceName limits the results to tasks that belong to that service.\n\n--desired-status (string)\n\nThe task desired status to use when filtering the ListTasks results. Specifying a desiredStatus of STOPPED limits the results to tasks that Amazon ECS has set the desired status to STOPPED . This can be useful for debugging tasks that are not starting properly or have died or finished. The default status filter is RUNNING , which shows tasks that Amazon ECS has set the desired status to RUNNING .\n\nNote\n\nAlthough you can filter results based on a desired status of PENDING , this does not return any results. Amazon ECS never sets the desired status of a task to that value (only a task’s lastStatus may have a value of PENDING ).\n\nPossible values:\n\nRUNNING\n\nPENDING\n\nSTOPPED\n\n--launch-type (string)\n\nThe launch type to use when filtering the ListTasks results.\n\nPossible values:\n\nEC2\n\nFARGATE\n\nEXTERNAL\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntaskArns -> (list)\n\nThe list of task ARN entries for the ListTasks request.\n\n(string)\n\nnextToken -> (string)\n\nThe nextToken value to include in a future ListTasks request. When the results of a ListTasks request exceed maxResults , this value can be used to retrieve the next page of results. This value is null when there are no more results to return.",
      "command_examples": "Examples\n\nExample 1: To list the tasks in a cluster\n\nThe following list-tasks example lists all of the tasks in a cluster.\n\naws ecs list-tasks --cluster default\n\n\nOutput:\n\n{\n    \"taskArns\": [\n        \"arn:aws:ecs:us-west-2:123456789012:task/a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\",\n        \"arn:aws:ecs:us-west-2:123456789012:task/a1b2c3d4-5678-90ab-cdef-22222EXAMPLE\"\n    ]\n}\n\n\nExample 2: To list the tasks on a particular container instance\n\nThe following list-tasks example lists the tasks on a container instance, using the container instance UUID as a filter.\n\naws ecs list-tasks --cluster default --container-instance a1b2c3d4-5678-90ab-cdef-33333EXAMPLE\n\n\nOutput:\n\n{\n    \"taskArns\": [\n        \"arn:aws:ecs:us-west-2:123456789012:task/a1b2c3d4-5678-90ab-cdef-44444EXAMPLE\"\n    ]\n}\n\n\nFor more information, see Amazon ECS Task Definitions in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "put-account-setting",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/put-account-setting.html",
      "command_description": "Description\n\nModifies an account setting. Account settings are set on a per-Region basis.\n\nIf you change the account setting for the root user, the default settings for all of the IAM users and roles for which no individual account setting has been specified are reset. For more information, see Account Settings in the Amazon Elastic Container Service Developer Guide .\n\nWhen serviceLongArnFormat , taskLongArnFormat , or containerInstanceLongArnFormat are specified, the Amazon Resource Name (ARN) and resource ID format of the resource type for a specified IAM user, IAM role, or the root user for an account is affected. The opt-in and opt-out account setting must be set for each Amazon ECS resource separately. The ARN and resource ID format of a resource will be defined by the opt-in status of the IAM user or role that created the resource. You must enable this setting to use Amazon ECS features such as resource tagging.\n\nWhen awsvpcTrunking is specified, the elastic network interface (ENI) limit for any new container instances that support the feature is changed. If awsvpcTrunking is enabled, any new container instances that support the feature are launched have the increased ENI limits available to them. For more information, see Elastic Network Interface Trunking in the Amazon Elastic Container Service Developer Guide .\n\nWhen containerInsights is specified, the default setting indicating whether CloudWatch Container Insights is enabled for your clusters is changed. If containerInsights is enabled, any new clusters that are created will have Container Insights enabled unless you disable it during cluster creation. For more information, see CloudWatch Container Insights in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  put-account-setting\n--name <value>\n--value <value>\n[--principal-arn <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--name <value>",
        "--value <value>",
        "[--principal-arn <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--name (string)\n\nThe Amazon ECS resource name for which to modify the account setting. If serviceLongArnFormat is specified, the ARN for your Amazon ECS services is affected. If taskLongArnFormat is specified, the ARN and resource ID for your Amazon ECS tasks is affected. If containerInstanceLongArnFormat is specified, the ARN and resource ID for your Amazon ECS container instances is affected. If awsvpcTrunking is specified, the elastic network interface (ENI) limit for your Amazon ECS container instances is affected. If containerInsights is specified, the default setting for CloudWatch Container Insights for your clusters is affected.\n\nPossible values:\n\nserviceLongArnFormat\n\ntaskLongArnFormat\n\ncontainerInstanceLongArnFormat\n\nawsvpcTrunking\n\ncontainerInsights\n\n--value (string)\n\nThe account setting value for the specified principal ARN. Accepted values are enabled and disabled .\n\n--principal-arn (string)\n\nThe ARN of the principal, which can be an IAM user, IAM role, or the root user. If you specify the root user, it modifies the account setting for all IAM users, IAM roles, and the root user of the account unless an IAM user or role explicitly overrides these settings. If this field is omitted, the setting is changed only for the authenticated user.\n\nNote\n\nFederated users assume the account setting of the root user and can’t have explicit account settings set for them.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nsetting -> (structure)\n\nThe current account setting for a resource.\n\nname -> (string)\n\nThe Amazon ECS resource name.\n\nvalue -> (string)\n\nWhether the account setting is enabled or disabled for the specified resource.\n\nprincipalArn -> (string)\n\nThe ARN of the principal, which can be an IAM user, IAM role, or the root user. If this field is omitted, the authenticated user is assumed.",
      "command_examples": "Examples\n\nTo modify the account setting for your IAM user account\n\nThe following put-account-setting example enables the serviceLongArnFormat account setting for your IAM user account.\n\naws ecs put-account-setting --name serviceLongArnFormat --value enabled\n\n\nOutput:\n\n{\n    \"setting\": {\n        \"name\": \"serviceLongArnFormat\",\n        \"value\": \"enabled\",\n        \"principalArn\": \"arn:aws:iam::130757420319:user/your_username\"\n    }\n}\n\n\nFor more information, see Modifying Account Settings in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "put-account-setting-default",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/put-account-setting-default.html",
      "command_description": "Description\n\nModifies an account setting for all IAM users on an account for whom no individual account setting has been specified. Account settings are set on a per-Region basis.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  put-account-setting-default\n--name <value>\n--value <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--name <value>",
        "--value <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--name (string)\n\nThe resource name for which to modify the account setting. If serviceLongArnFormat is specified, the ARN for your Amazon ECS services is affected. If taskLongArnFormat is specified, the ARN and resource ID for your Amazon ECS tasks is affected. If containerInstanceLongArnFormat is specified, the ARN and resource ID for your Amazon ECS container instances is affected. If awsvpcTrunking is specified, the ENI limit for your Amazon ECS container instances is affected. If containerInsights is specified, the default setting for CloudWatch Container Insights for your clusters is affected.\n\nPossible values:\n\nserviceLongArnFormat\n\ntaskLongArnFormat\n\ncontainerInstanceLongArnFormat\n\nawsvpcTrunking\n\ncontainerInsights\n\n--value (string)\n\nThe account setting value for the specified principal ARN. Accepted values are enabled and disabled .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nsetting -> (structure)\n\nThe current setting for a resource.\n\nname -> (string)\n\nThe Amazon ECS resource name.\n\nvalue -> (string)\n\nWhether the account setting is enabled or disabled for the specified resource.\n\nprincipalArn -> (string)\n\nThe ARN of the principal, which can be an IAM user, IAM role, or the root user. If this field is omitted, the authenticated user is assumed.",
      "command_examples": "Examples\n\nTo modify the default account settings\n\nThe following put-account-setting-default example modifies the default account setting for all IAM users or roles on your account. These changes apply to the entire AWS account unless an IAM user or role explicitly overrides these settings for themselves.\n\naws ecs put-account-setting-default --name serviceLongArnFormat --value enabled\n\n\nOutput:\n\n{\n    \"setting\": {\n        \"name\": \"serviceLongArnFormat\",\n        \"value\": \"enabled\",\n        \"principalArn\": \"arn:aws:iam::123456789012:root\"\n    }\n}\n\n\nFor more information, see Amazon Resource Names (ARNs) and IDs in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "put-attributes",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/put-attributes.html",
      "command_description": "Description\n\nCreate or update an attribute on an Amazon ECS resource. If the attribute does not exist, it is created. If the attribute exists, its value is replaced with the specified value. To delete an attribute, use DeleteAttributes . For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  put-attributes\n[--cluster <value>]\n--attributes <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--attributes <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that contains the resource to apply attributes. If you do not specify a cluster, the default cluster is assumed.\n\n--attributes (list)\n\nThe attributes to apply to your resource. You can specify up to 10 custom attributes per resource. You can specify up to 10 attributes in a single call.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nShorthand Syntax:\n\nname=string,value=string,targetType=string,targetId=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"name\": \"string\",\n    \"value\": \"string\",\n    \"targetType\": \"container-instance\",\n    \"targetId\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nattributes -> (list)\n\nThe attributes applied to your resource.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).",
      "command_examples": "Examples\n\nTo create an attribute and associate it with an Amazon ECS resource\n\nThe following put-attributes applies an attribute with the name stack and the value production to a container instance.\n\naws ecs put-attributes \\\n    --attributes name=stack,value=production,targetId=arn:aws:ecs:us-west-2:130757420319:container-instance/1c3be8ed-df30-47b4-8f1e-6e68ebd01f34\n\n\nOutput:\n\n{\n    \"attributes\": [\n        {\n            \"name\": \"stack\",\n            \"targetId\": \"arn:aws:ecs:us-west-2:130757420319:container-instance/1c3be8ed-df30-47b4-8f1e-6e68ebd01f34\",\n            \"value\": \"production\"\n        }\n    ]\n}\n"
    },
    {
      "command_name": "put-cluster-capacity-providers",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/put-cluster-capacity-providers.html",
      "command_description": "Description\n\nModifies the available capacity providers and the default capacity provider strategy for a cluster.\n\nYou must specify both the available capacity providers and a default capacity provider strategy for the cluster. If the specified cluster has existing capacity providers associated with it, you must specify all existing capacity providers in addition to any new ones you want to add. Any existing capacity providers associated with a cluster that are omitted from a PutClusterCapacityProviders API call will be disassociated with the cluster. You can only disassociate an existing capacity provider from a cluster if it’s not being used by any existing tasks.\n\nWhen creating a service or running a task on a cluster, if no capacity provider or launch type is specified, then the cluster’s default capacity provider strategy is used. It is recommended to define a default capacity provider strategy for your cluster, however you may specify an empty array ([] ) to bypass defining a default strategy.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  put-cluster-capacity-providers\n--cluster <value>\n--capacity-providers <value>\n--default-capacity-provider-strategy <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--cluster <value>",
        "--capacity-providers <value>",
        "--default-capacity-provider-strategy <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster to modify the capacity provider settings for. If you do not specify a cluster, the default cluster is assumed.\n\n--capacity-providers (list)\n\nThe name of one or more capacity providers to associate with the cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--default-capacity-provider-strategy (list)\n\nThe capacity provider strategy to use by default for the cluster.\n\nWhen creating a service or running a task on a cluster, if no capacity provider or launch type is specified then the default capacity provider strategy for the cluster is used.\n\nA capacity provider strategy consists of one or more capacity providers along with the base and weight to assign to them. A capacity provider must be associated with the cluster to be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster. Only capacity providers with an ACTIVE or UPDATING status can be used.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nShorthand Syntax:\n\ncapacityProvider=string,weight=integer,base=integer ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"capacityProvider\": \"string\",\n    \"weight\": integer,\n    \"base\": integer\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncluster -> (structure)\n\nDetails about the cluster.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the cluster. The ARN contains the arn:aws:ecs namespace, followed by the Region of the cluster, the Amazon Web Services account ID of the cluster owner, the cluster namespace, and then the cluster name. For example, arn:aws:ecs:region:012345678910:cluster/test .\n\nclusterName -> (string)\n\nA user-generated string that you use to identify your cluster.\n\nconfiguration -> (structure)\n\nThe execute command configuration for the cluster.\n\nexecuteCommandConfiguration -> (structure)\n\nThe details of the execute command configuration.\n\nkmsKeyId -> (string)\n\nSpecify an Key Management Service key ID to encrypt the data between the local client and the container.\n\nlogging -> (string)\n\nThe log setting to use for redirecting logs for your execute command results. The following log settings are available.\n\nNONE : The execute command session is not logged.\n\nDEFAULT : The awslogs configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no awslogs log driver is configured in the task definition, the output won’t be logged.\n\nOVERRIDE : Specify the logging details as a part of logConfiguration . If the OVERRIDE logging option is specified, the logConfiguration is required.\n\nlogConfiguration -> (structure)\n\nThe log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When logging=OVERRIDE is specified, a logConfiguration must be provided.\n\ncloudWatchLogGroupName -> (string)\n\nThe name of the CloudWatch log group to send logs to.\n\nNote\n\nThe CloudWatch log group must already be created.\n\ncloudWatchEncryptionEnabled -> (boolean)\n\nWhether or not to enable encryption on the CloudWatch logs. If not specified, encryption will be disabled.\n\ns3BucketName -> (string)\n\nThe name of the S3 bucket to send logs to.\n\nNote\n\nThe S3 bucket must already be created.\n\ns3EncryptionEnabled -> (boolean)\n\nWhether or not to use encryption on the S3 logs. If not specified, encryption is not used.\n\ns3KeyPrefix -> (string)\n\nAn optional folder in the S3 bucket to place logs in.\n\nstatus -> (string)\n\nThe status of the cluster. The following are the possible states that will be returned.\n\nACTIVE\n\nThe cluster is ready to accept tasks and if applicable you can register container instances with the cluster.\n\nPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being created.\n\nDEPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being deleted.\n\nFAILED\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider have failed to create.\n\nINACTIVE\n\nThe cluster has been deleted. Clusters with an INACTIVE status may remain discoverable in your account for a period of time. However, this behavior is subject to change in the future, so you should not rely on INACTIVE clusters persisting.\n\nregisteredContainerInstancesCount -> (integer)\n\nThe number of container instances registered into the cluster. This includes container instances in both ACTIVE and DRAINING status.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the RUNNING state.\n\npendingTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the PENDING state.\n\nactiveServicesCount -> (integer)\n\nThe number of services that are running on the cluster in an ACTIVE state. You can view these services with ListServices .\n\nstatistics -> (list)\n\nAdditional information about your clusters that are separated by launch type, including:\n\nrunningEC2TasksCount\n\nRunningFargateTasksCount\n\npendingEC2TasksCount\n\npendingFargateTasksCount\n\nactiveEC2ServiceCount\n\nactiveFargateServiceCount\n\ndrainingEC2ServiceCount\n\ndrainingFargateServiceCount\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the cluster to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nsettings -> (list)\n\nThe settings for the cluster. This parameter indicates whether CloudWatch Container Insights is enabled or disabled for a cluster.\n\n(structure)\n\nThe settings to use when creating a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster.\n\nname -> (string)\n\nThe name of the cluster setting. The only supported value is containerInsights .\n\nvalue -> (string)\n\nThe value to set for the cluster setting. The supported values are enabled and disabled . If enabled is specified, CloudWatch Container Insights will be enabled for the cluster, otherwise it will be disabled unless the containerInsights account setting is enabled. If a cluster value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\ncapacityProviders -> (list)\n\nThe capacity providers associated with the cluster.\n\n(string)\n\ndefaultCapacityProviderStrategy -> (list)\n\nThe default capacity provider strategy for the cluster. When services or tasks are run in the cluster with no launch type or capacity provider strategy specified, the default capacity provider strategy is used.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nattachments -> (list)\n\nThe resources attached to a cluster. When using a capacity provider with a cluster, the Auto Scaling plan that is created will be returned as a cluster attachment.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nattachmentsStatus -> (string)\n\nThe status of the capacity providers associated with the cluster. The following are the states that will be returned:\n\nUPDATE_IN_PROGRESS\n\nThe available capacity providers for the cluster are updating. This occurs when the Auto Scaling plan is provisioning or deprovisioning.\n\nUPDATE_COMPLETE\n\nThe capacity providers have successfully updated.\n\nUPDATE_FAILED\n\nThe capacity provider updates failed.",
      "command_examples": "Examples\n\nExample 1: To add an existing capacity provider to a cluster\n\nThe following put-cluster-capacity-providers example adds an existing capacity provider to a cluster. The create-capacity-provider command is used to create a capacity provider. The describe-clusters command is used to describe the current capacity providers and the default capacity provider strategy associated with a cluster. When adding a new capacity provider to a cluster, you must specify all existing capacity providers in addition to the new capacity provider you want to associate with the cluster. You must also specify the default capacity provider strategy to associate with the cluster. In this example, the MyCluster cluster has the MyCapacityProvider1 capacity provider associated with it and you want to add the MyCapacityProvider2 capacity provider and include it in the default capacity provider strategy so tasks are spread evenly across both capacity providers.\n\naws ecs put-cluster-capacity-providers \\\n    --cluster MyCluster \\\n    --capacity-providers MyCapacityProvider1 MyCapacityProvider2 \\\n    --default-capacity-provider-strategy capacityProvider=MyCapacityProvider1,weight=1 capacityProvider=MyCapacityProvider2,weight=1\n\n\nOutput:\n\n{\n    \"cluster\": {\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"clusterName\": \"MyCluster\",\n        \"status\": \"ACTIVE\",\n        \"registeredContainerInstancesCount\": 0,\n        \"runningTasksCount\": 0,\n        \"pendingTasksCount\": 0,\n        \"activeServicesCount\": 0,\n        \"statistics\": [],\n        \"tags\": [],\n        \"settings\": [\n            {\n                \"name\": \"containerInsights\",\n                \"value\": \"enabled\"\n            }\n        ],\n        \"capacityProviders\": [\n            \"MyCapacityProvider1\",\n            \"MyCapacityProvider2\"\n        ],\n        \"defaultCapacityProviderStrategy\": [\n            {\n                \"capacityProvider\": \"MyCapacityProvider1\",\n                \"weight\": 1,\n                \"base\": 0\n            },\n            {\n                \"capacityProvider\": \"MyCapacityProvider2\",\n                \"weight\": 1,\n                \"base\": 0\n            }\n        ],\n        \"attachments\": [\n           {\n                \"id\": \"0fb0c8f4-6edd-4de1-9b09-17e470ee1918\",\n                \"type\": \"asp\",\n                \"status\": \"ACTIVE\",\n                \"details\": [\n                    {\n                        \"name\": \"capacityProviderName\",\n                        \"value\": \"MyCapacityProvider1\"\n                    },\n                    {\n                        \"name\": \"scalingPlanName\",\n                        \"value\": \"ECSManagedAutoScalingPlan-a1b2c3d4-5678-90ab-cdef-EXAMPLE11111\"\n                    }\n                ]\n            },\n            {\n                \"id\": \"ae592060-2382-4663-9476-b015c685593c\",\n                \"type\": \"asp\",\n                \"status\": \"ACTIVE\",\n                \"details\": [\n                    {\n                        \"name\": \"capacityProviderName\",\n                        \"value\": \"MyCapacityProvider2\"\n                    },\n                    {\n                        \"name\": \"scalingPlanName\",\n                        \"value\": \"ECSManagedAutoScalingPlan-a1b2c3d4-5678-90ab-cdef-EXAMPLE22222\"\n                    }\n                ]\n            }\n        ],\n        \"attachmentsStatus\": \"UPDATE_IN_PROGRESS\"\n    }\n}\n\n\nFor more information, see Cluster capacity providers in the Amazon ECS Developer Guide.\n\nExample 2: To remove a capacity provider from a cluster\n\nThe following put-cluster-capacity-providers example removes a capacity provider from a cluster. The describe-clusters command is used to describe the current capacity providers associated with a cluster. When removing a capacity provider from a cluster, you must specify the capacity providers you want to remain associated with the cluster as well as the default capacity provider strategy to associate with the cluster. In this example, the cluster has the MyCapacityProvider1 and MyCapacityProvider2 capacity providers associated with it and you want to remove the MyCapacityProvider2 capacity provider, so you specify only MyCapacityProvider1 in the command along with the updated default capacity provider strategy.\n\naws ecs put-cluster-capacity-providers \\\n    --cluster MyCluster \\\n    --capacity-providers MyCapacityProvider1 \\\n    --default-capacity-provider-strategy capacityProvider=MyCapacityProvider1,weight=1,base=0\n\n\nOutput:\n\n{\n    \"cluster\": {\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"clusterName\": \"MyCluster\",\n        \"status\": \"ACTIVE\",\n        \"registeredContainerInstancesCount\": 0,\n        \"runningTasksCount\": 0,\n        \"pendingTasksCount\": 0,\n        \"activeServicesCount\": 0,\n        \"statistics\": [],\n        \"tags\": [],\n        \"settings\": [\n            {\n                \"name\": \"containerInsights\",\n                \"value\": \"enabled\"\n            }\n        ],\n        \"capacityProviders\": [\n            \"MyCapacityProvider1\"\n        ],\n        \"defaultCapacityProviderStrategy\": [\n            \"capacityProvider\": \"MyCapacityProvider1\",\n            \"weight\": 1,\n            \"base\": 0\n        ],\n        \"attachments\": [\n           {\n                \"id\": \"0fb0c8f4-6edd-4de1-9b09-17e470ee1918\",\n                \"type\": \"asp\",\n                \"status\": \"ACTIVE\",\n                \"details\": [\n                    {\n                        \"name\": \"capacityProviderName\",\n                        \"value\": \"MyCapacityProvider1\"\n                    },\n                    {\n                        \"name\": \"scalingPlanName\",\n                        \"value\": \"ECSManagedAutoScalingPlan-a1b2c3d4-5678-90ab-cdef-EXAMPLE11111\"\n                    }\n                ]\n            },\n            {\n                \"id\": \"ae592060-2382-4663-9476-b015c685593c\",\n                \"type\": \"asp\",\n                \"status\": \"DELETING\",\n                \"details\": [\n                    {\n                        \"name\": \"capacityProviderName\",\n                        \"value\": \"MyCapacityProvider2\"\n                    },\n                    {\n                        \"name\": \"scalingPlanName\",\n                        \"value\": \"ECSManagedAutoScalingPlan-a1b2c3d4-5678-90ab-cdef-EXAMPLE22222\"\n                    }\n                ]\n            }\n        ],\n        \"attachmentsStatus\": \"UPDATE_IN_PROGRESS\"\n    }\n}\n\n\nFor more information, see Cluster capacity providers in the Amazon ECS Developer Guide.\n\nExample 3: To remove all capacity providers from a cluster\n\nThe following put-cluster-capacity-providers example removes all existing capacity providers from the cluster.\n\naws ecs put-cluster-capacity-providers \\\n    --cluster MyCluster \\\n    --capacity-providers [] \\\n    --default-capacity-provider-strategy []\n\n\nOutput:\n\n{\n    \"cluster\": {\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"clusterName\": \"MyCluster\",\n        \"status\": \"ACTIVE\",\n        \"registeredContainerInstancesCount\": 0,\n        \"runningTasksCount\": 0,\n        \"pendingTasksCount\": 0,\n        \"activeServicesCount\": 0,\n        \"statistics\": [],\n        \"tags\": [],\n        \"settings\": [\n            {\n                \"name\": \"containerInsights\",\n                \"value\": \"enabled\"\n            }\n        ],\n        \"capacityProviders\": [],\n        \"defaultCapacityProviderStrategy\": [],\n        \"attachments\": [\n           {\n                \"id\": \"0fb0c8f4-6edd-4de1-9b09-17e470ee1918\",\n                \"type\": \"asp\",\n                \"status\": \"DELETING\",\n                \"details\": [\n                    {\n                        \"name\": \"capacityProviderName\",\n                        \"value\": \"MyCapacityProvider1\"\n                    },\n                    {\n                        \"name\": \"scalingPlanName\",\n                        \"value\": \"ECSManagedAutoScalingPlan-a1b2c3d4-5678-90ab-cdef-EXAMPLE11111\"\n                    }\n                ]\n            },\n            {\n                \"id\": \"ae592060-2382-4663-9476-b015c685593c\",\n                \"type\": \"asp\",\n                \"status\": \"DELETING\",\n                \"details\": [\n                    {\n                        \"name\": \"capacityProviderName\",\n                        \"value\": \"MyCapacityProvider2\"\n                    },\n                    {\n                        \"name\": \"scalingPlanName\",\n                        \"value\": \"ECSManagedAutoScalingPlan-a1b2c3d4-5678-90ab-cdef-EXAMPLE22222\"\n                    }\n                ]\n            }\n        ],\n        \"attachmentsStatus\": \"UPDATE_IN_PROGRESS\"\n    }\n}\n\n\nFor more information, see Cluster capacity providers in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "register-container-instance",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/register-container-instance.html",
      "command_description": "Description\n\nNote\n\nThis action is only used by the Amazon ECS agent, and it is not intended for use outside of the agent.\n\nRegisters an EC2 instance into the specified cluster. This instance becomes available to place containers on.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  register-container-instance\n[--cluster <value>]\n[--instance-identity-document <value>]\n[--instance-identity-document-signature <value>]\n[--total-resources <value>]\n[--version-info <value>]\n[--container-instance-arn <value>]\n[--attributes <value>]\n[--platform-devices <value>]\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "[--instance-identity-document <value>]",
        "[--instance-identity-document-signature <value>]",
        "[--total-resources <value>]",
        "[--version-info <value>]",
        "[--container-instance-arn <value>]",
        "[--attributes <value>]",
        "[--platform-devices <value>]",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster with which to register your container instance. If you do not specify a cluster, the default cluster is assumed.\n\n--instance-identity-document (string)\n\nThe instance identity document for the EC2 instance to register. This document can be found by running the following command from the instance: curl http://169.254.169.254/latest/dynamic/instance-identity/document/\n\n--instance-identity-document-signature (string)\n\nThe instance identity document signature for the EC2 instance to register. This signature can be found by running the following command from the instance: curl http://169.254.169.254/latest/dynamic/instance-identity/signature/\n\n--total-resources (list)\n\nThe resources available on the instance.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nShorthand Syntax:\n\nname=string,type=string,doubleValue=double,longValue=long,integerValue=integer,stringSetValue=string,string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"name\": \"string\",\n    \"type\": \"string\",\n    \"doubleValue\": double,\n    \"longValue\": long,\n    \"integerValue\": integer,\n    \"stringSetValue\": [\"string\", ...]\n  }\n  ...\n]\n\n\n--version-info (structure)\n\nThe version information for the Amazon ECS container agent and Docker daemon running on the container instance.\n\nagentVersion -> (string)\n\nThe version number of the Amazon ECS container agent.\n\nagentHash -> (string)\n\nThe Git commit hash for the Amazon ECS container agent build on the amazon-ecs-agent GitHub repository.\n\ndockerVersion -> (string)\n\nThe Docker version running on the container instance.\n\nShorthand Syntax:\n\nagentVersion=string,agentHash=string,dockerVersion=string\n\n\nJSON Syntax:\n\n{\n  \"agentVersion\": \"string\",\n  \"agentHash\": \"string\",\n  \"dockerVersion\": \"string\"\n}\n\n\n--container-instance-arn (string)\n\nThe ARN of the container instance (if it was previously registered).\n\n--attributes (list)\n\nThe container instance attributes that this container instance supports.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nShorthand Syntax:\n\nname=string,value=string,targetType=string,targetId=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"name\": \"string\",\n    \"value\": \"string\",\n    \"targetType\": \"container-instance\",\n    \"targetId\": \"string\"\n  }\n  ...\n]\n\n\n--platform-devices (list)\n\nThe devices that are available on the container instance. The only supported device type is a GPU.\n\n(structure)\n\nThe devices that are available on the container instance. The only supported device type is a GPU.\n\nid -> (string)\n\nThe ID for the GPU(s) on the container instance. The available GPU IDs can also be obtained on the container instance in the /var/lib/ecs/gpu/nvidia_gpu_info.json file.\n\ntype -> (string)\n\nThe type of device that is available on the container instance. The only supported value is GPU .\n\nShorthand Syntax:\n\nid=string,type=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"id\": \"string\",\n    \"type\": \"GPU\"\n  }\n  ...\n]\n\n\n--tags (list)\n\nThe metadata that you apply to the container instance to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncontainerInstance -> (structure)\n\nThe container instance that was registered.\n\ncontainerInstanceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the container instance. The ARN contains the arn:aws:ecs namespace, followed by the Region of the container instance, the Amazon Web Services account ID of the container instance owner, the container-instance namespace, and then the container instance ID. For example, arn:aws:ecs:region:aws_account_id:container-instance/container_instance_ID .\n\nec2InstanceId -> (string)\n\nThe ID of the container instance. For Amazon EC2 instances, this value is the Amazon EC2 instance ID. For external instances, this value is the Amazon Web Services Systems Manager managed instance ID.\n\ncapacityProviderName -> (string)\n\nThe capacity provider associated with the container instance.\n\nversion -> (long)\n\nThe version counter for the container instance. Every time a container instance experiences a change that triggers a CloudWatch event, the version counter is incremented. If you are replicating your Amazon ECS container instance state with CloudWatch Events, you can compare the version of a container instance reported by the Amazon ECS APIs with the version reported in CloudWatch Events for the container instance (inside the detail object) to verify that the version in your event stream is current.\n\nversionInfo -> (structure)\n\nThe version information for the Amazon ECS container agent and Docker daemon running on the container instance.\n\nagentVersion -> (string)\n\nThe version number of the Amazon ECS container agent.\n\nagentHash -> (string)\n\nThe Git commit hash for the Amazon ECS container agent build on the amazon-ecs-agent GitHub repository.\n\ndockerVersion -> (string)\n\nThe Docker version running on the container instance.\n\nremainingResources -> (list)\n\nFor CPU and memory resource types, this parameter describes the remaining CPU and memory that has not already been allocated to tasks and is therefore available for new tasks. For port resource types, this parameter describes the ports that were reserved by the Amazon ECS container agent (at instance registration time) and any task containers that have reserved port mappings on the host (with the host or bridge network mode). Any port that is not specified here is available for new tasks.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nregisteredResources -> (list)\n\nFor CPU and memory resource types, this parameter describes the amount of each resource that was available on the container instance when the container agent registered it with Amazon ECS. This value represents the total amount of CPU and memory that can be allocated on this container instance to tasks. For port resource types, this parameter describes the ports that were reserved by the Amazon ECS container agent when it registered the container instance with Amazon ECS.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nstatus -> (string)\n\nThe status of the container instance. The valid values are REGISTERING , REGISTRATION_FAILED , ACTIVE , INACTIVE , DEREGISTERING , or DRAINING .\n\nIf your account has opted in to the awsvpcTrunking account setting, then any newly registered container instance will transition to a REGISTERING status while the trunk elastic network interface is provisioned for the instance. If the registration fails, the instance will transition to a REGISTRATION_FAILED status. You can describe the container instance and see the reason for failure in the statusReason parameter. Once the container instance is terminated, the instance transitions to a DEREGISTERING status while the trunk elastic network interface is deprovisioned. The instance then transitions to an INACTIVE status.\n\nThe ACTIVE status indicates that the container instance can accept tasks. The DRAINING indicates that new tasks are not placed on the container instance and any service tasks running on the container instance are removed if possible. For more information, see Container Instance Draining in the Amazon Elastic Container Service Developer Guide .\n\nstatusReason -> (string)\n\nThe reason that the container instance reached its current status.\n\nagentConnected -> (boolean)\n\nThis parameter returns true if the agent is connected to Amazon ECS. Registered instances with an agent that may be unhealthy or stopped return false . Only instances connected to an agent can accept placement requests.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks on the container instance that are in the RUNNING status.\n\npendingTasksCount -> (integer)\n\nThe number of tasks on the container instance that are in the PENDING status.\n\nagentUpdateStatus -> (string)\n\nThe status of the most recent agent update. If an update has never been requested, this value is NULL .\n\nattributes -> (list)\n\nThe attributes set for the container instance, either by the Amazon ECS container agent at instance registration or manually with the PutAttributes operation.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nregisteredAt -> (timestamp)\n\nThe Unix timestamp for when the container instance was registered.\n\nattachments -> (list)\n\nThe resources attached to a container instance, such as elastic network interfaces.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the container instance to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key)."
    },
    {
      "command_name": "register-task-definition",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/register-task-definition.html",
      "command_description": "Description\n\nRegisters a new task definition from the supplied family and containerDefinitions . Optionally, you can add data volumes to your containers with the volumes parameter. For more information about task definition parameters and defaults, see Amazon ECS Task Definitions in the Amazon Elastic Container Service Developer Guide .\n\nYou can specify an IAM role for your task with the taskRoleArn parameter. When you specify an IAM role for a task, its containers can then use the latest versions of the CLI or SDKs to make API requests to the Amazon Web Services services that are specified in the IAM policy associated with the role. For more information, see IAM Roles for Tasks in the Amazon Elastic Container Service Developer Guide .\n\nYou can specify a Docker networking mode for the containers in your task definition with the networkMode parameter. The available network modes correspond to those described in Network settings in the Docker run reference. If you specify the awsvpc network mode, the task is allocated an elastic network interface, and you must specify a NetworkConfiguration when you create a service or run a task with the task definition. For more information, see Task Networking in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  register-task-definition\n--family <value>\n[--task-role-arn <value>]\n[--execution-role-arn <value>]\n[--network-mode <value>]\n--container-definitions <value>\n[--volumes <value>]\n[--placement-constraints <value>]\n[--requires-compatibilities <value>]\n[--cpu <value>]\n[--memory <value>]\n[--tags <value>]\n[--pid-mode <value>]\n[--ipc-mode <value>]\n[--proxy-configuration <value>]\n[--inference-accelerators <value>]\n[--ephemeral-storage <value>]\n[--runtime-platform <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--family <value>",
        "[--task-role-arn <value>]",
        "[--execution-role-arn <value>]",
        "[--network-mode <value>]",
        "--container-definitions <value>",
        "[--volumes <value>]",
        "[--placement-constraints <value>]",
        "[--requires-compatibilities <value>]",
        "[--cpu <value>]",
        "[--memory <value>]",
        "[--tags <value>]",
        "[--pid-mode <value>]",
        "[--ipc-mode <value>]",
        "[--proxy-configuration <value>]",
        "[--inference-accelerators <value>]",
        "[--ephemeral-storage <value>]",
        "[--runtime-platform <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--family (string)\n\nYou must specify a family for a task definition, which allows you to track multiple versions of the same task definition. The family is used as a name for your task definition. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed.\n\n--task-role-arn (string)\n\nThe short name or full Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see IAM Roles for Tasks in the Amazon Elastic Container Service Developer Guide .\n\n--execution-role-arn (string)\n\nThe Amazon Resource Name (ARN) of the task execution role that grants the Amazon ECS container agent permission to make Amazon Web Services API calls on your behalf. The task execution IAM role is required depending on the requirements of your task. For more information, see Amazon ECS task execution IAM role in the Amazon Elastic Container Service Developer Guide .\n\n--network-mode (string)\n\nThe Docker networking mode to use for the containers in the task. The valid values are none , bridge , awsvpc , and host . If no network mode is specified, the default is bridge .\n\nFor Amazon ECS tasks on Fargate, the awsvpc network mode is required. For Amazon ECS tasks on Amazon EC2 Linux instances, any network mode can be used. For Amazon ECS tasks on Amazon EC2 Windows instances, <default> or awsvpc can be used. If the network mode is set to none , you cannot specify port mappings in your container definitions, and the tasks containers do not have external connectivity. The host and awsvpc network modes offer the highest networking performance for containers because they use the EC2 network stack instead of the virtualized network stack provided by the bridge mode.\n\nWith the host and awsvpc network modes, exposed container ports are mapped directly to the corresponding host port (for the host network mode) or the attached elastic network interface port (for the awsvpc network mode), so you cannot take advantage of dynamic host port mappings.\n\nWarning\n\nWhen using the host network mode, you should not run containers using the root user (UID 0). It is considered best practice to use a non-root user.\n\nIf the network mode is awsvpc , the task is allocated an elastic network interface, and you must specify a NetworkConfiguration value when you create a service or run a task with the task definition. For more information, see Task Networking in the Amazon Elastic Container Service Developer Guide .\n\nIf the network mode is host , you cannot run multiple instantiations of the same task on a single container instance when port mappings are used.\n\nFor more information, see Network settings in the Docker run reference .\n\nPossible values:\n\nbridge\n\nhost\n\nawsvpc\n\nnone\n\n--container-definitions (list)\n\nA list of container definitions in JSON format that describe the different containers that make up your task.\n\n(structure)\n\nContainer definitions are used in task definitions to describe the different containers that are launched as part of a task.\n\nname -> (string)\n\nThe name of a container. If you are linking multiple containers together in a task definition, the name of one container can be entered in the links of another container to connect the containers. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This parameter maps to name in the Create a container section of the Docker Remote API and the --name option to docker run .\n\nimage -> (string)\n\nThe image used to start a container. This string is passed directly to the Docker daemon. Images in the Docker Hub registry are available by default. Other repositories are specified with either `` repository-url /image :tag `` or `` repository-url /image @*digest* `` . Up to 255 letters (uppercase and lowercase), numbers, hyphens, underscores, colons, periods, forward slashes, and number signs are allowed. This parameter maps to Image in the Create a container section of the Docker Remote API and the IMAGE parameter of docker run .\n\nWhen a new task starts, the Amazon ECS container agent pulls the latest version of the specified image and tag for the container to use. However, subsequent updates to a repository image are not propagated to already running tasks.\n\nImages in Amazon ECR repositories can be specified by either using the full registry/repository:tag or registry/repository@digest . For example, 012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>:latest or 012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>@sha256:94afd1f2e64d908bc90dbca0035a5b567EXAMPLE .\n\nImages in official repositories on Docker Hub use a single name (for example, ubuntu or mongo ).\n\nImages in other repositories on Docker Hub are qualified with an organization name (for example, amazon/amazon-ecs-agent ).\n\nImages in other online repositories are qualified further by a domain name (for example, quay.io/assemblyline/ubuntu ).\n\nrepositoryCredentials -> (structure)\n\nThe private repository authentication credentials to use.\n\ncredentialsParameter -> (string)\n\nThe Amazon Resource Name (ARN) of the secret containing the private repository credentials.\n\nNote\n\nWhen you are using the Amazon ECS API, CLI, or Amazon Web Services SDK, if the secret exists in the same Region as the task that you are launching then you can use either the full ARN or the name of the secret. When you are using the Amazon Web Services Management Console, you must specify the full ARN of the secret.\n\ncpu -> (integer)\n\nThe number of cpu units reserved for the container. This parameter maps to CpuShares in the Create a container section of the Docker Remote API and the --cpu-shares option to docker run .\n\nThis field is optional for tasks using the Fargate launch type, and the only requirement is that the total amount of CPU reserved for all containers within a task be lower than the task-level cpu value.\n\nNote\n\nYou can determine the number of CPU units that are available per EC2 instance type by multiplying the vCPUs listed for that instance type on the Amazon EC2 Instances detail page by 1,024.\n\nLinux containers share unallocated CPU units with other containers on the container instance with the same ratio as their allocated amount. For example, if you run a single-container task on a single-core instance type with 512 CPU units specified for that container, and that is the only task running on the container instance, that container could use the full 1,024 CPU unit share at any given time. However, if you launched another copy of the same task on that container instance, each task would be guaranteed a minimum of 512 CPU units when needed, and each container could float to higher CPU usage if the other container was not using it, but if both tasks were 100% active all of the time, they would be limited to 512 CPU units.\n\nOn Linux container instances, the Docker daemon on the container instance uses the CPU value to calculate the relative CPU share ratios for running containers. For more information, see CPU share constraint in the Docker documentation. The minimum valid CPU share value that the Linux kernel allows is 2. However, the CPU parameter is not required, and you can use CPU values below 2 in your container definitions. For CPU values below 2 (including null), the behavior varies based on your Amazon ECS container agent version:\n\nAgent versions less than or equal to 1.1.0: Null and zero CPU values are passed to Docker as 0, which Docker then converts to 1,024 CPU shares. CPU values of 1 are passed to Docker as 1, which the Linux kernel converts to two CPU shares.\n\nAgent versions greater than or equal to 1.2.0: Null, zero, and CPU values of 1 are passed to Docker as 2.\n\nOn Windows container instances, the CPU limit is enforced as an absolute limit, or a quota. Windows containers only have access to the specified amount of CPU that is described in the task definition. A null or zero CPU value is passed to Docker as 0 , which Windows interprets as 1% of one CPU.\n\nmemory -> (integer)\n\nThe amount (in MiB) of memory to present to the container. If your container attempts to exceed the memory specified here, the container is killed. The total amount of memory reserved for all containers within a task must be lower than the task memory value, if one is specified. This parameter maps to Memory in the Create a container section of the Docker Remote API and the --memory option to docker run .\n\nIf using the Fargate launch type, this parameter is optional.\n\nIf using the EC2 launch type, you must specify either a task-level memory value or a container-level memory value. If you specify both a container-level memory and memoryReservation value, memory must be greater than memoryReservation . If you specify memoryReservation , then that value is subtracted from the available memory resources for the container instance on which the container is placed. Otherwise, the value of memory is used.\n\nThe Docker daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.\n\nmemoryReservation -> (integer)\n\nThe soft limit (in MiB) of memory to reserve for the container. When system memory is under heavy contention, Docker attempts to keep the container memory to this soft limit. However, your container can consume more memory when it needs to, up to either the hard limit specified with the memory parameter (if applicable), or all of the available memory on the container instance, whichever comes first. This parameter maps to MemoryReservation in the Create a container section of the Docker Remote API and the --memory-reservation option to docker run .\n\nIf a task-level memory value is not specified, you must specify a non-zero integer for one or both of memory or memoryReservation in a container definition. If you specify both, memory must be greater than memoryReservation . If you specify memoryReservation , then that value is subtracted from the available memory resources for the container instance on which the container is placed. Otherwise, the value of memory is used.\n\nFor example, if your container normally uses 128 MiB of memory, but occasionally bursts to 256 MiB of memory for short periods of time, you can set a memoryReservation of 128 MiB, and a memory hard limit of 300 MiB. This configuration would allow the container to only reserve 128 MiB of memory from the remaining resources on the container instance, but also allow the container to consume more memory resources when needed.\n\nThe Docker daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.\n\nlinks -> (list)\n\nThe links parameter allows containers to communicate with each other without the need for port mappings. This parameter is only supported if the network mode of a task definition is bridge . The name:internalName construct is analogous to name:alias in Docker links. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. For more information about linking Docker containers, go to Legacy container links in the Docker documentation. This parameter maps to Links in the Create a container section of the Docker Remote API and the --link option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nWarning\n\nContainers that are collocated on a single container instance may be able to communicate with each other without requiring links or host port mappings. Network isolation is achieved on the container instance using security groups and VPC settings.\n\n(string)\n\nportMappings -> (list)\n\nThe list of port mappings for the container. Port mappings allow containers to access ports on the host container instance to send or receive traffic.\n\nFor task definitions that use the awsvpc network mode, you should only specify the containerPort . The hostPort can be left blank or it must be the same value as the containerPort .\n\nPort mappings on Windows use the NetNAT gateway address rather than localhost . There is no loopback for port mappings on Windows, so you cannot access a container’s mapped port from the host itself.\n\nThis parameter maps to PortBindings in the Create a container section of the Docker Remote API and the --publish option to docker run . If the network mode of a task definition is set to none , then you can’t specify port mappings. If the network mode of a task definition is set to host , then host ports must either be undefined or they must match the container port in the port mapping.\n\nNote\n\nAfter a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the Network Bindings section of a container description for a selected task in the Amazon ECS console. The assignments are also visible in the networkBindings section DescribeTasks responses.\n\n(structure)\n\nPort mappings allow containers to access ports on the host container instance to send or receive traffic. Port mappings are specified as part of the container definition.\n\nIf you are using containers in a task with the awsvpc or host network mode, exposed ports should be specified using containerPort . The hostPort can be left blank or it must be the same value as the containerPort .\n\nNote\n\nYou cannot expose the same container port for multiple protocols. An error will be returned if this is attempted\n\nAfter a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the networkBindings section of DescribeTasks API responses.\n\ncontainerPort -> (integer)\n\nThe port number on the container that is bound to the user-specified or automatically assigned host port.\n\nIf you are using containers in a task with the awsvpc or host network mode, exposed ports should be specified using containerPort .\n\nIf you are using containers in a task with the bridge network mode and you specify a container port and not a host port, your container automatically receives a host port in the ephemeral port range. For more information, see hostPort . Port mappings that are automatically assigned in this way do not count toward the 100 reserved ports limit of a container instance.\n\nhostPort -> (integer)\n\nThe port number on the container instance to reserve for your container.\n\nIf you are using containers in a task with the awsvpc or host network mode, the hostPort can either be left blank or set to the same value as the containerPort .\n\nIf you are using containers in a task with the bridge network mode, you can specify a non-reserved host port for your container port mapping, or you can omit the hostPort (or set it to 0 ) while specifying a containerPort and your container automatically receives a port in the ephemeral port range for your container instance operating system and Docker version.\n\nThe default ephemeral port range for Docker version 1.6.0 and later is listed on the instance under /proc/sys/net/ipv4/ip_local_port_range . If this kernel parameter is unavailable, the default ephemeral port range from 49153 through 65535 is used. Do not attempt to specify a host port in the ephemeral port range as these are reserved for automatic assignment. In general, ports below 32768 are outside of the ephemeral port range.\n\nNote\n\nThe default ephemeral port range from 49153 through 65535 is always used for Docker versions before 1.6.0.\n\nThe default reserved ports are 22 for SSH, the Docker ports 2375 and 2376, and the Amazon ECS container agent ports 51678-51680. Any host port that was previously specified in a running task is also reserved while the task is running (after a task stops, the host port is released). The current reserved ports are displayed in the remainingResources of DescribeContainerInstances output. A container instance can have up to 100 reserved ports at a time, including the default reserved ports. Automatically assigned ports don’t count toward the 100 reserved ports limit.\n\nprotocol -> (string)\n\nThe protocol used for the port mapping. Valid values are tcp and udp . The default is tcp .\n\nessential -> (boolean)\n\nIf the essential parameter of a container is marked as true , and that container fails or stops for any reason, all other containers that are part of the task are stopped. If the essential parameter of a container is marked as false , then its failure does not affect the rest of the containers in a task. If this parameter is omitted, a container is assumed to be essential.\n\nAll tasks must have at least one essential container. If you have an application that is composed of multiple containers, you should group containers that are used for a common purpose into components, and separate the different components into multiple task definitions. For more information, see Application Architecture in the Amazon Elastic Container Service Developer Guide .\n\nentryPoint -> (list)\n\nWarning\n\nEarly versions of the Amazon ECS container agent do not properly handle entryPoint parameters. If you have problems using entryPoint , update your container agent or enter your commands and arguments as command array items instead.\n\nThe entry point that is passed to the container. This parameter maps to Entrypoint in the Create a container section of the Docker Remote API and the --entrypoint option to docker run . For more information, see https://docs.docker.com/engine/reference/builder/#entrypoint .\n\n(string)\n\ncommand -> (list)\n\nThe command that is passed to the container. This parameter maps to Cmd in the Create a container section of the Docker Remote API and the COMMAND parameter to docker run . For more information, see https://docs.docker.com/engine/reference/builder/#cmd . If there are multiple arguments, each argument should be a separated string in the array.\n\n(string)\n\nenvironment -> (list)\n\nThe environment variables to pass to a container. This parameter maps to Env in the Create a container section of the Docker Remote API and the --env option to docker run .\n\nWarning\n\nWe do not recommend using plaintext environment variables for sensitive information, such as credential data.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nenvironmentFiles -> (list)\n\nA list of files containing the environment variables to pass to a container. This parameter maps to the --env-file option to docker run .\n\nYou can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying Environment Variables in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nA list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying environment variables in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nvalue -> (string)\n\nThe Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\ntype -> (string)\n\nThe file type to use. The only supported value is s3 .\n\nmountPoints -> (list)\n\nThe mount points for data volumes in your container.\n\nThis parameter maps to Volumes in the Create a container section of the Docker Remote API and the --volume option to docker run .\n\nWindows containers can mount whole directories on the same drive as $env:ProgramData . Windows containers cannot mount directories on a different drive, and mount point cannot be across drives.\n\n(structure)\n\nDetails on a volume mount point that is used in a container definition.\n\nsourceVolume -> (string)\n\nThe name of the volume to mount. Must be a volume name referenced in the name parameter of task definition volume .\n\ncontainerPath -> (string)\n\nThe path on the container to mount the host volume at.\n\nreadOnly -> (boolean)\n\nIf this value is true , the container has read-only access to the volume. If this value is false , then the container can write to the volume. The default value is false .\n\nvolumesFrom -> (list)\n\nData volumes to mount from another container. This parameter maps to VolumesFrom in the Create a container section of the Docker Remote API and the --volumes-from option to docker run .\n\n(structure)\n\nDetails on a data volume from another container in the same task definition.\n\nsourceContainer -> (string)\n\nThe name of another container within the same task definition from which to mount volumes.\n\nreadOnly -> (boolean)\n\nIf this value is true , the container has read-only access to the volume. If this value is false , then the container can write to the volume. The default value is false .\n\nlinuxParameters -> (structure)\n\nLinux-specific modifications that are applied to the container, such as Linux kernel capabilities. For more information see KernelCapabilities .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\ncapabilities -> (structure)\n\nThe Linux capabilities for the container that are added to or dropped from the default configuration provided by Docker.\n\nNote\n\nFor tasks that use the Fargate launch type, capabilities is supported for all platform versions but the add parameter is only supported if using platform version 1.4.0 or later.\n\nadd -> (list)\n\nThe Linux capabilities for the container that have been added to the default configuration provided by Docker. This parameter maps to CapAdd in the Create a container section of the Docker Remote API and the --cap-add option to docker run .\n\nNote\n\nTasks launched on Fargate only support adding the SYS_PTRACE kernel capability.\n\nValid values: \"ALL\" | \"AUDIT_CONTROL\" | \"AUDIT_WRITE\" | \"BLOCK_SUSPEND\" | \"CHOWN\" | \"DAC_OVERRIDE\" | \"DAC_READ_SEARCH\" | \"FOWNER\" | \"FSETID\" | \"IPC_LOCK\" | \"IPC_OWNER\" | \"KILL\" | \"LEASE\" | \"LINUX_IMMUTABLE\" | \"MAC_ADMIN\" | \"MAC_OVERRIDE\" | \"MKNOD\" | \"NET_ADMIN\" | \"NET_BIND_SERVICE\" | \"NET_BROADCAST\" | \"NET_RAW\" | \"SETFCAP\" | \"SETGID\" | \"SETPCAP\" | \"SETUID\" | \"SYS_ADMIN\" | \"SYS_BOOT\" | \"SYS_CHROOT\" | \"SYS_MODULE\" | \"SYS_NICE\" | \"SYS_PACCT\" | \"SYS_PTRACE\" | \"SYS_RAWIO\" | \"SYS_RESOURCE\" | \"SYS_TIME\" | \"SYS_TTY_CONFIG\" | \"SYSLOG\" | \"WAKE_ALARM\"\n\n(string)\n\ndrop -> (list)\n\nThe Linux capabilities for the container that have been removed from the default configuration provided by Docker. This parameter maps to CapDrop in the Create a container section of the Docker Remote API and the --cap-drop option to docker run .\n\nValid values: \"ALL\" | \"AUDIT_CONTROL\" | \"AUDIT_WRITE\" | \"BLOCK_SUSPEND\" | \"CHOWN\" | \"DAC_OVERRIDE\" | \"DAC_READ_SEARCH\" | \"FOWNER\" | \"FSETID\" | \"IPC_LOCK\" | \"IPC_OWNER\" | \"KILL\" | \"LEASE\" | \"LINUX_IMMUTABLE\" | \"MAC_ADMIN\" | \"MAC_OVERRIDE\" | \"MKNOD\" | \"NET_ADMIN\" | \"NET_BIND_SERVICE\" | \"NET_BROADCAST\" | \"NET_RAW\" | \"SETFCAP\" | \"SETGID\" | \"SETPCAP\" | \"SETUID\" | \"SYS_ADMIN\" | \"SYS_BOOT\" | \"SYS_CHROOT\" | \"SYS_MODULE\" | \"SYS_NICE\" | \"SYS_PACCT\" | \"SYS_PTRACE\" | \"SYS_RAWIO\" | \"SYS_RESOURCE\" | \"SYS_TIME\" | \"SYS_TTY_CONFIG\" | \"SYSLOG\" | \"WAKE_ALARM\"\n\n(string)\n\ndevices -> (list)\n\nAny host devices to expose to the container. This parameter maps to Devices in the Create a container section of the Docker Remote API and the --device option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the devices parameter is not supported.\n\n(structure)\n\nAn object representing a container instance host device.\n\nhostPath -> (string)\n\nThe path for the device on the host container instance.\n\ncontainerPath -> (string)\n\nThe path inside the container at which to expose the host device.\n\npermissions -> (list)\n\nThe explicit permissions to provide to the container for the device. By default, the container has permissions for read , write , and mknod for the device.\n\n(string)\n\ninitProcessEnabled -> (boolean)\n\nRun an init process inside the container that forwards signals and reaps processes. This parameter maps to the --init option to docker run . This parameter requires version 1.25 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nsharedMemorySize -> (integer)\n\nThe value for the size (in MiB) of the /dev/shm volume. This parameter maps to the --shm-size option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the sharedMemorySize parameter is not supported.\n\ntmpfs -> (list)\n\nThe container path, mount options, and size (in MiB) of the tmpfs mount. This parameter maps to the --tmpfs option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the tmpfs parameter is not supported.\n\n(structure)\n\nThe container path, mount options, and size of the tmpfs mount.\n\ncontainerPath -> (string)\n\nThe absolute file path where the tmpfs volume is to be mounted.\n\nsize -> (integer)\n\nThe maximum size (in MiB) of the tmpfs volume.\n\nmountOptions -> (list)\n\nThe list of tmpfs volume mount options.\n\nValid values: \"defaults\" | \"ro\" | \"rw\" | \"suid\" | \"nosuid\" | \"dev\" | \"nodev\" | \"exec\" | \"noexec\" | \"sync\" | \"async\" | \"dirsync\" | \"remount\" | \"mand\" | \"nomand\" | \"atime\" | \"noatime\" | \"diratime\" | \"nodiratime\" | \"bind\" | \"rbind\" | \"unbindable\" | \"runbindable\" | \"private\" | \"rprivate\" | \"shared\" | \"rshared\" | \"slave\" | \"rslave\" | \"relatime\" | \"norelatime\" | \"strictatime\" | \"nostrictatime\" | \"mode\" | \"uid\" | \"gid\" | \"nr_inodes\" | \"nr_blocks\" | \"mpol\"\n\n(string)\n\nmaxSwap -> (integer)\n\nThe total amount of swap memory (in MiB) a container can use. This parameter will be translated to the --memory-swap option to docker run where the value would be the sum of the container memory plus the maxSwap value.\n\nIf a maxSwap value of 0 is specified, the container will not use swap. Accepted values are 0 or any positive integer. If the maxSwap parameter is omitted, the container will use the swap configuration for the container instance it is running on. A maxSwap value must be set for the swappiness parameter to be used.\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the maxSwap parameter is not supported.\n\nswappiness -> (integer)\n\nThis allows you to tune a container’s memory swappiness behavior. A swappiness value of 0 will cause swapping to not happen unless absolutely necessary. A swappiness value of 100 will cause pages to be swapped very aggressively. Accepted values are whole numbers between 0 and 100 . If the swappiness parameter is not specified, a default value of 60 is used. If a value is not specified for maxSwap then this parameter is ignored. This parameter maps to the --memory-swappiness option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the swappiness parameter is not supported.\n\nsecrets -> (list)\n\nThe secrets to pass to the container. For more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nAn object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:\n\nTo inject sensitive data into your containers as environment variables, use the secrets container definition parameter.\n\nTo reference sensitive information in the log configuration of a container, use the secretOptions container definition parameter.\n\nFor more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the secret.\n\nvalueFrom -> (string)\n\nThe secret to expose to the container. The supported values are either the full ARN of the Secrets Manager secret or the full ARN of the parameter in the SSM Parameter Store.\n\nNote\n\nIf the SSM Parameter Store parameter exists in the same Region as the task you are launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.\n\ndependsOn -> (list)\n\nThe dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.\n\nFor tasks using the EC2 launch type, the container instances require at least version 1.26.0 of the container agent to enable container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\n(structure)\n\nThe dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.\n\nYour Amazon ECS container instances require at least version 1.26.0 of the container agent to enable container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\ncontainerName -> (string)\n\nThe name of a container.\n\ncondition -> (string)\n\nThe dependency condition of the container. The following are the available conditions and their behavior:\n\nSTART - This condition emulates the behavior of links and volumes today. It validates that a dependent container is started before permitting other containers to start.\n\nCOMPLETE - This condition validates that a dependent container runs to completion (exits) before permitting other containers to start. This can be useful for nonessential containers that run a script and then exit. This condition cannot be set on an essential container.\n\nSUCCESS - This condition is the same as COMPLETE , but it also requires that the container exits with a zero status. This condition cannot be set on an essential container.\n\nHEALTHY - This condition validates that the dependent container passes its Docker health check before permitting other containers to start. This requires that the dependent container has health checks configured. This condition is confirmed only at task startup.\n\nstartTimeout -> (integer)\n\nTime duration (in seconds) to wait before giving up on resolving dependencies for a container. For example, you specify two containers in a task definition with containerA having a dependency on containerB reaching a COMPLETE , SUCCESS , or HEALTHY status. If a startTimeout value is specified for containerB and it does not reach the desired status within that time then containerA will give up and not start. This results in the task transitioning to a STOPPED state.\n\nNote\n\nWhen the ECS_CONTAINER_START_TIMEOUT container agent configuration variable is used, it is enforced indendently from this start timeout value.\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nFor tasks using the EC2 launch type, your container instances require at least version 1.26.0 of the container agent to enable a container start timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nstopTimeout -> (integer)\n\nTime duration (in seconds) to wait before the container is forcefully killed if it doesn’t exit normally on its own.\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nThe max stop timeout value is 120 seconds and if the parameter is not specified, the default value of 30 seconds is used.\n\nFor tasks using the EC2 launch type, if the stopTimeout parameter is not specified, the value set for the Amazon ECS container agent configuration variable ECS_CONTAINER_STOP_TIMEOUT is used by default. If neither the stopTimeout parameter or the ECS_CONTAINER_STOP_TIMEOUT agent configuration variable are set, then the default values of 30 seconds for Linux containers and 30 seconds on Windows containers are used. Your container instances require at least version 1.26.0 of the container agent to enable a container stop timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nhostname -> (string)\n\nThe hostname to use for your container. This parameter maps to Hostname in the Create a container section of the Docker Remote API and the --hostname option to docker run .\n\nNote\n\nThe hostname parameter is not supported if you are using the awsvpc network mode.\n\nuser -> (string)\n\nThe user to use inside the container. This parameter maps to User in the Create a container section of the Docker Remote API and the --user option to docker run .\n\nWarning\n\nWhen running tasks using the host network mode, you should not run containers using the root user (UID 0). It is considered best practice to use a non-root user.\n\nYou can specify the user using the following formats. If specifying a UID or GID, you must specify it as a positive integer.\n\nuser\n\nuser:group\n\nuid\n\nuid:gid\n\nuser:gid\n\nuid:group\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nworkingDirectory -> (string)\n\nThe working directory in which to run commands inside the container. This parameter maps to WorkingDir in the Create a container section of the Docker Remote API and the --workdir option to docker run .\n\ndisableNetworking -> (boolean)\n\nWhen this parameter is true, networking is disabled within the container. This parameter maps to NetworkDisabled in the Create a container section of the Docker Remote API .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nprivileged -> (boolean)\n\nWhen this parameter is true, the container is given elevated privileges on the host container instance (similar to the root user). This parameter maps to Privileged in the Create a container section of the Docker Remote API and the --privileged option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nreadonlyRootFilesystem -> (boolean)\n\nWhen this parameter is true, the container is given read-only access to its root file system. This parameter maps to ReadonlyRootfs in the Create a container section of the Docker Remote API and the --read-only option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\ndnsServers -> (list)\n\nA list of DNS servers that are presented to the container. This parameter maps to Dns in the Create a container section of the Docker Remote API and the --dns option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(string)\n\ndnsSearchDomains -> (list)\n\nA list of DNS search domains that are presented to the container. This parameter maps to DnsSearch in the Create a container section of the Docker Remote API and the --dns-search option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(string)\n\nextraHosts -> (list)\n\nA list of hostnames and IP address mappings to append to the /etc/hosts file on the container. This parameter maps to ExtraHosts in the Create a container section of the Docker Remote API and the --add-host option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks that use the awsvpc network mode.\n\n(structure)\n\nHostnames and IP address entries that are added to the /etc/hosts file of a container via the extraHosts parameter of its ContainerDefinition .\n\nhostname -> (string)\n\nThe hostname to use in the /etc/hosts entry.\n\nipAddress -> (string)\n\nThe IP address to use in the /etc/hosts entry.\n\ndockerSecurityOptions -> (list)\n\nA list of strings to provide custom labels for SELinux and AppArmor multi-level security systems. This field is not valid for containers in tasks using the Fargate launch type.\n\nWith Windows containers, this parameter can be used to reference a credential spec file when configuring a container for Active Directory authentication. For more information, see Using gMSAs for Windows Containers in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter maps to SecurityOpt in the Create a container section of the Docker Remote API and the --security-opt option to docker run .\n\nNote\n\nThe Amazon ECS container agent running on a container instance must register with the ECS_SELINUX_CAPABLE=true or ECS_APPARMOR_CAPABLE=true environment variables before containers placed on that instance can use these security options. For more information, see Amazon ECS Container Agent Configuration in the Amazon Elastic Container Service Developer Guide .\n\nFor more information about valid values, see Docker Run Security Configuration .\n\nValid values: “no-new-privileges” | “apparmor:PROFILE” | “label:value” | “credentialspec:CredentialSpecFilePath”\n\n(string)\n\ninteractive -> (boolean)\n\nWhen this parameter is true , this allows you to deploy containerized applications that require stdin or a tty to be allocated. This parameter maps to OpenStdin in the Create a container section of the Docker Remote API and the --interactive option to docker run .\n\npseudoTerminal -> (boolean)\n\nWhen this parameter is true , a TTY is allocated. This parameter maps to Tty in the Create a container section of the Docker Remote API and the --tty option to docker run .\n\ndockerLabels -> (map)\n\nA key/value map of labels to add to the container. This parameter maps to Labels in the Create a container section of the Docker Remote API and the --label option to docker run . This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nkey -> (string)\n\nvalue -> (string)\n\nulimits -> (list)\n\nA list of ulimits to set in the container. If a ulimit value is specified in a task definition, it will override the default values set by Docker. This parameter maps to Ulimits in the Create a container section of the Docker Remote API and the --ulimit option to docker run . Valid naming values are displayed in the Ulimit data type.\n\nAmazon ECS tasks hosted on Fargate use the default resource limit values set by the operating system with the exception of the nofile resource limit parameter which Fargate overrides. The nofile resource limit sets a restriction on the number of open files that a container can use. The default nofile soft limit is 1024 and hard limit is 4096 .\n\nThis parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(structure)\n\nThe ulimit settings to pass to the container.\n\nAmazon ECS tasks hosted on Fargate use the default resource limit values set by the operating system with the exception of the nofile resource limit parameter which Fargate overrides. The nofile resource limit sets a restriction on the number of open files that a container can use. The default nofile soft limit is 1024 and hard limit is 4096 .\n\nname -> (string)\n\nThe type of the ulimit .\n\nsoftLimit -> (integer)\n\nThe soft limit for the ulimit type.\n\nhardLimit -> (integer)\n\nThe hard limit for the ulimit type.\n\nlogConfiguration -> (structure)\n\nThe log configuration specification for the container.\n\nThis parameter maps to LogConfig in the Create a container section of the Docker Remote API and the --log-driver option to docker run . By default, containers use the same logging driver that the Docker daemon uses. However the container may use a different logging driver than the Docker daemon by specifying a log driver with this parameter in the container definition. To use a different logging driver for a container, the log system must be configured properly on the container instance (or on a different log server for remote logging options). For more information on the options for different supported log drivers, see Configure logging drivers in the Docker documentation.\n\nNote\n\nAmazon ECS currently supports a subset of the logging drivers available to the Docker daemon (shown in the LogConfiguration data type). Additional log drivers may be available in future releases of the Amazon ECS container agent.\n\nThis parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nNote\n\nThe Amazon ECS container agent running on a container instance must register the logging drivers available on that instance with the ECS_AVAILABLE_LOGGING_DRIVERS environment variable before containers placed on that instance can use these log configuration options. For more information, see Amazon ECS Container Agent Configuration in the Amazon Elastic Container Service Developer Guide .\n\nlogDriver -> (string)\n\nThe log driver to use for the container.\n\nFor tasks on Fargate, the supported log drivers are awslogs , splunk , and awsfirelens .\n\nFor tasks hosted on Amazon EC2 instances, the supported log drivers are awslogs , fluentd , gelf , json-file , journald , logentries ,``syslog`` , splunk , and awsfirelens .\n\nFor more information about using the awslogs log driver, see Using the awslogs log driver in the Amazon Elastic Container Service Developer Guide .\n\nFor more information about using the awsfirelens log driver, see Custom log routing in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you have a custom driver that is not listed, you can fork the Amazon ECS container agent project that is available on GitHub and customize it to work with that driver. We encourage you to submit pull requests for changes that you would like to have included. However, we do not currently provide support for running modified copies of this software.\n\noptions -> (map)\n\nThe configuration options to send to the log driver. This parameter requires version 1.19 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nkey -> (string)\n\nvalue -> (string)\n\nsecretOptions -> (list)\n\nThe secrets to pass to the log configuration. For more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nAn object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:\n\nTo inject sensitive data into your containers as environment variables, use the secrets container definition parameter.\n\nTo reference sensitive information in the log configuration of a container, use the secretOptions container definition parameter.\n\nFor more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the secret.\n\nvalueFrom -> (string)\n\nThe secret to expose to the container. The supported values are either the full ARN of the Secrets Manager secret or the full ARN of the parameter in the SSM Parameter Store.\n\nNote\n\nIf the SSM Parameter Store parameter exists in the same Region as the task you are launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.\n\nhealthCheck -> (structure)\n\nThe container health check command and associated configuration parameters for the container. This parameter maps to HealthCheck in the Create a container section of the Docker Remote API and the HEALTHCHECK parameter of docker run .\n\ncommand -> (list)\n\nA string array representing the command that the container runs to determine if it is healthy. The string array must start with CMD to execute the command arguments directly, or CMD-SHELL to run the command with the container’s default shell.\n\nWhen you use the Amazon Web Services Management Console JSON panel, the Command Line Interface, or the APIs, you should enclose the list of commands in brackets, as shown below.\n\n[ \"CMD-SHELL\", \"curl -f http://localhost/ || exit 1\" ]\n\nYou do not need to include the brackets when you use the Amazon Web Services Management Consoleas shown below.\n\n\"CMD-SHELL\", \"curl -f http://localhost/ || exit 1\"\n\nAn exit code of 0 indicates success, and non-zero exit code indicates failure. For more information, see HealthCheck in the Create a container section of the Docker Remote API .\n\n(string)\n\ninterval -> (integer)\n\nThe time period in seconds between each health check execution. You may specify between 5 and 300 seconds. The default value is 30 seconds.\n\ntimeout -> (integer)\n\nThe time period in seconds to wait for a health check to succeed before it is considered a failure. You may specify between 2 and 60 seconds. The default value is 5.\n\nretries -> (integer)\n\nThe number of times to retry a failed health check before the container is considered unhealthy. You may specify between 1 and 10 retries. The default value is 3.\n\nstartPeriod -> (integer)\n\nThe optional grace period within which to provide containers time to bootstrap before failed health checks count towards the maximum number of retries. You may specify between 0 and 300 seconds. The startPeriod is disabled by default.\n\nNote\n\nIf a health check succeeds within the startPeriod , then the container is considered healthy and any subsequent failures count toward the maximum number of retries.\n\nsystemControls -> (list)\n\nA list of namespaced kernel parameters to set in the container. This parameter maps to Sysctls in the Create a container section of the Docker Remote API and the --sysctl option to docker run .\n\nNote\n\nIt is not recommended that you specify network-related systemControls parameters for multiple containers in a single task that also uses either the awsvpc or host network modes. For tasks that use the awsvpc network mode, the container that is started last determines which systemControls parameters take effect. For tasks that use the host network mode, it changes the container instance’s namespaced kernel parameters as well as the containers.\n\n(structure)\n\nA list of namespaced kernel parameters to set in the container. This parameter maps to Sysctls in the Create a container section of the Docker Remote API and the --sysctl option to docker run .\n\nIt is not recommended that you specify network-related systemControls parameters for multiple containers in a single task that also uses either the awsvpc or host network mode for the following reasons:\n\nFor tasks that use the awsvpc network mode, if you set systemControls for any container, it applies to all containers in the task. If you set different systemControls for multiple containers in a single task, the container that is started last determines which systemControls take effect.\n\nFor tasks that use the host network mode, the systemControls parameter applies to the container instance’s kernel parameter as well as that of all containers of any tasks running on that container instance.\n\nnamespace -> (string)\n\nThe namespaced kernel parameter for which to set a value .\n\nvalue -> (string)\n\nThe value for the namespaced kernel parameter specified in namespace .\n\nresourceRequirements -> (list)\n\nThe type and amount of a resource to assign to a container. The only supported resource is a GPU.\n\n(structure)\n\nThe type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see Working with GPUs on Amazon ECS or Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide\n\nvalue -> (string)\n\nThe value for the specified resource type.\n\nIf the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent will reserve for the container. The number of GPUs reserved for all containers in a task should not exceed the number of available GPUs on the container instance the task is launched on.\n\nIf the InferenceAccelerator type is used, the value should match the deviceName for an InferenceAccelerator specified in a task definition.\n\ntype -> (string)\n\nThe type of resource to assign to a container. The supported values are GPU or InferenceAccelerator .\n\nfirelensConfiguration -> (structure)\n\nThe FireLens configuration for the container. This is used to specify and configure a log router for container logs. For more information, see Custom Log Routing in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe log router to use. The valid values are fluentd or fluentbit .\n\noptions -> (map)\n\nThe options to use when configuring the log router. This field is optional and can be used to specify a custom configuration file or to add additional metadata, such as the task, task definition, cluster, and container instance details to the log event. If specified, the syntax to use is \"options\":{\"enable-ecs-log-metadata\":\"true|false\",\"config-file-type:\"s3|file\",\"config-file-value\":\"arn:aws:s3:::mybucket/fluent.conf|filepath\"} . For more information, see Creating a Task Definition that Uses a FireLens Configuration in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nTasks hosted on Fargate only support the file configuration file type.\n\nkey -> (string)\n\nvalue -> (string)\n\nJSON Syntax:\n\n[\n  {\n    \"name\": \"string\",\n    \"image\": \"string\",\n    \"repositoryCredentials\": {\n      \"credentialsParameter\": \"string\"\n    },\n    \"cpu\": integer,\n    \"memory\": integer,\n    \"memoryReservation\": integer,\n    \"links\": [\"string\", ...],\n    \"portMappings\": [\n      {\n        \"containerPort\": integer,\n        \"hostPort\": integer,\n        \"protocol\": \"tcp\"|\"udp\"\n      }\n      ...\n    ],\n    \"essential\": true|false,\n    \"entryPoint\": [\"string\", ...],\n    \"command\": [\"string\", ...],\n    \"environment\": [\n      {\n        \"name\": \"string\",\n        \"value\": \"string\"\n      }\n      ...\n    ],\n    \"environmentFiles\": [\n      {\n        \"value\": \"string\",\n        \"type\": \"s3\"\n      }\n      ...\n    ],\n    \"mountPoints\": [\n      {\n        \"sourceVolume\": \"string\",\n        \"containerPath\": \"string\",\n        \"readOnly\": true|false\n      }\n      ...\n    ],\n    \"volumesFrom\": [\n      {\n        \"sourceContainer\": \"string\",\n        \"readOnly\": true|false\n      }\n      ...\n    ],\n    \"linuxParameters\": {\n      \"capabilities\": {\n        \"add\": [\"string\", ...],\n        \"drop\": [\"string\", ...]\n      },\n      \"devices\": [\n        {\n          \"hostPath\": \"string\",\n          \"containerPath\": \"string\",\n          \"permissions\": [\"read\"|\"write\"|\"mknod\", ...]\n        }\n        ...\n      ],\n      \"initProcessEnabled\": true|false,\n      \"sharedMemorySize\": integer,\n      \"tmpfs\": [\n        {\n          \"containerPath\": \"string\",\n          \"size\": integer,\n          \"mountOptions\": [\"string\", ...]\n        }\n        ...\n      ],\n      \"maxSwap\": integer,\n      \"swappiness\": integer\n    },\n    \"secrets\": [\n      {\n        \"name\": \"string\",\n        \"valueFrom\": \"string\"\n      }\n      ...\n    ],\n    \"dependsOn\": [\n      {\n        \"containerName\": \"string\",\n        \"condition\": \"START\"|\"COMPLETE\"|\"SUCCESS\"|\"HEALTHY\"\n      }\n      ...\n    ],\n    \"startTimeout\": integer,\n    \"stopTimeout\": integer,\n    \"hostname\": \"string\",\n    \"user\": \"string\",\n    \"workingDirectory\": \"string\",\n    \"disableNetworking\": true|false,\n    \"privileged\": true|false,\n    \"readonlyRootFilesystem\": true|false,\n    \"dnsServers\": [\"string\", ...],\n    \"dnsSearchDomains\": [\"string\", ...],\n    \"extraHosts\": [\n      {\n        \"hostname\": \"string\",\n        \"ipAddress\": \"string\"\n      }\n      ...\n    ],\n    \"dockerSecurityOptions\": [\"string\", ...],\n    \"interactive\": true|false,\n    \"pseudoTerminal\": true|false,\n    \"dockerLabels\": {\"string\": \"string\"\n      ...},\n    \"ulimits\": [\n      {\n        \"name\": \"core\"|\"cpu\"|\"data\"|\"fsize\"|\"locks\"|\"memlock\"|\"msgqueue\"|\"nice\"|\"nofile\"|\"nproc\"|\"rss\"|\"rtprio\"|\"rttime\"|\"sigpending\"|\"stack\",\n        \"softLimit\": integer,\n        \"hardLimit\": integer\n      }\n      ...\n    ],\n    \"logConfiguration\": {\n      \"logDriver\": \"json-file\"|\"syslog\"|\"journald\"|\"gelf\"|\"fluentd\"|\"awslogs\"|\"splunk\"|\"awsfirelens\",\n      \"options\": {\"string\": \"string\"\n        ...},\n      \"secretOptions\": [\n        {\n          \"name\": \"string\",\n          \"valueFrom\": \"string\"\n        }\n        ...\n      ]\n    },\n    \"healthCheck\": {\n      \"command\": [\"string\", ...],\n      \"interval\": integer,\n      \"timeout\": integer,\n      \"retries\": integer,\n      \"startPeriod\": integer\n    },\n    \"systemControls\": [\n      {\n        \"namespace\": \"string\",\n        \"value\": \"string\"\n      }\n      ...\n    ],\n    \"resourceRequirements\": [\n      {\n        \"value\": \"string\",\n        \"type\": \"GPU\"|\"InferenceAccelerator\"\n      }\n      ...\n    ],\n    \"firelensConfiguration\": {\n      \"type\": \"fluentd\"|\"fluentbit\",\n      \"options\": {\"string\": \"string\"\n        ...}\n    }\n  }\n  ...\n]\n\n\n--volumes (list)\n\nA list of volume definitions in JSON format that containers in your task may use.\n\n(structure)\n\nA data volume used in a task definition. For tasks that use the Amazon Elastic File System (Amazon EFS), specify an efsVolumeConfiguration . For Windows tasks that use Amazon FSx for Windows File Server file system, specify a fsxWindowsFileServerVolumeConfiguration . For tasks that use a Docker volume, specify a DockerVolumeConfiguration . For tasks that use a bind mount host volume, specify a host and optional sourcePath . For more information, see Using Data Volumes in Tasks .\n\nname -> (string)\n\nThe name of the volume. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This name is referenced in the sourceVolume parameter of container definition mountPoints .\n\nhost -> (structure)\n\nThis parameter is specified when you are using bind mount host volumes. The contents of the host parameter determine whether your bind mount host volume persists on the host container instance and where it is stored. If the host parameter is empty, then the Docker daemon assigns a host path for your data volume. However, the data is not guaranteed to persist after the containers associated with it stop running.\n\nWindows containers can mount whole directories on the same drive as $env:ProgramData . Windows containers cannot mount directories on a different drive, and mount point cannot be across drives. For example, you can mount C:\\my\\path:C:\\my\\path and D:\\:D:\\ , but not D:\\my\\path:C:\\my\\path or D:\\:C:\\my\\path .\n\nsourcePath -> (string)\n\nWhen the host parameter is used, specify a sourcePath to declare the path on the host container instance that is presented to the container. If this parameter is empty, then the Docker daemon has assigned a host path for you. If the host parameter contains a sourcePath file location, then the data volume persists at the specified location on the host container instance until you delete it manually. If the sourcePath value does not exist on the host container instance, the Docker daemon creates it. If the location does exist, the contents of the source path folder are exported.\n\nIf you are using the Fargate launch type, the sourcePath parameter is not supported.\n\ndockerVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using Docker volumes.\n\nWindows containers only support the use of the local driver. To use bind mounts, specify the host parameter instead.\n\nNote\n\nDocker volumes are not supported by tasks run on Fargate.\n\nscope -> (string)\n\nThe scope for the Docker volume that determines its lifecycle. Docker volumes that are scoped to a task are automatically provisioned when the task starts and destroyed when the task stops. Docker volumes that are scoped as shared persist after the task stops.\n\nautoprovision -> (boolean)\n\nIf this value is true , the Docker volume is created if it does not already exist.\n\nNote\n\nThis field is only used if the scope is shared .\n\ndriver -> (string)\n\nThe Docker volume driver to use. The driver value must match the driver name provided by Docker because it is used for task placement. If the driver was installed using the Docker plugin CLI, use docker plugin ls to retrieve the driver name from your container instance. If the driver was installed using another method, use Docker plugin discovery to retrieve the driver name. For more information, see Docker plugin discovery . This parameter maps to Driver in the Create a volume section of the Docker Remote API and the xxdriver option to docker volume create .\n\ndriverOpts -> (map)\n\nA map of Docker driver-specific options passed through. This parameter maps to DriverOpts in the Create a volume section of the Docker Remote API and the xxopt option to docker volume create .\n\nkey -> (string)\n\nvalue -> (string)\n\nlabels -> (map)\n\nCustom metadata to add to your Docker volume. This parameter maps to Labels in the Create a volume section of the Docker Remote API and the xxlabel option to docker volume create .\n\nkey -> (string)\n\nvalue -> (string)\n\nefsVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using an Amazon Elastic File System file system for task storage.\n\nfileSystemId -> (string)\n\nThe Amazon EFS file system ID to use.\n\nrootDirectory -> (string)\n\nThe directory within the Amazon EFS file system to mount as the root directory inside the host. If this parameter is omitted, the root of the Amazon EFS volume will be used. Specifying / will have the same effect as omitting this parameter.\n\nWarning\n\nIf an EFS access point is specified in the authorizationConfig , the root directory parameter must either be omitted or set to / which will enforce the path set on the EFS access point.\n\ntransitEncryption -> (string)\n\nWhether or not to enable encryption for Amazon EFS data in transit between the Amazon ECS host and the Amazon EFS server. Transit encryption must be enabled if Amazon EFS IAM authorization is used. If this parameter is omitted, the default value of DISABLED is used. For more information, see Encrypting Data in Transit in the Amazon Elastic File System User Guide .\n\ntransitEncryptionPort -> (integer)\n\nThe port to use when sending encrypted data between the Amazon ECS host and the Amazon EFS server. If you do not specify a transit encryption port, it will use the port selection strategy that the Amazon EFS mount helper uses. For more information, see EFS Mount Helper in the Amazon Elastic File System User Guide .\n\nauthorizationConfig -> (structure)\n\nThe authorization configuration details for the Amazon EFS file system.\n\naccessPointId -> (string)\n\nThe Amazon EFS access point ID to use. If an access point is specified, the root directory value specified in the EFSVolumeConfiguration must either be omitted or set to / which will enforce the path set on the EFS access point. If an access point is used, transit encryption must be enabled in the EFSVolumeConfiguration . For more information, see Working with Amazon EFS Access Points in the Amazon Elastic File System User Guide .\n\niam -> (string)\n\nWhether or not to use the Amazon ECS task IAM role defined in a task definition when mounting the Amazon EFS file system. If enabled, transit encryption must be enabled in the EFSVolumeConfiguration . If this parameter is omitted, the default value of DISABLED is used. For more information, see Using Amazon EFS Access Points in the Amazon Elastic Container Service Developer Guide .\n\nfsxWindowsFileServerVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using Amazon FSx for Windows File Server file system for task storage.\n\nfileSystemId -> (string)\n\nThe Amazon FSx for Windows File Server file system ID to use.\n\nrootDirectory -> (string)\n\nThe directory within the Amazon FSx for Windows File Server file system to mount as the root directory inside the host.\n\nauthorizationConfig -> (structure)\n\nThe authorization configuration details for the Amazon FSx for Windows File Server file system.\n\ncredentialsParameter -> (string)\n\nThe authorization credential option to use. The authorization credential options can be provided using either the Amazon Resource Name (ARN) of an Secrets Manager secret or SSM Parameter Store parameter. The ARNs refer to the stored credentials.\n\ndomain -> (string)\n\nA fully qualified domain name hosted by an Directory Service Managed Microsoft AD (Active Directory) or self-hosted AD on Amazon EC2.\n\nShorthand Syntax:\n\nname=string,host={sourcePath=string},dockerVolumeConfiguration={scope=string,autoprovision=boolean,driver=string,driverOpts={KeyName1=string,KeyName2=string},labels={KeyName1=string,KeyName2=string}},efsVolumeConfiguration={fileSystemId=string,rootDirectory=string,transitEncryption=string,transitEncryptionPort=integer,authorizationConfig={accessPointId=string,iam=string}},fsxWindowsFileServerVolumeConfiguration={fileSystemId=string,rootDirectory=string,authorizationConfig={credentialsParameter=string,domain=string}} ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"name\": \"string\",\n    \"host\": {\n      \"sourcePath\": \"string\"\n    },\n    \"dockerVolumeConfiguration\": {\n      \"scope\": \"task\"|\"shared\",\n      \"autoprovision\": true|false,\n      \"driver\": \"string\",\n      \"driverOpts\": {\"string\": \"string\"\n        ...},\n      \"labels\": {\"string\": \"string\"\n        ...}\n    },\n    \"efsVolumeConfiguration\": {\n      \"fileSystemId\": \"string\",\n      \"rootDirectory\": \"string\",\n      \"transitEncryption\": \"ENABLED\"|\"DISABLED\",\n      \"transitEncryptionPort\": integer,\n      \"authorizationConfig\": {\n        \"accessPointId\": \"string\",\n        \"iam\": \"ENABLED\"|\"DISABLED\"\n      }\n    },\n    \"fsxWindowsFileServerVolumeConfiguration\": {\n      \"fileSystemId\": \"string\",\n      \"rootDirectory\": \"string\",\n      \"authorizationConfig\": {\n        \"credentialsParameter\": \"string\",\n        \"domain\": \"string\"\n      }\n    }\n  }\n  ...\n]\n\n\n--placement-constraints (list)\n\nAn array of placement constraint objects to use for the task. You can specify a maximum of 10 constraints per task (this limit includes constraints in the task definition and those specified at runtime).\n\n(structure)\n\nAn object representing a constraint on task placement in the task definition. For more information, see Task placement constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nTask placement constraints are not supported for tasks run on Fargate.\n\ntype -> (string)\n\nThe type of constraint. The MemberOf constraint restricts selection to be from a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\nShorthand Syntax:\n\ntype=string,expression=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"type\": \"memberOf\",\n    \"expression\": \"string\"\n  }\n  ...\n]\n\n\n--requires-compatibilities (list)\n\nThe task launch type that Amazon ECS should validate the task definition against. A client exception is returned if the task definition doesn’t validate against the compatibilities specified. If no value is specified, the parameter is omitted from the response.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  EC2\n  FARGATE\n  EXTERNAL\n\n\n--cpu (string)\n\nThe number of CPU units used by the task. It can be expressed as an integer using CPU units, for example 1024 , or as a string using vCPUs, for example 1 vCPU or 1 vcpu , in a task definition. String values are converted to an integer indicating the CPU units when the task definition is registered.\n\nNote\n\nTask-level CPU and memory parameters are ignored for Windows containers. We recommend specifying container-level resources for Windows containers.\n\nIf you are using the EC2 launch type, this field is optional. Supported values are between 128 CPU units (0.125 vCPUs) and 10240 CPU units (10 vCPUs).\n\nIf you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the memory parameter:\n\n256 (.25 vCPU) - Available memory values: 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)\n\n512 (.5 vCPU) - Available memory values: 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)\n\n1024 (1 vCPU) - Available memory values: 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)\n\n2048 (2 vCPU) - Available memory values: Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)\n\n4096 (4 vCPU) - Available memory values: Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)\n\n--memory (string)\n\nThe amount of memory (in MiB) used by the task. It can be expressed as an integer using MiB, for example 1024 , or as a string using GB, for example 1GB or 1 GB , in a task definition. String values are converted to an integer indicating the MiB when the task definition is registered.\n\nNote\n\nTask-level CPU and memory parameters are ignored for Windows containers. We recommend specifying container-level resources for Windows containers.\n\nIf using the EC2 launch type, this field is optional.\n\nIf using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the cpu parameter:\n\n512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)\n\n1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)\n\n2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)\n\nBetween 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)\n\nBetween 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)\n\n--tags (list)\n\nThe metadata that you apply to the task definition to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--pid-mode (string)\n\nThe process namespace to use for the containers in the task. The valid values are host or task . If host is specified, then all containers within the tasks that specified the host PID mode on the same container instance share the same process namespace with the host Amazon EC2 instance. If task is specified, all containers within the specified task share the same process namespace. If no value is specified, the default is a private namespace. For more information, see PID settings in the Docker run reference .\n\nIf the host PID mode is used, be aware that there is a heightened risk of undesired process namespace expose. For more information, see Docker security .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nPossible values:\n\nhost\n\ntask\n\n--ipc-mode (string)\n\nThe IPC resource namespace to use for the containers in the task. The valid values are host , task , or none . If host is specified, then all containers within the tasks that specified the host IPC mode on the same container instance share the same IPC resources with the host Amazon EC2 instance. If task is specified, all containers within the specified task share the same IPC resources. If none is specified, then IPC resources within the containers of a task are private and not shared with other containers in a task or on the container instance. If no value is specified, then the IPC resource namespace sharing depends on the Docker daemon setting on the container instance. For more information, see IPC settings in the Docker run reference .\n\nIf the host IPC mode is used, be aware that there is a heightened risk of undesired IPC namespace expose. For more information, see Docker security .\n\nIf you are setting namespaced kernel parameters using systemControls for the containers in the task, the following will apply to your IPC resource namespace. For more information, see System Controls in the Amazon Elastic Container Service Developer Guide .\n\nFor tasks that use the host IPC mode, IPC namespace related systemControls are not supported.\n\nFor tasks that use the task IPC mode, IPC namespace related systemControls will apply to all containers within a task.\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nPossible values:\n\nhost\n\ntask\n\nnone\n\n--proxy-configuration (structure)\n\nThe configuration details for the App Mesh proxy.\n\nFor tasks hosted on Amazon EC2 instances, the container instances require at least version 1.26.0 of the container agent and at least version 1.26.0-1 of the ecs-init package to enable a proxy configuration. If your container instances are launched from the Amazon ECS-optimized AMI version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized AMI versions in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe proxy type. The only supported value is APPMESH .\n\ncontainerName -> (string)\n\nThe name of the container that will serve as the App Mesh proxy.\n\nproperties -> (list)\n\nThe set of network configuration parameters to provide the Container Network Interface (CNI) plugin, specified as key-value pairs.\n\nIgnoredUID - (Required) The user ID (UID) of the proxy container as defined by the user parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If IgnoredGID is specified, this field can be empty.\n\nIgnoredGID - (Required) The group ID (GID) of the proxy container as defined by the user parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If IgnoredUID is specified, this field can be empty.\n\nAppPorts - (Required) The list of ports that the application uses. Network traffic to these ports is forwarded to the ProxyIngressPort and ProxyEgressPort .\n\nProxyIngressPort - (Required) Specifies the port that incoming traffic to the AppPorts is directed to.\n\nProxyEgressPort - (Required) Specifies the port that outgoing traffic from the AppPorts is directed to.\n\nEgressIgnoredPorts - (Required) The egress traffic going to the specified ports is ignored and not redirected to the ProxyEgressPort . It can be an empty list.\n\nEgressIgnoredIPs - (Required) The egress traffic going to the specified IP addresses is ignored and not redirected to the ProxyEgressPort . It can be an empty list.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nShorthand Syntax:\n\ntype=string,containerName=string,properties=[{name=string,value=string},{name=string,value=string}]\n\n\nJSON Syntax:\n\n{\n  \"type\": \"APPMESH\",\n  \"containerName\": \"string\",\n  \"properties\": [\n    {\n      \"name\": \"string\",\n      \"value\": \"string\"\n    }\n    ...\n  ]\n}\n\n\n--inference-accelerators (list)\n\nThe Elastic Inference accelerators to use for the containers in the task.\n\n(structure)\n\nDetails on a Elastic Inference accelerator. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name. The deviceName must also be referenced in a container definition as a ResourceRequirement .\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nShorthand Syntax:\n\ndeviceName=string,deviceType=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"deviceName\": \"string\",\n    \"deviceType\": \"string\"\n  }\n  ...\n]\n\n\n--ephemeral-storage (structure)\n\nThe amount of ephemeral storage to allocate for the task. This parameter is used to expand the total amount of ephemeral storage available, beyond the default amount, for tasks hosted on Fargate. For more information, see Fargate task storage in the Amazon ECS User Guide for Fargate .\n\nNote\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\nShorthand Syntax:\n\nsizeInGiB=integer\n\n\nJSON Syntax:\n\n{\n  \"sizeInGiB\": integer\n}\n\n\n--runtime-platform (structure)\n\nThe operating system that your tasks definitions run on. A platform family is specified only for tasks using the Fargate launch type.\n\nWhen you specify a task definition in a service, this value must match the runtimePlatform value of the service.\n\ncpuArchitecture -> (string)\n\nThe CPU architecture.\n\noperatingSystemFamily -> (string)\n\nThe operating system.\n\nShorthand Syntax:\n\ncpuArchitecture=string,operatingSystemFamily=string\n\n\nJSON Syntax:\n\n{\n  \"cpuArchitecture\": \"X86_64\"|\"ARM64\",\n  \"operatingSystemFamily\": \"WINDOWS_SERVER_2019_FULL\"|\"WINDOWS_SERVER_2019_CORE\"|\"WINDOWS_SERVER_2016_FULL\"|\"WINDOWS_SERVER_2004_CORE\"|\"WINDOWS_SERVER_2022_CORE\"|\"WINDOWS_SERVER_2022_FULL\"|\"WINDOWS_SERVER_20H2_CORE\"|\"LINUX\"\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntaskDefinition -> (structure)\n\nThe full description of the registered task definition.\n\ntaskDefinitionArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the task definition.\n\ncontainerDefinitions -> (list)\n\nA list of container definitions in JSON format that describe the different containers that make up your task. For more information about container definition parameters and defaults, see Amazon ECS Task Definitions in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nContainer definitions are used in task definitions to describe the different containers that are launched as part of a task.\n\nname -> (string)\n\nThe name of a container. If you are linking multiple containers together in a task definition, the name of one container can be entered in the links of another container to connect the containers. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This parameter maps to name in the Create a container section of the Docker Remote API and the --name option to docker run .\n\nimage -> (string)\n\nThe image used to start a container. This string is passed directly to the Docker daemon. Images in the Docker Hub registry are available by default. Other repositories are specified with either `` repository-url /image :tag `` or `` repository-url /image @*digest* `` . Up to 255 letters (uppercase and lowercase), numbers, hyphens, underscores, colons, periods, forward slashes, and number signs are allowed. This parameter maps to Image in the Create a container section of the Docker Remote API and the IMAGE parameter of docker run .\n\nWhen a new task starts, the Amazon ECS container agent pulls the latest version of the specified image and tag for the container to use. However, subsequent updates to a repository image are not propagated to already running tasks.\n\nImages in Amazon ECR repositories can be specified by either using the full registry/repository:tag or registry/repository@digest . For example, 012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>:latest or 012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>@sha256:94afd1f2e64d908bc90dbca0035a5b567EXAMPLE .\n\nImages in official repositories on Docker Hub use a single name (for example, ubuntu or mongo ).\n\nImages in other repositories on Docker Hub are qualified with an organization name (for example, amazon/amazon-ecs-agent ).\n\nImages in other online repositories are qualified further by a domain name (for example, quay.io/assemblyline/ubuntu ).\n\nrepositoryCredentials -> (structure)\n\nThe private repository authentication credentials to use.\n\ncredentialsParameter -> (string)\n\nThe Amazon Resource Name (ARN) of the secret containing the private repository credentials.\n\nNote\n\nWhen you are using the Amazon ECS API, CLI, or Amazon Web Services SDK, if the secret exists in the same Region as the task that you are launching then you can use either the full ARN or the name of the secret. When you are using the Amazon Web Services Management Console, you must specify the full ARN of the secret.\n\ncpu -> (integer)\n\nThe number of cpu units reserved for the container. This parameter maps to CpuShares in the Create a container section of the Docker Remote API and the --cpu-shares option to docker run .\n\nThis field is optional for tasks using the Fargate launch type, and the only requirement is that the total amount of CPU reserved for all containers within a task be lower than the task-level cpu value.\n\nNote\n\nYou can determine the number of CPU units that are available per EC2 instance type by multiplying the vCPUs listed for that instance type on the Amazon EC2 Instances detail page by 1,024.\n\nLinux containers share unallocated CPU units with other containers on the container instance with the same ratio as their allocated amount. For example, if you run a single-container task on a single-core instance type with 512 CPU units specified for that container, and that is the only task running on the container instance, that container could use the full 1,024 CPU unit share at any given time. However, if you launched another copy of the same task on that container instance, each task would be guaranteed a minimum of 512 CPU units when needed, and each container could float to higher CPU usage if the other container was not using it, but if both tasks were 100% active all of the time, they would be limited to 512 CPU units.\n\nOn Linux container instances, the Docker daemon on the container instance uses the CPU value to calculate the relative CPU share ratios for running containers. For more information, see CPU share constraint in the Docker documentation. The minimum valid CPU share value that the Linux kernel allows is 2. However, the CPU parameter is not required, and you can use CPU values below 2 in your container definitions. For CPU values below 2 (including null), the behavior varies based on your Amazon ECS container agent version:\n\nAgent versions less than or equal to 1.1.0: Null and zero CPU values are passed to Docker as 0, which Docker then converts to 1,024 CPU shares. CPU values of 1 are passed to Docker as 1, which the Linux kernel converts to two CPU shares.\n\nAgent versions greater than or equal to 1.2.0: Null, zero, and CPU values of 1 are passed to Docker as 2.\n\nOn Windows container instances, the CPU limit is enforced as an absolute limit, or a quota. Windows containers only have access to the specified amount of CPU that is described in the task definition. A null or zero CPU value is passed to Docker as 0 , which Windows interprets as 1% of one CPU.\n\nmemory -> (integer)\n\nThe amount (in MiB) of memory to present to the container. If your container attempts to exceed the memory specified here, the container is killed. The total amount of memory reserved for all containers within a task must be lower than the task memory value, if one is specified. This parameter maps to Memory in the Create a container section of the Docker Remote API and the --memory option to docker run .\n\nIf using the Fargate launch type, this parameter is optional.\n\nIf using the EC2 launch type, you must specify either a task-level memory value or a container-level memory value. If you specify both a container-level memory and memoryReservation value, memory must be greater than memoryReservation . If you specify memoryReservation , then that value is subtracted from the available memory resources for the container instance on which the container is placed. Otherwise, the value of memory is used.\n\nThe Docker daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.\n\nmemoryReservation -> (integer)\n\nThe soft limit (in MiB) of memory to reserve for the container. When system memory is under heavy contention, Docker attempts to keep the container memory to this soft limit. However, your container can consume more memory when it needs to, up to either the hard limit specified with the memory parameter (if applicable), or all of the available memory on the container instance, whichever comes first. This parameter maps to MemoryReservation in the Create a container section of the Docker Remote API and the --memory-reservation option to docker run .\n\nIf a task-level memory value is not specified, you must specify a non-zero integer for one or both of memory or memoryReservation in a container definition. If you specify both, memory must be greater than memoryReservation . If you specify memoryReservation , then that value is subtracted from the available memory resources for the container instance on which the container is placed. Otherwise, the value of memory is used.\n\nFor example, if your container normally uses 128 MiB of memory, but occasionally bursts to 256 MiB of memory for short periods of time, you can set a memoryReservation of 128 MiB, and a memory hard limit of 300 MiB. This configuration would allow the container to only reserve 128 MiB of memory from the remaining resources on the container instance, but also allow the container to consume more memory resources when needed.\n\nThe Docker daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.\n\nlinks -> (list)\n\nThe links parameter allows containers to communicate with each other without the need for port mappings. This parameter is only supported if the network mode of a task definition is bridge . The name:internalName construct is analogous to name:alias in Docker links. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. For more information about linking Docker containers, go to Legacy container links in the Docker documentation. This parameter maps to Links in the Create a container section of the Docker Remote API and the --link option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nWarning\n\nContainers that are collocated on a single container instance may be able to communicate with each other without requiring links or host port mappings. Network isolation is achieved on the container instance using security groups and VPC settings.\n\n(string)\n\nportMappings -> (list)\n\nThe list of port mappings for the container. Port mappings allow containers to access ports on the host container instance to send or receive traffic.\n\nFor task definitions that use the awsvpc network mode, you should only specify the containerPort . The hostPort can be left blank or it must be the same value as the containerPort .\n\nPort mappings on Windows use the NetNAT gateway address rather than localhost . There is no loopback for port mappings on Windows, so you cannot access a container’s mapped port from the host itself.\n\nThis parameter maps to PortBindings in the Create a container section of the Docker Remote API and the --publish option to docker run . If the network mode of a task definition is set to none , then you can’t specify port mappings. If the network mode of a task definition is set to host , then host ports must either be undefined or they must match the container port in the port mapping.\n\nNote\n\nAfter a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the Network Bindings section of a container description for a selected task in the Amazon ECS console. The assignments are also visible in the networkBindings section DescribeTasks responses.\n\n(structure)\n\nPort mappings allow containers to access ports on the host container instance to send or receive traffic. Port mappings are specified as part of the container definition.\n\nIf you are using containers in a task with the awsvpc or host network mode, exposed ports should be specified using containerPort . The hostPort can be left blank or it must be the same value as the containerPort .\n\nNote\n\nYou cannot expose the same container port for multiple protocols. An error will be returned if this is attempted\n\nAfter a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the networkBindings section of DescribeTasks API responses.\n\ncontainerPort -> (integer)\n\nThe port number on the container that is bound to the user-specified or automatically assigned host port.\n\nIf you are using containers in a task with the awsvpc or host network mode, exposed ports should be specified using containerPort .\n\nIf you are using containers in a task with the bridge network mode and you specify a container port and not a host port, your container automatically receives a host port in the ephemeral port range. For more information, see hostPort . Port mappings that are automatically assigned in this way do not count toward the 100 reserved ports limit of a container instance.\n\nhostPort -> (integer)\n\nThe port number on the container instance to reserve for your container.\n\nIf you are using containers in a task with the awsvpc or host network mode, the hostPort can either be left blank or set to the same value as the containerPort .\n\nIf you are using containers in a task with the bridge network mode, you can specify a non-reserved host port for your container port mapping, or you can omit the hostPort (or set it to 0 ) while specifying a containerPort and your container automatically receives a port in the ephemeral port range for your container instance operating system and Docker version.\n\nThe default ephemeral port range for Docker version 1.6.0 and later is listed on the instance under /proc/sys/net/ipv4/ip_local_port_range . If this kernel parameter is unavailable, the default ephemeral port range from 49153 through 65535 is used. Do not attempt to specify a host port in the ephemeral port range as these are reserved for automatic assignment. In general, ports below 32768 are outside of the ephemeral port range.\n\nNote\n\nThe default ephemeral port range from 49153 through 65535 is always used for Docker versions before 1.6.0.\n\nThe default reserved ports are 22 for SSH, the Docker ports 2375 and 2376, and the Amazon ECS container agent ports 51678-51680. Any host port that was previously specified in a running task is also reserved while the task is running (after a task stops, the host port is released). The current reserved ports are displayed in the remainingResources of DescribeContainerInstances output. A container instance can have up to 100 reserved ports at a time, including the default reserved ports. Automatically assigned ports don’t count toward the 100 reserved ports limit.\n\nprotocol -> (string)\n\nThe protocol used for the port mapping. Valid values are tcp and udp . The default is tcp .\n\nessential -> (boolean)\n\nIf the essential parameter of a container is marked as true , and that container fails or stops for any reason, all other containers that are part of the task are stopped. If the essential parameter of a container is marked as false , then its failure does not affect the rest of the containers in a task. If this parameter is omitted, a container is assumed to be essential.\n\nAll tasks must have at least one essential container. If you have an application that is composed of multiple containers, you should group containers that are used for a common purpose into components, and separate the different components into multiple task definitions. For more information, see Application Architecture in the Amazon Elastic Container Service Developer Guide .\n\nentryPoint -> (list)\n\nWarning\n\nEarly versions of the Amazon ECS container agent do not properly handle entryPoint parameters. If you have problems using entryPoint , update your container agent or enter your commands and arguments as command array items instead.\n\nThe entry point that is passed to the container. This parameter maps to Entrypoint in the Create a container section of the Docker Remote API and the --entrypoint option to docker run . For more information, see https://docs.docker.com/engine/reference/builder/#entrypoint .\n\n(string)\n\ncommand -> (list)\n\nThe command that is passed to the container. This parameter maps to Cmd in the Create a container section of the Docker Remote API and the COMMAND parameter to docker run . For more information, see https://docs.docker.com/engine/reference/builder/#cmd . If there are multiple arguments, each argument should be a separated string in the array.\n\n(string)\n\nenvironment -> (list)\n\nThe environment variables to pass to a container. This parameter maps to Env in the Create a container section of the Docker Remote API and the --env option to docker run .\n\nWarning\n\nWe do not recommend using plaintext environment variables for sensitive information, such as credential data.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nenvironmentFiles -> (list)\n\nA list of files containing the environment variables to pass to a container. This parameter maps to the --env-file option to docker run .\n\nYou can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying Environment Variables in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nA list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying environment variables in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nvalue -> (string)\n\nThe Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\ntype -> (string)\n\nThe file type to use. The only supported value is s3 .\n\nmountPoints -> (list)\n\nThe mount points for data volumes in your container.\n\nThis parameter maps to Volumes in the Create a container section of the Docker Remote API and the --volume option to docker run .\n\nWindows containers can mount whole directories on the same drive as $env:ProgramData . Windows containers cannot mount directories on a different drive, and mount point cannot be across drives.\n\n(structure)\n\nDetails on a volume mount point that is used in a container definition.\n\nsourceVolume -> (string)\n\nThe name of the volume to mount. Must be a volume name referenced in the name parameter of task definition volume .\n\ncontainerPath -> (string)\n\nThe path on the container to mount the host volume at.\n\nreadOnly -> (boolean)\n\nIf this value is true , the container has read-only access to the volume. If this value is false , then the container can write to the volume. The default value is false .\n\nvolumesFrom -> (list)\n\nData volumes to mount from another container. This parameter maps to VolumesFrom in the Create a container section of the Docker Remote API and the --volumes-from option to docker run .\n\n(structure)\n\nDetails on a data volume from another container in the same task definition.\n\nsourceContainer -> (string)\n\nThe name of another container within the same task definition from which to mount volumes.\n\nreadOnly -> (boolean)\n\nIf this value is true , the container has read-only access to the volume. If this value is false , then the container can write to the volume. The default value is false .\n\nlinuxParameters -> (structure)\n\nLinux-specific modifications that are applied to the container, such as Linux kernel capabilities. For more information see KernelCapabilities .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\ncapabilities -> (structure)\n\nThe Linux capabilities for the container that are added to or dropped from the default configuration provided by Docker.\n\nNote\n\nFor tasks that use the Fargate launch type, capabilities is supported for all platform versions but the add parameter is only supported if using platform version 1.4.0 or later.\n\nadd -> (list)\n\nThe Linux capabilities for the container that have been added to the default configuration provided by Docker. This parameter maps to CapAdd in the Create a container section of the Docker Remote API and the --cap-add option to docker run .\n\nNote\n\nTasks launched on Fargate only support adding the SYS_PTRACE kernel capability.\n\nValid values: \"ALL\" | \"AUDIT_CONTROL\" | \"AUDIT_WRITE\" | \"BLOCK_SUSPEND\" | \"CHOWN\" | \"DAC_OVERRIDE\" | \"DAC_READ_SEARCH\" | \"FOWNER\" | \"FSETID\" | \"IPC_LOCK\" | \"IPC_OWNER\" | \"KILL\" | \"LEASE\" | \"LINUX_IMMUTABLE\" | \"MAC_ADMIN\" | \"MAC_OVERRIDE\" | \"MKNOD\" | \"NET_ADMIN\" | \"NET_BIND_SERVICE\" | \"NET_BROADCAST\" | \"NET_RAW\" | \"SETFCAP\" | \"SETGID\" | \"SETPCAP\" | \"SETUID\" | \"SYS_ADMIN\" | \"SYS_BOOT\" | \"SYS_CHROOT\" | \"SYS_MODULE\" | \"SYS_NICE\" | \"SYS_PACCT\" | \"SYS_PTRACE\" | \"SYS_RAWIO\" | \"SYS_RESOURCE\" | \"SYS_TIME\" | \"SYS_TTY_CONFIG\" | \"SYSLOG\" | \"WAKE_ALARM\"\n\n(string)\n\ndrop -> (list)\n\nThe Linux capabilities for the container that have been removed from the default configuration provided by Docker. This parameter maps to CapDrop in the Create a container section of the Docker Remote API and the --cap-drop option to docker run .\n\nValid values: \"ALL\" | \"AUDIT_CONTROL\" | \"AUDIT_WRITE\" | \"BLOCK_SUSPEND\" | \"CHOWN\" | \"DAC_OVERRIDE\" | \"DAC_READ_SEARCH\" | \"FOWNER\" | \"FSETID\" | \"IPC_LOCK\" | \"IPC_OWNER\" | \"KILL\" | \"LEASE\" | \"LINUX_IMMUTABLE\" | \"MAC_ADMIN\" | \"MAC_OVERRIDE\" | \"MKNOD\" | \"NET_ADMIN\" | \"NET_BIND_SERVICE\" | \"NET_BROADCAST\" | \"NET_RAW\" | \"SETFCAP\" | \"SETGID\" | \"SETPCAP\" | \"SETUID\" | \"SYS_ADMIN\" | \"SYS_BOOT\" | \"SYS_CHROOT\" | \"SYS_MODULE\" | \"SYS_NICE\" | \"SYS_PACCT\" | \"SYS_PTRACE\" | \"SYS_RAWIO\" | \"SYS_RESOURCE\" | \"SYS_TIME\" | \"SYS_TTY_CONFIG\" | \"SYSLOG\" | \"WAKE_ALARM\"\n\n(string)\n\ndevices -> (list)\n\nAny host devices to expose to the container. This parameter maps to Devices in the Create a container section of the Docker Remote API and the --device option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the devices parameter is not supported.\n\n(structure)\n\nAn object representing a container instance host device.\n\nhostPath -> (string)\n\nThe path for the device on the host container instance.\n\ncontainerPath -> (string)\n\nThe path inside the container at which to expose the host device.\n\npermissions -> (list)\n\nThe explicit permissions to provide to the container for the device. By default, the container has permissions for read , write , and mknod for the device.\n\n(string)\n\ninitProcessEnabled -> (boolean)\n\nRun an init process inside the container that forwards signals and reaps processes. This parameter maps to the --init option to docker run . This parameter requires version 1.25 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nsharedMemorySize -> (integer)\n\nThe value for the size (in MiB) of the /dev/shm volume. This parameter maps to the --shm-size option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the sharedMemorySize parameter is not supported.\n\ntmpfs -> (list)\n\nThe container path, mount options, and size (in MiB) of the tmpfs mount. This parameter maps to the --tmpfs option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the tmpfs parameter is not supported.\n\n(structure)\n\nThe container path, mount options, and size of the tmpfs mount.\n\ncontainerPath -> (string)\n\nThe absolute file path where the tmpfs volume is to be mounted.\n\nsize -> (integer)\n\nThe maximum size (in MiB) of the tmpfs volume.\n\nmountOptions -> (list)\n\nThe list of tmpfs volume mount options.\n\nValid values: \"defaults\" | \"ro\" | \"rw\" | \"suid\" | \"nosuid\" | \"dev\" | \"nodev\" | \"exec\" | \"noexec\" | \"sync\" | \"async\" | \"dirsync\" | \"remount\" | \"mand\" | \"nomand\" | \"atime\" | \"noatime\" | \"diratime\" | \"nodiratime\" | \"bind\" | \"rbind\" | \"unbindable\" | \"runbindable\" | \"private\" | \"rprivate\" | \"shared\" | \"rshared\" | \"slave\" | \"rslave\" | \"relatime\" | \"norelatime\" | \"strictatime\" | \"nostrictatime\" | \"mode\" | \"uid\" | \"gid\" | \"nr_inodes\" | \"nr_blocks\" | \"mpol\"\n\n(string)\n\nmaxSwap -> (integer)\n\nThe total amount of swap memory (in MiB) a container can use. This parameter will be translated to the --memory-swap option to docker run where the value would be the sum of the container memory plus the maxSwap value.\n\nIf a maxSwap value of 0 is specified, the container will not use swap. Accepted values are 0 or any positive integer. If the maxSwap parameter is omitted, the container will use the swap configuration for the container instance it is running on. A maxSwap value must be set for the swappiness parameter to be used.\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the maxSwap parameter is not supported.\n\nswappiness -> (integer)\n\nThis allows you to tune a container’s memory swappiness behavior. A swappiness value of 0 will cause swapping to not happen unless absolutely necessary. A swappiness value of 100 will cause pages to be swapped very aggressively. Accepted values are whole numbers between 0 and 100 . If the swappiness parameter is not specified, a default value of 60 is used. If a value is not specified for maxSwap then this parameter is ignored. This parameter maps to the --memory-swappiness option to docker run .\n\nNote\n\nIf you are using tasks that use the Fargate launch type, the swappiness parameter is not supported.\n\nsecrets -> (list)\n\nThe secrets to pass to the container. For more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nAn object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:\n\nTo inject sensitive data into your containers as environment variables, use the secrets container definition parameter.\n\nTo reference sensitive information in the log configuration of a container, use the secretOptions container definition parameter.\n\nFor more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the secret.\n\nvalueFrom -> (string)\n\nThe secret to expose to the container. The supported values are either the full ARN of the Secrets Manager secret or the full ARN of the parameter in the SSM Parameter Store.\n\nNote\n\nIf the SSM Parameter Store parameter exists in the same Region as the task you are launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.\n\ndependsOn -> (list)\n\nThe dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.\n\nFor tasks using the EC2 launch type, the container instances require at least version 1.26.0 of the container agent to enable container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\n(structure)\n\nThe dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.\n\nYour Amazon ECS container instances require at least version 1.26.0 of the container agent to enable container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\ncontainerName -> (string)\n\nThe name of a container.\n\ncondition -> (string)\n\nThe dependency condition of the container. The following are the available conditions and their behavior:\n\nSTART - This condition emulates the behavior of links and volumes today. It validates that a dependent container is started before permitting other containers to start.\n\nCOMPLETE - This condition validates that a dependent container runs to completion (exits) before permitting other containers to start. This can be useful for nonessential containers that run a script and then exit. This condition cannot be set on an essential container.\n\nSUCCESS - This condition is the same as COMPLETE , but it also requires that the container exits with a zero status. This condition cannot be set on an essential container.\n\nHEALTHY - This condition validates that the dependent container passes its Docker health check before permitting other containers to start. This requires that the dependent container has health checks configured. This condition is confirmed only at task startup.\n\nstartTimeout -> (integer)\n\nTime duration (in seconds) to wait before giving up on resolving dependencies for a container. For example, you specify two containers in a task definition with containerA having a dependency on containerB reaching a COMPLETE , SUCCESS , or HEALTHY status. If a startTimeout value is specified for containerB and it does not reach the desired status within that time then containerA will give up and not start. This results in the task transitioning to a STOPPED state.\n\nNote\n\nWhen the ECS_CONTAINER_START_TIMEOUT container agent configuration variable is used, it is enforced indendently from this start timeout value.\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nFor tasks using the EC2 launch type, your container instances require at least version 1.26.0 of the container agent to enable a container start timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nstopTimeout -> (integer)\n\nTime duration (in seconds) to wait before the container is forcefully killed if it doesn’t exit normally on its own.\n\nFor tasks using the Fargate launch type, the task or service requires the followiwng platforms:\n\nLinux platform version 1.3.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nThe max stop timeout value is 120 seconds and if the parameter is not specified, the default value of 30 seconds is used.\n\nFor tasks using the EC2 launch type, if the stopTimeout parameter is not specified, the value set for the Amazon ECS container agent configuration variable ECS_CONTAINER_STOP_TIMEOUT is used by default. If neither the stopTimeout parameter or the ECS_CONTAINER_STOP_TIMEOUT agent configuration variable are set, then the default values of 30 seconds for Linux containers and 30 seconds on Windows containers are used. Your container instances require at least version 1.26.0 of the container agent to enable a container stop timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see Updating the Amazon ECS Container Agent in the Amazon Elastic Container Service Developer Guide . If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ecs-init package. If your container instances are launched from version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\nhostname -> (string)\n\nThe hostname to use for your container. This parameter maps to Hostname in the Create a container section of the Docker Remote API and the --hostname option to docker run .\n\nNote\n\nThe hostname parameter is not supported if you are using the awsvpc network mode.\n\nuser -> (string)\n\nThe user to use inside the container. This parameter maps to User in the Create a container section of the Docker Remote API and the --user option to docker run .\n\nWarning\n\nWhen running tasks using the host network mode, you should not run containers using the root user (UID 0). It is considered best practice to use a non-root user.\n\nYou can specify the user using the following formats. If specifying a UID or GID, you must specify it as a positive integer.\n\nuser\n\nuser:group\n\nuid\n\nuid:gid\n\nuser:gid\n\nuid:group\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nworkingDirectory -> (string)\n\nThe working directory in which to run commands inside the container. This parameter maps to WorkingDir in the Create a container section of the Docker Remote API and the --workdir option to docker run .\n\ndisableNetworking -> (boolean)\n\nWhen this parameter is true, networking is disabled within the container. This parameter maps to NetworkDisabled in the Create a container section of the Docker Remote API .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\nprivileged -> (boolean)\n\nWhen this parameter is true, the container is given elevated privileges on the host container instance (similar to the root user). This parameter maps to Privileged in the Create a container section of the Docker Remote API and the --privileged option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nreadonlyRootFilesystem -> (boolean)\n\nWhen this parameter is true, the container is given read-only access to its root file system. This parameter maps to ReadonlyRootfs in the Create a container section of the Docker Remote API and the --read-only option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\ndnsServers -> (list)\n\nA list of DNS servers that are presented to the container. This parameter maps to Dns in the Create a container section of the Docker Remote API and the --dns option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(string)\n\ndnsSearchDomains -> (list)\n\nA list of DNS search domains that are presented to the container. This parameter maps to DnsSearch in the Create a container section of the Docker Remote API and the --dns-search option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(string)\n\nextraHosts -> (list)\n\nA list of hostnames and IP address mappings to append to the /etc/hosts file on the container. This parameter maps to ExtraHosts in the Create a container section of the Docker Remote API and the --add-host option to docker run .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks that use the awsvpc network mode.\n\n(structure)\n\nHostnames and IP address entries that are added to the /etc/hosts file of a container via the extraHosts parameter of its ContainerDefinition .\n\nhostname -> (string)\n\nThe hostname to use in the /etc/hosts entry.\n\nipAddress -> (string)\n\nThe IP address to use in the /etc/hosts entry.\n\ndockerSecurityOptions -> (list)\n\nA list of strings to provide custom labels for SELinux and AppArmor multi-level security systems. This field is not valid for containers in tasks using the Fargate launch type.\n\nWith Windows containers, this parameter can be used to reference a credential spec file when configuring a container for Active Directory authentication. For more information, see Using gMSAs for Windows Containers in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter maps to SecurityOpt in the Create a container section of the Docker Remote API and the --security-opt option to docker run .\n\nNote\n\nThe Amazon ECS container agent running on a container instance must register with the ECS_SELINUX_CAPABLE=true or ECS_APPARMOR_CAPABLE=true environment variables before containers placed on that instance can use these security options. For more information, see Amazon ECS Container Agent Configuration in the Amazon Elastic Container Service Developer Guide .\n\nFor more information about valid values, see Docker Run Security Configuration .\n\nValid values: “no-new-privileges” | “apparmor:PROFILE” | “label:value” | “credentialspec:CredentialSpecFilePath”\n\n(string)\n\ninteractive -> (boolean)\n\nWhen this parameter is true , this allows you to deploy containerized applications that require stdin or a tty to be allocated. This parameter maps to OpenStdin in the Create a container section of the Docker Remote API and the --interactive option to docker run .\n\npseudoTerminal -> (boolean)\n\nWhen this parameter is true , a TTY is allocated. This parameter maps to Tty in the Create a container section of the Docker Remote API and the --tty option to docker run .\n\ndockerLabels -> (map)\n\nA key/value map of labels to add to the container. This parameter maps to Labels in the Create a container section of the Docker Remote API and the --label option to docker run . This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nkey -> (string)\n\nvalue -> (string)\n\nulimits -> (list)\n\nA list of ulimits to set in the container. If a ulimit value is specified in a task definition, it will override the default values set by Docker. This parameter maps to Ulimits in the Create a container section of the Docker Remote API and the --ulimit option to docker run . Valid naming values are displayed in the Ulimit data type.\n\nAmazon ECS tasks hosted on Fargate use the default resource limit values set by the operating system with the exception of the nofile resource limit parameter which Fargate overrides. The nofile resource limit sets a restriction on the number of open files that a container can use. The default nofile soft limit is 1024 and hard limit is 4096 .\n\nThis parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nNote\n\nThis parameter is not supported for Windows containers.\n\n(structure)\n\nThe ulimit settings to pass to the container.\n\nAmazon ECS tasks hosted on Fargate use the default resource limit values set by the operating system with the exception of the nofile resource limit parameter which Fargate overrides. The nofile resource limit sets a restriction on the number of open files that a container can use. The default nofile soft limit is 1024 and hard limit is 4096 .\n\nname -> (string)\n\nThe type of the ulimit .\n\nsoftLimit -> (integer)\n\nThe soft limit for the ulimit type.\n\nhardLimit -> (integer)\n\nThe hard limit for the ulimit type.\n\nlogConfiguration -> (structure)\n\nThe log configuration specification for the container.\n\nThis parameter maps to LogConfig in the Create a container section of the Docker Remote API and the --log-driver option to docker run . By default, containers use the same logging driver that the Docker daemon uses. However the container may use a different logging driver than the Docker daemon by specifying a log driver with this parameter in the container definition. To use a different logging driver for a container, the log system must be configured properly on the container instance (or on a different log server for remote logging options). For more information on the options for different supported log drivers, see Configure logging drivers in the Docker documentation.\n\nNote\n\nAmazon ECS currently supports a subset of the logging drivers available to the Docker daemon (shown in the LogConfiguration data type). Additional log drivers may be available in future releases of the Amazon ECS container agent.\n\nThis parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nNote\n\nThe Amazon ECS container agent running on a container instance must register the logging drivers available on that instance with the ECS_AVAILABLE_LOGGING_DRIVERS environment variable before containers placed on that instance can use these log configuration options. For more information, see Amazon ECS Container Agent Configuration in the Amazon Elastic Container Service Developer Guide .\n\nlogDriver -> (string)\n\nThe log driver to use for the container.\n\nFor tasks on Fargate, the supported log drivers are awslogs , splunk , and awsfirelens .\n\nFor tasks hosted on Amazon EC2 instances, the supported log drivers are awslogs , fluentd , gelf , json-file , journald , logentries ,``syslog`` , splunk , and awsfirelens .\n\nFor more information about using the awslogs log driver, see Using the awslogs log driver in the Amazon Elastic Container Service Developer Guide .\n\nFor more information about using the awsfirelens log driver, see Custom log routing in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you have a custom driver that is not listed, you can fork the Amazon ECS container agent project that is available on GitHub and customize it to work with that driver. We encourage you to submit pull requests for changes that you would like to have included. However, we do not currently provide support for running modified copies of this software.\n\noptions -> (map)\n\nThe configuration options to send to the log driver. This parameter requires version 1.19 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: sudo docker version --format '{{.Server.APIVersion}}'\n\nkey -> (string)\n\nvalue -> (string)\n\nsecretOptions -> (list)\n\nThe secrets to pass to the log configuration. For more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\n(structure)\n\nAn object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:\n\nTo inject sensitive data into your containers as environment variables, use the secrets container definition parameter.\n\nTo reference sensitive information in the log configuration of a container, use the secretOptions container definition parameter.\n\nFor more information, see Specifying Sensitive Data in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the secret.\n\nvalueFrom -> (string)\n\nThe secret to expose to the container. The supported values are either the full ARN of the Secrets Manager secret or the full ARN of the parameter in the SSM Parameter Store.\n\nNote\n\nIf the SSM Parameter Store parameter exists in the same Region as the task you are launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.\n\nhealthCheck -> (structure)\n\nThe container health check command and associated configuration parameters for the container. This parameter maps to HealthCheck in the Create a container section of the Docker Remote API and the HEALTHCHECK parameter of docker run .\n\ncommand -> (list)\n\nA string array representing the command that the container runs to determine if it is healthy. The string array must start with CMD to execute the command arguments directly, or CMD-SHELL to run the command with the container’s default shell.\n\nWhen you use the Amazon Web Services Management Console JSON panel, the Command Line Interface, or the APIs, you should enclose the list of commands in brackets, as shown below.\n\n[ \"CMD-SHELL\", \"curl -f http://localhost/ || exit 1\" ]\n\nYou do not need to include the brackets when you use the Amazon Web Services Management Consoleas shown below.\n\n\"CMD-SHELL\", \"curl -f http://localhost/ || exit 1\"\n\nAn exit code of 0 indicates success, and non-zero exit code indicates failure. For more information, see HealthCheck in the Create a container section of the Docker Remote API .\n\n(string)\n\ninterval -> (integer)\n\nThe time period in seconds between each health check execution. You may specify between 5 and 300 seconds. The default value is 30 seconds.\n\ntimeout -> (integer)\n\nThe time period in seconds to wait for a health check to succeed before it is considered a failure. You may specify between 2 and 60 seconds. The default value is 5.\n\nretries -> (integer)\n\nThe number of times to retry a failed health check before the container is considered unhealthy. You may specify between 1 and 10 retries. The default value is 3.\n\nstartPeriod -> (integer)\n\nThe optional grace period within which to provide containers time to bootstrap before failed health checks count towards the maximum number of retries. You may specify between 0 and 300 seconds. The startPeriod is disabled by default.\n\nNote\n\nIf a health check succeeds within the startPeriod , then the container is considered healthy and any subsequent failures count toward the maximum number of retries.\n\nsystemControls -> (list)\n\nA list of namespaced kernel parameters to set in the container. This parameter maps to Sysctls in the Create a container section of the Docker Remote API and the --sysctl option to docker run .\n\nNote\n\nIt is not recommended that you specify network-related systemControls parameters for multiple containers in a single task that also uses either the awsvpc or host network modes. For tasks that use the awsvpc network mode, the container that is started last determines which systemControls parameters take effect. For tasks that use the host network mode, it changes the container instance’s namespaced kernel parameters as well as the containers.\n\n(structure)\n\nA list of namespaced kernel parameters to set in the container. This parameter maps to Sysctls in the Create a container section of the Docker Remote API and the --sysctl option to docker run .\n\nIt is not recommended that you specify network-related systemControls parameters for multiple containers in a single task that also uses either the awsvpc or host network mode for the following reasons:\n\nFor tasks that use the awsvpc network mode, if you set systemControls for any container, it applies to all containers in the task. If you set different systemControls for multiple containers in a single task, the container that is started last determines which systemControls take effect.\n\nFor tasks that use the host network mode, the systemControls parameter applies to the container instance’s kernel parameter as well as that of all containers of any tasks running on that container instance.\n\nnamespace -> (string)\n\nThe namespaced kernel parameter for which to set a value .\n\nvalue -> (string)\n\nThe value for the namespaced kernel parameter specified in namespace .\n\nresourceRequirements -> (list)\n\nThe type and amount of a resource to assign to a container. The only supported resource is a GPU.\n\n(structure)\n\nThe type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see Working with GPUs on Amazon ECS or Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide\n\nvalue -> (string)\n\nThe value for the specified resource type.\n\nIf the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent will reserve for the container. The number of GPUs reserved for all containers in a task should not exceed the number of available GPUs on the container instance the task is launched on.\n\nIf the InferenceAccelerator type is used, the value should match the deviceName for an InferenceAccelerator specified in a task definition.\n\ntype -> (string)\n\nThe type of resource to assign to a container. The supported values are GPU or InferenceAccelerator .\n\nfirelensConfiguration -> (structure)\n\nThe FireLens configuration for the container. This is used to specify and configure a log router for container logs. For more information, see Custom Log Routing in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe log router to use. The valid values are fluentd or fluentbit .\n\noptions -> (map)\n\nThe options to use when configuring the log router. This field is optional and can be used to specify a custom configuration file or to add additional metadata, such as the task, task definition, cluster, and container instance details to the log event. If specified, the syntax to use is \"options\":{\"enable-ecs-log-metadata\":\"true|false\",\"config-file-type:\"s3|file\",\"config-file-value\":\"arn:aws:s3:::mybucket/fluent.conf|filepath\"} . For more information, see Creating a Task Definition that Uses a FireLens Configuration in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nTasks hosted on Fargate only support the file configuration file type.\n\nkey -> (string)\n\nvalue -> (string)\n\nfamily -> (string)\n\nThe name of a family that this task definition is registered to. Up to 255 letters (uppercase and lowercase), numbers, hyphens, and underscores are allowed.\n\nA family groups multiple versions of a task definition. Amazon ECS gives the first task definition that you registered to a family a revision number of 1. Amazon ECS gives sequential revision numbers to each task definition that you add.\n\ntaskRoleArn -> (string)\n\nThe short name or full Amazon Resource Name (ARN) of the Identity and Access Management role that grants containers in the task permission to call Amazon Web Services APIs on your behalf. For more information, see Amazon ECS Task Role in the Amazon Elastic Container Service Developer Guide .\n\nIAM roles for tasks on Windows require that the -EnableTaskIAMRole option is set when you launch the Amazon ECS-optimized Windows AMI. Your containers must also run some configuration code in order to take advantage of the feature. For more information, see Windows IAM roles for tasks in the Amazon Elastic Container Service Developer Guide .\n\nexecutionRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task execution role that grants the Amazon ECS container agent permission to make Amazon Web Services API calls on your behalf. The task execution IAM role is required depending on the requirements of your task. For more information, see Amazon ECS task execution IAM role in the Amazon Elastic Container Service Developer Guide .\n\nnetworkMode -> (string)\n\nThe Docker networking mode to use for the containers in the task. The valid values are none , bridge , awsvpc , and host . If no network mode is specified, the default is bridge .\n\nFor Amazon ECS tasks on Fargate, the awsvpc network mode is required. For Amazon ECS tasks on Amazon EC2 Linux instances, any network mode can be used. For Amazon ECS tasks on Amazon EC2 Windows instances, <default> or awsvpc can be used. If the network mode is set to none , you cannot specify port mappings in your container definitions, and the tasks containers do not have external connectivity. The host and awsvpc network modes offer the highest networking performance for containers because they use the EC2 network stack instead of the virtualized network stack provided by the bridge mode.\n\nWith the host and awsvpc network modes, exposed container ports are mapped directly to the corresponding host port (for the host network mode) or the attached elastic network interface port (for the awsvpc network mode), so you cannot take advantage of dynamic host port mappings.\n\nWarning\n\nWhen using the host network mode, you should not run containers using the root user (UID 0). It is considered best practice to use a non-root user.\n\nIf the network mode is awsvpc , the task is allocated an elastic network interface, and you must specify a NetworkConfiguration value when you create a service or run a task with the task definition. For more information, see Task Networking in the Amazon Elastic Container Service Developer Guide .\n\nIf the network mode is host , you cannot run multiple instantiations of the same task on a single container instance when port mappings are used.\n\nFor more information, see Network settings in the Docker run reference .\n\nrevision -> (integer)\n\nThe revision of the task in a particular family. The revision is a version number of a task definition in a family. When you register a task definition for the first time, the revision is 1 . Each time that you register a new revision of a task definition in the same family, the revision value always increases by one, even if you have deregistered previous revisions in this family.\n\nvolumes -> (list)\n\nThe list of data volume definitions for the task. For more information, see Using data volumes in tasks in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nThe host and sourcePath parameters are not supported for tasks run on Fargate.\n\n(structure)\n\nA data volume used in a task definition. For tasks that use the Amazon Elastic File System (Amazon EFS), specify an efsVolumeConfiguration . For Windows tasks that use Amazon FSx for Windows File Server file system, specify a fsxWindowsFileServerVolumeConfiguration . For tasks that use a Docker volume, specify a DockerVolumeConfiguration . For tasks that use a bind mount host volume, specify a host and optional sourcePath . For more information, see Using Data Volumes in Tasks .\n\nname -> (string)\n\nThe name of the volume. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This name is referenced in the sourceVolume parameter of container definition mountPoints .\n\nhost -> (structure)\n\nThis parameter is specified when you are using bind mount host volumes. The contents of the host parameter determine whether your bind mount host volume persists on the host container instance and where it is stored. If the host parameter is empty, then the Docker daemon assigns a host path for your data volume. However, the data is not guaranteed to persist after the containers associated with it stop running.\n\nWindows containers can mount whole directories on the same drive as $env:ProgramData . Windows containers cannot mount directories on a different drive, and mount point cannot be across drives. For example, you can mount C:\\my\\path:C:\\my\\path and D:\\:D:\\ , but not D:\\my\\path:C:\\my\\path or D:\\:C:\\my\\path .\n\nsourcePath -> (string)\n\nWhen the host parameter is used, specify a sourcePath to declare the path on the host container instance that is presented to the container. If this parameter is empty, then the Docker daemon has assigned a host path for you. If the host parameter contains a sourcePath file location, then the data volume persists at the specified location on the host container instance until you delete it manually. If the sourcePath value does not exist on the host container instance, the Docker daemon creates it. If the location does exist, the contents of the source path folder are exported.\n\nIf you are using the Fargate launch type, the sourcePath parameter is not supported.\n\ndockerVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using Docker volumes.\n\nWindows containers only support the use of the local driver. To use bind mounts, specify the host parameter instead.\n\nNote\n\nDocker volumes are not supported by tasks run on Fargate.\n\nscope -> (string)\n\nThe scope for the Docker volume that determines its lifecycle. Docker volumes that are scoped to a task are automatically provisioned when the task starts and destroyed when the task stops. Docker volumes that are scoped as shared persist after the task stops.\n\nautoprovision -> (boolean)\n\nIf this value is true , the Docker volume is created if it does not already exist.\n\nNote\n\nThis field is only used if the scope is shared .\n\ndriver -> (string)\n\nThe Docker volume driver to use. The driver value must match the driver name provided by Docker because it is used for task placement. If the driver was installed using the Docker plugin CLI, use docker plugin ls to retrieve the driver name from your container instance. If the driver was installed using another method, use Docker plugin discovery to retrieve the driver name. For more information, see Docker plugin discovery . This parameter maps to Driver in the Create a volume section of the Docker Remote API and the xxdriver option to docker volume create .\n\ndriverOpts -> (map)\n\nA map of Docker driver-specific options passed through. This parameter maps to DriverOpts in the Create a volume section of the Docker Remote API and the xxopt option to docker volume create .\n\nkey -> (string)\n\nvalue -> (string)\n\nlabels -> (map)\n\nCustom metadata to add to your Docker volume. This parameter maps to Labels in the Create a volume section of the Docker Remote API and the xxlabel option to docker volume create .\n\nkey -> (string)\n\nvalue -> (string)\n\nefsVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using an Amazon Elastic File System file system for task storage.\n\nfileSystemId -> (string)\n\nThe Amazon EFS file system ID to use.\n\nrootDirectory -> (string)\n\nThe directory within the Amazon EFS file system to mount as the root directory inside the host. If this parameter is omitted, the root of the Amazon EFS volume will be used. Specifying / will have the same effect as omitting this parameter.\n\nWarning\n\nIf an EFS access point is specified in the authorizationConfig , the root directory parameter must either be omitted or set to / which will enforce the path set on the EFS access point.\n\ntransitEncryption -> (string)\n\nWhether or not to enable encryption for Amazon EFS data in transit between the Amazon ECS host and the Amazon EFS server. Transit encryption must be enabled if Amazon EFS IAM authorization is used. If this parameter is omitted, the default value of DISABLED is used. For more information, see Encrypting Data in Transit in the Amazon Elastic File System User Guide .\n\ntransitEncryptionPort -> (integer)\n\nThe port to use when sending encrypted data between the Amazon ECS host and the Amazon EFS server. If you do not specify a transit encryption port, it will use the port selection strategy that the Amazon EFS mount helper uses. For more information, see EFS Mount Helper in the Amazon Elastic File System User Guide .\n\nauthorizationConfig -> (structure)\n\nThe authorization configuration details for the Amazon EFS file system.\n\naccessPointId -> (string)\n\nThe Amazon EFS access point ID to use. If an access point is specified, the root directory value specified in the EFSVolumeConfiguration must either be omitted or set to / which will enforce the path set on the EFS access point. If an access point is used, transit encryption must be enabled in the EFSVolumeConfiguration . For more information, see Working with Amazon EFS Access Points in the Amazon Elastic File System User Guide .\n\niam -> (string)\n\nWhether or not to use the Amazon ECS task IAM role defined in a task definition when mounting the Amazon EFS file system. If enabled, transit encryption must be enabled in the EFSVolumeConfiguration . If this parameter is omitted, the default value of DISABLED is used. For more information, see Using Amazon EFS Access Points in the Amazon Elastic Container Service Developer Guide .\n\nfsxWindowsFileServerVolumeConfiguration -> (structure)\n\nThis parameter is specified when you are using Amazon FSx for Windows File Server file system for task storage.\n\nfileSystemId -> (string)\n\nThe Amazon FSx for Windows File Server file system ID to use.\n\nrootDirectory -> (string)\n\nThe directory within the Amazon FSx for Windows File Server file system to mount as the root directory inside the host.\n\nauthorizationConfig -> (structure)\n\nThe authorization configuration details for the Amazon FSx for Windows File Server file system.\n\ncredentialsParameter -> (string)\n\nThe authorization credential option to use. The authorization credential options can be provided using either the Amazon Resource Name (ARN) of an Secrets Manager secret or SSM Parameter Store parameter. The ARNs refer to the stored credentials.\n\ndomain -> (string)\n\nA fully qualified domain name hosted by an Directory Service Managed Microsoft AD (Active Directory) or self-hosted AD on Amazon EC2.\n\nstatus -> (string)\n\nThe status of the task definition.\n\nrequiresAttributes -> (list)\n\nThe container instance attributes required by your task. When an Amazon EC2 instance is registered to your cluster, the Amazon ECS container agent assigns some standard attributes to the instance. You can apply custom attributes, specified as key-value pairs using the Amazon ECS console or the PutAttributes API. These attributes are used when considering task placement for tasks hosted on Amazon EC2 instances. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nThis parameter is not supported for tasks run on Fargate.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nplacementConstraints -> (list)\n\nAn array of placement constraint objects to use for tasks.\n\nNote\n\nThis parameter is not supported for tasks run on Fargate.\n\n(structure)\n\nAn object representing a constraint on task placement in the task definition. For more information, see Task placement constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nTask placement constraints are not supported for tasks run on Fargate.\n\ntype -> (string)\n\nThe type of constraint. The MemberOf constraint restricts selection to be from a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\ncompatibilities -> (list)\n\nThe task launch types the task definition validated against during task definition registration. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\n(string)\n\nruntimePlatform -> (structure)\n\nThe operating system that your task definitions are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nWhen you specify a task in a service, this value must match the runtimePlatform value of the service.\n\ncpuArchitecture -> (string)\n\nThe CPU architecture.\n\noperatingSystemFamily -> (string)\n\nThe operating system.\n\nrequiresCompatibilities -> (list)\n\nThe task launch types the task definition was validated against. To determine which task launch types the task definition is validated for, see the TaskDefinition$compatibilities parameter.\n\n(string)\n\ncpu -> (string)\n\nThe number of cpu units used by the task. If you are using the EC2 launch type, this field is optional and any value can be used. If you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of valid values for the memory parameter:\n\n256 (.25 vCPU) - Available memory values: 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)\n\n512 (.5 vCPU) - Available memory values: 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)\n\n1024 (1 vCPU) - Available memory values: 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)\n\n2048 (2 vCPU) - Available memory values: Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)\n\n4096 (4 vCPU) - Available memory values: Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)\n\nmemory -> (string)\n\nThe amount (in MiB) of memory used by the task.\n\nIf your tasks will be run on Amazon EC2 instances, you must specify either a task-level memory value or a container-level memory value. This field is optional and any value can be used. If a task-level memory value is specified then the container-level memory value is optional. For more information regarding container-level memory and memory reservation, see ContainerDefinition .\n\nIf your tasks will be run on Fargate, this field is required and you must use one of the following values, which determines your range of valid values for the cpu parameter:\n\n512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)\n\n1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)\n\n2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)\n\nBetween 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)\n\nBetween 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)\n\ninferenceAccelerators -> (list)\n\nThe Elastic Inference accelerator associated with the task.\n\n(structure)\n\nDetails on a Elastic Inference accelerator. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name. The deviceName must also be referenced in a container definition as a ResourceRequirement .\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\npidMode -> (string)\n\nThe process namespace to use for the containers in the task. The valid values are host or task . If host is specified, then all containers within the tasks that specified the host PID mode on the same container instance share the same process namespace with the host Amazon EC2 instance. If task is specified, all containers within the specified task share the same process namespace. If no value is specified, the default is a private namespace. For more information, see PID settings in the Docker run reference .\n\nIf the host PID mode is used, be aware that there is a heightened risk of undesired process namespace expose. For more information, see Docker security .\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nipcMode -> (string)\n\nThe IPC resource namespace to use for the containers in the task. The valid values are host , task , or none . If host is specified, then all containers within the tasks that specified the host IPC mode on the same container instance share the same IPC resources with the host Amazon EC2 instance. If task is specified, all containers within the specified task share the same IPC resources. If none is specified, then IPC resources within the containers of a task are private and not shared with other containers in a task or on the container instance. If no value is specified, then the IPC resource namespace sharing depends on the Docker daemon setting on the container instance. For more information, see IPC settings in the Docker run reference .\n\nIf the host IPC mode is used, be aware that there is a heightened risk of undesired IPC namespace expose. For more information, see Docker security .\n\nIf you are setting namespaced kernel parameters using systemControls for the containers in the task, the following will apply to your IPC resource namespace. For more information, see System Controls in the Amazon Elastic Container Service Developer Guide .\n\nFor tasks that use the host IPC mode, IPC namespace related systemControls are not supported.\n\nFor tasks that use the task IPC mode, IPC namespace related systemControls will apply to all containers within a task.\n\nNote\n\nThis parameter is not supported for Windows containers or tasks run on Fargate.\n\nproxyConfiguration -> (structure)\n\nThe configuration details for the App Mesh proxy.\n\nYour Amazon ECS container instances require at least version 1.26.0 of the container agent and at least version 1.26.0-1 of the ecs-init package to enable a proxy configuration. If your container instances are launched from the Amazon ECS-optimized AMI version 20190301 or later, then they contain the required versions of the container agent and ecs-init . For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe proxy type. The only supported value is APPMESH .\n\ncontainerName -> (string)\n\nThe name of the container that will serve as the App Mesh proxy.\n\nproperties -> (list)\n\nThe set of network configuration parameters to provide the Container Network Interface (CNI) plugin, specified as key-value pairs.\n\nIgnoredUID - (Required) The user ID (UID) of the proxy container as defined by the user parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If IgnoredGID is specified, this field can be empty.\n\nIgnoredGID - (Required) The group ID (GID) of the proxy container as defined by the user parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If IgnoredUID is specified, this field can be empty.\n\nAppPorts - (Required) The list of ports that the application uses. Network traffic to these ports is forwarded to the ProxyIngressPort and ProxyEgressPort .\n\nProxyIngressPort - (Required) Specifies the port that incoming traffic to the AppPorts is directed to.\n\nProxyEgressPort - (Required) Specifies the port that outgoing traffic from the AppPorts is directed to.\n\nEgressIgnoredPorts - (Required) The egress traffic going to the specified ports is ignored and not redirected to the ProxyEgressPort . It can be an empty list.\n\nEgressIgnoredIPs - (Required) The egress traffic going to the specified IP addresses is ignored and not redirected to the ProxyEgressPort . It can be an empty list.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nregisteredAt -> (timestamp)\n\nThe Unix timestamp for when the task definition was registered.\n\nderegisteredAt -> (timestamp)\n\nThe Unix timestamp for when the task definition was deregistered.\n\nregisteredBy -> (string)\n\nThe principal that registered the task definition.\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage settings to use for tasks run with the task definition.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\ntags -> (list)\n\nThe list of tags associated with the task definition.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nExample 1: To register a task definition with a JSON file\n\nThe following register-task-definition example registers a task definition to the specified family with container definitions that are saved in JSON format at the specified file location.\n\naws ecs register-task-definition \\\n    --cli-input-json file://<path_to_json_file>/sleep360.json\n\n\nsleep360.json file contents:\n\n{\n    \"containerDefinitions\": [\n        {\n            \"name\": \"sleep\",\n            \"image\": \"busybox\",\n            \"cpu\": 10,\n            \"command\": [\n                \"sleep\",\n                \"360\"\n            ],\n            \"memory\": 10,\n            \"essential\": true\n        }\n    ],\n    \"family\": \"sleep360\"\n}\n\n\nOutput:\n\n{\n    \"taskDefinition\": {\n        \"taskDefinitionArn\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sleep360:2\",\n        \"containerDefinitions\": [\n            {\n                \"name\": \"sleep\",\n                \"image\": \"busybox\",\n                \"cpu\": 10,\n                \"memory\": 10,\n                \"portMappings\": [],\n                \"essential\": true,\n                \"command\": [\n                    \"sleep\",\n                    \"360\"\n                ],\n                \"environment\": [],\n                \"mountPoints\": [],\n                \"volumesFrom\": []\n            }\n        ],\n        \"family\": \"sleep360\",\n        \"revision\": 2,\n        \"volumes\": [],\n        \"status\": \"ACTIVE\",\n        \"placementConstraints\": [],\n        \"compatibilities\": [\n            \"EC2\"\n        ]\n    }\n}\n\n\nExample 2: To register a task definition with a JSON string parameter\n\nThe following register-task-definition example registers the same task definition from the previous example, but the container definitions are provided as a string parameter with the double quotes escaped.\n\naws ecs register-task-definition \\\n    --family sleep360 \\\n    --container-definitions \"[{\\\"name\\\":\\\"sleep\\\",\\\"image\\\":\\\"busybox\\\",\\\"cpu\\\":10,\\\"command\\\":[\\\"sleep\\\",\\\"360\\\"],\\\"memory\\\":10,\\\"essential\\\":true}]\"\n\n\nThe output is identical to the previous example.\n\nExample 3: To use data volumes in a task definition\n\nThis example task definition file creates a data volume called webdata that exists at /ecs/webdata on the container instance. The volume is mounted read-only as /usr/share/nginx/html on the web container, and read-write as /nginx/ on the timer container.\n\n{\n    \"family\": \"web-timer\",\n    \"containerDefinitions\": [\n        {\n            \"name\": \"web\",\n            \"image\": \"nginx\",\n            \"cpu\": 99,\n            \"memory\": 100,\n            \"portMappings\": [\n                {\n                    \"containerPort\": 80,\n                    \"hostPort\": 80\n                }\n            ],\n            \"essential\": true,\n            \"mountPoints\": [\n                {\n                    \"sourceVolume\": \"webdata\",\n                    \"containerPath\": \"/usr/share/nginx/html\",\n                    \"readOnly\": true\n                }\n            ]\n        },\n        {\n            \"name\": \"timer\",\n            \"image\": \"busybox\",\n            \"cpu\": 10,\n            \"memory\": 20,\n            \"entryPoint\": [\"sh\", \"-c\"],\n            \"command\": [\"while true; do date > /nginx/index.html; sleep 1; done\"],\n            \"mountPoints\": [\n                {\n                    \"sourceVolume\": \"webdata\",\n                    \"containerPath\": \"/nginx/\"\n                }\n            ]\n        }\n    ],\n    \"volumes\": [\n        {\n            \"name\": \"webdata\",\n            \"host\": {\n                \"sourcePath\": \"/ecs/webdata\"\n            }\n        }\n    ]\n}\n\n\nFor more information, see Creating a Task Definition in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "run-task",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/run-task.html",
      "command_description": "Description\n\nStarts a new task using the specified task definition.\n\nYou can allow Amazon ECS to place tasks for you, or you can customize how Amazon ECS places tasks using placement constraints and placement strategies. For more information, see Scheduling Tasks in the Amazon Elastic Container Service Developer Guide .\n\nAlternatively, you can use StartTask to use your own scheduler or place tasks manually on specific container instances.\n\nThe Amazon ECS API follows an eventual consistency model, due to the distributed nature of the system supporting the API. This means that the result of an API command you run that affects your Amazon ECS resources might not be immediately visible to all subsequent commands you run. Keep this in mind when you carry out an API command that immediately follows a previous API command.\n\nTo manage eventual consistency, you can do the following:\n\nConfirm the state of the resource before you run a command to modify it. Run the DescribeTasks command using an exponential backoff algorithm to ensure that you allow enough time for the previous command to propagate through the system. To do this, run the DescribeTasks command repeatedly, starting with a couple of seconds of wait time and increasing gradually up to five minutes of wait time.\n\nAdd wait time between subsequent commands, even if the DescribeTasks command returns an accurate response. Apply an exponential backoff algorithm starting with a couple of seconds of wait time, and increase gradually up to about five minutes of wait time.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  run-task\n[--capacity-provider-strategy <value>]\n[--cluster <value>]\n[--count <value>]\n[--enable-ecs-managed-tags | --no-enable-ecs-managed-tags]\n[--enable-execute-command | --disable-execute-command]\n[--group <value>]\n[--launch-type <value>]\n[--network-configuration <value>]\n[--overrides <value>]\n[--placement-constraints <value>]\n[--placement-strategy <value>]\n[--platform-version <value>]\n[--propagate-tags <value>]\n[--reference-id <value>]\n[--started-by <value>]\n[--tags <value>]\n--task-definition <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--capacity-provider-strategy <value>]",
        "[--cluster <value>]",
        "[--count <value>]",
        "[--enable-ecs-managed-tags | --no-enable-ecs-managed-tags]",
        "[--enable-execute-command | --disable-execute-command]",
        "[--group <value>]",
        "[--launch-type <value>]",
        "[--network-configuration <value>]",
        "[--overrides <value>]",
        "[--placement-constraints <value>]",
        "[--placement-strategy <value>]",
        "[--platform-version <value>]",
        "[--propagate-tags <value>]",
        "[--reference-id <value>]",
        "[--started-by <value>]",
        "[--tags <value>]",
        "--task-definition <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--capacity-provider-strategy (list)\n\nThe capacity provider strategy to use for the task.\n\nIf a capacityProviderStrategy is specified, the launchType parameter must be omitted. If no capacityProviderStrategy or launchType is specified, the defaultCapacityProviderStrategy for the cluster is used.\n\nWhen you use cluster auto scaling, you must specify capacityProviderStrategy and not launchType .\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nShorthand Syntax:\n\ncapacityProvider=string,weight=integer,base=integer ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"capacityProvider\": \"string\",\n    \"weight\": integer,\n    \"base\": integer\n  }\n  ...\n]\n\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster on which to run your task. If you do not specify a cluster, the default cluster is assumed.\n\n--count (integer)\n\nThe number of instantiations of the specified task to place on your cluster. You can specify up to 10 tasks per call.\n\n--enable-ecs-managed-tags | --no-enable-ecs-managed-tags (boolean)\n\nSpecifies whether to enable Amazon ECS managed tags for the task. For more information, see Tagging Your Amazon ECS Resources in the Amazon Elastic Container Service Developer Guide .\n\n--enable-execute-command | --disable-execute-command (boolean)\n\nWhether or not to enable the execute command functionality for the containers in this task. If true , this enables execute command functionality on all containers in the task.\n\n--group (string)\n\nThe name of the task group to associate with the task. The default value is the family name of the task definition (for example, family:my-family-name ).\n\n--launch-type (string)\n\nThe infrastructure on which to run your standalone task. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\nThe FARGATE launch type runs your tasks on Fargate On-Demand infrastructure.\n\nNote\n\nFargate Spot infrastructure is available for use but a capacity provider strategy must be used. For more information, see Fargate capacity providers in the Amazon ECS User Guide for Fargate .\n\nThe EC2 launch type runs your tasks on Amazon EC2 instances registered to your cluster.\n\nThe EXTERNAL launch type runs your tasks on your on-premise server or virtual machine (VM) capacity registered to your cluster.\n\nA task can use either a launch type or a capacity provider strategy. If a launchType is specified, the capacityProviderStrategy parameter must be omitted.\n\nWhen you use cluster auto scaling, you must specify capacityProviderStrategy and not launchType .\n\nPossible values:\n\nEC2\n\nFARGATE\n\nEXTERNAL\n\n--network-configuration (structure)\n\nThe network configuration for the task. This parameter is required for task definitions that use the awsvpc network mode to receive their own elastic network interface, and it is not supported for other network modes. For more information, see Task networking in the Amazon Elastic Container Service Developer Guide .\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nShorthand Syntax:\n\nawsvpcConfiguration={subnets=[string,string],securityGroups=[string,string],assignPublicIp=string}\n\n\nJSON Syntax:\n\n{\n  \"awsvpcConfiguration\": {\n    \"subnets\": [\"string\", ...],\n    \"securityGroups\": [\"string\", ...],\n    \"assignPublicIp\": \"ENABLED\"|\"DISABLED\"\n  }\n}\n\n\n--overrides (structure)\n\nA list of container overrides in JSON format that specify the name of a container in the specified task definition and the overrides it should receive. You can override the default command for a container (that is specified in the task definition or Docker image) with a command override. You can also override existing environment variables (that are specified in the task definition or Docker image) on a container or add new environment variables to it with an environment override.\n\nA total of 8192 characters are allowed for overrides. This limit includes the JSON formatting characters of the override structure.\n\ncontainerOverrides -> (list)\n\nOne or more container overrides sent to a task.\n\n(structure)\n\nThe overrides that should be sent to a container. An empty container override can be passed in. An example of an empty container override would be {\"containerOverrides\": [ ] } . If a non-empty container override is specified, the name parameter must be included.\n\nname -> (string)\n\nThe name of the container that receives the override. This parameter is required if any override is specified.\n\ncommand -> (list)\n\nThe command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.\n\n(string)\n\nenvironment -> (list)\n\nThe environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nenvironmentFiles -> (list)\n\nA list of files containing the environment variables to pass to a container, instead of the value from the container definition.\n\n(structure)\n\nA list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying environment variables in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nvalue -> (string)\n\nThe Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\ntype -> (string)\n\nThe file type to use. The only supported value is s3 .\n\ncpu -> (integer)\n\nThe number of cpu units reserved for the container, instead of the default value from the task definition. You must also specify a container name.\n\nmemory -> (integer)\n\nThe hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.\n\nmemoryReservation -> (integer)\n\nThe soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.\n\nresourceRequirements -> (list)\n\nThe type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.\n\n(structure)\n\nThe type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see Working with GPUs on Amazon ECS or Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide\n\nvalue -> (string)\n\nThe value for the specified resource type.\n\nIf the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent will reserve for the container. The number of GPUs reserved for all containers in a task should not exceed the number of available GPUs on the container instance the task is launched on.\n\nIf the InferenceAccelerator type is used, the value should match the deviceName for an InferenceAccelerator specified in a task definition.\n\ntype -> (string)\n\nThe type of resource to assign to a container. The supported values are GPU or InferenceAccelerator .\n\ncpu -> (string)\n\nThe cpu override for the task.\n\ninferenceAcceleratorOverrides -> (list)\n\nThe Elastic Inference accelerator override for the task.\n\n(structure)\n\nDetails on an Elastic Inference accelerator task override. This parameter is used to override the Elastic Inference accelerator specified in the task definition. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name to override for the task. This parameter must match a deviceName specified in the task definition.\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nexecutionRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see Amazon ECS task execution IAM role in the Amazon Elastic Container Service Developer Guide .\n\nmemory -> (string)\n\nThe memory override for the task.\n\ntaskRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see IAM Role for Tasks in the Amazon Elastic Container Service Developer Guide .\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage setting override for the task.\n\nNote\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\nJSON Syntax:\n\n{\n  \"containerOverrides\": [\n    {\n      \"name\": \"string\",\n      \"command\": [\"string\", ...],\n      \"environment\": [\n        {\n          \"name\": \"string\",\n          \"value\": \"string\"\n        }\n        ...\n      ],\n      \"environmentFiles\": [\n        {\n          \"value\": \"string\",\n          \"type\": \"s3\"\n        }\n        ...\n      ],\n      \"cpu\": integer,\n      \"memory\": integer,\n      \"memoryReservation\": integer,\n      \"resourceRequirements\": [\n        {\n          \"value\": \"string\",\n          \"type\": \"GPU\"|\"InferenceAccelerator\"\n        }\n        ...\n      ]\n    }\n    ...\n  ],\n  \"cpu\": \"string\",\n  \"inferenceAcceleratorOverrides\": [\n    {\n      \"deviceName\": \"string\",\n      \"deviceType\": \"string\"\n    }\n    ...\n  ],\n  \"executionRoleArn\": \"string\",\n  \"memory\": \"string\",\n  \"taskRoleArn\": \"string\",\n  \"ephemeralStorage\": {\n    \"sizeInGiB\": integer\n  }\n}\n\n\n--placement-constraints (list)\n\nAn array of placement constraint objects to use for the task. You can specify up to 10 constraints per task (including constraints in the task definition and those specified at runtime).\n\n(structure)\n\nAn object representing a constraint on task placement. For more information, see Task Placement Constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you are using the Fargate launch type, task placement constraints are not supported.\n\ntype -> (string)\n\nThe type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. The expression can have a maximum length of 2000 characters. You can’t specify an expression if the constraint type is distinctInstance . For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\nShorthand Syntax:\n\ntype=string,expression=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"type\": \"distinctInstance\"|\"memberOf\",\n    \"expression\": \"string\"\n  }\n  ...\n]\n\n\n--placement-strategy (list)\n\nThe placement strategy objects to use for the task. You can specify a maximum of 5 strategy rules per task.\n\n(structure)\n\nThe task placement strategy for a task or service. For more information, see Task Placement Strategies in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).\n\nfield -> (string)\n\nThe field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host , which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone . For the binpack placement strategy, valid values are cpu and memory . For the random placement strategy, this field is not used.\n\nShorthand Syntax:\n\ntype=string,field=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"type\": \"random\"|\"spread\"|\"binpack\",\n    \"field\": \"string\"\n  }\n  ...\n]\n\n\n--platform-version (string)\n\nThe platform version the task should use. A platform version is only specified for tasks hosted on Fargate. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\n--propagate-tags (string)\n\nSpecifies whether to propagate the tags from the task definition to the task. If no value is specified, the tags are not propagated. Tags can only be propagated to the task during task creation. To add tags to a task after task creation, use the TagResource API action.\n\nNote\n\nAn error will be received if you specify the SERVICE option when running a task.\n\nPossible values:\n\nTASK_DEFINITION\n\nSERVICE\n\n--reference-id (string)\n\nThe reference ID to use for the task. The reference ID can have a maximum length of 1024 characters.\n\n--started-by (string)\n\nAn optional tag specified when a task is started. For example, if you automatically trigger a task to run a batch process job, you could apply a unique identifier for that job to your task with the startedBy parameter. You can then identify which tasks belong to that job by filtering the results of a ListTasks call with the startedBy value. Up to 36 letters (uppercase and lowercase), numbers, hyphens, and underscores are allowed.\n\nIf a task is started by an Amazon ECS service, then the startedBy parameter contains the deployment ID of the service that starts it.\n\n--tags (list)\n\nThe metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--task-definition (string)\n\nThe family and revision (family:revision ) or full ARN of the task definition to run. If a revision is not specified, the latest ACTIVE revision is used.\n\nThe full ARN value must match the value that you specified ias the Resource of the IAM principal’s permissions policy. For example, if the Resource is arn:aws:ecs:us-east-1:111122223333:task-definition/TaskFamilyName:*, the taskDefinition ARN value must be arn:aws:ecs:us-east-1:111122223333:task-definition/TaskFamilyName .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntasks -> (list)\n\nA full description of the tasks that were run. The tasks that were successfully placed on your cluster are described here.\n\n(structure)\n\nDetails on a task in a cluster.\n\nattachments -> (list)\n\nThe Elastic Network Adapter associated with the task if the task uses the awsvpc network mode.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nattributes -> (list)\n\nThe attributes of the task\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\navailabilityZone -> (string)\n\nThe availability zone of the task.\n\ncapacityProviderName -> (string)\n\nThe capacity provider associated with the task.\n\nclusterArn -> (string)\n\nThe ARN of the cluster that hosts the task.\n\nconnectivity -> (string)\n\nThe connectivity status of a task.\n\nconnectivityAt -> (timestamp)\n\nThe Unix timestamp for when the task last went into CONNECTED status.\n\ncontainerInstanceArn -> (string)\n\nThe ARN of the container instances that host the task.\n\ncontainers -> (list)\n\nThe containers associated with the task.\n\n(structure)\n\nA Docker container that is part of a task.\n\ncontainerArn -> (string)\n\nThe Amazon Resource Name (ARN) of the container.\n\ntaskArn -> (string)\n\nThe ARN of the task.\n\nname -> (string)\n\nThe name of the container.\n\nimage -> (string)\n\nThe image used for the container.\n\nimageDigest -> (string)\n\nThe container image manifest digest.\n\nNote\n\nThe imageDigest is only returned if the container is using an image hosted in Amazon ECR, otherwise it is omitted.\n\nruntimeId -> (string)\n\nThe ID of the Docker container.\n\nlastStatus -> (string)\n\nThe last known status of the container.\n\nexitCode -> (integer)\n\nThe exit code returned from the container.\n\nreason -> (string)\n\nA short (255 max characters) human-readable string to provide additional details about a running or stopped container.\n\nnetworkBindings -> (list)\n\nThe network bindings associated with the container.\n\n(structure)\n\nDetails on the network bindings between a container and its host container instance. After a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the networkBindings section of DescribeTasks API responses.\n\nbindIP -> (string)\n\nThe IP address that the container is bound to on the container instance.\n\ncontainerPort -> (integer)\n\nThe port number on the container that is used with the network binding.\n\nhostPort -> (integer)\n\nThe port number on the host that is used with the network binding.\n\nprotocol -> (string)\n\nThe protocol used for the network binding.\n\nnetworkInterfaces -> (list)\n\nThe network interfaces associated with the container.\n\n(structure)\n\nAn object representing the elastic network interface for tasks that use the awsvpc network mode.\n\nattachmentId -> (string)\n\nThe attachment ID for the network interface.\n\nprivateIpv4Address -> (string)\n\nThe private IPv4 address for the network interface.\n\nipv6Address -> (string)\n\nThe private IPv6 address for the network interface.\n\nhealthStatus -> (string)\n\nThe health status of the container. If health checks are not configured for this container in its task definition, then it reports the health status as UNKNOWN .\n\nmanagedAgents -> (list)\n\nThe details of any Amazon ECS managed agents associated with the container.\n\n(structure)\n\nDetails about the managed agent status for the container.\n\nlastStartedAt -> (timestamp)\n\nThe Unix timestamp for when the managed agent was last started.\n\nname -> (string)\n\nThe name of the managed agent. When the execute command feature is enabled, the managed agent name is ExecuteCommandAgent .\n\nreason -> (string)\n\nThe reason for why the managed agent is in the state it is in.\n\nlastStatus -> (string)\n\nThe last known status of the managed agent.\n\ncpu -> (string)\n\nThe number of CPU units set for the container. The value will be 0 if no value was specified in the container definition when the task definition was registered.\n\nmemory -> (string)\n\nThe hard limit (in MiB) of memory set for the container.\n\nmemoryReservation -> (string)\n\nThe soft limit (in MiB) of memory set for the container.\n\ngpuIds -> (list)\n\nThe IDs of each GPU assigned to the container.\n\n(string)\n\ncpu -> (string)\n\nThe number of CPU units used by the task as expressed in a task definition. It can be expressed as an integer using CPU units, for example 1024 . It can also be expressed as a string using vCPUs, for example 1 vCPU or 1 vcpu . String values are converted to an integer indicating the CPU units when the task definition is registered.\n\nIf you are using the EC2 launch type, this field is optional. Supported values are between 128 CPU units (0.125 vCPUs) and 10240 CPU units (10 vCPUs).\n\nIf you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the memory parameter:\n\n256 (.25 vCPU) - Available memory values: 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)\n\n512 (.5 vCPU) - Available memory values: 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)\n\n1024 (1 vCPU) - Available memory values: 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)\n\n2048 (2 vCPU) - Available memory values: Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)\n\n4096 (4 vCPU) - Available memory values: Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task was created (the task entered the PENDING state).\n\ndesiredStatus -> (string)\n\nThe desired status of the task. For more information, see Task Lifecycle .\n\nenableExecuteCommand -> (boolean)\n\nWhether or not execute command functionality is enabled for this task. If true , this enables execute command functionality on all containers in the task.\n\nexecutionStoppedAt -> (timestamp)\n\nThe Unix timestamp for when the task execution stopped.\n\ngroup -> (string)\n\nThe name of the task group associated with the task.\n\nhealthStatus -> (string)\n\nThe health status for the task, which is determined by the health of the essential containers in the task. If all essential containers in the task are reporting as HEALTHY , then the task status also reports as HEALTHY . If any essential containers in the task are reporting as UNHEALTHY or UNKNOWN , then the task status also reports as UNHEALTHY or UNKNOWN , accordingly.\n\nNote\n\nThe Amazon ECS container agent does not monitor or report on Docker health checks that are embedded in a container image (such as those specified in a parent image or from the image’s Dockerfile) and not specified in the container definition. Health check parameters that are specified in a container definition override any Docker health checks that exist in the container image.\n\ninferenceAccelerators -> (list)\n\nThe Elastic Inference accelerator associated with the task.\n\n(structure)\n\nDetails on a Elastic Inference accelerator. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name. The deviceName must also be referenced in a container definition as a ResourceRequirement .\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nlastStatus -> (string)\n\nThe last known status of the task. For more information, see Task Lifecycle .\n\nlaunchType -> (string)\n\nThe infrastructure on which your task is running. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\nmemory -> (string)\n\nThe amount of memory (in MiB) used by the task as expressed in a task definition. It can be expressed as an integer using MiB, for example 1024 . It can also be expressed as a string using GB, for example 1GB or 1 GB . String values are converted to an integer indicating the MiB when the task definition is registered.\n\nIf you are using the EC2 launch type, this field is optional.\n\nIf you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the cpu parameter:\n\n512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)\n\n1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)\n\n2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)\n\nBetween 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)\n\nBetween 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)\n\noverrides -> (structure)\n\nOne or more container overrides.\n\ncontainerOverrides -> (list)\n\nOne or more container overrides sent to a task.\n\n(structure)\n\nThe overrides that should be sent to a container. An empty container override can be passed in. An example of an empty container override would be {\"containerOverrides\": [ ] } . If a non-empty container override is specified, the name parameter must be included.\n\nname -> (string)\n\nThe name of the container that receives the override. This parameter is required if any override is specified.\n\ncommand -> (list)\n\nThe command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.\n\n(string)\n\nenvironment -> (list)\n\nThe environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nenvironmentFiles -> (list)\n\nA list of files containing the environment variables to pass to a container, instead of the value from the container definition.\n\n(structure)\n\nA list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying environment variables in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nvalue -> (string)\n\nThe Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\ntype -> (string)\n\nThe file type to use. The only supported value is s3 .\n\ncpu -> (integer)\n\nThe number of cpu units reserved for the container, instead of the default value from the task definition. You must also specify a container name.\n\nmemory -> (integer)\n\nThe hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.\n\nmemoryReservation -> (integer)\n\nThe soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.\n\nresourceRequirements -> (list)\n\nThe type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.\n\n(structure)\n\nThe type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see Working with GPUs on Amazon ECS or Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide\n\nvalue -> (string)\n\nThe value for the specified resource type.\n\nIf the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent will reserve for the container. The number of GPUs reserved for all containers in a task should not exceed the number of available GPUs on the container instance the task is launched on.\n\nIf the InferenceAccelerator type is used, the value should match the deviceName for an InferenceAccelerator specified in a task definition.\n\ntype -> (string)\n\nThe type of resource to assign to a container. The supported values are GPU or InferenceAccelerator .\n\ncpu -> (string)\n\nThe cpu override for the task.\n\ninferenceAcceleratorOverrides -> (list)\n\nThe Elastic Inference accelerator override for the task.\n\n(structure)\n\nDetails on an Elastic Inference accelerator task override. This parameter is used to override the Elastic Inference accelerator specified in the task definition. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name to override for the task. This parameter must match a deviceName specified in the task definition.\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nexecutionRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see Amazon ECS task execution IAM role in the Amazon Elastic Container Service Developer Guide .\n\nmemory -> (string)\n\nThe memory override for the task.\n\ntaskRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see IAM Role for Tasks in the Amazon Elastic Container Service Developer Guide .\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage setting override for the task.\n\nNote\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\nplatformVersion -> (string)\n\nThe platform version on which your task is running. A platform version is only specified for tasks using the Fargate launch type. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX. .\n\npullStartedAt -> (timestamp)\n\nThe Unix timestamp for when the container image pull began.\n\npullStoppedAt -> (timestamp)\n\nThe Unix timestamp for when the container image pull completed.\n\nstartedAt -> (timestamp)\n\nThe Unix timestamp for when the task started (the task transitioned from the PENDING state to the RUNNING state).\n\nstartedBy -> (string)\n\nThe tag specified when a task is started. If the task is started by an Amazon ECS service, then the startedBy parameter contains the deployment ID of the service that starts it.\n\nstopCode -> (string)\n\nThe stop code indicating why a task was stopped. The stoppedReason may contain additional details.\n\nstoppedAt -> (timestamp)\n\nThe Unix timestamp for when the task was stopped (the task transitioned from the RUNNING state to the STOPPED state).\n\nstoppedReason -> (string)\n\nThe reason that the task was stopped.\n\nstoppingAt -> (timestamp)\n\nThe Unix timestamp for when the task stops (transitions from the RUNNING state to STOPPED ).\n\ntags -> (list)\n\nThe metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ntaskArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task.\n\ntaskDefinitionArn -> (string)\n\nThe ARN of the task definition that creates the task.\n\nversion -> (long)\n\nThe version counter for the task. Every time a task experiences a change that triggers a CloudWatch event, the version counter is incremented. If you are replicating your Amazon ECS task state with CloudWatch Events, you can compare the version of a task reported by the Amazon ECS API actions with the version reported in CloudWatch Events for the task (inside the detail object) to verify that the version in your event stream is current.\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage settings for the task.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\nfailures -> (list)\n\nAny failures associated with the call.\n\n(structure)\n\nA failed resource. For a list of common causes, see API failure reasons in the Amazon Elastic Container Service Developer Guide .\n\narn -> (string)\n\nThe Amazon Resource Name (ARN) of the failed resource.\n\nreason -> (string)\n\nThe reason for the failure.\n\ndetail -> (string)\n\nThe details of the failure.",
      "command_examples": "Examples\n\nTo run a task on your default cluster\n\nThe following run-task example runs a task on the default cluster.\n\naws ecs run-task --cluster default --task-definition sleep360:1\n\n\nOutput:\n\n{\n    \"tasks\": [\n        {\n            \"taskArn\": \"arn:aws:ecs:us-west-2:123456789012:task/a1b2c3d4-5678-90ab-ccdef-11111EXAMPLE\",\n            \"overrides\": {\n                \"containerOverrides\": [\n                    {\n                        \"name\": \"sleep\"\n                    }\n                ]\n            },\n            \"lastStatus\": \"PENDING\",\n            \"containerInstanceArn\": \"arn:aws:ecs:us-west-2:123456789012:container-instance/a1b2c3d4-5678-90ab-ccdef-22222EXAMPLE\",\n            \"desiredStatus\": \"RUNNING\",\n            \"taskDefinitionArn\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sleep360:1\",\n            \"containers\": [\n                {\n                    \"containerArn\": \"arn:aws:ecs:us-west-2:123456789012:container/a1b2c3d4-5678-90ab-ccdef-33333EXAMPLE\",\n                    \"taskArn\": \"arn:aws:ecs:us-west-2:123456789012:task/a1b2c3d4-5678-90ab-ccdef-11111EXAMPLE\",\n                    \"lastStatus\": \"PENDING\",\n                    \"name\": \"sleep\"\n                }\n            ]\n        }\n    ]\n}\n\n\nFor more information, see Running Tasks in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "start-task",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/start-task.html",
      "command_description": "Description\n\nStarts a new task from the specified task definition on the specified container instance or instances.\n\nAlternatively, you can use RunTask to place tasks for you. For more information, see Scheduling Tasks in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-task\n[--cluster <value>]\n--container-instances <value>\n[--enable-ecs-managed-tags | --no-enable-ecs-managed-tags]\n[--enable-execute-command | --disable-execute-command]\n[--group <value>]\n[--network-configuration <value>]\n[--overrides <value>]\n[--propagate-tags <value>]\n[--reference-id <value>]\n[--started-by <value>]\n[--tags <value>]\n--task-definition <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--container-instances <value>",
        "[--enable-ecs-managed-tags | --no-enable-ecs-managed-tags]",
        "[--enable-execute-command | --disable-execute-command]",
        "[--group <value>]",
        "[--network-configuration <value>]",
        "[--overrides <value>]",
        "[--propagate-tags <value>]",
        "[--reference-id <value>]",
        "[--started-by <value>]",
        "[--tags <value>]",
        "--task-definition <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster on which to start your task. If you do not specify a cluster, the default cluster is assumed.\n\n--container-instances (list)\n\nThe container instance IDs or full ARN entries for the container instances on which you would like to place your task. You can specify up to 10 container instances.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--enable-ecs-managed-tags | --no-enable-ecs-managed-tags (boolean)\n\nSpecifies whether to enable Amazon ECS managed tags for the task. For more information, see Tagging Your Amazon ECS Resources in the Amazon Elastic Container Service Developer Guide .\n\n--enable-execute-command | --disable-execute-command (boolean)\n\nWhether or not the execute command functionality is enabled for the task. If true , this enables execute command functionality on all containers in the task.\n\n--group (string)\n\nThe name of the task group to associate with the task. The default value is the family name of the task definition (for example, family:my-family-name).\n\n--network-configuration (structure)\n\nThe VPC subnet and security group configuration for tasks that receive their own elastic network interface by using the awsvpc networking mode.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nShorthand Syntax:\n\nawsvpcConfiguration={subnets=[string,string],securityGroups=[string,string],assignPublicIp=string}\n\n\nJSON Syntax:\n\n{\n  \"awsvpcConfiguration\": {\n    \"subnets\": [\"string\", ...],\n    \"securityGroups\": [\"string\", ...],\n    \"assignPublicIp\": \"ENABLED\"|\"DISABLED\"\n  }\n}\n\n\n--overrides (structure)\n\nA list of container overrides in JSON format that specify the name of a container in the specified task definition and the overrides it should receive. You can override the default command for a container (that is specified in the task definition or Docker image) with a command override. You can also override existing environment variables (that are specified in the task definition or Docker image) on a container or add new environment variables to it with an environment override.\n\nNote\n\nA total of 8192 characters are allowed for overrides. This limit includes the JSON formatting characters of the override structure.\n\ncontainerOverrides -> (list)\n\nOne or more container overrides sent to a task.\n\n(structure)\n\nThe overrides that should be sent to a container. An empty container override can be passed in. An example of an empty container override would be {\"containerOverrides\": [ ] } . If a non-empty container override is specified, the name parameter must be included.\n\nname -> (string)\n\nThe name of the container that receives the override. This parameter is required if any override is specified.\n\ncommand -> (list)\n\nThe command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.\n\n(string)\n\nenvironment -> (list)\n\nThe environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nenvironmentFiles -> (list)\n\nA list of files containing the environment variables to pass to a container, instead of the value from the container definition.\n\n(structure)\n\nA list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying environment variables in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nvalue -> (string)\n\nThe Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\ntype -> (string)\n\nThe file type to use. The only supported value is s3 .\n\ncpu -> (integer)\n\nThe number of cpu units reserved for the container, instead of the default value from the task definition. You must also specify a container name.\n\nmemory -> (integer)\n\nThe hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.\n\nmemoryReservation -> (integer)\n\nThe soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.\n\nresourceRequirements -> (list)\n\nThe type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.\n\n(structure)\n\nThe type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see Working with GPUs on Amazon ECS or Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide\n\nvalue -> (string)\n\nThe value for the specified resource type.\n\nIf the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent will reserve for the container. The number of GPUs reserved for all containers in a task should not exceed the number of available GPUs on the container instance the task is launched on.\n\nIf the InferenceAccelerator type is used, the value should match the deviceName for an InferenceAccelerator specified in a task definition.\n\ntype -> (string)\n\nThe type of resource to assign to a container. The supported values are GPU or InferenceAccelerator .\n\ncpu -> (string)\n\nThe cpu override for the task.\n\ninferenceAcceleratorOverrides -> (list)\n\nThe Elastic Inference accelerator override for the task.\n\n(structure)\n\nDetails on an Elastic Inference accelerator task override. This parameter is used to override the Elastic Inference accelerator specified in the task definition. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name to override for the task. This parameter must match a deviceName specified in the task definition.\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nexecutionRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see Amazon ECS task execution IAM role in the Amazon Elastic Container Service Developer Guide .\n\nmemory -> (string)\n\nThe memory override for the task.\n\ntaskRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see IAM Role for Tasks in the Amazon Elastic Container Service Developer Guide .\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage setting override for the task.\n\nNote\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\nJSON Syntax:\n\n{\n  \"containerOverrides\": [\n    {\n      \"name\": \"string\",\n      \"command\": [\"string\", ...],\n      \"environment\": [\n        {\n          \"name\": \"string\",\n          \"value\": \"string\"\n        }\n        ...\n      ],\n      \"environmentFiles\": [\n        {\n          \"value\": \"string\",\n          \"type\": \"s3\"\n        }\n        ...\n      ],\n      \"cpu\": integer,\n      \"memory\": integer,\n      \"memoryReservation\": integer,\n      \"resourceRequirements\": [\n        {\n          \"value\": \"string\",\n          \"type\": \"GPU\"|\"InferenceAccelerator\"\n        }\n        ...\n      ]\n    }\n    ...\n  ],\n  \"cpu\": \"string\",\n  \"inferenceAcceleratorOverrides\": [\n    {\n      \"deviceName\": \"string\",\n      \"deviceType\": \"string\"\n    }\n    ...\n  ],\n  \"executionRoleArn\": \"string\",\n  \"memory\": \"string\",\n  \"taskRoleArn\": \"string\",\n  \"ephemeralStorage\": {\n    \"sizeInGiB\": integer\n  }\n}\n\n\n--propagate-tags (string)\n\nSpecifies whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags are not propagated.\n\nPossible values:\n\nTASK_DEFINITION\n\nSERVICE\n\n--reference-id (string)\n\nThe reference ID to use for the task.\n\n--started-by (string)\n\nAn optional tag specified when a task is started. For example, if you automatically trigger a task to run a batch process job, you could apply a unique identifier for that job to your task with the startedBy parameter. You can then identify which tasks belong to that job by filtering the results of a ListTasks call with the startedBy value. Up to 36 letters (uppercase and lowercase), numbers, hyphens, and underscores are allowed.\n\nIf a task is started by an Amazon ECS service, then the startedBy parameter contains the deployment ID of the service that starts it.\n\n--tags (list)\n\nThe metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--task-definition (string)\n\nThe family and revision (family:revision ) or full ARN of the task definition to start. If a revision is not specified, the latest ACTIVE revision is used.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntasks -> (list)\n\nA full description of the tasks that were started. Each task that was successfully placed on your container instances is described.\n\n(structure)\n\nDetails on a task in a cluster.\n\nattachments -> (list)\n\nThe Elastic Network Adapter associated with the task if the task uses the awsvpc network mode.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nattributes -> (list)\n\nThe attributes of the task\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\navailabilityZone -> (string)\n\nThe availability zone of the task.\n\ncapacityProviderName -> (string)\n\nThe capacity provider associated with the task.\n\nclusterArn -> (string)\n\nThe ARN of the cluster that hosts the task.\n\nconnectivity -> (string)\n\nThe connectivity status of a task.\n\nconnectivityAt -> (timestamp)\n\nThe Unix timestamp for when the task last went into CONNECTED status.\n\ncontainerInstanceArn -> (string)\n\nThe ARN of the container instances that host the task.\n\ncontainers -> (list)\n\nThe containers associated with the task.\n\n(structure)\n\nA Docker container that is part of a task.\n\ncontainerArn -> (string)\n\nThe Amazon Resource Name (ARN) of the container.\n\ntaskArn -> (string)\n\nThe ARN of the task.\n\nname -> (string)\n\nThe name of the container.\n\nimage -> (string)\n\nThe image used for the container.\n\nimageDigest -> (string)\n\nThe container image manifest digest.\n\nNote\n\nThe imageDigest is only returned if the container is using an image hosted in Amazon ECR, otherwise it is omitted.\n\nruntimeId -> (string)\n\nThe ID of the Docker container.\n\nlastStatus -> (string)\n\nThe last known status of the container.\n\nexitCode -> (integer)\n\nThe exit code returned from the container.\n\nreason -> (string)\n\nA short (255 max characters) human-readable string to provide additional details about a running or stopped container.\n\nnetworkBindings -> (list)\n\nThe network bindings associated with the container.\n\n(structure)\n\nDetails on the network bindings between a container and its host container instance. After a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the networkBindings section of DescribeTasks API responses.\n\nbindIP -> (string)\n\nThe IP address that the container is bound to on the container instance.\n\ncontainerPort -> (integer)\n\nThe port number on the container that is used with the network binding.\n\nhostPort -> (integer)\n\nThe port number on the host that is used with the network binding.\n\nprotocol -> (string)\n\nThe protocol used for the network binding.\n\nnetworkInterfaces -> (list)\n\nThe network interfaces associated with the container.\n\n(structure)\n\nAn object representing the elastic network interface for tasks that use the awsvpc network mode.\n\nattachmentId -> (string)\n\nThe attachment ID for the network interface.\n\nprivateIpv4Address -> (string)\n\nThe private IPv4 address for the network interface.\n\nipv6Address -> (string)\n\nThe private IPv6 address for the network interface.\n\nhealthStatus -> (string)\n\nThe health status of the container. If health checks are not configured for this container in its task definition, then it reports the health status as UNKNOWN .\n\nmanagedAgents -> (list)\n\nThe details of any Amazon ECS managed agents associated with the container.\n\n(structure)\n\nDetails about the managed agent status for the container.\n\nlastStartedAt -> (timestamp)\n\nThe Unix timestamp for when the managed agent was last started.\n\nname -> (string)\n\nThe name of the managed agent. When the execute command feature is enabled, the managed agent name is ExecuteCommandAgent .\n\nreason -> (string)\n\nThe reason for why the managed agent is in the state it is in.\n\nlastStatus -> (string)\n\nThe last known status of the managed agent.\n\ncpu -> (string)\n\nThe number of CPU units set for the container. The value will be 0 if no value was specified in the container definition when the task definition was registered.\n\nmemory -> (string)\n\nThe hard limit (in MiB) of memory set for the container.\n\nmemoryReservation -> (string)\n\nThe soft limit (in MiB) of memory set for the container.\n\ngpuIds -> (list)\n\nThe IDs of each GPU assigned to the container.\n\n(string)\n\ncpu -> (string)\n\nThe number of CPU units used by the task as expressed in a task definition. It can be expressed as an integer using CPU units, for example 1024 . It can also be expressed as a string using vCPUs, for example 1 vCPU or 1 vcpu . String values are converted to an integer indicating the CPU units when the task definition is registered.\n\nIf you are using the EC2 launch type, this field is optional. Supported values are between 128 CPU units (0.125 vCPUs) and 10240 CPU units (10 vCPUs).\n\nIf you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the memory parameter:\n\n256 (.25 vCPU) - Available memory values: 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)\n\n512 (.5 vCPU) - Available memory values: 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)\n\n1024 (1 vCPU) - Available memory values: 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)\n\n2048 (2 vCPU) - Available memory values: Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)\n\n4096 (4 vCPU) - Available memory values: Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task was created (the task entered the PENDING state).\n\ndesiredStatus -> (string)\n\nThe desired status of the task. For more information, see Task Lifecycle .\n\nenableExecuteCommand -> (boolean)\n\nWhether or not execute command functionality is enabled for this task. If true , this enables execute command functionality on all containers in the task.\n\nexecutionStoppedAt -> (timestamp)\n\nThe Unix timestamp for when the task execution stopped.\n\ngroup -> (string)\n\nThe name of the task group associated with the task.\n\nhealthStatus -> (string)\n\nThe health status for the task, which is determined by the health of the essential containers in the task. If all essential containers in the task are reporting as HEALTHY , then the task status also reports as HEALTHY . If any essential containers in the task are reporting as UNHEALTHY or UNKNOWN , then the task status also reports as UNHEALTHY or UNKNOWN , accordingly.\n\nNote\n\nThe Amazon ECS container agent does not monitor or report on Docker health checks that are embedded in a container image (such as those specified in a parent image or from the image’s Dockerfile) and not specified in the container definition. Health check parameters that are specified in a container definition override any Docker health checks that exist in the container image.\n\ninferenceAccelerators -> (list)\n\nThe Elastic Inference accelerator associated with the task.\n\n(structure)\n\nDetails on a Elastic Inference accelerator. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name. The deviceName must also be referenced in a container definition as a ResourceRequirement .\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nlastStatus -> (string)\n\nThe last known status of the task. For more information, see Task Lifecycle .\n\nlaunchType -> (string)\n\nThe infrastructure on which your task is running. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\nmemory -> (string)\n\nThe amount of memory (in MiB) used by the task as expressed in a task definition. It can be expressed as an integer using MiB, for example 1024 . It can also be expressed as a string using GB, for example 1GB or 1 GB . String values are converted to an integer indicating the MiB when the task definition is registered.\n\nIf you are using the EC2 launch type, this field is optional.\n\nIf you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the cpu parameter:\n\n512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)\n\n1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)\n\n2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)\n\nBetween 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)\n\nBetween 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)\n\noverrides -> (structure)\n\nOne or more container overrides.\n\ncontainerOverrides -> (list)\n\nOne or more container overrides sent to a task.\n\n(structure)\n\nThe overrides that should be sent to a container. An empty container override can be passed in. An example of an empty container override would be {\"containerOverrides\": [ ] } . If a non-empty container override is specified, the name parameter must be included.\n\nname -> (string)\n\nThe name of the container that receives the override. This parameter is required if any override is specified.\n\ncommand -> (list)\n\nThe command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.\n\n(string)\n\nenvironment -> (list)\n\nThe environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nenvironmentFiles -> (list)\n\nA list of files containing the environment variables to pass to a container, instead of the value from the container definition.\n\n(structure)\n\nA list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying environment variables in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nvalue -> (string)\n\nThe Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\ntype -> (string)\n\nThe file type to use. The only supported value is s3 .\n\ncpu -> (integer)\n\nThe number of cpu units reserved for the container, instead of the default value from the task definition. You must also specify a container name.\n\nmemory -> (integer)\n\nThe hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.\n\nmemoryReservation -> (integer)\n\nThe soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.\n\nresourceRequirements -> (list)\n\nThe type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.\n\n(structure)\n\nThe type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see Working with GPUs on Amazon ECS or Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide\n\nvalue -> (string)\n\nThe value for the specified resource type.\n\nIf the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent will reserve for the container. The number of GPUs reserved for all containers in a task should not exceed the number of available GPUs on the container instance the task is launched on.\n\nIf the InferenceAccelerator type is used, the value should match the deviceName for an InferenceAccelerator specified in a task definition.\n\ntype -> (string)\n\nThe type of resource to assign to a container. The supported values are GPU or InferenceAccelerator .\n\ncpu -> (string)\n\nThe cpu override for the task.\n\ninferenceAcceleratorOverrides -> (list)\n\nThe Elastic Inference accelerator override for the task.\n\n(structure)\n\nDetails on an Elastic Inference accelerator task override. This parameter is used to override the Elastic Inference accelerator specified in the task definition. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name to override for the task. This parameter must match a deviceName specified in the task definition.\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nexecutionRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see Amazon ECS task execution IAM role in the Amazon Elastic Container Service Developer Guide .\n\nmemory -> (string)\n\nThe memory override for the task.\n\ntaskRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see IAM Role for Tasks in the Amazon Elastic Container Service Developer Guide .\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage setting override for the task.\n\nNote\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\nplatformVersion -> (string)\n\nThe platform version on which your task is running. A platform version is only specified for tasks using the Fargate launch type. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX. .\n\npullStartedAt -> (timestamp)\n\nThe Unix timestamp for when the container image pull began.\n\npullStoppedAt -> (timestamp)\n\nThe Unix timestamp for when the container image pull completed.\n\nstartedAt -> (timestamp)\n\nThe Unix timestamp for when the task started (the task transitioned from the PENDING state to the RUNNING state).\n\nstartedBy -> (string)\n\nThe tag specified when a task is started. If the task is started by an Amazon ECS service, then the startedBy parameter contains the deployment ID of the service that starts it.\n\nstopCode -> (string)\n\nThe stop code indicating why a task was stopped. The stoppedReason may contain additional details.\n\nstoppedAt -> (timestamp)\n\nThe Unix timestamp for when the task was stopped (the task transitioned from the RUNNING state to the STOPPED state).\n\nstoppedReason -> (string)\n\nThe reason that the task was stopped.\n\nstoppingAt -> (timestamp)\n\nThe Unix timestamp for when the task stops (transitions from the RUNNING state to STOPPED ).\n\ntags -> (list)\n\nThe metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ntaskArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task.\n\ntaskDefinitionArn -> (string)\n\nThe ARN of the task definition that creates the task.\n\nversion -> (long)\n\nThe version counter for the task. Every time a task experiences a change that triggers a CloudWatch event, the version counter is incremented. If you are replicating your Amazon ECS task state with CloudWatch Events, you can compare the version of a task reported by the Amazon ECS API actions with the version reported in CloudWatch Events for the task (inside the detail object) to verify that the version in your event stream is current.\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage settings for the task.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\nfailures -> (list)\n\nAny failures associated with the call.\n\n(structure)\n\nA failed resource. For a list of common causes, see API failure reasons in the Amazon Elastic Container Service Developer Guide .\n\narn -> (string)\n\nThe Amazon Resource Name (ARN) of the failed resource.\n\nreason -> (string)\n\nThe reason for the failure.\n\ndetail -> (string)\n\nThe details of the failure.",
      "command_examples": "Examples\n\nTo start a new task\n\nThe following start-task starts a task using the latest revision of the sleep360 task definition on the specified container instance in the default cluster.\n\naws ecs start-task \\\n    --task-definition sleep360 \\\n    --container-instances 765936fadbdd46b5991a4bd70c2a43d4\n\n\nOutput:\n\n{\n    \"tasks\": [\n        {\n            \"taskArn\": \"arn:aws:ecs:us-west-2:130757420319:task/default/666fdccc2e2d4b6894dd422f4eeee8f8\",\n            \"clusterArn\": \"arn:aws:ecs:us-west-2:130757420319:cluster/default\",\n            \"taskDefinitionArn\": \"arn:aws:ecs:us-west-2:130757420319:task-definition/sleep360:3\",\n            \"containerInstanceArn\": \"arn:aws:ecs:us-west-2:130757420319:container-instance/default/765936fadbdd46b5991a4bd70c2a43d4\",\n            \"overrides\": {\n                \"containerOverrides\": [\n                    {\n                        \"name\": \"sleep\"\n                    }\n                ]\n            },\n            \"lastStatus\": \"PENDING\",\n            \"desiredStatus\": \"RUNNING\",\n            \"cpu\": \"128\",\n            \"memory\": \"128\",\n            \"containers\": [\n                {\n                    \"containerArn\": \"arn:aws:ecs:us-west-2:130757420319:container/75f11ed4-8a3d-4f26-a33b-ad1db9e02d41\",\n                    \"taskArn\": \"arn:aws:ecs:us-west-2:130757420319:task/default/666fdccc2e2d4b6894dd422f4eeee8f8\",\n                    \"name\": \"sleep\",\n                    \"lastStatus\": \"PENDING\",\n                    \"networkInterfaces\": [],\n                    \"cpu\": \"10\",\n                    \"memory\": \"10\"\n                }\n            ],\n            \"version\": 1,\n            \"createdAt\": 1563421494.186,\n            \"group\": \"family:sleep360\",\n            \"launchType\": \"EC2\",\n            \"attachments\": [],\n            \"tags\": []\n        }\n    ],\n    \"failures\": []\n}\n"
    },
    {
      "command_name": "stop-task",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/stop-task.html",
      "command_description": "Description\n\nStops a running task. Any tags associated with the task will be deleted.\n\nWhen StopTask is called on a task, the equivalent of docker stop is issued to the containers running in the task. This results in a SIGTERM value and a default 30-second timeout, after which the SIGKILL value is sent and the containers are forcibly stopped. If the container handles the SIGTERM value gracefully and exits within 30 seconds from receiving it, no SIGKILL value is sent.\n\nNote\n\nThe default 30-second timeout can be configured on the Amazon ECS container agent with the ECS_CONTAINER_STOP_TIMEOUT variable. For more information, see Amazon ECS Container Agent Configuration in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  stop-task\n[--cluster <value>]\n--task <value>\n[--reason <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--task <value>",
        "[--reason <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the task to stop. If you do not specify a cluster, the default cluster is assumed.\n\n--task (string)\n\nThe task ID or full Amazon Resource Name (ARN) of the task to stop.\n\n--reason (string)\n\nAn optional message specified when a task is stopped. For example, if you are using a custom scheduler, you can use this parameter to specify the reason for stopping the task here, and the message appears in subsequent DescribeTasks API operations on this task. Up to 255 characters are allowed in this message.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntask -> (structure)\n\nThe task that was stopped.\n\nattachments -> (list)\n\nThe Elastic Network Adapter associated with the task if the task uses the awsvpc network mode.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nattributes -> (list)\n\nThe attributes of the task\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\navailabilityZone -> (string)\n\nThe availability zone of the task.\n\ncapacityProviderName -> (string)\n\nThe capacity provider associated with the task.\n\nclusterArn -> (string)\n\nThe ARN of the cluster that hosts the task.\n\nconnectivity -> (string)\n\nThe connectivity status of a task.\n\nconnectivityAt -> (timestamp)\n\nThe Unix timestamp for when the task last went into CONNECTED status.\n\ncontainerInstanceArn -> (string)\n\nThe ARN of the container instances that host the task.\n\ncontainers -> (list)\n\nThe containers associated with the task.\n\n(structure)\n\nA Docker container that is part of a task.\n\ncontainerArn -> (string)\n\nThe Amazon Resource Name (ARN) of the container.\n\ntaskArn -> (string)\n\nThe ARN of the task.\n\nname -> (string)\n\nThe name of the container.\n\nimage -> (string)\n\nThe image used for the container.\n\nimageDigest -> (string)\n\nThe container image manifest digest.\n\nNote\n\nThe imageDigest is only returned if the container is using an image hosted in Amazon ECR, otherwise it is omitted.\n\nruntimeId -> (string)\n\nThe ID of the Docker container.\n\nlastStatus -> (string)\n\nThe last known status of the container.\n\nexitCode -> (integer)\n\nThe exit code returned from the container.\n\nreason -> (string)\n\nA short (255 max characters) human-readable string to provide additional details about a running or stopped container.\n\nnetworkBindings -> (list)\n\nThe network bindings associated with the container.\n\n(structure)\n\nDetails on the network bindings between a container and its host container instance. After a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the networkBindings section of DescribeTasks API responses.\n\nbindIP -> (string)\n\nThe IP address that the container is bound to on the container instance.\n\ncontainerPort -> (integer)\n\nThe port number on the container that is used with the network binding.\n\nhostPort -> (integer)\n\nThe port number on the host that is used with the network binding.\n\nprotocol -> (string)\n\nThe protocol used for the network binding.\n\nnetworkInterfaces -> (list)\n\nThe network interfaces associated with the container.\n\n(structure)\n\nAn object representing the elastic network interface for tasks that use the awsvpc network mode.\n\nattachmentId -> (string)\n\nThe attachment ID for the network interface.\n\nprivateIpv4Address -> (string)\n\nThe private IPv4 address for the network interface.\n\nipv6Address -> (string)\n\nThe private IPv6 address for the network interface.\n\nhealthStatus -> (string)\n\nThe health status of the container. If health checks are not configured for this container in its task definition, then it reports the health status as UNKNOWN .\n\nmanagedAgents -> (list)\n\nThe details of any Amazon ECS managed agents associated with the container.\n\n(structure)\n\nDetails about the managed agent status for the container.\n\nlastStartedAt -> (timestamp)\n\nThe Unix timestamp for when the managed agent was last started.\n\nname -> (string)\n\nThe name of the managed agent. When the execute command feature is enabled, the managed agent name is ExecuteCommandAgent .\n\nreason -> (string)\n\nThe reason for why the managed agent is in the state it is in.\n\nlastStatus -> (string)\n\nThe last known status of the managed agent.\n\ncpu -> (string)\n\nThe number of CPU units set for the container. The value will be 0 if no value was specified in the container definition when the task definition was registered.\n\nmemory -> (string)\n\nThe hard limit (in MiB) of memory set for the container.\n\nmemoryReservation -> (string)\n\nThe soft limit (in MiB) of memory set for the container.\n\ngpuIds -> (list)\n\nThe IDs of each GPU assigned to the container.\n\n(string)\n\ncpu -> (string)\n\nThe number of CPU units used by the task as expressed in a task definition. It can be expressed as an integer using CPU units, for example 1024 . It can also be expressed as a string using vCPUs, for example 1 vCPU or 1 vcpu . String values are converted to an integer indicating the CPU units when the task definition is registered.\n\nIf you are using the EC2 launch type, this field is optional. Supported values are between 128 CPU units (0.125 vCPUs) and 10240 CPU units (10 vCPUs).\n\nIf you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the memory parameter:\n\n256 (.25 vCPU) - Available memory values: 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)\n\n512 (.5 vCPU) - Available memory values: 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)\n\n1024 (1 vCPU) - Available memory values: 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)\n\n2048 (2 vCPU) - Available memory values: Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)\n\n4096 (4 vCPU) - Available memory values: Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task was created (the task entered the PENDING state).\n\ndesiredStatus -> (string)\n\nThe desired status of the task. For more information, see Task Lifecycle .\n\nenableExecuteCommand -> (boolean)\n\nWhether or not execute command functionality is enabled for this task. If true , this enables execute command functionality on all containers in the task.\n\nexecutionStoppedAt -> (timestamp)\n\nThe Unix timestamp for when the task execution stopped.\n\ngroup -> (string)\n\nThe name of the task group associated with the task.\n\nhealthStatus -> (string)\n\nThe health status for the task, which is determined by the health of the essential containers in the task. If all essential containers in the task are reporting as HEALTHY , then the task status also reports as HEALTHY . If any essential containers in the task are reporting as UNHEALTHY or UNKNOWN , then the task status also reports as UNHEALTHY or UNKNOWN , accordingly.\n\nNote\n\nThe Amazon ECS container agent does not monitor or report on Docker health checks that are embedded in a container image (such as those specified in a parent image or from the image’s Dockerfile) and not specified in the container definition. Health check parameters that are specified in a container definition override any Docker health checks that exist in the container image.\n\ninferenceAccelerators -> (list)\n\nThe Elastic Inference accelerator associated with the task.\n\n(structure)\n\nDetails on a Elastic Inference accelerator. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name. The deviceName must also be referenced in a container definition as a ResourceRequirement .\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nlastStatus -> (string)\n\nThe last known status of the task. For more information, see Task Lifecycle .\n\nlaunchType -> (string)\n\nThe infrastructure on which your task is running. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\nmemory -> (string)\n\nThe amount of memory (in MiB) used by the task as expressed in a task definition. It can be expressed as an integer using MiB, for example 1024 . It can also be expressed as a string using GB, for example 1GB or 1 GB . String values are converted to an integer indicating the MiB when the task definition is registered.\n\nIf you are using the EC2 launch type, this field is optional.\n\nIf you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the cpu parameter:\n\n512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)\n\n1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)\n\n2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)\n\nBetween 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)\n\nBetween 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)\n\noverrides -> (structure)\n\nOne or more container overrides.\n\ncontainerOverrides -> (list)\n\nOne or more container overrides sent to a task.\n\n(structure)\n\nThe overrides that should be sent to a container. An empty container override can be passed in. An example of an empty container override would be {\"containerOverrides\": [ ] } . If a non-empty container override is specified, the name parameter must be included.\n\nname -> (string)\n\nThe name of the container that receives the override. This parameter is required if any override is specified.\n\ncommand -> (list)\n\nThe command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.\n\n(string)\n\nenvironment -> (list)\n\nThe environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nenvironmentFiles -> (list)\n\nA list of files containing the environment variables to pass to a container, instead of the value from the container definition.\n\n(structure)\n\nA list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a .env file extension. Each line in an environment file should contain an environment variable in VARIABLE=VALUE format. Lines beginning with # are treated as comments and are ignored. For more information on the environment variable file syntax, see Declare default environment variables in file .\n\nIf there are environment variables specified using the environment parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they are processed from the top down. It is recommended to use unique variable names. For more information, see Specifying environment variables in the Amazon Elastic Container Service Developer Guide .\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nvalue -> (string)\n\nThe Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\ntype -> (string)\n\nThe file type to use. The only supported value is s3 .\n\ncpu -> (integer)\n\nThe number of cpu units reserved for the container, instead of the default value from the task definition. You must also specify a container name.\n\nmemory -> (integer)\n\nThe hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.\n\nmemoryReservation -> (integer)\n\nThe soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.\n\nresourceRequirements -> (list)\n\nThe type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.\n\n(structure)\n\nThe type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see Working with GPUs on Amazon ECS or Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide\n\nvalue -> (string)\n\nThe value for the specified resource type.\n\nIf the GPU type is used, the value is the number of physical GPUs the Amazon ECS container agent will reserve for the container. The number of GPUs reserved for all containers in a task should not exceed the number of available GPUs on the container instance the task is launched on.\n\nIf the InferenceAccelerator type is used, the value should match the deviceName for an InferenceAccelerator specified in a task definition.\n\ntype -> (string)\n\nThe type of resource to assign to a container. The supported values are GPU or InferenceAccelerator .\n\ncpu -> (string)\n\nThe cpu override for the task.\n\ninferenceAcceleratorOverrides -> (list)\n\nThe Elastic Inference accelerator override for the task.\n\n(structure)\n\nDetails on an Elastic Inference accelerator task override. This parameter is used to override the Elastic Inference accelerator specified in the task definition. For more information, see Working with Amazon Elastic Inference on Amazon ECS in the Amazon Elastic Container Service Developer Guide .\n\ndeviceName -> (string)\n\nThe Elastic Inference accelerator device name to override for the task. This parameter must match a deviceName specified in the task definition.\n\ndeviceType -> (string)\n\nThe Elastic Inference accelerator type to use.\n\nexecutionRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see Amazon ECS task execution IAM role in the Amazon Elastic Container Service Developer Guide .\n\nmemory -> (string)\n\nThe memory override for the task.\n\ntaskRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see IAM Role for Tasks in the Amazon Elastic Container Service Developer Guide .\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage setting override for the task.\n\nNote\n\nThis parameter is only supported for tasks hosted on Fargate using the following platform versions:\n\nLinux platform version 1.4.0 or later.\n\nWindows platform version 1.0.0 or later.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.\n\nplatformVersion -> (string)\n\nThe platform version on which your task is running. A platform version is only specified for tasks using the Fargate launch type. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX. .\n\npullStartedAt -> (timestamp)\n\nThe Unix timestamp for when the container image pull began.\n\npullStoppedAt -> (timestamp)\n\nThe Unix timestamp for when the container image pull completed.\n\nstartedAt -> (timestamp)\n\nThe Unix timestamp for when the task started (the task transitioned from the PENDING state to the RUNNING state).\n\nstartedBy -> (string)\n\nThe tag specified when a task is started. If the task is started by an Amazon ECS service, then the startedBy parameter contains the deployment ID of the service that starts it.\n\nstopCode -> (string)\n\nThe stop code indicating why a task was stopped. The stoppedReason may contain additional details.\n\nstoppedAt -> (timestamp)\n\nThe Unix timestamp for when the task was stopped (the task transitioned from the RUNNING state to the STOPPED state).\n\nstoppedReason -> (string)\n\nThe reason that the task was stopped.\n\nstoppingAt -> (timestamp)\n\nThe Unix timestamp for when the task stops (transitions from the RUNNING state to STOPPED ).\n\ntags -> (list)\n\nThe metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ntaskArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task.\n\ntaskDefinitionArn -> (string)\n\nThe ARN of the task definition that creates the task.\n\nversion -> (long)\n\nThe version counter for the task. Every time a task experiences a change that triggers a CloudWatch event, the version counter is incremented. If you are replicating your Amazon ECS task state with CloudWatch Events, you can compare the version of a task reported by the Amazon ECS API actions with the version reported in CloudWatch Events for the task (inside the detail object) to verify that the version in your event stream is current.\n\nephemeralStorage -> (structure)\n\nThe ephemeral storage settings for the task.\n\nsizeInGiB -> (integer)\n\nThe total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.",
      "command_examples": "Examples\n\nTo stop a task\n\nThe following stop-task stops the specified task from running in the default cluster.\n\naws ecs stop-task \\\n    --task 666fdccc2e2d4b6894dd422f4eeee8f8\n\n\nOutput:\n\n{\n    \"task\": {\n        \"taskArn\": \"arn:aws:ecs:us-west-2:130757420319:task/default/666fdccc2e2d4b6894dd422f4eeee8f8\",\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:130757420319:cluster/default\",\n        \"taskDefinitionArn\": \"arn:aws:ecs:us-west-2:130757420319:task-definition/sleep360:3\",\n        \"containerInstanceArn\": \"arn:aws:ecs:us-west-2:130757420319:container-instance/default/765936fadbdd46b5991a4bd70c2a43d4\",\n        \"overrides\": {\n            \"containerOverrides\": []\n        },\n        \"lastStatus\": \"STOPPED\",\n        \"desiredStatus\": \"STOPPED\",\n        \"cpu\": \"128\",\n        \"memory\": \"128\",\n        \"containers\": [],\n        \"version\": 2,\n        \"stoppedReason\": \"Taskfailedtostart\",\n        \"stopCode\": \"TaskFailedToStart\",\n        \"connectivity\": \"CONNECTED\",\n        \"connectivityAt\": 1563421494.186,\n        \"pullStartedAt\": 1563421494.252,\n        \"pullStoppedAt\": 1563421496.252,\n        \"executionStoppedAt\": 1563421497,\n        \"createdAt\": 1563421494.186,\n        \"stoppingAt\": 1563421497.252,\n        \"stoppedAt\": 1563421497.252,\n        \"group\": \"family:sleep360\",\n        \"launchType\": \"EC2\",\n        \"attachments\": [],\n        \"tags\": []\n    }\n}\n"
    },
    {
      "command_name": "submit-attachment-state-changes",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/submit-attachment-state-changes.html",
      "command_description": "Description\n\nNote\n\nThis action is only used by the Amazon ECS agent, and it is not intended for use outside of the agent.\n\nSent to acknowledge that an attachment changed states.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  submit-attachment-state-changes\n[--cluster <value>]\n--attachments <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--attachments <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full ARN of the cluster that hosts the container instance the attachment belongs to.\n\n--attachments (list)\n\nAny attachments associated with the state change request.\n\n(structure)\n\nAn object representing a change in state for a task attachment.\n\nattachmentArn -> (string)\n\nThe Amazon Resource Name (ARN) of the attachment.\n\nstatus -> (string)\n\nThe status of the attachment.\n\nShorthand Syntax:\n\nattachmentArn=string,status=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"attachmentArn\": \"string\",\n    \"status\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nacknowledgment -> (string)\n\nAcknowledgement of the state change."
    },
    {
      "command_name": "submit-container-state-change",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/submit-container-state-change.html",
      "command_description": "Description\n\nNote\n\nThis action is only used by the Amazon ECS agent, and it is not intended for use outside of the agent.\n\nSent to acknowledge that a container changed states.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  submit-container-state-change\n[--cluster <value>]\n[--task <value>]\n[--container-name <value>]\n[--runtime-id <value>]\n[--status <value>]\n[--exit-code <value>]\n[--reason <value>]\n[--network-bindings <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "[--task <value>]",
        "[--container-name <value>]",
        "[--runtime-id <value>]",
        "[--status <value>]",
        "[--exit-code <value>]",
        "[--reason <value>]",
        "[--network-bindings <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full ARN of the cluster that hosts the container.\n\n--task (string)\n\nThe task ID or full Amazon Resource Name (ARN) of the task that hosts the container.\n\n--container-name (string)\n\nThe name of the container.\n\n--runtime-id (string)\n\nThe ID of the Docker container.\n\n--status (string)\n\nThe status of the state change request.\n\n--exit-code (integer)\n\nThe exit code returned for the state change request.\n\n--reason (string)\n\nThe reason for the state change request.\n\n--network-bindings (list)\n\nThe network bindings of the container.\n\n(structure)\n\nDetails on the network bindings between a container and its host container instance. After a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the networkBindings section of DescribeTasks API responses.\n\nbindIP -> (string)\n\nThe IP address that the container is bound to on the container instance.\n\ncontainerPort -> (integer)\n\nThe port number on the container that is used with the network binding.\n\nhostPort -> (integer)\n\nThe port number on the host that is used with the network binding.\n\nprotocol -> (string)\n\nThe protocol used for the network binding.\n\nShorthand Syntax:\n\nbindIP=string,containerPort=integer,hostPort=integer,protocol=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"bindIP\": \"string\",\n    \"containerPort\": integer,\n    \"hostPort\": integer,\n    \"protocol\": \"tcp\"|\"udp\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nacknowledgment -> (string)\n\nAcknowledgement of the state change."
    },
    {
      "command_name": "submit-task-state-change",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/submit-task-state-change.html",
      "command_description": "Description\n\nNote\n\nThis action is only used by the Amazon ECS agent, and it is not intended for use outside of the agent.\n\nSent to acknowledge that a task changed states.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  submit-task-state-change\n[--cluster <value>]\n[--task <value>]\n[--status <value>]\n[--reason <value>]\n[--containers <value>]\n[--attachments <value>]\n[--managed-agents <value>]\n[--pull-started-at <value>]\n[--pull-stopped-at <value>]\n[--execution-stopped-at <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "[--task <value>]",
        "[--status <value>]",
        "[--reason <value>]",
        "[--containers <value>]",
        "[--attachments <value>]",
        "[--managed-agents <value>]",
        "[--pull-started-at <value>]",
        "[--pull-stopped-at <value>]",
        "[--execution-stopped-at <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the task.\n\n--task (string)\n\nThe task ID or full ARN of the task in the state change request.\n\n--status (string)\n\nThe status of the state change request.\n\n--reason (string)\n\nThe reason for the state change request.\n\n--containers (list)\n\nAny containers associated with the state change request.\n\n(structure)\n\nAn object representing a change in state for a container.\n\ncontainerName -> (string)\n\nThe name of the container.\n\nimageDigest -> (string)\n\nThe container image SHA 256 digest.\n\nruntimeId -> (string)\n\nThe ID of the Docker container.\n\nexitCode -> (integer)\n\nThe exit code for the container, if the state change is a result of the container exiting.\n\nnetworkBindings -> (list)\n\nAny network bindings associated with the container.\n\n(structure)\n\nDetails on the network bindings between a container and its host container instance. After a task reaches the RUNNING status, manual and automatic host and container port assignments are visible in the networkBindings section of DescribeTasks API responses.\n\nbindIP -> (string)\n\nThe IP address that the container is bound to on the container instance.\n\ncontainerPort -> (integer)\n\nThe port number on the container that is used with the network binding.\n\nhostPort -> (integer)\n\nThe port number on the host that is used with the network binding.\n\nprotocol -> (string)\n\nThe protocol used for the network binding.\n\nreason -> (string)\n\nThe reason for the state change.\n\nstatus -> (string)\n\nThe status of the container.\n\nShorthand Syntax:\n\ncontainerName=string,imageDigest=string,runtimeId=string,exitCode=integer,networkBindings=[{bindIP=string,containerPort=integer,hostPort=integer,protocol=string},{bindIP=string,containerPort=integer,hostPort=integer,protocol=string}],reason=string,status=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"containerName\": \"string\",\n    \"imageDigest\": \"string\",\n    \"runtimeId\": \"string\",\n    \"exitCode\": integer,\n    \"networkBindings\": [\n      {\n        \"bindIP\": \"string\",\n        \"containerPort\": integer,\n        \"hostPort\": integer,\n        \"protocol\": \"tcp\"|\"udp\"\n      }\n      ...\n    ],\n    \"reason\": \"string\",\n    \"status\": \"string\"\n  }\n  ...\n]\n\n\n--attachments (list)\n\nAny attachments associated with the state change request.\n\n(structure)\n\nAn object representing a change in state for a task attachment.\n\nattachmentArn -> (string)\n\nThe Amazon Resource Name (ARN) of the attachment.\n\nstatus -> (string)\n\nThe status of the attachment.\n\nShorthand Syntax:\n\nattachmentArn=string,status=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"attachmentArn\": \"string\",\n    \"status\": \"string\"\n  }\n  ...\n]\n\n\n--managed-agents (list)\n\nThe details for the managed agent associated with the task.\n\n(structure)\n\nAn object representing a change in state for a managed agent.\n\ncontainerName -> (string)\n\nThe name of the container associated with the managed agent.\n\nmanagedAgentName -> (string)\n\nThe name of the managed agent.\n\nstatus -> (string)\n\nThe status of the managed agent.\n\nreason -> (string)\n\nThe reason for the status of the managed agent.\n\nShorthand Syntax:\n\ncontainerName=string,managedAgentName=string,status=string,reason=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"containerName\": \"string\",\n    \"managedAgentName\": \"ExecuteCommandAgent\",\n    \"status\": \"string\",\n    \"reason\": \"string\"\n  }\n  ...\n]\n\n\n--pull-started-at (timestamp)\n\nThe Unix timestamp for when the container image pull began.\n\n--pull-stopped-at (timestamp)\n\nThe Unix timestamp for when the container image pull completed.\n\n--execution-stopped-at (timestamp)\n\nThe Unix timestamp for when the task execution stopped.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nacknowledgment -> (string)\n\nAcknowledgement of the state change."
    },
    {
      "command_name": "tag-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/tag-resource.html",
      "command_description": "Description\n\nAssociates the specified tags to a resource with the specified resourceArn . If existing tags on a resource are not specified in the request parameters, they are not changed. When a resource is deleted, the tags associated with that resource are deleted as well.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  tag-resource\n--resource-arn <value>\n--tags <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "--tags <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe Amazon Resource Name (ARN) of the resource to which to add tags. Currently, the supported resources are Amazon ECS capacity providers, tasks, services, task definitions, clusters, and container instances.\n\n--tags (list)\n\nThe tags to add to the resource. A tag is an array of key-value pairs.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo tag a resource\n\nThe following tag-resource example adds a single tag to the specified resource.\n\naws ecs tag-resource \\\n    --resource-arn arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\n    --tags key=key1,value=value1\n\n\nThis command produces no output.\n\nTo add multiple tags to a resource\n\nThe following tag-resource example adds multiple tags to the specified resource.\n\naws ecs tag-resource \\\n--resource-arn arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster \\\n--tags key=key1,value=value1 key=key2,value=value2 key=key3,value=value3\n\n\nThis command produces no output."
    },
    {
      "command_name": "untag-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/untag-resource.html",
      "command_description": "Description\n\nDeletes specified tags from a resource.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  untag-resource\n--resource-arn <value>\n--tag-keys <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "--tag-keys <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe Amazon Resource Name (ARN) of the resource from which to delete tags. Currently, the supported resources are Amazon ECS capacity providers, tasks, services, task definitions, clusters, and container instances.\n\n--tag-keys (list)\n\nThe keys of the tags to be removed.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo remove a tag from a resource\n\nThe following untag-resource example removes the listed tags from the specified resource.\n\naws ecs untag-resource \\\n    --resource-arn arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster \\\n    --tag-keys key1,key2\n\n\nThis command produces no output."
    },
    {
      "command_name": "update-capacity-provider",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update-capacity-provider.html",
      "command_description": "Description\n\nModifies the parameters for a capacity provider.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-capacity-provider\n--name <value>\n--auto-scaling-group-provider <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--name <value>",
        "--auto-scaling-group-provider <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--name (string)\n\nThe name of the capacity provider to update.\n\n--auto-scaling-group-provider (structure)\n\nAn object representing the parameters to update for the Auto Scaling group capacity provider.\n\nmanagedScaling -> (structure)\n\nThe managed scaling settings for the Auto Scaling group capacity provider.\n\nstatus -> (string)\n\nWhether or not to enable managed scaling for the capacity provider.\n\ntargetCapacity -> (integer)\n\nThe target capacity value for the capacity provider. The specified value must be greater than 0 and less than or equal to 100 . A value of 100 will result in the Amazon EC2 instances in your Auto Scaling group being completely utilized.\n\nminimumScalingStepSize -> (integer)\n\nThe minimum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 1 is used.\n\nmaximumScalingStepSize -> (integer)\n\nThe maximum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 10000 is used.\n\ninstanceWarmupPeriod -> (integer)\n\nThe period of time, in seconds, after a newly launched Amazon EC2 instance can contribute to CloudWatch metrics for Auto Scaling group. If this parameter is omitted, the default value of 300 seconds is used.\n\nmanagedTerminationProtection -> (string)\n\nThe managed termination protection setting to use for the Auto Scaling group capacity provider. This determines whether the Auto Scaling group has managed termination protection.\n\nWarning\n\nWhen using managed termination protection, managed scaling must also be used otherwise managed termination protection will not work.\n\nWhen managed termination protection is enabled, Amazon ECS prevents the Amazon EC2 instances in an Auto Scaling group that contain tasks from being terminated during a scale-in action. The Auto Scaling group and each instance in the Auto Scaling group must have instance protection from scale-in actions enabled as well. For more information, see Instance Protection in the Auto Scaling User Guide .\n\nWhen managed termination protection is disabled, your Amazon EC2 instances are not protected from termination when the Auto Scaling group scales in.\n\nShorthand Syntax:\n\nmanagedScaling={status=string,targetCapacity=integer,minimumScalingStepSize=integer,maximumScalingStepSize=integer,instanceWarmupPeriod=integer},managedTerminationProtection=string\n\n\nJSON Syntax:\n\n{\n  \"managedScaling\": {\n    \"status\": \"ENABLED\"|\"DISABLED\",\n    \"targetCapacity\": integer,\n    \"minimumScalingStepSize\": integer,\n    \"maximumScalingStepSize\": integer,\n    \"instanceWarmupPeriod\": integer\n  },\n  \"managedTerminationProtection\": \"ENABLED\"|\"DISABLED\"\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncapacityProvider -> (structure)\n\nDetails about the capacity provider.\n\ncapacityProviderArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the capacity provider.\n\nname -> (string)\n\nThe name of the capacity provider.\n\nstatus -> (string)\n\nThe current status of the capacity provider. Only capacity providers in an ACTIVE state can be used in a cluster. When a capacity provider is successfully deleted, it will have an INACTIVE status.\n\nautoScalingGroupProvider -> (structure)\n\nThe Auto Scaling group settings for the capacity provider.\n\nautoScalingGroupArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the Auto Scaling group.\n\nmanagedScaling -> (structure)\n\nThe managed scaling settings for the Auto Scaling group capacity provider.\n\nstatus -> (string)\n\nWhether or not to enable managed scaling for the capacity provider.\n\ntargetCapacity -> (integer)\n\nThe target capacity value for the capacity provider. The specified value must be greater than 0 and less than or equal to 100 . A value of 100 will result in the Amazon EC2 instances in your Auto Scaling group being completely utilized.\n\nminimumScalingStepSize -> (integer)\n\nThe minimum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 1 is used.\n\nmaximumScalingStepSize -> (integer)\n\nThe maximum number of container instances that Amazon ECS will scale in or scale out at one time. If this parameter is omitted, the default value of 10000 is used.\n\ninstanceWarmupPeriod -> (integer)\n\nThe period of time, in seconds, after a newly launched Amazon EC2 instance can contribute to CloudWatch metrics for Auto Scaling group. If this parameter is omitted, the default value of 300 seconds is used.\n\nmanagedTerminationProtection -> (string)\n\nThe managed termination protection setting to use for the Auto Scaling group capacity provider. This determines whether the Auto Scaling group has managed termination protection.\n\nWarning\n\nWhen using managed termination protection, managed scaling must also be used otherwise managed termination protection will not work.\n\nWhen managed termination protection is enabled, Amazon ECS prevents the Amazon EC2 instances in an Auto Scaling group that contain tasks from being terminated during a scale-in action. The Auto Scaling group and each instance in the Auto Scaling group must have instance protection from scale-in actions enabled as well. For more information, see Instance Protection in the Auto Scaling User Guide .\n\nWhen managed termination protection is disabled, your Amazon EC2 instances are not protected from termination when the Auto Scaling group scales in.\n\nupdateStatus -> (string)\n\nThe update status of the capacity provider. The following are the possible states that will be returned.\n\nDELETE_IN_PROGRESS\n\nThe capacity provider is in the process of being deleted.\n\nDELETE_COMPLETE\n\nThe capacity provider has been successfully deleted and will have an INACTIVE status.\n\nDELETE_FAILED\n\nThe capacity provider was unable to be deleted. The update status reason will provide further details about why the delete failed.\n\nupdateStatusReason -> (string)\n\nThe update status reason. This provides further details about the update status for the capacity provider.\n\ntags -> (list)\n\nThe metadata that you apply to the capacity provider to help you categorize and organize it. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key)."
    },
    {
      "command_name": "update-cluster",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update-cluster.html",
      "command_description": "Description\n\nUpdates the cluster.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-cluster\n--cluster <value>\n[--settings <value>]\n[--configuration <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--cluster <value>",
        "[--settings <value>]",
        "[--configuration <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe name of the cluster to modify the settings for.\n\n--settings (list)\n\nThe cluster settings for your cluster.\n\n(structure)\n\nThe settings to use when creating a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster.\n\nname -> (string)\n\nThe name of the cluster setting. The only supported value is containerInsights .\n\nvalue -> (string)\n\nThe value to set for the cluster setting. The supported values are enabled and disabled . If enabled is specified, CloudWatch Container Insights will be enabled for the cluster, otherwise it will be disabled unless the containerInsights account setting is enabled. If a cluster value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\nShorthand Syntax:\n\nname=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"name\": \"containerInsights\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--configuration (structure)\n\nThe execute command configuration for the cluster.\n\nexecuteCommandConfiguration -> (structure)\n\nThe details of the execute command configuration.\n\nkmsKeyId -> (string)\n\nSpecify an Key Management Service key ID to encrypt the data between the local client and the container.\n\nlogging -> (string)\n\nThe log setting to use for redirecting logs for your execute command results. The following log settings are available.\n\nNONE : The execute command session is not logged.\n\nDEFAULT : The awslogs configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no awslogs log driver is configured in the task definition, the output won’t be logged.\n\nOVERRIDE : Specify the logging details as a part of logConfiguration . If the OVERRIDE logging option is specified, the logConfiguration is required.\n\nlogConfiguration -> (structure)\n\nThe log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When logging=OVERRIDE is specified, a logConfiguration must be provided.\n\ncloudWatchLogGroupName -> (string)\n\nThe name of the CloudWatch log group to send logs to.\n\nNote\n\nThe CloudWatch log group must already be created.\n\ncloudWatchEncryptionEnabled -> (boolean)\n\nWhether or not to enable encryption on the CloudWatch logs. If not specified, encryption will be disabled.\n\ns3BucketName -> (string)\n\nThe name of the S3 bucket to send logs to.\n\nNote\n\nThe S3 bucket must already be created.\n\ns3EncryptionEnabled -> (boolean)\n\nWhether or not to use encryption on the S3 logs. If not specified, encryption is not used.\n\ns3KeyPrefix -> (string)\n\nAn optional folder in the S3 bucket to place logs in.\n\nShorthand Syntax:\n\nexecuteCommandConfiguration={kmsKeyId=string,logging=string,logConfiguration={cloudWatchLogGroupName=string,cloudWatchEncryptionEnabled=boolean,s3BucketName=string,s3EncryptionEnabled=boolean,s3KeyPrefix=string}}\n\n\nJSON Syntax:\n\n{\n  \"executeCommandConfiguration\": {\n    \"kmsKeyId\": \"string\",\n    \"logging\": \"NONE\"|\"DEFAULT\"|\"OVERRIDE\",\n    \"logConfiguration\": {\n      \"cloudWatchLogGroupName\": \"string\",\n      \"cloudWatchEncryptionEnabled\": true|false,\n      \"s3BucketName\": \"string\",\n      \"s3EncryptionEnabled\": true|false,\n      \"s3KeyPrefix\": \"string\"\n    }\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncluster -> (structure)\n\nDetails about the cluster.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the cluster. The ARN contains the arn:aws:ecs namespace, followed by the Region of the cluster, the Amazon Web Services account ID of the cluster owner, the cluster namespace, and then the cluster name. For example, arn:aws:ecs:region:012345678910:cluster/test .\n\nclusterName -> (string)\n\nA user-generated string that you use to identify your cluster.\n\nconfiguration -> (structure)\n\nThe execute command configuration for the cluster.\n\nexecuteCommandConfiguration -> (structure)\n\nThe details of the execute command configuration.\n\nkmsKeyId -> (string)\n\nSpecify an Key Management Service key ID to encrypt the data between the local client and the container.\n\nlogging -> (string)\n\nThe log setting to use for redirecting logs for your execute command results. The following log settings are available.\n\nNONE : The execute command session is not logged.\n\nDEFAULT : The awslogs configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no awslogs log driver is configured in the task definition, the output won’t be logged.\n\nOVERRIDE : Specify the logging details as a part of logConfiguration . If the OVERRIDE logging option is specified, the logConfiguration is required.\n\nlogConfiguration -> (structure)\n\nThe log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When logging=OVERRIDE is specified, a logConfiguration must be provided.\n\ncloudWatchLogGroupName -> (string)\n\nThe name of the CloudWatch log group to send logs to.\n\nNote\n\nThe CloudWatch log group must already be created.\n\ncloudWatchEncryptionEnabled -> (boolean)\n\nWhether or not to enable encryption on the CloudWatch logs. If not specified, encryption will be disabled.\n\ns3BucketName -> (string)\n\nThe name of the S3 bucket to send logs to.\n\nNote\n\nThe S3 bucket must already be created.\n\ns3EncryptionEnabled -> (boolean)\n\nWhether or not to use encryption on the S3 logs. If not specified, encryption is not used.\n\ns3KeyPrefix -> (string)\n\nAn optional folder in the S3 bucket to place logs in.\n\nstatus -> (string)\n\nThe status of the cluster. The following are the possible states that will be returned.\n\nACTIVE\n\nThe cluster is ready to accept tasks and if applicable you can register container instances with the cluster.\n\nPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being created.\n\nDEPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being deleted.\n\nFAILED\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider have failed to create.\n\nINACTIVE\n\nThe cluster has been deleted. Clusters with an INACTIVE status may remain discoverable in your account for a period of time. However, this behavior is subject to change in the future, so you should not rely on INACTIVE clusters persisting.\n\nregisteredContainerInstancesCount -> (integer)\n\nThe number of container instances registered into the cluster. This includes container instances in both ACTIVE and DRAINING status.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the RUNNING state.\n\npendingTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the PENDING state.\n\nactiveServicesCount -> (integer)\n\nThe number of services that are running on the cluster in an ACTIVE state. You can view these services with ListServices .\n\nstatistics -> (list)\n\nAdditional information about your clusters that are separated by launch type, including:\n\nrunningEC2TasksCount\n\nRunningFargateTasksCount\n\npendingEC2TasksCount\n\npendingFargateTasksCount\n\nactiveEC2ServiceCount\n\nactiveFargateServiceCount\n\ndrainingEC2ServiceCount\n\ndrainingFargateServiceCount\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the cluster to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nsettings -> (list)\n\nThe settings for the cluster. This parameter indicates whether CloudWatch Container Insights is enabled or disabled for a cluster.\n\n(structure)\n\nThe settings to use when creating a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster.\n\nname -> (string)\n\nThe name of the cluster setting. The only supported value is containerInsights .\n\nvalue -> (string)\n\nThe value to set for the cluster setting. The supported values are enabled and disabled . If enabled is specified, CloudWatch Container Insights will be enabled for the cluster, otherwise it will be disabled unless the containerInsights account setting is enabled. If a cluster value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\ncapacityProviders -> (list)\n\nThe capacity providers associated with the cluster.\n\n(string)\n\ndefaultCapacityProviderStrategy -> (list)\n\nThe default capacity provider strategy for the cluster. When services or tasks are run in the cluster with no launch type or capacity provider strategy specified, the default capacity provider strategy is used.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nattachments -> (list)\n\nThe resources attached to a cluster. When using a capacity provider with a cluster, the Auto Scaling plan that is created will be returned as a cluster attachment.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nattachmentsStatus -> (string)\n\nThe status of the capacity providers associated with the cluster. The following are the states that will be returned:\n\nUPDATE_IN_PROGRESS\n\nThe available capacity providers for the cluster are updating. This occurs when the Auto Scaling plan is provisioning or deprovisioning.\n\nUPDATE_COMPLETE\n\nThe capacity providers have successfully updated.\n\nUPDATE_FAILED\n\nThe capacity provider updates failed."
    },
    {
      "command_name": "update-cluster-settings",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update-cluster-settings.html",
      "command_description": "Description\n\nModifies the settings to use for a cluster.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-cluster-settings\n--cluster <value>\n--settings <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--cluster <value>",
        "--settings <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe name of the cluster to modify the settings for.\n\n--settings (list)\n\nThe setting to use by default for a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster. If this value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\n(structure)\n\nThe settings to use when creating a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster.\n\nname -> (string)\n\nThe name of the cluster setting. The only supported value is containerInsights .\n\nvalue -> (string)\n\nThe value to set for the cluster setting. The supported values are enabled and disabled . If enabled is specified, CloudWatch Container Insights will be enabled for the cluster, otherwise it will be disabled unless the containerInsights account setting is enabled. If a cluster value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\nShorthand Syntax:\n\nname=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"name\": \"containerInsights\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncluster -> (structure)\n\nDetails about the cluster\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) that identifies the cluster. The ARN contains the arn:aws:ecs namespace, followed by the Region of the cluster, the Amazon Web Services account ID of the cluster owner, the cluster namespace, and then the cluster name. For example, arn:aws:ecs:region:012345678910:cluster/test .\n\nclusterName -> (string)\n\nA user-generated string that you use to identify your cluster.\n\nconfiguration -> (structure)\n\nThe execute command configuration for the cluster.\n\nexecuteCommandConfiguration -> (structure)\n\nThe details of the execute command configuration.\n\nkmsKeyId -> (string)\n\nSpecify an Key Management Service key ID to encrypt the data between the local client and the container.\n\nlogging -> (string)\n\nThe log setting to use for redirecting logs for your execute command results. The following log settings are available.\n\nNONE : The execute command session is not logged.\n\nDEFAULT : The awslogs configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no awslogs log driver is configured in the task definition, the output won’t be logged.\n\nOVERRIDE : Specify the logging details as a part of logConfiguration . If the OVERRIDE logging option is specified, the logConfiguration is required.\n\nlogConfiguration -> (structure)\n\nThe log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When logging=OVERRIDE is specified, a logConfiguration must be provided.\n\ncloudWatchLogGroupName -> (string)\n\nThe name of the CloudWatch log group to send logs to.\n\nNote\n\nThe CloudWatch log group must already be created.\n\ncloudWatchEncryptionEnabled -> (boolean)\n\nWhether or not to enable encryption on the CloudWatch logs. If not specified, encryption will be disabled.\n\ns3BucketName -> (string)\n\nThe name of the S3 bucket to send logs to.\n\nNote\n\nThe S3 bucket must already be created.\n\ns3EncryptionEnabled -> (boolean)\n\nWhether or not to use encryption on the S3 logs. If not specified, encryption is not used.\n\ns3KeyPrefix -> (string)\n\nAn optional folder in the S3 bucket to place logs in.\n\nstatus -> (string)\n\nThe status of the cluster. The following are the possible states that will be returned.\n\nACTIVE\n\nThe cluster is ready to accept tasks and if applicable you can register container instances with the cluster.\n\nPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being created.\n\nDEPROVISIONING\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider are being deleted.\n\nFAILED\n\nThe cluster has capacity providers associated with it and the resources needed for the capacity provider have failed to create.\n\nINACTIVE\n\nThe cluster has been deleted. Clusters with an INACTIVE status may remain discoverable in your account for a period of time. However, this behavior is subject to change in the future, so you should not rely on INACTIVE clusters persisting.\n\nregisteredContainerInstancesCount -> (integer)\n\nThe number of container instances registered into the cluster. This includes container instances in both ACTIVE and DRAINING status.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the RUNNING state.\n\npendingTasksCount -> (integer)\n\nThe number of tasks in the cluster that are in the PENDING state.\n\nactiveServicesCount -> (integer)\n\nThe number of services that are running on the cluster in an ACTIVE state. You can view these services with ListServices .\n\nstatistics -> (list)\n\nAdditional information about your clusters that are separated by launch type, including:\n\nrunningEC2TasksCount\n\nRunningFargateTasksCount\n\npendingEC2TasksCount\n\npendingFargateTasksCount\n\nactiveEC2ServiceCount\n\nactiveFargateServiceCount\n\ndrainingEC2ServiceCount\n\ndrainingFargateServiceCount\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the cluster to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nsettings -> (list)\n\nThe settings for the cluster. This parameter indicates whether CloudWatch Container Insights is enabled or disabled for a cluster.\n\n(structure)\n\nThe settings to use when creating a cluster. This parameter is used to enable CloudWatch Container Insights for a cluster.\n\nname -> (string)\n\nThe name of the cluster setting. The only supported value is containerInsights .\n\nvalue -> (string)\n\nThe value to set for the cluster setting. The supported values are enabled and disabled . If enabled is specified, CloudWatch Container Insights will be enabled for the cluster, otherwise it will be disabled unless the containerInsights account setting is enabled. If a cluster value is specified, it will override the containerInsights value set with PutAccountSetting or PutAccountSettingDefault .\n\ncapacityProviders -> (list)\n\nThe capacity providers associated with the cluster.\n\n(string)\n\ndefaultCapacityProviderStrategy -> (list)\n\nThe default capacity provider strategy for the cluster. When services or tasks are run in the cluster with no launch type or capacity provider strategy specified, the default capacity provider strategy is used.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nattachments -> (list)\n\nThe resources attached to a cluster. When using a capacity provider with a cluster, the Auto Scaling plan that is created will be returned as a cluster attachment.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\nattachmentsStatus -> (string)\n\nThe status of the capacity providers associated with the cluster. The following are the states that will be returned:\n\nUPDATE_IN_PROGRESS\n\nThe available capacity providers for the cluster are updating. This occurs when the Auto Scaling plan is provisioning or deprovisioning.\n\nUPDATE_COMPLETE\n\nThe capacity providers have successfully updated.\n\nUPDATE_FAILED\n\nThe capacity provider updates failed.",
      "command_examples": "Examples\n\nTo modify the settings for your cluster\n\nThe following update-cluster-settings example enables CloudWatch Container Insights for the default cluster.\n\naws ecs update-cluster-settings \\\n    --cluster default \\\n    --settings name=containerInsights,value=enabled\n\n\nOutput:\n\n{\n    \"cluster\": {\n        \"clusterArn\": \"arn:aws:ecs:us-west-2:123456789012:cluster/MyCluster\",\n        \"clusterName\": \"default\",\n        \"status\": \"ACTIVE\",\n        \"registeredContainerInstancesCount\": 0,\n        \"runningTasksCount\": 0,\n        \"pendingTasksCount\": 0,\n        \"activeServicesCount\": 0,\n        \"statistics\": [],\n        \"tags\": [],\n        \"settings\": [\n            {\n                \"name\": \"containerInsights\",\n                \"value\": \"enabled\"\n            }\n        ]\n    }\n}\n\n\nFor more information, see Modifying Account Settings in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "update-container-agent",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update-container-agent.html",
      "command_description": "Description\n\nUpdates the Amazon ECS container agent on a specified container instance. Updating the Amazon ECS container agent does not interrupt running tasks or services on the container instance. The process for updating the agent differs depending on whether your container instance was launched with the Amazon ECS-optimized AMI or another operating system.\n\nNote\n\nThe UpdateContainerAgent API isn’t supported for container instances using the Amazon ECS-optimized Amazon Linux 2 (arm64) AMI. To update the container agent, you can update the ecs-init package which will update the agent. For more information, see Updating the Amazon ECS container agent in the Amazon Elastic Container Service Developer Guide .\n\nThe UpdateContainerAgent API requires an Amazon ECS-optimized AMI or Amazon Linux AMI with the ecs-init service installed and running. For help updating the Amazon ECS container agent on other operating systems, see Manually updating the Amazon ECS container agent in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-container-agent\n[--cluster <value>]\n--container-instance <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--container-instance <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that your container instance is running on. If you do not specify a cluster, the default cluster is assumed.\n\n--container-instance (string)\n\nThe container instance ID or full ARN entries for the container instance on which you would like to update the Amazon ECS container agent.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncontainerInstance -> (structure)\n\nThe container instance for which the container agent was updated.\n\ncontainerInstanceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the container instance. The ARN contains the arn:aws:ecs namespace, followed by the Region of the container instance, the Amazon Web Services account ID of the container instance owner, the container-instance namespace, and then the container instance ID. For example, arn:aws:ecs:region:aws_account_id:container-instance/container_instance_ID .\n\nec2InstanceId -> (string)\n\nThe ID of the container instance. For Amazon EC2 instances, this value is the Amazon EC2 instance ID. For external instances, this value is the Amazon Web Services Systems Manager managed instance ID.\n\ncapacityProviderName -> (string)\n\nThe capacity provider associated with the container instance.\n\nversion -> (long)\n\nThe version counter for the container instance. Every time a container instance experiences a change that triggers a CloudWatch event, the version counter is incremented. If you are replicating your Amazon ECS container instance state with CloudWatch Events, you can compare the version of a container instance reported by the Amazon ECS APIs with the version reported in CloudWatch Events for the container instance (inside the detail object) to verify that the version in your event stream is current.\n\nversionInfo -> (structure)\n\nThe version information for the Amazon ECS container agent and Docker daemon running on the container instance.\n\nagentVersion -> (string)\n\nThe version number of the Amazon ECS container agent.\n\nagentHash -> (string)\n\nThe Git commit hash for the Amazon ECS container agent build on the amazon-ecs-agent GitHub repository.\n\ndockerVersion -> (string)\n\nThe Docker version running on the container instance.\n\nremainingResources -> (list)\n\nFor CPU and memory resource types, this parameter describes the remaining CPU and memory that has not already been allocated to tasks and is therefore available for new tasks. For port resource types, this parameter describes the ports that were reserved by the Amazon ECS container agent (at instance registration time) and any task containers that have reserved port mappings on the host (with the host or bridge network mode). Any port that is not specified here is available for new tasks.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nregisteredResources -> (list)\n\nFor CPU and memory resource types, this parameter describes the amount of each resource that was available on the container instance when the container agent registered it with Amazon ECS. This value represents the total amount of CPU and memory that can be allocated on this container instance to tasks. For port resource types, this parameter describes the ports that were reserved by the Amazon ECS container agent when it registered the container instance with Amazon ECS.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nstatus -> (string)\n\nThe status of the container instance. The valid values are REGISTERING , REGISTRATION_FAILED , ACTIVE , INACTIVE , DEREGISTERING , or DRAINING .\n\nIf your account has opted in to the awsvpcTrunking account setting, then any newly registered container instance will transition to a REGISTERING status while the trunk elastic network interface is provisioned for the instance. If the registration fails, the instance will transition to a REGISTRATION_FAILED status. You can describe the container instance and see the reason for failure in the statusReason parameter. Once the container instance is terminated, the instance transitions to a DEREGISTERING status while the trunk elastic network interface is deprovisioned. The instance then transitions to an INACTIVE status.\n\nThe ACTIVE status indicates that the container instance can accept tasks. The DRAINING indicates that new tasks are not placed on the container instance and any service tasks running on the container instance are removed if possible. For more information, see Container Instance Draining in the Amazon Elastic Container Service Developer Guide .\n\nstatusReason -> (string)\n\nThe reason that the container instance reached its current status.\n\nagentConnected -> (boolean)\n\nThis parameter returns true if the agent is connected to Amazon ECS. Registered instances with an agent that may be unhealthy or stopped return false . Only instances connected to an agent can accept placement requests.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks on the container instance that are in the RUNNING status.\n\npendingTasksCount -> (integer)\n\nThe number of tasks on the container instance that are in the PENDING status.\n\nagentUpdateStatus -> (string)\n\nThe status of the most recent agent update. If an update has never been requested, this value is NULL .\n\nattributes -> (list)\n\nThe attributes set for the container instance, either by the Amazon ECS container agent at instance registration or manually with the PutAttributes operation.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nregisteredAt -> (timestamp)\n\nThe Unix timestamp for when the container instance was registered.\n\nattachments -> (list)\n\nThe resources attached to a container instance, such as elastic network interfaces.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the container instance to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nTo update the container agent on an Amazon ECS container instance\n\nThe following update-container-agent example updates the container agent on the specified container instance in the default cluster.\n\naws ecs update-container-agent --cluster default --container-instance a1b2c3d4-5678-90ab-cdef-11111EXAMPLE\n\n\nOutput:\n\n{\n    \"containerInstance\": {\n        \"status\": \"ACTIVE\",\n...\n        \"agentUpdateStatus\": \"PENDING\",\n        \"versionInfo\": {\n            \"agentVersion\": \"1.0.0\",\n            \"agentHash\": \"4023248\",\n            \"dockerVersion\": \"DockerVersion: 1.5.0\"\n        }\n    }\n}\n\n\nFor more information, see Updating the Amazon ECS Container Agent in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "update-container-instances-state",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update-container-instances-state.html",
      "command_description": "Description\n\nModifies the status of an Amazon ECS container instance.\n\nOnce a container instance has reached an ACTIVE state, you can change the status of a container instance to DRAINING to manually remove an instance from a cluster, for example to perform system updates, update the Docker daemon, or scale down the cluster size.\n\nWarning\n\nA container instance cannot be changed to DRAINING until it has reached an ACTIVE status. If the instance is in any other status, an error will be received.\n\nWhen you set a container instance to DRAINING , Amazon ECS prevents new tasks from being scheduled for placement on the container instance and replacement service tasks are started on other container instances in the cluster if the resources are available. Service tasks on the container instance that are in the PENDING state are stopped immediately.\n\nService tasks on the container instance that are in the RUNNING state are stopped and replaced according to the service’s deployment configuration parameters, minimumHealthyPercent and maximumPercent . You can change the deployment configuration of your service using UpdateService .\n\nIf minimumHealthyPercent is below 100%, the scheduler can ignore desiredCount temporarily during task replacement. For example, desiredCount is four tasks, a minimum of 50% allows the scheduler to stop two existing tasks before starting two new tasks. If the minimum is 100%, the service scheduler can’t remove existing tasks until the replacement tasks are considered healthy. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state. Tasks for services that use a load balancer are considered healthy if they are in the RUNNING state and the container instance they are hosted on is reported as healthy by the load balancer.\n\nThe maximumPercent parameter represents an upper limit on the number of running tasks during task replacement, which enables you to define the replacement batch size. For example, if desiredCount is four tasks, a maximum of 200% starts four new tasks before stopping the four tasks to be drained, provided that the cluster resources required to do this are available. If the maximum is 100%, then replacement tasks can’t start until the draining tasks have stopped.\n\nAny PENDING or RUNNING tasks that do not belong to a service are not affected. You must wait for them to finish or stop them manually.\n\nA container instance has completed draining when it has no more RUNNING tasks. You can verify this using ListTasks .\n\nWhen a container instance has been drained, you can set a container instance to ACTIVE status and once it has reached that status the Amazon ECS scheduler can begin scheduling tasks on the instance again.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-container-instances-state\n[--cluster <value>]\n--container-instances <value>\n--status <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--container-instances <value>",
        "--status <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the container instance to update. If you do not specify a cluster, the default cluster is assumed.\n\n--container-instances (list)\n\nA list of container instance IDs or full ARN entries.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--status (string)\n\nThe container instance state with which to update the container instance. The only valid values for this action are ACTIVE and DRAINING . A container instance can only be updated to DRAINING status once it has reached an ACTIVE state. If a container instance is in REGISTERING , DEREGISTERING , or REGISTRATION_FAILED state you can describe the container instance but will be unable to update the container instance state.\n\nPossible values:\n\nACTIVE\n\nDRAINING\n\nREGISTERING\n\nDEREGISTERING\n\nREGISTRATION_FAILED\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ncontainerInstances -> (list)\n\nThe list of container instances.\n\n(structure)\n\nAn EC2 instance that is running the Amazon ECS agent and has been registered with a cluster.\n\ncontainerInstanceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the container instance. The ARN contains the arn:aws:ecs namespace, followed by the Region of the container instance, the Amazon Web Services account ID of the container instance owner, the container-instance namespace, and then the container instance ID. For example, arn:aws:ecs:region:aws_account_id:container-instance/container_instance_ID .\n\nec2InstanceId -> (string)\n\nThe ID of the container instance. For Amazon EC2 instances, this value is the Amazon EC2 instance ID. For external instances, this value is the Amazon Web Services Systems Manager managed instance ID.\n\ncapacityProviderName -> (string)\n\nThe capacity provider associated with the container instance.\n\nversion -> (long)\n\nThe version counter for the container instance. Every time a container instance experiences a change that triggers a CloudWatch event, the version counter is incremented. If you are replicating your Amazon ECS container instance state with CloudWatch Events, you can compare the version of a container instance reported by the Amazon ECS APIs with the version reported in CloudWatch Events for the container instance (inside the detail object) to verify that the version in your event stream is current.\n\nversionInfo -> (structure)\n\nThe version information for the Amazon ECS container agent and Docker daemon running on the container instance.\n\nagentVersion -> (string)\n\nThe version number of the Amazon ECS container agent.\n\nagentHash -> (string)\n\nThe Git commit hash for the Amazon ECS container agent build on the amazon-ecs-agent GitHub repository.\n\ndockerVersion -> (string)\n\nThe Docker version running on the container instance.\n\nremainingResources -> (list)\n\nFor CPU and memory resource types, this parameter describes the remaining CPU and memory that has not already been allocated to tasks and is therefore available for new tasks. For port resource types, this parameter describes the ports that were reserved by the Amazon ECS container agent (at instance registration time) and any task containers that have reserved port mappings on the host (with the host or bridge network mode). Any port that is not specified here is available for new tasks.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nregisteredResources -> (list)\n\nFor CPU and memory resource types, this parameter describes the amount of each resource that was available on the container instance when the container agent registered it with Amazon ECS. This value represents the total amount of CPU and memory that can be allocated on this container instance to tasks. For port resource types, this parameter describes the ports that were reserved by the Amazon ECS container agent when it registered the container instance with Amazon ECS.\n\n(structure)\n\nDescribes the resources available for a container instance.\n\nname -> (string)\n\nThe name of the resource, such as CPU , MEMORY , PORTS , PORTS_UDP , or a user-defined resource.\n\ntype -> (string)\n\nThe type of the resource, such as INTEGER , DOUBLE , LONG , or STRINGSET .\n\ndoubleValue -> (double)\n\nWhen the doubleValue type is set, the value of the resource must be a double precision floating-point type.\n\nlongValue -> (long)\n\nWhen the longValue type is set, the value of the resource must be an extended precision floating-point type.\n\nintegerValue -> (integer)\n\nWhen the integerValue type is set, the value of the resource must be an integer.\n\nstringSetValue -> (list)\n\nWhen the stringSetValue type is set, the value of the resource must be a string type.\n\n(string)\n\nstatus -> (string)\n\nThe status of the container instance. The valid values are REGISTERING , REGISTRATION_FAILED , ACTIVE , INACTIVE , DEREGISTERING , or DRAINING .\n\nIf your account has opted in to the awsvpcTrunking account setting, then any newly registered container instance will transition to a REGISTERING status while the trunk elastic network interface is provisioned for the instance. If the registration fails, the instance will transition to a REGISTRATION_FAILED status. You can describe the container instance and see the reason for failure in the statusReason parameter. Once the container instance is terminated, the instance transitions to a DEREGISTERING status while the trunk elastic network interface is deprovisioned. The instance then transitions to an INACTIVE status.\n\nThe ACTIVE status indicates that the container instance can accept tasks. The DRAINING indicates that new tasks are not placed on the container instance and any service tasks running on the container instance are removed if possible. For more information, see Container Instance Draining in the Amazon Elastic Container Service Developer Guide .\n\nstatusReason -> (string)\n\nThe reason that the container instance reached its current status.\n\nagentConnected -> (boolean)\n\nThis parameter returns true if the agent is connected to Amazon ECS. Registered instances with an agent that may be unhealthy or stopped return false . Only instances connected to an agent can accept placement requests.\n\nrunningTasksCount -> (integer)\n\nThe number of tasks on the container instance that are in the RUNNING status.\n\npendingTasksCount -> (integer)\n\nThe number of tasks on the container instance that are in the PENDING status.\n\nagentUpdateStatus -> (string)\n\nThe status of the most recent agent update. If an update has never been requested, this value is NULL .\n\nattributes -> (list)\n\nThe attributes set for the container instance, either by the Amazon ECS container agent at instance registration or manually with the PutAttributes operation.\n\n(structure)\n\nAn attribute is a name-value pair associated with an Amazon ECS object. Attributes enable you to extend the Amazon ECS data model by adding custom metadata to your resources. For more information, see Attributes in the Amazon Elastic Container Service Developer Guide .\n\nname -> (string)\n\nThe name of the attribute. The name must contain between 1 and 128 characters and name may contain letters (uppercase and lowercase), numbers, hyphens, underscores, forward slashes, back slashes, or periods.\n\nvalue -> (string)\n\nThe value of the attribute. The value must contain between 1 and 128 characters and may contain letters (uppercase and lowercase), numbers, hyphens, underscores, periods, at signs (@), forward slashes, back slashes, colons, or spaces. The value cannot contain any leading or trailing whitespace.\n\ntargetType -> (string)\n\nThe type of the target with which to attach the attribute. This parameter is required if you use the short form ID for a resource instead of the full ARN.\n\ntargetId -> (string)\n\nThe ID of the target. You can specify the short form ID for a resource or the full Amazon Resource Name (ARN).\n\nregisteredAt -> (timestamp)\n\nThe Unix timestamp for when the container instance was registered.\n\nattachments -> (list)\n\nThe resources attached to a container instance, such as elastic network interfaces.\n\n(structure)\n\nAn object representing a container instance or task attachment.\n\nid -> (string)\n\nThe unique identifier for the attachment.\n\ntype -> (string)\n\nThe type of the attachment, such as ElasticNetworkInterface .\n\nstatus -> (string)\n\nThe status of the attachment. Valid values are PRECREATED , CREATED , ATTACHING , ATTACHED , DETACHING , DETACHED , and DELETED .\n\ndetails -> (list)\n\nDetails of the attachment. For elastic network interfaces, this includes the network interface ID, the MAC address, the subnet ID, and the private IPv4 address.\n\n(structure)\n\nA key-value pair object.\n\nname -> (string)\n\nThe name of the key-value pair. For environment variables, this is the name of the environment variable.\n\nvalue -> (string)\n\nThe value of the key-value pair. For environment variables, this is the value of the environment variable.\n\ntags -> (list)\n\nThe metadata that you apply to the container instance to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\nfailures -> (list)\n\nAny failures associated with the call.\n\n(structure)\n\nA failed resource. For a list of common causes, see API failure reasons in the Amazon Elastic Container Service Developer Guide .\n\narn -> (string)\n\nThe Amazon Resource Name (ARN) of the failed resource.\n\nreason -> (string)\n\nThe reason for the failure.\n\ndetail -> (string)\n\nThe details of the failure.",
      "command_examples": "Examples\n\nTo update the state of a container instance\n\nThe following update-container-instances-state updates the state of the specified container instance to DRAINING which will remove it from the cluster is it registered to.\n\naws ecs update-container-instances-state \\\n    --container-instances 765936fadbdd46b5991a4bd70c2a43d4 \\\n    --status DRAINING\n\n\nOutput:\n\n{\n    \"containerInstances\": [\n        {\n            \"containerInstanceArn\": \"arn:aws:ecs:us-west-2:130757420319:container-instance/default/765936fadbdd46b5991a4bd70c2a43d4\",\n            \"ec2InstanceId\": \"i-013d87ffbb4d513bf\",\n            \"version\": 4390,\n            \"versionInfo\": {\n                \"agentVersion\": \"1.29.0\",\n                \"agentHash\": \"a190a73f\",\n                \"dockerVersion\": \"DockerVersion:18.06.1-ce\"\n            },\n            \"remainingResources\": [\n                {\n                    \"name\": \"CPU\",\n                    \"type\": \"INTEGER\",\n                    \"doubleValue\": 0,\n                    \"longValue\": 0,\n                    \"integerValue\": 1536\n                },\n                {\n                    \"name\": \"MEMORY\",\n                    \"type\": \"INTEGER\",\n                    \"doubleValue\": 0,\n                    \"longValue\": 0,\n                    \"integerValue\": 2681\n                },\n                {\n                    \"name\": \"PORTS\",\n                    \"type\": \"STRINGSET\",\n                    \"doubleValue\": 0,\n                    \"longValue\": 0,\n                    \"integerValue\": 0,\n                    \"stringSetValue\": [\n                        \"22\",\n                        \"2376\",\n                        \"2375\",\n                        \"51678\",\n                        \"51679\"\n                    ]\n                },\n                {\n                    \"name\": \"PORTS_UDP\",\n                    \"type\": \"STRINGSET\",\n                    \"doubleValue\": 0,\n                    \"longValue\": 0,\n                    \"integerValue\": 0,\n                    \"stringSetValue\": []\n                }\n            ],\n            \"registeredResources\": [\n                {\n                    \"name\": \"CPU\",\n                    \"type\": \"INTEGER\",\n                    \"doubleValue\": 0,\n                    \"longValue\": 0,\n                    \"integerValue\": 2048\n                },\n                {\n                    \"name\": \"MEMORY\",\n                    \"type\": \"INTEGER\",\n                    \"doubleValue\": 0,\n                    \"longValue\": 0,\n                    \"integerValue\": 3705\n                },\n                {\n                    \"name\": \"PORTS\",\n                    \"type\": \"STRINGSET\",\n                    \"doubleValue\": 0,\n                    \"longValue\": 0,\n                    \"integerValue\": 0,\n                    \"stringSetValue\": [\n                        \"22\",\n                        \"2376\",\n                        \"2375\",\n                        \"51678\",\n                        \"51679\"\n                    ]\n                },\n                {\n                    \"name\": \"PORTS_UDP\",\n                    \"type\": \"STRINGSET\",\n                    \"doubleValue\": 0,\n                    \"longValue\": 0,\n                    \"integerValue\": 0,\n                    \"stringSetValue\": []\n                }\n            ],\n            \"status\": \"DRAINING\",\n            \"agentConnected\": true,\n            \"runningTasksCount\": 2,\n            \"pendingTasksCount\": 0,\n            \"attributes\": [\n                {\n                    \"name\": \"ecs.capability.secrets.asm.environment-variables\"\n                },\n                {\n                    \"name\": \"ecs.capability.branch-cni-plugin-version\",\n                    \"value\": \"e0703516-\"\n                },\n                {\n                    \"name\": \"ecs.ami-id\",\n                    \"value\": \"ami-00e0090ac21971297\"\n                },\n                {\n                    \"name\": \"ecs.capability.secrets.asm.bootstrap.log-driver\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.logging-driver.none\"\n                },\n                {\n                    \"name\": \"ecs.capability.ecr-endpoint\"\n                },\n                {\n                    \"name\": \"ecs.capability.docker-plugin.local\"\n                },\n                {\n                    \"name\": \"ecs.capability.task-cpu-mem-limit\"\n                },\n                {\n                    \"name\": \"ecs.capability.secrets.ssm.bootstrap.log-driver\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.30\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.31\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.32\"\n                },\n                {\n                    \"name\": \"ecs.availability-zone\",\n                    \"value\": \"us-west-2c\"\n                },\n                {\n                    \"name\": \"ecs.capability.aws-appmesh\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.logging-driver.awslogs\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.24\"\n                },\n                {\n                    \"name\": \"ecs.capability.task-eni-trunking\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.25\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.26\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.27\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.28\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.privileged-container\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.29\"\n                },\n                {\n                    \"name\": \"ecs.cpu-architecture\",\n                    \"value\": \"x86_64\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.ecr-auth\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.20\"\n                },\n                {\n                    \"name\": \"ecs.os-type\",\n                    \"value\": \"linux\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.21\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.22\"\n                },\n                {\n                    \"name\": \"ecs.capability.task-eia\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.23\"\n                },\n                {\n                    \"name\": \"ecs.capability.private-registry-authentication.secretsmanager\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.logging-driver.syslog\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.logging-driver.json-file\"\n                },\n                {\n                    \"name\": \"ecs.capability.execution-role-awslogs\"\n                },\n                {\n                    \"name\": \"ecs.vpc-id\",\n                    \"value\": \"vpc-1234\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.17\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.18\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.docker-remote-api.1.19\"\n                },\n                {\n                    \"name\": \"ecs.capability.task-eni\"\n                },\n                {\n                    \"name\": \"ecs.capability.execution-role-ecr-pull\"\n                },\n                {\n                    \"name\": \"ecs.capability.container-health-check\"\n                },\n                {\n                    \"name\": \"ecs.subnet-id\",\n                    \"value\": \"subnet-1234\"\n                },\n                {\n                    \"name\": \"ecs.instance-type\",\n                    \"value\": \"c5.large\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.task-iam-role-network-host\"\n                },\n                {\n                    \"name\": \"ecs.capability.container-ordering\"\n                },\n                {\n                    \"name\": \"ecs.capability.cni-plugin-version\",\n                    \"value\": \"91ccefc8-2019.06.0\"\n                },\n                {\n                    \"name\": \"ecs.capability.pid-ipc-namespace-sharing\"\n                },\n                {\n                    \"name\": \"ecs.capability.secrets.ssm.environment-variables\"\n                },\n                {\n                    \"name\": \"com.amazonaws.ecs.capability.task-iam-role\"\n                }\n            ],\n            \"registeredAt\": 1560788724.507,\n            \"attachments\": [],\n            \"tags\": []\n        }\n    ],\n    \"failures\": []\n}\n"
    },
    {
      "command_name": "update-service",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update-service.html",
      "command_description": "Description\n\nWarning\n\nUpdating the task placement strategies and constraints on an Amazon ECS service remains in preview and is a Beta Service as defined by and subject to the Beta Service Participation Service Terms located at https://aws.amazon.com/service-terms (“Beta Terms”). These Beta Terms apply to your participation in this preview.\n\nModifies the parameters of a service.\n\nFor services using the rolling update (ECS ) deployment controller, the desired count, deployment configuration, network configuration, task placement constraints and strategies, or task definition used can be updated.\n\nFor services using the blue/green (CODE_DEPLOY ) deployment controller, only the desired count, deployment configuration, task placement constraints and strategies, and health check grace period can be updated using this API. If the network configuration, platform version, or task definition need to be updated, a new CodeDeploy deployment should be created. For more information, see CreateDeployment in the CodeDeploy API Reference .\n\nFor services using an external deployment controller, you can update only the desired count, task placement constraints and strategies, and health check grace period using this API. If the launch type, load balancer, network configuration, platform version, or task definition need to be updated, you should create a new task set. For more information, see CreateTaskSet .\n\nYou can add to or subtract from the number of instantiations of a task definition in a service by specifying the cluster that the service is running in and a new desiredCount parameter.\n\nIf you have updated the Docker image of your application, you can create a new task definition with that image and deploy it to your service. The service scheduler uses the minimum healthy percent and maximum percent parameters (in the service’s deployment configuration) to determine the deployment strategy.\n\nNote\n\nIf your updated Docker image uses the same tag as what is in the existing task definition for your service (for example, my_image:latest ), you do not need to create a new revision of your task definition. You can update the service using the forceNewDeployment option. The new tasks launched by the deployment pull the current image/tag combination from your repository when they start.\n\nYou can also update the deployment configuration of a service. When a deployment is triggered by updating the task definition of a service, the service scheduler uses the deployment configuration parameters, minimumHealthyPercent and maximumPercent , to determine the deployment strategy.\n\nIf minimumHealthyPercent is below 100%, the scheduler can ignore desiredCount temporarily during a deployment. For example, if desiredCount is four tasks, a minimum of 50% allows the scheduler to stop two existing tasks before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state. Tasks for services that use a load balancer are considered healthy if they are in the RUNNING state and the container instance they are hosted on is reported as healthy by the load balancer.\n\nThe maximumPercent parameter represents an upper limit on the number of running tasks during a deployment, which enables you to define the deployment batch size. For example, if desiredCount is four tasks, a maximum of 200% starts four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available).\n\nWhen UpdateService stops a task during a deployment, the equivalent of docker stop is issued to the containers running in the task. This results in a SIGTERM and a 30-second timeout, after which SIGKILL is sent and the containers are forcibly stopped. If the container handles the SIGTERM gracefully and exits within 30 seconds from receiving it, no SIGKILL is sent.\n\nWhen the service scheduler launches new tasks, it determines task placement in your cluster with the following logic:\n\nDetermine which of the container instances in your cluster can support your service’s task definition (for example, they have the required CPU, memory, ports, and container instance attributes).\n\nBy default, the service scheduler attempts to balance tasks across Availability Zones in this manner (although you can choose a different placement strategy):\n\nSort the valid container instances by the fewest number of running tasks for this service in the same Availability Zone as the instance. For example, if zone A has one running service task and zones B and C each have zero, valid container instances in either zone B or C are considered optimal for placement.\n\nPlace the new service task on a valid container instance in an optimal Availability Zone (based on the previous steps), favoring container instances with the fewest number of running tasks for this service.\n\nWhen the service scheduler stops running tasks, it attempts to maintain balance across the Availability Zones in your cluster using the following logic:\n\nSort the container instances by the largest number of running tasks for this service in the same Availability Zone as the instance. For example, if zone A has one running service task and zones B and C each have two, container instances in either zone B or C are considered optimal for termination.\n\nStop the task on a container instance in an optimal Availability Zone (based on the previous steps), favoring container instances with the largest number of running tasks for this service.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-service\n[--cluster <value>]\n--service <value>\n[--desired-count <value>]\n[--task-definition <value>]\n[--capacity-provider-strategy <value>]\n[--deployment-configuration <value>]\n[--network-configuration <value>]\n[--placement-constraints <value>]\n[--placement-strategy <value>]\n[--platform-version <value>]\n[--force-new-deployment | --no-force-new-deployment]\n[--health-check-grace-period-seconds <value>]\n[--enable-execute-command | --disable-execute-command]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cluster <value>]",
        "--service <value>",
        "[--desired-count <value>]",
        "[--task-definition <value>]",
        "[--capacity-provider-strategy <value>]",
        "[--deployment-configuration <value>]",
        "[--network-configuration <value>]",
        "[--placement-constraints <value>]",
        "[--placement-strategy <value>]",
        "[--platform-version <value>]",
        "[--force-new-deployment | --no-force-new-deployment]",
        "[--health-check-grace-period-seconds <value>]",
        "[--enable-execute-command | --disable-execute-command]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that your service is running on. If you do not specify a cluster, the default cluster is assumed.\n\n--service (string)\n\nThe name of the service to update.\n\n--desired-count (integer)\n\nThe number of instantiations of the task to place and keep running in your service.\n\n--task-definition (string)\n\nThe family and revision (family:revision ) or full ARN of the task definition to run in your service. If a revision is not specified, the latest ACTIVE revision is used. If you modify the task definition with UpdateService , Amazon ECS spawns a task with the new version of the task definition and then stops an old task after the new version is running.\n\n--capacity-provider-strategy (list)\n\nThe capacity provider strategy to update the service to use.\n\nIf the service is using the default capacity provider strategy for the cluster, the service can be updated to use one or more capacity providers as opposed to the default capacity provider strategy. However, when a service is using a capacity provider strategy that is not the default capacity provider strategy, the service cannot be updated to use the cluster’s default capacity provider strategy.\n\nA capacity provider strategy consists of one or more capacity providers along with the base and weight to assign to them. A capacity provider must be associated with the cluster to be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster. Only capacity providers with an ACTIVE or UPDATING status can be used.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used.\n\nThe PutClusterCapacityProviders API operation is used to update the list of available capacity providers for a cluster after the cluster is created.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nShorthand Syntax:\n\ncapacityProvider=string,weight=integer,base=integer ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"capacityProvider\": \"string\",\n    \"weight\": integer,\n    \"base\": integer\n  }\n  ...\n]\n\n\n--deployment-configuration (structure)\n\nOptional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.\n\ndeploymentCircuitBreaker -> (structure)\n\nNote\n\nThe deployment circuit breaker can only be used for services using the rolling update (ECS ) deployment type.\n\nThe deployment circuit breaker determines whether a service deployment will fail if the service can’t reach a steady state. If deployment circuit breaker is enabled, a service deployment will transition to a failed state and stop launching new tasks. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nenable -> (boolean)\n\nWhether to enable the deployment circuit breaker logic for the service.\n\nrollback -> (boolean)\n\nWhether to enable Amazon ECS to roll back the service if a service deployment fails. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nmaximumPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the maximum percent parameter represents an upper limit on the number of tasks in a service that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desired number of tasks (rounded down to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to define the deployment batch size. For example, if your service has a desired number of four tasks and a maximum percent value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default value for maximum percent is 200%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the maximum percent value is set to the default value and is used to define the upper limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the maximum percent value is not used, although it is returned when describing your service.\n\nminimumHealthyPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the minimum healthy percent represents a lower limit on the number of tasks in a service that must remain in the RUNNING state during a deployment, as a percentage of the desired number of tasks (rounded up to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a desired number of four tasks and a minimum healthy percent of 50%, the scheduler may stop two existing tasks to free up cluster capacity before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state; tasks for services that do use a load balancer are considered healthy if they are in the RUNNING state and they are reported as healthy by the load balancer. The default value for minimum healthy percent is 100%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the minimum healthy percent value is set to the default value and is used to define the lower limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the minimum healthy percent value is not used, although it is returned when describing your service.\n\nShorthand Syntax:\n\ndeploymentCircuitBreaker={enable=boolean,rollback=boolean},maximumPercent=integer,minimumHealthyPercent=integer\n\n\nJSON Syntax:\n\n{\n  \"deploymentCircuitBreaker\": {\n    \"enable\": true|false,\n    \"rollback\": true|false\n  },\n  \"maximumPercent\": integer,\n  \"minimumHealthyPercent\": integer\n}\n\n\n--network-configuration (structure)\n\nAn object representing the network configuration for the service.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nShorthand Syntax:\n\nawsvpcConfiguration={subnets=[string,string],securityGroups=[string,string],assignPublicIp=string}\n\n\nJSON Syntax:\n\n{\n  \"awsvpcConfiguration\": {\n    \"subnets\": [\"string\", ...],\n    \"securityGroups\": [\"string\", ...],\n    \"assignPublicIp\": \"ENABLED\"|\"DISABLED\"\n  }\n}\n\n\n--placement-constraints (list)\n\nAn array of task placement constraint objects to update the service to use. If no value is specified, the existing placement constraints for the service will remain unchanged. If this value is specified, it will override any existing placement constraints defined for the service. To remove all existing placement constraints, specify an empty array.\n\nYou can specify a maximum of 10 constraints per task (this limit includes constraints in the task definition and those specified at runtime).\n\n(structure)\n\nAn object representing a constraint on task placement. For more information, see Task Placement Constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you are using the Fargate launch type, task placement constraints are not supported.\n\ntype -> (string)\n\nThe type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. The expression can have a maximum length of 2000 characters. You can’t specify an expression if the constraint type is distinctInstance . For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\nShorthand Syntax:\n\ntype=string,expression=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"type\": \"distinctInstance\"|\"memberOf\",\n    \"expression\": \"string\"\n  }\n  ...\n]\n\n\n--placement-strategy (list)\n\nThe task placement strategy objects to update the service to use. If no value is specified, the existing placement strategy for the service will remain unchanged. If this value is specified, it will override the existing placement strategy defined for the service. To remove an existing placement strategy, specify an empty object.\n\nYou can specify a maximum of five strategy rules per service.\n\n(structure)\n\nThe task placement strategy for a task or service. For more information, see Task Placement Strategies in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).\n\nfield -> (string)\n\nThe field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host , which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone . For the binpack placement strategy, valid values are cpu and memory . For the random placement strategy, this field is not used.\n\nShorthand Syntax:\n\ntype=string,field=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"type\": \"random\"|\"spread\"|\"binpack\",\n    \"field\": \"string\"\n  }\n  ...\n]\n\n\n--platform-version (string)\n\nThe platform version on which your tasks in the service are running. A platform version is only specified for tasks using the Fargate launch type. If a platform version is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\n--force-new-deployment | --no-force-new-deployment (boolean)\n\nWhether to force a new deployment of the service. Deployments are not forced by default. You can use this option to trigger a new deployment with no service definition changes. For example, you can update a service’s tasks to use a newer Docker image with the same image/tag combination (my_image:latest ) or to roll Fargate tasks onto a newer platform version.\n\n--health-check-grace-period-seconds (integer)\n\nThe period of time, in seconds, that the Amazon ECS service scheduler should ignore unhealthy Elastic Load Balancing target health checks after a task has first started. This is only valid if your service is configured to use a load balancer. If your service’s tasks take a while to start and respond to Elastic Load Balancing health checks, you can specify a health check grace period of up to 2,147,483,647 seconds. During that time, the Amazon ECS service scheduler ignores the Elastic Load Balancing health check status. This grace period can prevent the ECS service scheduler from marking tasks as unhealthy and stopping them before they have time to come up.\n\n--enable-execute-command | --disable-execute-command (boolean)\n\nIf true , this enables execute command functionality on all task containers.\n\nIf you do not want to override the value that was set when the service was created, you can set this to null when performing this action.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nservice -> (structure)\n\nThe full description of your service following the update call.\n\nserviceArn -> (string)\n\nThe ARN that identifies the service. The ARN contains the arn:aws:ecs namespace, followed by the Region of the service, the Amazon Web Services account ID of the service owner, the service namespace, and then the service name. For example, arn:aws:ecs:region:012345678910:service/my-service .\n\nserviceName -> (string)\n\nThe name of your service. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. Service names must be unique within a cluster, but you can have similarly named services in multiple clusters within a Region or across multiple Regions.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that hosts the service.\n\nloadBalancers -> (list)\n\nA list of Elastic Load Balancing load balancer objects, containing the load balancer name, the container name (as it appears in a container definition), and the container port to access from the load balancer.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this service. For more information, see Service Discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nstatus -> (string)\n\nThe status of the service. The valid values are ACTIVE , DRAINING , or INACTIVE .\n\ndesiredCount -> (integer)\n\nThe desired number of instantiations of the task definition to keep running on the service. This value is specified when the service is created with CreateService , and it can be modified with UpdateService .\n\nrunningCount -> (integer)\n\nThe number of tasks in the cluster that are in the RUNNING state.\n\npendingCount -> (integer)\n\nThe number of tasks in the cluster that are in the PENDING state.\n\nlaunchType -> (string)\n\nThe launch type the service is using. When using the DescribeServices API, this field is omitted if the service was created using a capacity provider strategy.\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy the service is using. When using the DescribeServices API, this field is omitted if the service was created using a launch type.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe platform version on which to run your service. A platform version is only specified for tasks hosted on Fargate. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the service are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX .\n\ntaskDefinition -> (string)\n\nThe task definition to use for tasks in the service. This value is specified when the service is created with CreateService , and it can be modified with UpdateService .\n\ndeploymentConfiguration -> (structure)\n\nOptional deployment parameters that control how many tasks run during the deployment and the ordering of stopping and starting tasks.\n\ndeploymentCircuitBreaker -> (structure)\n\nNote\n\nThe deployment circuit breaker can only be used for services using the rolling update (ECS ) deployment type.\n\nThe deployment circuit breaker determines whether a service deployment will fail if the service can’t reach a steady state. If deployment circuit breaker is enabled, a service deployment will transition to a failed state and stop launching new tasks. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nenable -> (boolean)\n\nWhether to enable the deployment circuit breaker logic for the service.\n\nrollback -> (boolean)\n\nWhether to enable Amazon ECS to roll back the service if a service deployment fails. If rollback is enabled, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.\n\nmaximumPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the maximum percent parameter represents an upper limit on the number of tasks in a service that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desired number of tasks (rounded down to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to define the deployment batch size. For example, if your service has a desired number of four tasks and a maximum percent value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default value for maximum percent is 200%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the maximum percent value is set to the default value and is used to define the upper limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the maximum percent value is not used, although it is returned when describing your service.\n\nminimumHealthyPercent -> (integer)\n\nIf a service is using the rolling update (ECS ) deployment type, the minimum healthy percent represents a lower limit on the number of tasks in a service that must remain in the RUNNING state during a deployment, as a percentage of the desired number of tasks (rounded up to the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a desired number of four tasks and a minimum healthy percent of 50%, the scheduler may stop two existing tasks to free up cluster capacity before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state; tasks for services that do use a load balancer are considered healthy if they are in the RUNNING state and they are reported as healthy by the load balancer. The default value for minimum healthy percent is 100%.\n\nIf a service is using the blue/green (CODE_DEPLOY ) or EXTERNAL deployment types and tasks that use the EC2 launch type, the minimum healthy percent value is set to the default value and is used to define the lower limit on the number of the tasks in the service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks in the service use the Fargate launch type, the minimum healthy percent value is not used, although it is returned when describing your service.\n\ntaskSets -> (list)\n\nInformation about a set of Amazon ECS tasks in either an CodeDeploy or an EXTERNAL deployment. An Amazon ECS task set includes details such as the desired number of tasks, how many tasks are running, and whether the task set serves production traffic.\n\n(structure)\n\nInformation about a set of Amazon ECS tasks in either an CodeDeploy or an EXTERNAL deployment. An Amazon ECS task set includes details such as the desired number of tasks, how many tasks are running, and whether the task set serves production traffic.\n\nid -> (string)\n\nThe ID of the task set.\n\ntaskSetArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task set.\n\nserviceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service the task set exists in.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that the service that hosts the task set exists in.\n\nstartedBy -> (string)\n\nThe tag specified when a task set is started. If the task set is created by an CodeDeploy deployment, the startedBy parameter is CODE_DEPLOY . For a task set created for an external deployment, the startedBy field isn’t used.\n\nexternalId -> (string)\n\nThe external ID associated with the task set.\n\nIf a task set is created by an CodeDeploy deployment, the externalId parameter contains the CodeDeploy deployment ID.\n\nIf a task set is created for an external deployment and is associated with a service discovery registry, the externalId parameter contains the ECS_TASK_SET_EXTERNAL_ID Cloud Map attribute.\n\nstatus -> (string)\n\nThe status of the task set. The following describes each state:\n\nPRIMARY\n\nThe task set is serving production traffic.\n\nACTIVE\n\nThe task set is not serving production traffic.\n\nDRAINING\n\nThe tasks in the task set are being stopped and their corresponding targets are being deregistered from their target group.\n\ntaskDefinition -> (string)\n\nThe task definition the task set is using.\n\ncomputedDesiredCount -> (integer)\n\nThe computed desired count for the task set. This is calculated by multiplying the service’s desiredCount by the task set’s scale percentage. The result is always rounded up. For example, if the computed desired count is 1.2, it rounds up to 2 tasks.\n\npendingCount -> (integer)\n\nThe number of tasks in the task set that are in the PENDING status during a deployment. A task in the PENDING state is preparing to enter the RUNNING state. A task set enters the PENDING status when it launches for the first time or when it is restarted after being in the STOPPED state.\n\nrunningCount -> (integer)\n\nThe number of tasks in the task set that are in the RUNNING status during a deployment. A task in the RUNNING state is running and ready for use.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was last updated.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the task set are using. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy associated with the task set.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe Fargate platform version on which the tasks in the task set are running. A platform version is only specified for tasks run on Fargate. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the set are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks in the set must have the same value.\n\nnetworkConfiguration -> (structure)\n\nThe network configuration for the task set.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nloadBalancers -> (list)\n\nDetails on a load balancer that is used with a task set.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this task set. For more information, see Service discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nscale -> (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nstabilityStatus -> (string)\n\nThe stability status, which indicates whether the task set has reached a steady state. If the following conditions are met, the task set will be in STEADY_STATE :\n\nThe task runningCount is equal to the computedDesiredCount .\n\nThe pendingCount is 0 .\n\nThere are no tasks running on container instances in the DRAINING status.\n\nAll tasks are reporting a healthy status from the load balancers, service discovery, and container health checks.\n\nIf any of those conditions are not met, the stability status returns STABILIZING .\n\nstabilityStatusAt -> (timestamp)\n\nThe Unix timestamp for when the task set stability status was retrieved.\n\ntags -> (list)\n\nThe metadata that you apply to the task set to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ndeployments -> (list)\n\nThe current state of deployments for the service.\n\n(structure)\n\nThe details of an Amazon ECS service deployment. This is used only when a service uses the ECS deployment controller type.\n\nid -> (string)\n\nThe ID of the deployment.\n\nstatus -> (string)\n\nThe status of the deployment. The following describes each state:\n\nPRIMARY\n\nThe most recent deployment of a service.\n\nACTIVE\n\nA service deployment that still has running tasks, but are in the process of being replaced with a new PRIMARY deployment.\n\nINACTIVE\n\nA deployment that has been completely replaced.\n\ntaskDefinition -> (string)\n\nThe most recent task definition that was specified for the tasks in the service to use.\n\ndesiredCount -> (integer)\n\nThe most recent desired count of tasks that was specified for the service to deploy or maintain.\n\npendingCount -> (integer)\n\nThe number of tasks in the deployment that are in the PENDING status.\n\nrunningCount -> (integer)\n\nThe number of tasks in the deployment that are in the RUNNING status.\n\nfailedTasks -> (integer)\n\nThe number of consecutively failed tasks in the deployment. A task is considered a failure if the service scheduler can’t launch the task, the task doesn’t transition to a RUNNING state, or if it fails any of its defined health checks and is stopped.\n\nNote\n\nOnce a service deployment has one or more successfully running tasks, the failed task count resets to zero and stops being evaluated.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the service deployment was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the service deployment was last updated.\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy that the deployment is using.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the service are using. For more information, see Amazon ECS Launch Types in the Amazon Elastic Container Service Developer Guide .\n\nplatformVersion -> (string)\n\nThe platform version on which your tasks in the service are running. A platform version is only specified for tasks using the Fargate launch type. If one is not specified, the LATEST platform version is used by default. For more information, see Fargate Platform Versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the service, or tasks are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks that run as part of this service must use the same platformFamily value as the service, for example, LINUX. .\n\nnetworkConfiguration -> (structure)\n\nThe VPC subnet and security group configuration for tasks that receive their own elastic network interface by using the awsvpc networking mode.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nrolloutState -> (string)\n\nNote\n\nThe rolloutState of a service is only returned for services that use the rolling update (ECS ) deployment type that are not behind a Classic Load Balancer.\n\nThe rollout state of the deployment. When a service deployment is started, it begins in an IN_PROGRESS state. When the service reaches a steady state, the deployment will transition to a COMPLETED state. If the service fails to reach a steady state and circuit breaker is enabled, the deployment will transition to a FAILED state. A deployment in FAILED state will launch no new tasks. For more information, see DeploymentCircuitBreaker .\n\nrolloutStateReason -> (string)\n\nA description of the rollout state of a deployment.\n\nroleArn -> (string)\n\nThe ARN of the IAM role associated with the service that allows the Amazon ECS container agent to register container instances with an Elastic Load Balancing load balancer.\n\nevents -> (list)\n\nThe event stream for your service. A maximum of 100 of the latest events are displayed.\n\n(structure)\n\nDetails on an event associated with a service.\n\nid -> (string)\n\nThe ID string of the event.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the event was triggered.\n\nmessage -> (string)\n\nThe event message.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the service was created.\n\nplacementConstraints -> (list)\n\nThe placement constraints for the tasks in the service.\n\n(structure)\n\nAn object representing a constraint on task placement. For more information, see Task Placement Constraints in the Amazon Elastic Container Service Developer Guide .\n\nNote\n\nIf you are using the Fargate launch type, task placement constraints are not supported.\n\ntype -> (string)\n\nThe type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.\n\nexpression -> (string)\n\nA cluster query language expression to apply to the constraint. The expression can have a maximum length of 2000 characters. You can’t specify an expression if the constraint type is distinctInstance . For more information, see Cluster query language in the Amazon Elastic Container Service Developer Guide .\n\nplacementStrategy -> (list)\n\nThe placement strategy that determines how tasks for the service are placed.\n\n(structure)\n\nThe task placement strategy for a task or service. For more information, see Task Placement Strategies in the Amazon Elastic Container Service Developer Guide .\n\ntype -> (string)\n\nThe type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).\n\nfield -> (string)\n\nThe field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host , which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone . For the binpack placement strategy, valid values are cpu and memory . For the random placement strategy, this field is not used.\n\nnetworkConfiguration -> (structure)\n\nThe VPC subnet and security group configuration for tasks that receive their own elastic network interface by using the awsvpc networking mode.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nhealthCheckGracePeriodSeconds -> (integer)\n\nThe period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started.\n\nschedulingStrategy -> (string)\n\nThe scheduling strategy to use for the service. For more information, see Services .\n\nThere are two service scheduler strategies available:\n\nREPLICA -The replica scheduling strategy places and maintains the desired number of tasks across your cluster. By default, the service scheduler spreads tasks across Availability Zones. You can use task placement strategies and constraints to customize task placement decisions.\n\nDAEMON -The daemon scheduling strategy deploys exactly one task on each active container instance that meets all of the task placement constraints that you specify in your cluster. The service scheduler also evaluates the task placement constraints for running tasks and will stop tasks that do not meet the placement constraints.\n\nNote\n\nFargate tasks do not support the DAEMON scheduling strategy.\n\ndeploymentController -> (structure)\n\nThe deployment controller type the service is using. When using the DescribeServices API, this field is omitted if the service is using the ECS deployment controller type.\n\ntype -> (string)\n\nThe deployment controller type to use.\n\nThere are three deployment controller types available:\n\nECS\n\nThe rolling update (ECS ) deployment type involves replacing the current running version of the container with the latest version. The number of containers Amazon ECS adds or removes from the service during a rolling update is controlled by adjusting the minimum and maximum number of healthy tasks allowed during a service deployment, as specified in the DeploymentConfiguration .\n\nCODE_DEPLOY\n\nThe blue/green (CODE_DEPLOY ) deployment type uses the blue/green deployment model powered by CodeDeploy, which allows you to verify a new deployment of a service before sending production traffic to it.\n\nEXTERNAL\n\nThe external (EXTERNAL ) deployment type enables you to use any third-party deployment controller for full control over the deployment process for an Amazon ECS service.\n\ntags -> (list)\n\nThe metadata that you apply to the service to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).\n\ncreatedBy -> (string)\n\nThe principal that created the service.\n\nenableECSManagedTags -> (boolean)\n\nSpecifies whether to enable Amazon ECS managed tags for the tasks in the service. For more information, see Tagging Your Amazon ECS Resources in the Amazon Elastic Container Service Developer Guide .\n\npropagateTags -> (string)\n\nSpecifies whether to propagate the tags from the task definition or the service to the task. If no value is specified, the tags are not propagated.\n\nenableExecuteCommand -> (boolean)\n\nWhether or not the execute command functionality is enabled for the service. If true , the execute command functionality is enabled for all containers in tasks as part of the service.",
      "command_examples": "Examples\n\nExample 1: To change the task definition used in a service\n\nThe following update-service example updates the my-http-service service to use the amazon-ecs-sample task definition.\n\naws ecs update-service --service my-http-service --task-definition amazon-ecs-sample\n\n\nExample 2: To change the number of tasks in a service\n\nThe following update-service example updates the desired task count of the service my-http-service to 3.\n\naws ecs update-service --service my-http-service --desired-count 3\n\n\nFor more information, see Updating a Service in the Amazon ECS Developer Guide."
    },
    {
      "command_name": "update-service-primary-task-set",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update-service-primary-task-set.html",
      "command_description": "Description\n\nModifies which task set in a service is the primary task set. Any parameters that are updated on the primary task set in a service will transition to the service. This is used when a service uses the EXTERNAL deployment controller type. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-service-primary-task-set\n--cluster <value>\n--service <value>\n--primary-task-set <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--cluster <value>",
        "--service <value>",
        "--primary-task-set <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the service that the task set exists in.\n\n--service (string)\n\nThe short name or full Amazon Resource Name (ARN) of the service that the task set exists in.\n\n--primary-task-set (string)\n\nThe short name or full Amazon Resource Name (ARN) of the task set to set as the primary task set in the deployment.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntaskSet -> (structure)\n\nDetails about the task set.\n\nid -> (string)\n\nThe ID of the task set.\n\ntaskSetArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task set.\n\nserviceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service the task set exists in.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that the service that hosts the task set exists in.\n\nstartedBy -> (string)\n\nThe tag specified when a task set is started. If the task set is created by an CodeDeploy deployment, the startedBy parameter is CODE_DEPLOY . For a task set created for an external deployment, the startedBy field isn’t used.\n\nexternalId -> (string)\n\nThe external ID associated with the task set.\n\nIf a task set is created by an CodeDeploy deployment, the externalId parameter contains the CodeDeploy deployment ID.\n\nIf a task set is created for an external deployment and is associated with a service discovery registry, the externalId parameter contains the ECS_TASK_SET_EXTERNAL_ID Cloud Map attribute.\n\nstatus -> (string)\n\nThe status of the task set. The following describes each state:\n\nPRIMARY\n\nThe task set is serving production traffic.\n\nACTIVE\n\nThe task set is not serving production traffic.\n\nDRAINING\n\nThe tasks in the task set are being stopped and their corresponding targets are being deregistered from their target group.\n\ntaskDefinition -> (string)\n\nThe task definition the task set is using.\n\ncomputedDesiredCount -> (integer)\n\nThe computed desired count for the task set. This is calculated by multiplying the service’s desiredCount by the task set’s scale percentage. The result is always rounded up. For example, if the computed desired count is 1.2, it rounds up to 2 tasks.\n\npendingCount -> (integer)\n\nThe number of tasks in the task set that are in the PENDING status during a deployment. A task in the PENDING state is preparing to enter the RUNNING state. A task set enters the PENDING status when it launches for the first time or when it is restarted after being in the STOPPED state.\n\nrunningCount -> (integer)\n\nThe number of tasks in the task set that are in the RUNNING status during a deployment. A task in the RUNNING state is running and ready for use.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was last updated.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the task set are using. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy associated with the task set.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe Fargate platform version on which the tasks in the task set are running. A platform version is only specified for tasks run on Fargate. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the set are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks in the set must have the same value.\n\nnetworkConfiguration -> (structure)\n\nThe network configuration for the task set.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nloadBalancers -> (list)\n\nDetails on a load balancer that is used with a task set.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this task set. For more information, see Service discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nscale -> (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nstabilityStatus -> (string)\n\nThe stability status, which indicates whether the task set has reached a steady state. If the following conditions are met, the task set will be in STEADY_STATE :\n\nThe task runningCount is equal to the computedDesiredCount .\n\nThe pendingCount is 0 .\n\nThere are no tasks running on container instances in the DRAINING status.\n\nAll tasks are reporting a healthy status from the load balancers, service discovery, and container health checks.\n\nIf any of those conditions are not met, the stability status returns STABILIZING .\n\nstabilityStatusAt -> (timestamp)\n\nThe Unix timestamp for when the task set stability status was retrieved.\n\ntags -> (list)\n\nThe metadata that you apply to the task set to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nTo update the primary task set for a service\n\nThe following update-service-primary-task-set example updates the primary task set for the specified service.\n\naws ecs update-service-primary-task-set \\\n    --cluster MyCluster \\\n    --service MyService \\\n    --primary-task-set arn:aws:ecs:us-west-2:123456789012:task-set/MyCluster/MyService/ecs-svc/1234567890123456789\n\n\nOutput:\n\n{\n    \"taskSet\": {\n        \"id\": \"ecs-svc/1234567890123456789\",\n        \"taskSetArn\": \"arn:aws:ecs:us-west-2:123456789012:task-set/MyCluster/MyService/ecs-svc/1234567890123456789\",\n        \"status\": \"PRIMARY\",\n        \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sample-fargate:2\",\n        \"computedDesiredCount\": 1,\n        \"pendingCount\": 0,\n        \"runningCount\": 0,\n        \"createdAt\": 1557128360.711,\n        \"updatedAt\": 1557129412.653,\n        \"launchType\": \"EC2\",\n        \"networkConfiguration\": {\n            \"awsvpcConfiguration\": {\n                \"subnets\": [\n                    \"subnet-12344321\"\n                ],\n                \"securityGroups\": [\n                    \"sg-12344312\"\n                ],\n                \"assignPublicIp\": \"DISABLED\"\n            }\n        },\n        \"loadBalancers\": [],\n        \"serviceRegistries\": [],\n        \"scale\": {\n            \"value\": 50.0,\n            \"unit\": \"PERCENT\"\n        },\n        \"stabilityStatus\": \"STABILIZING\",\n        \"stabilityStatusAt\": 1557129279.914\n    }\n}\n"
    },
    {
      "command_name": "update-task-set",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update-task-set.html",
      "command_description": "Description\n\nModifies a task set. This is used when a service uses the EXTERNAL deployment controller type. For more information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-task-set\n--cluster <value>\n--service <value>\n--task-set <value>\n--scale <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--cluster <value>",
        "--service <value>",
        "--task-set <value>",
        "--scale <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cluster (string)\n\nThe short name or full Amazon Resource Name (ARN) of the cluster that hosts the service that the task set exists in.\n\n--service (string)\n\nThe short name or full Amazon Resource Name (ARN) of the service that the task set exists in.\n\n--task-set (string)\n\nThe short name or full Amazon Resource Name (ARN) of the task set to update.\n\n--scale (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nShorthand Syntax:\n\nvalue=double,unit=string\n\n\nJSON Syntax:\n\n{\n  \"value\": double,\n  \"unit\": \"PERCENT\"\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntaskSet -> (structure)\n\nDetails about the task set.\n\nid -> (string)\n\nThe ID of the task set.\n\ntaskSetArn -> (string)\n\nThe Amazon Resource Name (ARN) of the task set.\n\nserviceArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service the task set exists in.\n\nclusterArn -> (string)\n\nThe Amazon Resource Name (ARN) of the cluster that the service that hosts the task set exists in.\n\nstartedBy -> (string)\n\nThe tag specified when a task set is started. If the task set is created by an CodeDeploy deployment, the startedBy parameter is CODE_DEPLOY . For a task set created for an external deployment, the startedBy field isn’t used.\n\nexternalId -> (string)\n\nThe external ID associated with the task set.\n\nIf a task set is created by an CodeDeploy deployment, the externalId parameter contains the CodeDeploy deployment ID.\n\nIf a task set is created for an external deployment and is associated with a service discovery registry, the externalId parameter contains the ECS_TASK_SET_EXTERNAL_ID Cloud Map attribute.\n\nstatus -> (string)\n\nThe status of the task set. The following describes each state:\n\nPRIMARY\n\nThe task set is serving production traffic.\n\nACTIVE\n\nThe task set is not serving production traffic.\n\nDRAINING\n\nThe tasks in the task set are being stopped and their corresponding targets are being deregistered from their target group.\n\ntaskDefinition -> (string)\n\nThe task definition the task set is using.\n\ncomputedDesiredCount -> (integer)\n\nThe computed desired count for the task set. This is calculated by multiplying the service’s desiredCount by the task set’s scale percentage. The result is always rounded up. For example, if the computed desired count is 1.2, it rounds up to 2 tasks.\n\npendingCount -> (integer)\n\nThe number of tasks in the task set that are in the PENDING status during a deployment. A task in the PENDING state is preparing to enter the RUNNING state. A task set enters the PENDING status when it launches for the first time or when it is restarted after being in the STOPPED state.\n\nrunningCount -> (integer)\n\nThe number of tasks in the task set that are in the RUNNING status during a deployment. A task in the RUNNING state is running and ready for use.\n\ncreatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was created.\n\nupdatedAt -> (timestamp)\n\nThe Unix timestamp for when the task set was last updated.\n\nlaunchType -> (string)\n\nThe launch type the tasks in the task set are using. For more information, see Amazon ECS launch types in the Amazon Elastic Container Service Developer Guide .\n\ncapacityProviderStrategy -> (list)\n\nThe capacity provider strategy associated with the task set.\n\n(structure)\n\nThe details of a capacity provider strategy. A capacity provider strategy can be set when using the RunTask or CreateCluster APIs or as the default capacity provider strategy for a cluster with the CreateCluster API.\n\nOnly capacity providers that are already associated with a cluster and have an ACTIVE or UPDATING status can be used in a capacity provider strategy. The PutClusterCapacityProviders API is used to associate a capacity provider with a cluster.\n\nIf specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the CreateCapacityProvider API operation.\n\nTo use a Fargate capacity provider, specify either the FARGATE or FARGATE_SPOT capacity providers. The Fargate capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.\n\nA capacity provider strategy may contain a maximum of 6 capacity providers.\n\ncapacityProvider -> (string)\n\nThe short name of the capacity provider.\n\nweight -> (integer)\n\nThe weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.\n\nIf no weight value is specified, the default value of 0 is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of 0 will not be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of 0 , any RunTask or CreateService actions using the capacity provider strategy will fail.\n\nAn example scenario for using weights is defining a strategy that contains two capacity providers and both have a weight of 1 , then when the base is satisfied, the tasks will be split evenly across the two capacity providers. Using that same logic, if you specify a weight of 1 for capacityProviderA and a weight of 4 for capacityProviderB , then for every one task that is run using capacityProviderA , four tasks would use capacityProviderB .\n\nbase -> (integer)\n\nThe base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.\n\nplatformVersion -> (string)\n\nThe Fargate platform version on which the tasks in the task set are running. A platform version is only specified for tasks run on Fargate. For more information, see Fargate platform versions in the Amazon Elastic Container Service Developer Guide .\n\nplatformFamily -> (string)\n\nThe operating system that your tasks in the set are running on. A platform family is specified only for tasks using the Fargate launch type.\n\nAll tasks in the set must have the same value.\n\nnetworkConfiguration -> (structure)\n\nThe network configuration for the task set.\n\nawsvpcConfiguration -> (structure)\n\nThe VPC subnets and security groups associated with a task.\n\nNote\n\nAll specified subnets and security groups must be from the same VPC.\n\nsubnets -> (list)\n\nThe IDs of the subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified subnets must be from the same VPC.\n\n(string)\n\nsecurityGroups -> (list)\n\nThe IDs of the security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration .\n\nNote\n\nAll specified security groups must be from the same VPC.\n\n(string)\n\nassignPublicIp -> (string)\n\nWhether the task’s elastic network interface receives a public IP address. The default value is DISABLED .\n\nloadBalancers -> (list)\n\nDetails on a load balancer that is used with a task set.\n\n(structure)\n\nThe load balancer configuration to use with a service or task set.\n\nFor specific notes and restrictions regarding the use of load balancers with services and task sets, see the CreateService and CreateTaskSet actions.\n\ntargetGroupArn -> (string)\n\nThe full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.\n\nA target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer the target group ARN should be omitted.\n\nFor services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see Registering Multiple Target Groups with a Service in the Amazon Elastic Container Service Developer Guide .\n\nFor services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see Blue/Green Deployment with CodeDeploy in the Amazon Elastic Container Service Developer Guide .\n\nWarning\n\nIf your service’s task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance , when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.\n\nloadBalancerName -> (string)\n\nThe name of the load balancer to associate with the Amazon ECS service or task set.\n\nA load balancer name is only specified when using a Classic Load Balancer. If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.\n\ncontainerName -> (string)\n\nThe name of the container (as it appears in a container definition) to associate with the load balancer.\n\ncontainerPort -> (integer)\n\nThe port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.\n\nserviceRegistries -> (list)\n\nThe details of the service discovery registries to assign to this task set. For more information, see Service discovery .\n\n(structure)\n\nDetails of the service registry.\n\nregistryArn -> (string)\n\nThe Amazon Resource Name (ARN) of the service registry. The currently supported service registry is Cloud Map. For more information, see CreateService .\n\nport -> (integer)\n\nThe port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.\n\ncontainerName -> (string)\n\nThe container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\ncontainerPort -> (integer)\n\nThe port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.\n\nscale -> (structure)\n\nA floating-point percentage of the desired number of tasks to place and keep running in the task set.\n\nvalue -> (double)\n\nThe value, specified as a percent total of a service’s desiredCount , to scale the task set. Accepted values are numbers between 0 and 100.\n\nunit -> (string)\n\nThe unit of measure for the scale value.\n\nstabilityStatus -> (string)\n\nThe stability status, which indicates whether the task set has reached a steady state. If the following conditions are met, the task set will be in STEADY_STATE :\n\nThe task runningCount is equal to the computedDesiredCount .\n\nThe pendingCount is 0 .\n\nThere are no tasks running on container instances in the DRAINING status.\n\nAll tasks are reporting a healthy status from the load balancers, service discovery, and container health checks.\n\nIf any of those conditions are not met, the stability status returns STABILIZING .\n\nstabilityStatusAt -> (timestamp)\n\nThe Unix timestamp for when the task set stability status was retrieved.\n\ntags -> (list)\n\nThe metadata that you apply to the task set to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\n(structure)\n\nThe metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define.\n\nThe following basic restrictions apply to tags:\n\nMaximum number of tags per resource - 50\n\nFor each resource, each tag key must be unique, and each tag key can have only one value.\n\nMaximum key length - 128 Unicode characters in UTF-8\n\nMaximum value length - 256 Unicode characters in UTF-8\n\nIf your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.\n\nTag keys and values are case-sensitive.\n\nDo not use aws: , AWS: , or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.\n\nkey -> (string)\n\nOne part of a key-value pair that make up a tag. A key is a general label that acts like a category for more specific tag values.\n\nvalue -> (string)\n\nThe optional part of a key-value pair that make up a tag. A value acts as a descriptor within a tag category (key).",
      "command_examples": "Examples\n\nTo update a task set\n\nThe following update-task-set example updates a task set to adjust the scale.\n\naws ecs update-task-set \\\n    --cluster MyCluster \\\n    --service MyService \\\n    --task-set arn:aws:ecs:us-west-2:123456789012:task-set/MyCluster/MyService/ecs-svc/1234567890123456789 \\\n    --scale value=50,unit=PERCENT\n\n\nOutput:\n\n{\n    \"taskSet\": {\n        \"id\": \"ecs-svc/1234567890123456789\",\n        \"taskSetArn\": \"arn:aws:ecs:us-west-2:123456789012:task-set/MyCluster/MyService/ecs-svc/1234567890123456789\",\n        \"status\": \"ACTIVE\",\n        \"taskDefinition\": \"arn:aws:ecs:us-west-2:123456789012:task-definition/sample-fargate:2\",\n        \"computedDesiredCount\": 0,\n        \"pendingCount\": 0,\n        \"runningCount\": 0,\n        \"createdAt\": 1557128360.711,\n        \"updatedAt\": 1557129279.914,\n        \"launchType\": \"EC2\",\n        \"networkConfiguration\": {\n            \"awsvpcConfiguration\": {\n                \"subnets\": [\n                    \"subnet-12344321\"\n                ],\n                \"securityGroups\": [\n                    \"sg-12344321\"\n                ],\n                \"assignPublicIp\": \"DISABLED\"\n            }\n        },\n        \"loadBalancers\": [],\n        \"serviceRegistries\": [],\n        \"scale\": {\n            \"value\": 50.0,\n            \"unit\": \"PERCENT\"\n        },\n        \"stabilityStatus\": \"STABILIZING\",\n        \"stabilityStatusAt\": 1557129279.914\n    }\n}\n"
    },
    {
      "command_name": "wait",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/wait/index.html",
      "command_description": "Description\n\nWait until a particular condition is satisfied. Each subcommand polls an API until the listed requirement is met.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_options": []
    }
  ],
  "service_description": "Description\n\nAmazon Elastic Container Service (Amazon ECS) is a highly scalable, fast, container management service that makes it easy to run, stop, and manage Docker containers on a cluster. You can host your cluster on a serverless infrastructure that is managed by Amazon ECS by launching your services or tasks on Fargate. For more control, you can host your tasks on a cluster of Amazon Elastic Compute Cloud (Amazon EC2) instances that you manage.\n\nAmazon ECS makes it easy to launch and stop container-based applications with simple API calls, allows you to get the state of your cluster from a centralized service, and gives you access to many familiar Amazon EC2 features.\n\nYou can use Amazon ECS to schedule the placement of containers across your cluster based on your resource needs, isolation policies, and availability requirements. Amazon ECS eliminates the need for you to operate your own cluster management and configuration management systems or worry about scaling your management infrastructure."
}