{
  "service_name": "kinesisanalyticsv2",
  "service_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/index.html",
  "service_commands": [
    {
      "command_name": "add-application-cloud-watch-logging-option",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/add-application-cloud-watch-logging-option.html",
      "command_description": "Description\n\nAdds an Amazon CloudWatch log stream to monitor application configuration errors.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  add-application-cloud-watch-logging-option\n--application-name <value>\n[--current-application-version-id <value>]\n--cloud-watch-logging-option <value>\n[--conditional-token <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--current-application-version-id <value>]",
        "--cloud-watch-logging-option <value>",
        "[--conditional-token <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe Kinesis Data Analytics application name.\n\n--current-application-version-id (long)\n\nThe version ID of the Kinesis Data Analytics application. You must provide the CurrentApplicationVersionId or the ConditionalToken .You can retrieve the application version ID using DescribeApplication . For better concurrency support, use the ConditionalToken parameter instead of CurrentApplicationVersionId .\n\n--cloud-watch-logging-option (structure)\n\nProvides the Amazon CloudWatch log stream Amazon Resource Name (ARN).\n\nLogStreamARN -> (string)\n\nThe ARN of the CloudWatch log to receive application messages.\n\nShorthand Syntax:\n\nLogStreamARN=string\n\n\nJSON Syntax:\n\n{\n  \"LogStreamARN\": \"string\"\n}\n\n\n--conditional-token (string)\n\nA value you use to implement strong concurrency for application updates. You must provide the CurrentApplicationVersionId or the ConditionalToken . You get the application’s current ConditionalToken using DescribeApplication . For better concurrency support, use the ConditionalToken parameter instead of CurrentApplicationVersionId .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe application’s ARN.\n\nApplicationVersionId -> (long)\n\nThe new version ID of the Kinesis Data Analytics application. Kinesis Data Analytics updates the ApplicationVersionId each time you change the CloudWatch logging options.\n\nCloudWatchLoggingOptionDescriptions -> (list)\n\nThe descriptions of the current CloudWatch logging options for the Kinesis Data Analytics application.\n\n(structure)\n\nDescribes the Amazon CloudWatch logging option.\n\nCloudWatchLoggingOptionId -> (string)\n\nThe ID of the CloudWatch logging option description.\n\nLogStreamARN -> (string)\n\nThe Amazon Resource Name (ARN) of the CloudWatch log to receive application messages.\n\nRoleARN -> (string)\n\nThe IAM ARN of the role to use to send application messages.\n\nNote\n\nProvided for backward compatibility. Applications created with the current API version have an application-level service execution role rather than a resource-level role."
    },
    {
      "command_name": "add-application-input",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/add-application-input.html",
      "command_description": "Description\n\nAdds a streaming source to your SQL-based Kinesis Data Analytics application.\n\nYou can add a streaming source when you create an application, or you can use this operation to add a streaming source after you create an application. For more information, see CreateApplication .\n\nAny configuration update, including adding a streaming source using this operation, results in a new version of the application. You can use the DescribeApplication operation to find the current application version.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  add-application-input\n--application-name <value>\n--current-application-version-id <value>\n--input <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--current-application-version-id <value>",
        "--input <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of your existing application to which you want to add the streaming source.\n\n--current-application-version-id (long)\n\nThe current version of your application. You must provide the ApplicationVersionID or the ConditionalToken .You can use the DescribeApplication operation to find the current application version.\n\n--input (structure)\n\nThe Input to add.\n\nNamePrefix -> (string)\n\nThe name prefix to use when creating an in-application stream. Suppose that you specify a prefix “MyInApplicationStream .” Kinesis Data Analytics then creates one or more (as per the InputParallelism count you specified) in-application streams with the names “MyInApplicationStream_001 ,” “MyInApplicationStream_002 ,” and so on.\n\nInputProcessingConfiguration -> (structure)\n\nThe InputProcessingConfiguration for the input. An input processor transforms records as they are received from the stream, before the application’s SQL code executes. Currently, the only input processing configuration available is InputLambdaProcessor .\n\nInputLambdaProcessor -> (structure)\n\nThe InputLambdaProcessor that is used to preprocess the records in the stream before being processed by your application code.\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that operates on records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nKinesisStreamsInput -> (structure)\n\nIf the streaming source is an Amazon Kinesis data stream, identifies the stream’s Amazon Resource Name (ARN).\n\nResourceARN -> (string)\n\nThe ARN of the input Kinesis data stream to read.\n\nKinesisFirehoseInput -> (structure)\n\nIf the streaming source is an Amazon Kinesis Data Firehose delivery stream, identifies the delivery stream’s ARN.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nInputParallelism -> (structure)\n\nDescribes the number of in-application streams to create.\n\nCount -> (integer)\n\nThe number of in-application streams to create.\n\nInputSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns in the in-application stream that is being created.\n\nAlso used to describe the format of the reference data source.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nJSON Syntax:\n\n{\n  \"NamePrefix\": \"string\",\n  \"InputProcessingConfiguration\": {\n    \"InputLambdaProcessor\": {\n      \"ResourceARN\": \"string\"\n    }\n  },\n  \"KinesisStreamsInput\": {\n    \"ResourceARN\": \"string\"\n  },\n  \"KinesisFirehoseInput\": {\n    \"ResourceARN\": \"string\"\n  },\n  \"InputParallelism\": {\n    \"Count\": integer\n  },\n  \"InputSchema\": {\n    \"RecordFormat\": {\n      \"RecordFormatType\": \"JSON\"|\"CSV\",\n      \"MappingParameters\": {\n        \"JSONMappingParameters\": {\n          \"RecordRowPath\": \"string\"\n        },\n        \"CSVMappingParameters\": {\n          \"RecordRowDelimiter\": \"string\",\n          \"RecordColumnDelimiter\": \"string\"\n        }\n      }\n    },\n    \"RecordEncoding\": \"string\",\n    \"RecordColumns\": [\n      {\n        \"Name\": \"string\",\n        \"Mapping\": \"string\",\n        \"SqlType\": \"string\"\n      }\n      ...\n    ]\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe Amazon Resource Name (ARN) of the application.\n\nApplicationVersionId -> (long)\n\nProvides the current application version.\n\nInputDescriptions -> (list)\n\nDescribes the application input configuration.\n\n(structure)\n\nDescribes the application input configuration for a SQL-based Kinesis Data Analytics application.\n\nInputId -> (string)\n\nThe input ID that is associated with the application input. This is the ID that Kinesis Data Analytics assigns to each input configuration that you add to your application.\n\nNamePrefix -> (string)\n\nThe in-application name prefix.\n\nInAppStreamNames -> (list)\n\nReturns the in-application stream names that are mapped to the stream source.\n\n(string)\n\nInputProcessingConfigurationDescription -> (structure)\n\nThe description of the preprocessor that executes on records in this input before the application’s code is run.\n\nInputLambdaProcessorDescription -> (structure)\n\nProvides configuration information about the associated InputLambdaProcessorDescription\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that is used to preprocess the records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that is used to access the Amazon Lambda function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisStreamsInputDescription -> (structure)\n\nIf a Kinesis data stream is configured as a streaming source, provides the Kinesis data stream’s Amazon Resource Name (ARN).\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseInputDescription -> (structure)\n\nIf a Kinesis Data Firehose delivery stream is configured as a streaming source, provides the delivery stream’s ARN.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics assumes to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nInputSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns in the in-application stream that is being created.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nInputParallelism -> (structure)\n\nDescribes the configured parallelism (number of in-application streams mapped to the streaming source).\n\nCount -> (integer)\n\nThe number of in-application streams to create.\n\nInputStartingPositionConfiguration -> (structure)\n\nThe point at which the application is configured to read from the input stream.\n\nInputStartingPosition -> (string)\n\nThe starting position on the stream.\n\nNOW - Start reading just after the most recent record in the stream, and start at the request timestamp that the customer issued.\n\nTRIM_HORIZON - Start reading at the last untrimmed record in the stream, which is the oldest record available in the stream. This option is not available for an Amazon Kinesis Data Firehose delivery stream.\n\nLAST_STOPPED_POINT - Resume reading from where the application last stopped reading."
    },
    {
      "command_name": "add-application-input-processing-configuration",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/add-application-input-processing-configuration.html",
      "command_description": "Description\n\nAdds an InputProcessingConfiguration to a SQL-based Kinesis Data Analytics application. An input processor pre-processes records on the input stream before the application’s SQL code executes. Currently, the only input processor available is Amazon Lambda .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  add-application-input-processing-configuration\n--application-name <value>\n--current-application-version-id <value>\n--input-id <value>\n--input-processing-configuration <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--current-application-version-id <value>",
        "--input-id <value>",
        "--input-processing-configuration <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application to which you want to add the input processing configuration.\n\n--current-application-version-id (long)\n\nThe version of the application to which you want to add the input processing configuration. You can use the DescribeApplication operation to get the current application version. If the version specified is not the current version, the ConcurrentModificationException is returned.\n\n--input-id (string)\n\nThe ID of the input configuration to add the input processing configuration to. You can get a list of the input IDs for an application using the DescribeApplication operation.\n\n--input-processing-configuration (structure)\n\nThe InputProcessingConfiguration to add to the application.\n\nInputLambdaProcessor -> (structure)\n\nThe InputLambdaProcessor that is used to preprocess the records in the stream before being processed by your application code.\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that operates on records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nShorthand Syntax:\n\nInputLambdaProcessor={ResourceARN=string}\n\n\nJSON Syntax:\n\n{\n  \"InputLambdaProcessor\": {\n    \"ResourceARN\": \"string\"\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe Amazon Resource Name (ARN) of the application.\n\nApplicationVersionId -> (long)\n\nProvides the current application version.\n\nInputId -> (string)\n\nThe input ID that is associated with the application input. This is the ID that Kinesis Data Analytics assigns to each input configuration that you add to your application.\n\nInputProcessingConfigurationDescription -> (structure)\n\nThe description of the preprocessor that executes on records in this input before the application’s code is run.\n\nInputLambdaProcessorDescription -> (structure)\n\nProvides configuration information about the associated InputLambdaProcessorDescription\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that is used to preprocess the records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that is used to access the Amazon Lambda function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role."
    },
    {
      "command_name": "add-application-output",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/add-application-output.html",
      "command_description": "Description\n\nAdds an external destination to your SQL-based Kinesis Data Analytics application.\n\nIf you want Kinesis Data Analytics to deliver data from an in-application stream within your application to an external destination (such as an Kinesis data stream, a Kinesis Data Firehose delivery stream, or an Amazon Lambda function), you add the relevant configuration to your application using this operation. You can configure one or more outputs for your application. Each output configuration maps an in-application stream and an external destination.\n\nYou can use one of the output configurations to deliver data from your in-application error stream to an external destination so that you can analyze the errors.\n\nAny configuration update, including adding a streaming source using this operation, results in a new version of the application. You can use the DescribeApplication operation to find the current application version.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  add-application-output\n--application-name <value>\n--current-application-version-id <value>\n--application-output <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--current-application-version-id <value>",
        "--application-output <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application to which you want to add the output configuration.\n\n--current-application-version-id (long)\n\nThe version of the application to which you want to add the output configuration. You can use the DescribeApplication operation to get the current application version. If the version specified is not the current version, the ConcurrentModificationException is returned.\n\n--application-output (structure)\n\nAn array of objects, each describing one output configuration. In the output configuration, you specify the name of an in-application stream, a destination (that is, a Kinesis data stream, a Kinesis Data Firehose delivery stream, or an Amazon Lambda function), and record the formation to use when writing to the destination.\n\nName -> (string)\n\nThe name of the in-application stream.\n\nKinesisStreamsOutput -> (structure)\n\nIdentifies a Kinesis data stream as the destination.\n\nResourceARN -> (string)\n\nThe ARN of the destination Kinesis data stream to write to.\n\nKinesisFirehoseOutput -> (structure)\n\nIdentifies a Kinesis Data Firehose delivery stream as the destination.\n\nResourceARN -> (string)\n\nThe ARN of the destination delivery stream to write to.\n\nLambdaOutput -> (structure)\n\nIdentifies an Amazon Lambda function as the destination.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the destination Lambda function to write to.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nDestinationSchema -> (structure)\n\nDescribes the data format when records are written to the destination.\n\nRecordFormatType -> (string)\n\nSpecifies the format of the records on the output stream.\n\nShorthand Syntax:\n\nName=string,KinesisStreamsOutput={ResourceARN=string},KinesisFirehoseOutput={ResourceARN=string},LambdaOutput={ResourceARN=string},DestinationSchema={RecordFormatType=string}\n\n\nJSON Syntax:\n\n{\n  \"Name\": \"string\",\n  \"KinesisStreamsOutput\": {\n    \"ResourceARN\": \"string\"\n  },\n  \"KinesisFirehoseOutput\": {\n    \"ResourceARN\": \"string\"\n  },\n  \"LambdaOutput\": {\n    \"ResourceARN\": \"string\"\n  },\n  \"DestinationSchema\": {\n    \"RecordFormatType\": \"JSON\"|\"CSV\"\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe application Amazon Resource Name (ARN).\n\nApplicationVersionId -> (long)\n\nThe updated application version ID. Kinesis Data Analytics increments this ID when the application is updated.\n\nOutputDescriptions -> (list)\n\nDescribes the application output configuration. For more information, see Configuring Application Output .\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the application output configuration, which includes the in-application stream name and the destination where the stream data is written. The destination can be a Kinesis data stream or a Kinesis Data Firehose delivery stream.\n\nOutputId -> (string)\n\nA unique identifier for the output configuration.\n\nName -> (string)\n\nThe name of the in-application stream that is configured as output.\n\nKinesisStreamsOutputDescription -> (structure)\n\nDescribes the Kinesis data stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseOutputDescription -> (structure)\n\nDescribes the Kinesis Data Firehose delivery stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nLambdaOutputDescription -> (structure)\n\nDescribes the Lambda function that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the destination Lambda function.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to write to the destination function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nDestinationSchema -> (structure)\n\nThe data format used for writing data to the destination.\n\nRecordFormatType -> (string)\n\nSpecifies the format of the records on the output stream."
    },
    {
      "command_name": "add-application-reference-data-source",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/add-application-reference-data-source.html",
      "command_description": "Description\n\nAdds a reference data source to an existing SQL-based Kinesis Data Analytics application.\n\nKinesis Data Analytics reads reference data (that is, an Amazon S3 object) and creates an in-application table within your application. In the request, you provide the source (S3 bucket name and object key name), name of the in-application table to create, and the necessary mapping information that describes how data in an Amazon S3 object maps to columns in the resulting in-application table.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  add-application-reference-data-source\n--application-name <value>\n--current-application-version-id <value>\n--reference-data-source <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--current-application-version-id <value>",
        "--reference-data-source <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of an existing application.\n\n--current-application-version-id (long)\n\nThe version of the application for which you are adding the reference data source. You can use the DescribeApplication operation to get the current application version. If the version specified is not the current version, the ConcurrentModificationException is returned.\n\n--reference-data-source (structure)\n\nThe reference data source can be an object in your Amazon S3 bucket. Kinesis Data Analytics reads the object and copies the data into the in-application table that is created. You provide an S3 bucket, object key name, and the resulting in-application table that is created.\n\nTableName -> (string)\n\nThe name of the in-application table to create.\n\nS3ReferenceDataSource -> (structure)\n\nIdentifies the S3 bucket and object that contains the reference data. A Kinesis Data Analytics application loads reference data only once. If the data changes, you call the UpdateApplication operation to trigger reloading of data into your application.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nFileKey -> (string)\n\nThe object key name containing the reference data.\n\nReferenceSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns created in the in-application stream.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nJSON Syntax:\n\n{\n  \"TableName\": \"string\",\n  \"S3ReferenceDataSource\": {\n    \"BucketARN\": \"string\",\n    \"FileKey\": \"string\"\n  },\n  \"ReferenceSchema\": {\n    \"RecordFormat\": {\n      \"RecordFormatType\": \"JSON\"|\"CSV\",\n      \"MappingParameters\": {\n        \"JSONMappingParameters\": {\n          \"RecordRowPath\": \"string\"\n        },\n        \"CSVMappingParameters\": {\n          \"RecordRowDelimiter\": \"string\",\n          \"RecordColumnDelimiter\": \"string\"\n        }\n      }\n    },\n    \"RecordEncoding\": \"string\",\n    \"RecordColumns\": [\n      {\n        \"Name\": \"string\",\n        \"Mapping\": \"string\",\n        \"SqlType\": \"string\"\n      }\n      ...\n    ]\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe application Amazon Resource Name (ARN).\n\nApplicationVersionId -> (long)\n\nThe updated application version ID. Kinesis Data Analytics increments this ID when the application is updated.\n\nReferenceDataSourceDescriptions -> (list)\n\nDescribes reference data sources configured for the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the reference data source configured for an application.\n\nReferenceId -> (string)\n\nThe ID of the reference data source. This is the ID that Kinesis Data Analytics assigns when you add the reference data source to your application using the CreateApplication or UpdateApplication operation.\n\nTableName -> (string)\n\nThe in-application table name created by the specific reference data source configuration.\n\nS3ReferenceDataSourceDescription -> (structure)\n\nProvides the Amazon S3 bucket name, the object key name that contains the reference data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nFileKey -> (string)\n\nAmazon S3 object key name.\n\nReferenceRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to read the Amazon S3 object on your behalf to populate the in-application reference table.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nReferenceSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns created in the in-application stream.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table."
    },
    {
      "command_name": "add-application-vpc-configuration",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/add-application-vpc-configuration.html",
      "command_description": "Description\n\nAdds a Virtual Private Cloud (VPC) configuration to the application. Applications can use VPCs to store and access resources securely.\n\nNote the following about VPC configurations for Kinesis Data Analytics applications:\n\nVPC configurations are not supported for SQL applications.\n\nWhen a VPC is added to a Kinesis Data Analytics application, the application can no longer be accessed from the Internet directly. To enable Internet access to the application, add an Internet gateway to your VPC.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  add-application-vpc-configuration\n--application-name <value>\n[--current-application-version-id <value>]\n--vpc-configuration <value>\n[--conditional-token <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--current-application-version-id <value>]",
        "--vpc-configuration <value>",
        "[--conditional-token <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of an existing application.\n\n--current-application-version-id (long)\n\nThe version of the application to which you want to add the VPC configuration. You must provide the CurrentApplicationVersionId or the ConditionalToken . You can use the DescribeApplication operation to get the current application version. If the version specified is not the current version, the ConcurrentModificationException is returned. For better concurrency support, use the ConditionalToken parameter instead of CurrentApplicationVersionId .\n\n--vpc-configuration (structure)\n\nDescription of the VPC to add to the application.\n\nSubnetIds -> (list)\n\nThe array of Subnet IDs used by the VPC configuration.\n\n(string)\n\nSecurityGroupIds -> (list)\n\nThe array of SecurityGroup IDs used by the VPC configuration.\n\n(string)\n\nShorthand Syntax:\n\nSubnetIds=string,string,SecurityGroupIds=string,string\n\n\nJSON Syntax:\n\n{\n  \"SubnetIds\": [\"string\", ...],\n  \"SecurityGroupIds\": [\"string\", ...]\n}\n\n\n--conditional-token (string)\n\nA value you use to implement strong concurrency for application updates. You must provide the ApplicationVersionID or the ConditionalToken . You get the application’s current ConditionalToken using DescribeApplication . For better concurrency support, use the ConditionalToken parameter instead of CurrentApplicationVersionId .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe ARN of the application.\n\nApplicationVersionId -> (long)\n\nProvides the current application version. Kinesis Data Analytics updates the ApplicationVersionId each time you update the application.\n\nVpcConfigurationDescription -> (structure)\n\nThe parameters of the new VPC configuration.\n\nVpcConfigurationId -> (string)\n\nThe ID of the VPC configuration.\n\nVpcId -> (string)\n\nThe ID of the associated VPC.\n\nSubnetIds -> (list)\n\nThe array of Subnet IDs used by the VPC configuration.\n\n(string)\n\nSecurityGroupIds -> (list)\n\nThe array of SecurityGroup IDs used by the VPC configuration.\n\n(string)"
    },
    {
      "command_name": "create-application",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/create-application.html",
      "command_description": "Description\n\nCreates a Kinesis Data Analytics application. For information about creating a Kinesis Data Analytics application, see Creating an Application .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-application\n--application-name <value>\n[--application-description <value>]\n--runtime-environment <value>\n--service-execution-role <value>\n[--application-configuration <value>]\n[--cloud-watch-logging-options <value>]\n[--tags <value>]\n[--application-mode <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--application-description <value>]",
        "--runtime-environment <value>",
        "--service-execution-role <value>",
        "[--application-configuration <value>]",
        "[--cloud-watch-logging-options <value>]",
        "[--tags <value>]",
        "[--application-mode <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of your application (for example, sample-app ).\n\n--application-description (string)\n\nA summary description of the application.\n\n--runtime-environment (string)\n\nThe runtime environment for the application (SQL-1_0 , FLINK-1_6 , FLINK-1_8 , or FLINK-1_11 ).\n\nPossible values:\n\nSQL-1_0\n\nFLINK-1_6\n\nFLINK-1_8\n\nZEPPELIN-FLINK-1_0\n\nFLINK-1_11\n\nFLINK-1_13\n\nZEPPELIN-FLINK-2_0\n\n--service-execution-role (string)\n\nThe IAM role used by the application to access Kinesis data streams, Kinesis Data Firehose delivery streams, Amazon S3 objects, and other external resources.\n\n--application-configuration (structure)\n\nUse this parameter to configure the application.\n\nSqlApplicationConfiguration -> (structure)\n\nThe creation and update parameters for a SQL-based Kinesis Data Analytics application.\n\nInputs -> (list)\n\nThe array of Input objects describing the input streams used by the application.\n\n(structure)\n\nWhen you configure the application input for a SQL-based Kinesis Data Analytics application, you specify the streaming source, the in-application stream name that is created, and the mapping between the two.\n\nNamePrefix -> (string)\n\nThe name prefix to use when creating an in-application stream. Suppose that you specify a prefix “MyInApplicationStream .” Kinesis Data Analytics then creates one or more (as per the InputParallelism count you specified) in-application streams with the names “MyInApplicationStream_001 ,” “MyInApplicationStream_002 ,” and so on.\n\nInputProcessingConfiguration -> (structure)\n\nThe InputProcessingConfiguration for the input. An input processor transforms records as they are received from the stream, before the application’s SQL code executes. Currently, the only input processing configuration available is InputLambdaProcessor .\n\nInputLambdaProcessor -> (structure)\n\nThe InputLambdaProcessor that is used to preprocess the records in the stream before being processed by your application code.\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that operates on records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nKinesisStreamsInput -> (structure)\n\nIf the streaming source is an Amazon Kinesis data stream, identifies the stream’s Amazon Resource Name (ARN).\n\nResourceARN -> (string)\n\nThe ARN of the input Kinesis data stream to read.\n\nKinesisFirehoseInput -> (structure)\n\nIf the streaming source is an Amazon Kinesis Data Firehose delivery stream, identifies the delivery stream’s ARN.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nInputParallelism -> (structure)\n\nDescribes the number of in-application streams to create.\n\nCount -> (integer)\n\nThe number of in-application streams to create.\n\nInputSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns in the in-application stream that is being created.\n\nAlso used to describe the format of the reference data source.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nOutputs -> (list)\n\nThe array of Output objects describing the destination streams used by the application.\n\n(structure)\n\nDescribes a SQL-based Kinesis Data Analytics application’s output configuration, in which you identify an in-application stream and a destination where you want the in-application stream data to be written. The destination can be a Kinesis data stream or a Kinesis Data Firehose delivery stream.\n\nName -> (string)\n\nThe name of the in-application stream.\n\nKinesisStreamsOutput -> (structure)\n\nIdentifies a Kinesis data stream as the destination.\n\nResourceARN -> (string)\n\nThe ARN of the destination Kinesis data stream to write to.\n\nKinesisFirehoseOutput -> (structure)\n\nIdentifies a Kinesis Data Firehose delivery stream as the destination.\n\nResourceARN -> (string)\n\nThe ARN of the destination delivery stream to write to.\n\nLambdaOutput -> (structure)\n\nIdentifies an Amazon Lambda function as the destination.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the destination Lambda function to write to.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nDestinationSchema -> (structure)\n\nDescribes the data format when records are written to the destination.\n\nRecordFormatType -> (string)\n\nSpecifies the format of the records on the output stream.\n\nReferenceDataSources -> (list)\n\nThe array of ReferenceDataSource objects describing the reference data sources used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the reference data source by providing the source information (Amazon S3 bucket name and object key name), the resulting in-application table name that is created, and the necessary schema to map the data elements in the Amazon S3 object to the in-application table.\n\nTableName -> (string)\n\nThe name of the in-application table to create.\n\nS3ReferenceDataSource -> (structure)\n\nIdentifies the S3 bucket and object that contains the reference data. A Kinesis Data Analytics application loads reference data only once. If the data changes, you call the UpdateApplication operation to trigger reloading of data into your application.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nFileKey -> (string)\n\nThe object key name containing the reference data.\n\nReferenceSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns created in the in-application stream.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nFlinkApplicationConfiguration -> (structure)\n\nThe creation and update parameters for a Flink-based Kinesis Data Analytics application.\n\nCheckpointConfiguration -> (structure)\n\nDescribes an application’s checkpointing configuration. Checkpointing is the process of persisting application state for fault tolerance. For more information, see Checkpoints for Fault Tolerance in the Apache Flink Documentation .\n\nConfigurationType -> (string)\n\nDescribes whether the application uses Kinesis Data Analytics’ default checkpointing behavior. You must set this property to CUSTOM in order to set the CheckpointingEnabled , CheckpointInterval , or MinPauseBetweenCheckpoints parameters.\n\nNote\n\nIf this value is set to DEFAULT , the application will use the following values, even if they are set to other values using APIs or application code:\n\nCheckpointingEnabled: true\n\nCheckpointInterval: 60000\n\nMinPauseBetweenCheckpoints: 5000\n\nCheckpointingEnabled -> (boolean)\n\nDescribes whether checkpointing is enabled for a Flink-based Kinesis Data Analytics application.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointingEnabled value of true , even if this value is set to another value using this API or in application code.\n\nCheckpointInterval -> (long)\n\nDescribes the interval in milliseconds between checkpoint operations.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointInterval value of 60000, even if this value is set to another value using this API or in application code.\n\nMinPauseBetweenCheckpoints -> (long)\n\nDescribes the minimum time in milliseconds after a checkpoint operation completes that a new checkpoint operation can start. If a checkpoint operation takes longer than the CheckpointInterval , the application otherwise performs continual checkpoint operations. For more information, see Tuning Checkpointing in the Apache Flink Documentation .\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a MinPauseBetweenCheckpoints value of 5000, even if this value is set using this API or in application code.\n\nMonitoringConfiguration -> (structure)\n\nDescribes configuration parameters for Amazon CloudWatch logging for an application.\n\nConfigurationType -> (string)\n\nDescribes whether to use the default CloudWatch logging configuration for an application. You must set this property to CUSTOM in order to set the LogLevel or MetricsLevel parameters.\n\nMetricsLevel -> (string)\n\nDescribes the granularity of the CloudWatch Logs for an application. The Parallelism level is not recommended for applications with a Parallelism over 64 due to excessive costs.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nParallelismConfiguration -> (structure)\n\nDescribes parameters for how an application executes multiple tasks simultaneously.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default parallelism for the Kinesis Data Analytics service. You must set this property to CUSTOM in order to change your application’s AutoScalingEnabled , Parallelism , or ParallelismPerKPU properties.\n\nParallelism -> (integer)\n\nDescribes the initial number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, Kinesis Data Analytics increases the CurrentParallelism value in response to application load. The service can increase the CurrentParallelism value up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nParallelismPerKPU -> (integer)\n\nDescribes the number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform per Kinesis Processing Unit (KPU) used by the application. For more information about KPUs, see Amazon Kinesis Data Analytics Pricing .\n\nAutoScalingEnabled -> (boolean)\n\nDescribes whether the Kinesis Data Analytics service can increase the parallelism of the application in response to increased throughput.\n\nEnvironmentProperties -> (structure)\n\nDescribes execution properties for a Flink-based Kinesis Data Analytics application.\n\nPropertyGroups -> (list)\n\nDescribes the execution property groups.\n\n(structure)\n\nProperty key-value pairs passed into an application.\n\nPropertyGroupId -> (string)\n\nDescribes the key of an application execution property key-value pair.\n\nPropertyMap -> (map)\n\nDescribes the value of an application execution property key-value pair.\n\nkey -> (string)\n\nvalue -> (string)\n\nApplicationCodeConfiguration -> (structure)\n\nThe code location and type parameters for a Flink-based Kinesis Data Analytics application.\n\nCodeContent -> (structure)\n\nThe location and type of the application code.\n\nTextContent -> (string)\n\nThe text-format code for a Flink-based Kinesis Data Analytics application.\n\nZipFileContent -> (blob)\n\nThe zip-format code for a Flink-based Kinesis Data Analytics application.\n\nS3ContentLocation -> (structure)\n\nInformation about the Amazon S3 bucket that contains the application code.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nCodeContentType -> (string)\n\nSpecifies whether the code content is in text or zip format.\n\nApplicationSnapshotConfiguration -> (structure)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nSnapshotsEnabled -> (boolean)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nVpcConfigurations -> (list)\n\nThe array of descriptions of VPC configurations available to the application.\n\n(structure)\n\nDescribes the parameters of a VPC used by the application.\n\nSubnetIds -> (list)\n\nThe array of Subnet IDs used by the VPC configuration.\n\n(string)\n\nSecurityGroupIds -> (list)\n\nThe array of SecurityGroup IDs used by the VPC configuration.\n\n(string)\n\nZeppelinApplicationConfiguration -> (structure)\n\nThe configuration parameters for a Kinesis Data Analytics Studio notebook.\n\nMonitoringConfiguration -> (structure)\n\nThe monitoring configuration of a Kinesis Data Analytics Studio notebook.\n\nLogLevel -> (string)\n\nThe verbosity of the CloudWatch Logs for an application.\n\nCatalogConfiguration -> (structure)\n\nThe Amazon Glue Data Catalog that you use in queries in a Kinesis Data Analytics Studio notebook.\n\nGlueDataCatalogConfiguration -> (structure)\n\nThe configuration parameters for the default Amazon Glue database. You use this database for Apache Flink SQL queries and table API transforms that you write in a Kinesis Data Analytics Studio notebook.\n\nDatabaseARN -> (string)\n\nThe Amazon Resource Name (ARN) of the database.\n\nDeployAsApplicationConfiguration -> (structure)\n\nThe information required to deploy a Kinesis Data Analytics Studio notebook as an application with durable state.\n\nS3ContentLocation -> (structure)\n\nThe description of an Amazon S3 object that contains the Amazon Data Analytics application, including the Amazon Resource Name (ARN) of the S3 bucket, the name of the Amazon S3 object that contains the data, and the version number of the Amazon S3 object that contains the data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nBasePath -> (string)\n\nThe base path for the S3 bucket.\n\nCustomArtifactsConfiguration -> (list)\n\nCustom artifacts are dependency JARs and user-defined functions (UDF).\n\n(structure)\n\nSpecifies dependency JARs, as well as JAR files that contain user-defined functions (UDF).\n\nArtifactType -> (string)\n\nUDF stands for user-defined functions. This type of artifact must be in an S3 bucket. A DEPENDENCY_JAR can be in either Maven or an S3 bucket.\n\nS3ContentLocation -> (structure)\n\nFor a Kinesis Data Analytics application provides a description of an Amazon S3 object, including the Amazon Resource Name (ARN) of the S3 bucket, the name of the Amazon S3 object that contains the data, and the version number of the Amazon S3 object that contains the data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nMavenReference -> (structure)\n\nThe parameters required to fully specify a Maven reference.\n\nGroupId -> (string)\n\nThe group ID of the Maven reference.\n\nArtifactId -> (string)\n\nThe artifact ID of the Maven reference.\n\nVersion -> (string)\n\nThe version of the Maven reference.\n\nJSON Syntax:\n\n{\n  \"SqlApplicationConfiguration\": {\n    \"Inputs\": [\n      {\n        \"NamePrefix\": \"string\",\n        \"InputProcessingConfiguration\": {\n          \"InputLambdaProcessor\": {\n            \"ResourceARN\": \"string\"\n          }\n        },\n        \"KinesisStreamsInput\": {\n          \"ResourceARN\": \"string\"\n        },\n        \"KinesisFirehoseInput\": {\n          \"ResourceARN\": \"string\"\n        },\n        \"InputParallelism\": {\n          \"Count\": integer\n        },\n        \"InputSchema\": {\n          \"RecordFormat\": {\n            \"RecordFormatType\": \"JSON\"|\"CSV\",\n            \"MappingParameters\": {\n              \"JSONMappingParameters\": {\n                \"RecordRowPath\": \"string\"\n              },\n              \"CSVMappingParameters\": {\n                \"RecordRowDelimiter\": \"string\",\n                \"RecordColumnDelimiter\": \"string\"\n              }\n            }\n          },\n          \"RecordEncoding\": \"string\",\n          \"RecordColumns\": [\n            {\n              \"Name\": \"string\",\n              \"Mapping\": \"string\",\n              \"SqlType\": \"string\"\n            }\n            ...\n          ]\n        }\n      }\n      ...\n    ],\n    \"Outputs\": [\n      {\n        \"Name\": \"string\",\n        \"KinesisStreamsOutput\": {\n          \"ResourceARN\": \"string\"\n        },\n        \"KinesisFirehoseOutput\": {\n          \"ResourceARN\": \"string\"\n        },\n        \"LambdaOutput\": {\n          \"ResourceARN\": \"string\"\n        },\n        \"DestinationSchema\": {\n          \"RecordFormatType\": \"JSON\"|\"CSV\"\n        }\n      }\n      ...\n    ],\n    \"ReferenceDataSources\": [\n      {\n        \"TableName\": \"string\",\n        \"S3ReferenceDataSource\": {\n          \"BucketARN\": \"string\",\n          \"FileKey\": \"string\"\n        },\n        \"ReferenceSchema\": {\n          \"RecordFormat\": {\n            \"RecordFormatType\": \"JSON\"|\"CSV\",\n            \"MappingParameters\": {\n              \"JSONMappingParameters\": {\n                \"RecordRowPath\": \"string\"\n              },\n              \"CSVMappingParameters\": {\n                \"RecordRowDelimiter\": \"string\",\n                \"RecordColumnDelimiter\": \"string\"\n              }\n            }\n          },\n          \"RecordEncoding\": \"string\",\n          \"RecordColumns\": [\n            {\n              \"Name\": \"string\",\n              \"Mapping\": \"string\",\n              \"SqlType\": \"string\"\n            }\n            ...\n          ]\n        }\n      }\n      ...\n    ]\n  },\n  \"FlinkApplicationConfiguration\": {\n    \"CheckpointConfiguration\": {\n      \"ConfigurationType\": \"DEFAULT\"|\"CUSTOM\",\n      \"CheckpointingEnabled\": true|false,\n      \"CheckpointInterval\": long,\n      \"MinPauseBetweenCheckpoints\": long\n    },\n    \"MonitoringConfiguration\": {\n      \"ConfigurationType\": \"DEFAULT\"|\"CUSTOM\",\n      \"MetricsLevel\": \"APPLICATION\"|\"TASK\"|\"OPERATOR\"|\"PARALLELISM\",\n      \"LogLevel\": \"INFO\"|\"WARN\"|\"ERROR\"|\"DEBUG\"\n    },\n    \"ParallelismConfiguration\": {\n      \"ConfigurationType\": \"DEFAULT\"|\"CUSTOM\",\n      \"Parallelism\": integer,\n      \"ParallelismPerKPU\": integer,\n      \"AutoScalingEnabled\": true|false\n    }\n  },\n  \"EnvironmentProperties\": {\n    \"PropertyGroups\": [\n      {\n        \"PropertyGroupId\": \"string\",\n        \"PropertyMap\": {\"string\": \"string\"\n          ...}\n      }\n      ...\n    ]\n  },\n  \"ApplicationCodeConfiguration\": {\n    \"CodeContent\": {\n      \"TextContent\": \"string\",\n      \"ZipFileContent\": blob,\n      \"S3ContentLocation\": {\n        \"BucketARN\": \"string\",\n        \"FileKey\": \"string\",\n        \"ObjectVersion\": \"string\"\n      }\n    },\n    \"CodeContentType\": \"PLAINTEXT\"|\"ZIPFILE\"\n  },\n  \"ApplicationSnapshotConfiguration\": {\n    \"SnapshotsEnabled\": true|false\n  },\n  \"VpcConfigurations\": [\n    {\n      \"SubnetIds\": [\"string\", ...],\n      \"SecurityGroupIds\": [\"string\", ...]\n    }\n    ...\n  ],\n  \"ZeppelinApplicationConfiguration\": {\n    \"MonitoringConfiguration\": {\n      \"LogLevel\": \"INFO\"|\"WARN\"|\"ERROR\"|\"DEBUG\"\n    },\n    \"CatalogConfiguration\": {\n      \"GlueDataCatalogConfiguration\": {\n        \"DatabaseARN\": \"string\"\n      }\n    },\n    \"DeployAsApplicationConfiguration\": {\n      \"S3ContentLocation\": {\n        \"BucketARN\": \"string\",\n        \"BasePath\": \"string\"\n      }\n    },\n    \"CustomArtifactsConfiguration\": [\n      {\n        \"ArtifactType\": \"UDF\"|\"DEPENDENCY_JAR\",\n        \"S3ContentLocation\": {\n          \"BucketARN\": \"string\",\n          \"FileKey\": \"string\",\n          \"ObjectVersion\": \"string\"\n        },\n        \"MavenReference\": {\n          \"GroupId\": \"string\",\n          \"ArtifactId\": \"string\",\n          \"Version\": \"string\"\n        }\n      }\n      ...\n    ]\n  }\n}\n\n\n--cloud-watch-logging-options (list)\n\nUse this parameter to configure an Amazon CloudWatch log stream to monitor application configuration errors.\n\n(structure)\n\nProvides a description of Amazon CloudWatch logging options, including the log stream Amazon Resource Name (ARN).\n\nLogStreamARN -> (string)\n\nThe ARN of the CloudWatch log to receive application messages.\n\nShorthand Syntax:\n\nLogStreamARN=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"LogStreamARN\": \"string\"\n  }\n  ...\n]\n\n\n--tags (list)\n\nA list of one or more tags to assign to the application. A tag is a key-value pair that identifies an application. Note that the maximum number of application tags includes system tags. The maximum number of user-defined application tags is 50. For more information, see Using Tagging .\n\n(structure)\n\nA key-value pair (the value is optional) that you can define and assign to Amazon resources. If you specify a tag that already exists, the tag value is replaced with the value that you specify in the request. Note that the maximum number of application tags includes system tags. The maximum number of user-defined application tags is 50. For more information, see Using Tagging .\n\nKey -> (string)\n\nThe key of the key-value tag.\n\nValue -> (string)\n\nThe value of the key-value tag. The value is optional.\n\nShorthand Syntax:\n\nKey=string,Value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Key\": \"string\",\n    \"Value\": \"string\"\n  }\n  ...\n]\n\n\n--application-mode (string)\n\nUse the STREAMING mode to create a Kinesis Data Analytics Studio notebook. To create a Kinesis Data Analytics Studio notebook, use the INTERACTIVE mode.\n\nPossible values:\n\nSTREAMING\n\nINTERACTIVE\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationDetail -> (structure)\n\nIn response to your CreateApplication request, Kinesis Data Analytics returns a response with details of the application it created.\n\nApplicationARN -> (string)\n\nThe ARN of the application.\n\nApplicationDescription -> (string)\n\nThe description of the application.\n\nApplicationName -> (string)\n\nThe name of the application.\n\nRuntimeEnvironment -> (string)\n\nThe runtime environment for the application (SQL-1_0 , FLINK-1_6 , FLINK-1_8 , or FLINK-1_11 ).\n\nServiceExecutionRole -> (string)\n\nSpecifies the IAM role that the application uses to access external resources.\n\nApplicationStatus -> (string)\n\nThe status of the application.\n\nApplicationVersionId -> (long)\n\nProvides the current application version. Kinesis Data Analytics updates the ApplicationVersionId each time you update the application.\n\nCreateTimestamp -> (timestamp)\n\nThe current timestamp when the application was created.\n\nLastUpdateTimestamp -> (timestamp)\n\nThe current timestamp when the application was last updated.\n\nApplicationConfigurationDescription -> (structure)\n\nDescribes details about the application code and starting parameters for a Kinesis Data Analytics application.\n\nSqlApplicationConfigurationDescription -> (structure)\n\nThe details about inputs, outputs, and reference data sources for a SQL-based Kinesis Data Analytics application.\n\nInputDescriptions -> (list)\n\nThe array of InputDescription objects describing the input streams used by the application.\n\n(structure)\n\nDescribes the application input configuration for a SQL-based Kinesis Data Analytics application.\n\nInputId -> (string)\n\nThe input ID that is associated with the application input. This is the ID that Kinesis Data Analytics assigns to each input configuration that you add to your application.\n\nNamePrefix -> (string)\n\nThe in-application name prefix.\n\nInAppStreamNames -> (list)\n\nReturns the in-application stream names that are mapped to the stream source.\n\n(string)\n\nInputProcessingConfigurationDescription -> (structure)\n\nThe description of the preprocessor that executes on records in this input before the application’s code is run.\n\nInputLambdaProcessorDescription -> (structure)\n\nProvides configuration information about the associated InputLambdaProcessorDescription\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that is used to preprocess the records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that is used to access the Amazon Lambda function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisStreamsInputDescription -> (structure)\n\nIf a Kinesis data stream is configured as a streaming source, provides the Kinesis data stream’s Amazon Resource Name (ARN).\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseInputDescription -> (structure)\n\nIf a Kinesis Data Firehose delivery stream is configured as a streaming source, provides the delivery stream’s ARN.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics assumes to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nInputSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns in the in-application stream that is being created.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nInputParallelism -> (structure)\n\nDescribes the configured parallelism (number of in-application streams mapped to the streaming source).\n\nCount -> (integer)\n\nThe number of in-application streams to create.\n\nInputStartingPositionConfiguration -> (structure)\n\nThe point at which the application is configured to read from the input stream.\n\nInputStartingPosition -> (string)\n\nThe starting position on the stream.\n\nNOW - Start reading just after the most recent record in the stream, and start at the request timestamp that the customer issued.\n\nTRIM_HORIZON - Start reading at the last untrimmed record in the stream, which is the oldest record available in the stream. This option is not available for an Amazon Kinesis Data Firehose delivery stream.\n\nLAST_STOPPED_POINT - Resume reading from where the application last stopped reading.\n\nOutputDescriptions -> (list)\n\nThe array of OutputDescription objects describing the destination streams used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the application output configuration, which includes the in-application stream name and the destination where the stream data is written. The destination can be a Kinesis data stream or a Kinesis Data Firehose delivery stream.\n\nOutputId -> (string)\n\nA unique identifier for the output configuration.\n\nName -> (string)\n\nThe name of the in-application stream that is configured as output.\n\nKinesisStreamsOutputDescription -> (structure)\n\nDescribes the Kinesis data stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseOutputDescription -> (structure)\n\nDescribes the Kinesis Data Firehose delivery stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nLambdaOutputDescription -> (structure)\n\nDescribes the Lambda function that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the destination Lambda function.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to write to the destination function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nDestinationSchema -> (structure)\n\nThe data format used for writing data to the destination.\n\nRecordFormatType -> (string)\n\nSpecifies the format of the records on the output stream.\n\nReferenceDataSourceDescriptions -> (list)\n\nThe array of ReferenceDataSourceDescription objects describing the reference data sources used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the reference data source configured for an application.\n\nReferenceId -> (string)\n\nThe ID of the reference data source. This is the ID that Kinesis Data Analytics assigns when you add the reference data source to your application using the CreateApplication or UpdateApplication operation.\n\nTableName -> (string)\n\nThe in-application table name created by the specific reference data source configuration.\n\nS3ReferenceDataSourceDescription -> (structure)\n\nProvides the Amazon S3 bucket name, the object key name that contains the reference data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nFileKey -> (string)\n\nAmazon S3 object key name.\n\nReferenceRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to read the Amazon S3 object on your behalf to populate the in-application reference table.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nReferenceSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns created in the in-application stream.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nApplicationCodeConfigurationDescription -> (structure)\n\nThe details about the application code for a Flink-based Kinesis Data Analytics application.\n\nCodeContentType -> (string)\n\nSpecifies whether the code content is in text or zip format.\n\nCodeContentDescription -> (structure)\n\nDescribes details about the location and format of the application code.\n\nTextContent -> (string)\n\nThe text-format code\n\nCodeMD5 -> (string)\n\nThe checksum that can be used to validate zip-format code.\n\nCodeSize -> (long)\n\nThe size in bytes of the application code. Can be used to validate zip-format code.\n\nS3ApplicationCodeLocationDescription -> (structure)\n\nThe S3 bucket Amazon Resource Name (ARN), file key, and object version of the application code stored in Amazon S3.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nRunConfigurationDescription -> (structure)\n\nThe details about the starting properties for a Kinesis Data Analytics application.\n\nApplicationRestoreConfigurationDescription -> (structure)\n\nDescribes the restore behavior of a restarting application.\n\nApplicationRestoreType -> (string)\n\nSpecifies how the application should be restored.\n\nSnapshotName -> (string)\n\nThe identifier of an existing snapshot of application state to use to restart an application. The application uses this value if RESTORE_FROM_CUSTOM_SNAPSHOT is specified for the ApplicationRestoreType .\n\nFlinkRunConfigurationDescription -> (structure)\n\nDescribes the starting parameters for a Flink-based Kinesis Data Analytics application.\n\nAllowNonRestoredState -> (boolean)\n\nWhen restoring from a snapshot, specifies whether the runtime is allowed to skip a state that cannot be mapped to the new program. This will happen if the program is updated between snapshots to remove stateful parameters, and state data in the snapshot no longer corresponds to valid application data. For more information, see Allowing Non-Restored State in the Apache Flink documentation .\n\nNote\n\nThis value defaults to false . If you update your application without specifying this parameter, AllowNonRestoredState will be set to false , even if it was previously set to true .\n\nFlinkApplicationConfigurationDescription -> (structure)\n\nThe details about a Flink-based Kinesis Data Analytics application.\n\nCheckpointConfigurationDescription -> (structure)\n\nDescribes an application’s checkpointing configuration. Checkpointing is the process of persisting application state for fault tolerance.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default checkpointing behavior in Kinesis Data Analytics.\n\nNote\n\nIf this value is set to DEFAULT , the application will use the following values, even if they are set to other values using APIs or application code:\n\nCheckpointingEnabled: true\n\nCheckpointInterval: 60000\n\nMinPauseBetweenCheckpoints: 5000\n\nCheckpointingEnabled -> (boolean)\n\nDescribes whether checkpointing is enabled for a Flink-based Kinesis Data Analytics application.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointingEnabled value of true , even if this value is set to another value using this API or in application code.\n\nCheckpointInterval -> (long)\n\nDescribes the interval in milliseconds between checkpoint operations.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointInterval value of 60000, even if this value is set to another value using this API or in application code.\n\nMinPauseBetweenCheckpoints -> (long)\n\nDescribes the minimum time in milliseconds after a checkpoint operation completes that a new checkpoint operation can start.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a MinPauseBetweenCheckpoints value of 5000, even if this value is set using this API or in application code.\n\nMonitoringConfigurationDescription -> (structure)\n\nDescribes configuration parameters for Amazon CloudWatch logging for an application.\n\nConfigurationType -> (string)\n\nDescribes whether to use the default CloudWatch logging configuration for an application.\n\nMetricsLevel -> (string)\n\nDescribes the granularity of the CloudWatch Logs for an application.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nParallelismConfigurationDescription -> (structure)\n\nDescribes parameters for how an application executes multiple tasks simultaneously.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default parallelism for the Kinesis Data Analytics service.\n\nParallelism -> (integer)\n\nDescribes the initial number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, then Kinesis Data Analytics can increase the CurrentParallelism value in response to application load. The service can increase CurrentParallelism up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nParallelismPerKPU -> (integer)\n\nDescribes the number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform per Kinesis Processing Unit (KPU) used by the application.\n\nCurrentParallelism -> (integer)\n\nDescribes the current number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, Kinesis Data Analytics can increase this value in response to application load. The service can increase this value up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nAutoScalingEnabled -> (boolean)\n\nDescribes whether the Kinesis Data Analytics service can increase the parallelism of the application in response to increased throughput.\n\nJobPlanDescription -> (string)\n\nThe job plan for an application. For more information about the job plan, see Jobs and Scheduling in the Apache Flink Documentation . To retrieve the job plan for the application, use the DescribeApplicationRequest$IncludeAdditionalDetails parameter of the DescribeApplication operation.\n\nEnvironmentPropertyDescriptions -> (structure)\n\nDescribes execution properties for a Flink-based Kinesis Data Analytics application.\n\nPropertyGroupDescriptions -> (list)\n\nDescribes the execution property groups.\n\n(structure)\n\nProperty key-value pairs passed into an application.\n\nPropertyGroupId -> (string)\n\nDescribes the key of an application execution property key-value pair.\n\nPropertyMap -> (map)\n\nDescribes the value of an application execution property key-value pair.\n\nkey -> (string)\n\nvalue -> (string)\n\nApplicationSnapshotConfigurationDescription -> (structure)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nSnapshotsEnabled -> (boolean)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nVpcConfigurationDescriptions -> (list)\n\nThe array of descriptions of VPC configurations available to the application.\n\n(structure)\n\nDescribes the parameters of a VPC used by the application.\n\nVpcConfigurationId -> (string)\n\nThe ID of the VPC configuration.\n\nVpcId -> (string)\n\nThe ID of the associated VPC.\n\nSubnetIds -> (list)\n\nThe array of Subnet IDs used by the VPC configuration.\n\n(string)\n\nSecurityGroupIds -> (list)\n\nThe array of SecurityGroup IDs used by the VPC configuration.\n\n(string)\n\nZeppelinApplicationConfigurationDescription -> (structure)\n\nThe configuration parameters for a Kinesis Data Analytics Studio notebook.\n\nMonitoringConfigurationDescription -> (structure)\n\nThe monitoring configuration of a Kinesis Data Analytics Studio notebook.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nCatalogConfigurationDescription -> (structure)\n\nThe Amazon Glue Data Catalog that is associated with the Kinesis Data Analytics Studio notebook.\n\nGlueDataCatalogConfigurationDescription -> (structure)\n\nThe configuration parameters for the default Amazon Glue database. You use this database for SQL queries that you write in a Kinesis Data Analytics Studio notebook.\n\nDatabaseARN -> (string)\n\nThe Amazon Resource Name (ARN) of the database.\n\nDeployAsApplicationConfigurationDescription -> (structure)\n\nThe parameters required to deploy a Kinesis Data Analytics Studio notebook as an application with durable state.\n\nS3ContentLocationDescription -> (structure)\n\nThe location that holds the data required to specify an Amazon Data Analytics application.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nBasePath -> (string)\n\nThe base path for the S3 bucket.\n\nCustomArtifactsConfigurationDescription -> (list)\n\nCustom artifacts are dependency JARs and user-defined functions (UDF).\n\n(structure)\n\nSpecifies a dependency JAR or a JAR of user-defined functions.\n\nArtifactType -> (string)\n\nUDF stands for user-defined functions. This type of artifact must be in an S3 bucket. A DEPENDENCY_JAR can be in either Maven or an S3 bucket.\n\nS3ContentLocationDescription -> (structure)\n\nFor a Kinesis Data Analytics application provides a description of an Amazon S3 object, including the Amazon Resource Name (ARN) of the S3 bucket, the name of the Amazon S3 object that contains the data, and the version number of the Amazon S3 object that contains the data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nMavenReferenceDescription -> (structure)\n\nThe parameters that are required to specify a Maven dependency.\n\nGroupId -> (string)\n\nThe group ID of the Maven reference.\n\nArtifactId -> (string)\n\nThe artifact ID of the Maven reference.\n\nVersion -> (string)\n\nThe version of the Maven reference.\n\nCloudWatchLoggingOptionDescriptions -> (list)\n\nDescribes the application Amazon CloudWatch logging options.\n\n(structure)\n\nDescribes the Amazon CloudWatch logging option.\n\nCloudWatchLoggingOptionId -> (string)\n\nThe ID of the CloudWatch logging option description.\n\nLogStreamARN -> (string)\n\nThe Amazon Resource Name (ARN) of the CloudWatch log to receive application messages.\n\nRoleARN -> (string)\n\nThe IAM ARN of the role to use to send application messages.\n\nNote\n\nProvided for backward compatibility. Applications created with the current API version have an application-level service execution role rather than a resource-level role.\n\nApplicationMaintenanceConfigurationDescription -> (structure)\n\nThe details of the maintenance configuration for the application.\n\nApplicationMaintenanceWindowStartTime -> (string)\n\nThe start time for the maintenance window.\n\nApplicationMaintenanceWindowEndTime -> (string)\n\nThe end time for the maintenance window.\n\nApplicationVersionUpdatedFrom -> (long)\n\nThe previous application version before the latest application update. RollbackApplication reverts the application to this version.\n\nApplicationVersionRolledBackFrom -> (long)\n\nIf you reverted the application using RollbackApplication , the application version when RollbackApplication was called.\n\nConditionalToken -> (string)\n\nA value you use to implement strong concurrency for application updates.\n\nApplicationVersionRolledBackTo -> (long)\n\nThe version to which you want to roll back the application.\n\nApplicationMode -> (string)\n\nTo create a Kinesis Data Analytics Studio notebook, you must set the mode to INTERACTIVE . However, for a Kinesis Data Analytics for Apache Flink application, the mode is optional."
    },
    {
      "command_name": "create-application-presigned-url",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/create-application-presigned-url.html",
      "command_description": "Description\n\nCreates and returns a URL that you can use to connect to an application’s extension. Currently, the only available extension is the Apache Flink dashboard.\n\nThe IAM role or user used to call this API defines the permissions to access the extension. After the presigned URL is created, no additional permission is required to access this URL. IAM authorization policies for this API are also enforced for every HTTP request that attempts to connect to the extension.\n\nYou control the amount of time that the URL will be valid using the SessionExpirationDurationInSeconds parameter. If you do not provide this parameter, the returned URL is valid for twelve hours.\n\nNote\n\nThe URL that you get from a call to CreateApplicationPresignedUrl must be used within 3 minutes to be valid. If you first try to use the URL after the 3-minute limit expires, the service returns an HTTP 403 Forbidden error.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-application-presigned-url\n--application-name <value>\n--url-type <value>\n[--session-expiration-duration-in-seconds <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--url-type <value>",
        "[--session-expiration-duration-in-seconds <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application.\n\n--url-type (string)\n\nThe type of the extension for which to create and return a URL. Currently, the only valid extension URL type is FLINK_DASHBOARD_URL .\n\nPossible values:\n\nFLINK_DASHBOARD_URL\n\nZEPPELIN_UI_URL\n\n--session-expiration-duration-in-seconds (long)\n\nThe duration in seconds for which the returned URL will be valid.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nAuthorizedUrl -> (string)\n\nThe URL of the extension."
    },
    {
      "command_name": "create-application-snapshot",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/create-application-snapshot.html",
      "command_description": "Description\n\nCreates a snapshot of the application’s state data.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-application-snapshot\n--application-name <value>\n--snapshot-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--snapshot-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of an existing application\n\n--snapshot-name (string)\n\nAn identifier for the application snapshot.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "delete-application",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/delete-application.html",
      "command_description": "Description\n\nDeletes the specified application. Kinesis Data Analytics halts application execution and deletes the application.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-application\n--application-name <value>\n--create-timestamp <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--create-timestamp <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application to delete.\n\n--create-timestamp (timestamp)\n\nUse the DescribeApplication operation to get this value.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "delete-application-cloud-watch-logging-option",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/delete-application-cloud-watch-logging-option.html",
      "command_description": "Description\n\nDeletes an Amazon CloudWatch log stream from an Kinesis Data Analytics application.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-application-cloud-watch-logging-option\n--application-name <value>\n[--current-application-version-id <value>]\n--cloud-watch-logging-option-id <value>\n[--conditional-token <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--current-application-version-id <value>]",
        "--cloud-watch-logging-option-id <value>",
        "[--conditional-token <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe application name.\n\n--current-application-version-id (long)\n\nThe version ID of the application. You must provide the CurrentApplicationVersionId or the ConditionalToken . You can retrieve the application version ID using DescribeApplication . For better concurrency support, use the ConditionalToken parameter instead of CurrentApplicationVersionId .\n\n--cloud-watch-logging-option-id (string)\n\nThe CloudWatchLoggingOptionId of the Amazon CloudWatch logging option to delete. You can get the CloudWatchLoggingOptionId by using the DescribeApplication operation.\n\n--conditional-token (string)\n\nA value you use to implement strong concurrency for application updates. You must provide the CurrentApplicationVersionId or the ConditionalToken . You get the application’s current ConditionalToken using DescribeApplication . For better concurrency support, use the ConditionalToken parameter instead of CurrentApplicationVersionId .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe application’s Amazon Resource Name (ARN).\n\nApplicationVersionId -> (long)\n\nThe version ID of the application. Kinesis Data Analytics updates the ApplicationVersionId each time you change the CloudWatch logging options.\n\nCloudWatchLoggingOptionDescriptions -> (list)\n\nThe descriptions of the remaining CloudWatch logging options for the application.\n\n(structure)\n\nDescribes the Amazon CloudWatch logging option.\n\nCloudWatchLoggingOptionId -> (string)\n\nThe ID of the CloudWatch logging option description.\n\nLogStreamARN -> (string)\n\nThe Amazon Resource Name (ARN) of the CloudWatch log to receive application messages.\n\nRoleARN -> (string)\n\nThe IAM ARN of the role to use to send application messages.\n\nNote\n\nProvided for backward compatibility. Applications created with the current API version have an application-level service execution role rather than a resource-level role."
    },
    {
      "command_name": "delete-application-input-processing-configuration",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/delete-application-input-processing-configuration.html",
      "command_description": "Description\n\nDeletes an InputProcessingConfiguration from an input.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-application-input-processing-configuration\n--application-name <value>\n--current-application-version-id <value>\n--input-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--current-application-version-id <value>",
        "--input-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application.\n\n--current-application-version-id (long)\n\nThe application version. You can use the DescribeApplication operation to get the current application version. If the version specified is not the current version, the ConcurrentModificationException is returned.\n\n--input-id (string)\n\nThe ID of the input configuration from which to delete the input processing configuration. You can get a list of the input IDs for an application by using the DescribeApplication operation.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe Amazon Resource Name (ARN) of the application.\n\nApplicationVersionId -> (long)\n\nThe current application version ID."
    },
    {
      "command_name": "delete-application-output",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/delete-application-output.html",
      "command_description": "Description\n\nDeletes the output destination configuration from your SQL-based Kinesis Data Analytics application’s configuration. Kinesis Data Analytics will no longer write data from the corresponding in-application stream to the external output destination.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-application-output\n--application-name <value>\n--current-application-version-id <value>\n--output-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--current-application-version-id <value>",
        "--output-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe application name.\n\n--current-application-version-id (long)\n\nThe application version. You can use the DescribeApplication operation to get the current application version. If the version specified is not the current version, the ConcurrentModificationException is returned.\n\n--output-id (string)\n\nThe ID of the configuration to delete. Each output configuration that is added to the application (either when the application is created or later) using the AddApplicationOutput operation has a unique ID. You need to provide the ID to uniquely identify the output configuration that you want to delete from the application configuration. You can use the DescribeApplication operation to get the specific OutputId .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe application Amazon Resource Name (ARN).\n\nApplicationVersionId -> (long)\n\nThe current application version ID."
    },
    {
      "command_name": "delete-application-reference-data-source",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/delete-application-reference-data-source.html",
      "command_description": "Description\n\nDeletes a reference data source configuration from the specified SQL-based Kinesis Data Analytics application’s configuration.\n\nIf the application is running, Kinesis Data Analytics immediately removes the in-application table that you created using the AddApplicationReferenceDataSource operation.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-application-reference-data-source\n--application-name <value>\n--current-application-version-id <value>\n--reference-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--current-application-version-id <value>",
        "--reference-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of an existing application.\n\n--current-application-version-id (long)\n\nThe current application version. You can use the DescribeApplication operation to get the current application version. If the version specified is not the current version, the ConcurrentModificationException is returned.\n\n--reference-id (string)\n\nThe ID of the reference data source. When you add a reference data source to your application using the AddApplicationReferenceDataSource , Kinesis Data Analytics assigns an ID. You can use the DescribeApplication operation to get the reference ID.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe application Amazon Resource Name (ARN).\n\nApplicationVersionId -> (long)\n\nThe updated version ID of the application."
    },
    {
      "command_name": "delete-application-snapshot",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/delete-application-snapshot.html",
      "command_description": "Description\n\nDeletes a snapshot of application state.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-application-snapshot\n--application-name <value>\n--snapshot-name <value>\n--snapshot-creation-timestamp <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--snapshot-name <value>",
        "--snapshot-creation-timestamp <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of an existing application.\n\n--snapshot-name (string)\n\nThe identifier for the snapshot delete.\n\n--snapshot-creation-timestamp (timestamp)\n\nThe creation timestamp of the application snapshot to delete. You can retrieve this value using or .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "delete-application-vpc-configuration",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/delete-application-vpc-configuration.html",
      "command_description": "Description\n\nRemoves a VPC configuration from a Kinesis Data Analytics application.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-application-vpc-configuration\n--application-name <value>\n[--current-application-version-id <value>]\n--vpc-configuration-id <value>\n[--conditional-token <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--current-application-version-id <value>]",
        "--vpc-configuration-id <value>",
        "[--conditional-token <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of an existing application.\n\n--current-application-version-id (long)\n\nThe current application version ID. You must provide the CurrentApplicationVersionId or the ConditionalToken . You can retrieve the application version ID using DescribeApplication . For better concurrency support, use the ConditionalToken parameter instead of CurrentApplicationVersionId .\n\n--vpc-configuration-id (string)\n\nThe ID of the VPC configuration to delete.\n\n--conditional-token (string)\n\nA value you use to implement strong concurrency for application updates. You must provide the CurrentApplicationVersionId or the ConditionalToken . You get the application’s current ConditionalToken using DescribeApplication . For better concurrency support, use the ConditionalToken parameter instead of CurrentApplicationVersionId .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe ARN of the Kinesis Data Analytics application.\n\nApplicationVersionId -> (long)\n\nThe updated version ID of the application."
    },
    {
      "command_name": "describe-application",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/describe-application.html",
      "command_description": "Description\n\nReturns information about a specific Kinesis Data Analytics application.\n\nIf you want to retrieve a list of all applications in your account, use the ListApplications operation.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-application\n--application-name <value>\n[--include-additional-details | --no-include-additional-details]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--include-additional-details | --no-include-additional-details]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application.\n\n--include-additional-details | --no-include-additional-details (boolean)\n\nDisplays verbose information about a Kinesis Data Analytics application, including the application’s job plan.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationDetail -> (structure)\n\nProvides a description of the application, such as the application’s Amazon Resource Name (ARN), status, and latest version.\n\nApplicationARN -> (string)\n\nThe ARN of the application.\n\nApplicationDescription -> (string)\n\nThe description of the application.\n\nApplicationName -> (string)\n\nThe name of the application.\n\nRuntimeEnvironment -> (string)\n\nThe runtime environment for the application (SQL-1_0 , FLINK-1_6 , FLINK-1_8 , or FLINK-1_11 ).\n\nServiceExecutionRole -> (string)\n\nSpecifies the IAM role that the application uses to access external resources.\n\nApplicationStatus -> (string)\n\nThe status of the application.\n\nApplicationVersionId -> (long)\n\nProvides the current application version. Kinesis Data Analytics updates the ApplicationVersionId each time you update the application.\n\nCreateTimestamp -> (timestamp)\n\nThe current timestamp when the application was created.\n\nLastUpdateTimestamp -> (timestamp)\n\nThe current timestamp when the application was last updated.\n\nApplicationConfigurationDescription -> (structure)\n\nDescribes details about the application code and starting parameters for a Kinesis Data Analytics application.\n\nSqlApplicationConfigurationDescription -> (structure)\n\nThe details about inputs, outputs, and reference data sources for a SQL-based Kinesis Data Analytics application.\n\nInputDescriptions -> (list)\n\nThe array of InputDescription objects describing the input streams used by the application.\n\n(structure)\n\nDescribes the application input configuration for a SQL-based Kinesis Data Analytics application.\n\nInputId -> (string)\n\nThe input ID that is associated with the application input. This is the ID that Kinesis Data Analytics assigns to each input configuration that you add to your application.\n\nNamePrefix -> (string)\n\nThe in-application name prefix.\n\nInAppStreamNames -> (list)\n\nReturns the in-application stream names that are mapped to the stream source.\n\n(string)\n\nInputProcessingConfigurationDescription -> (structure)\n\nThe description of the preprocessor that executes on records in this input before the application’s code is run.\n\nInputLambdaProcessorDescription -> (structure)\n\nProvides configuration information about the associated InputLambdaProcessorDescription\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that is used to preprocess the records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that is used to access the Amazon Lambda function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisStreamsInputDescription -> (structure)\n\nIf a Kinesis data stream is configured as a streaming source, provides the Kinesis data stream’s Amazon Resource Name (ARN).\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseInputDescription -> (structure)\n\nIf a Kinesis Data Firehose delivery stream is configured as a streaming source, provides the delivery stream’s ARN.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics assumes to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nInputSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns in the in-application stream that is being created.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nInputParallelism -> (structure)\n\nDescribes the configured parallelism (number of in-application streams mapped to the streaming source).\n\nCount -> (integer)\n\nThe number of in-application streams to create.\n\nInputStartingPositionConfiguration -> (structure)\n\nThe point at which the application is configured to read from the input stream.\n\nInputStartingPosition -> (string)\n\nThe starting position on the stream.\n\nNOW - Start reading just after the most recent record in the stream, and start at the request timestamp that the customer issued.\n\nTRIM_HORIZON - Start reading at the last untrimmed record in the stream, which is the oldest record available in the stream. This option is not available for an Amazon Kinesis Data Firehose delivery stream.\n\nLAST_STOPPED_POINT - Resume reading from where the application last stopped reading.\n\nOutputDescriptions -> (list)\n\nThe array of OutputDescription objects describing the destination streams used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the application output configuration, which includes the in-application stream name and the destination where the stream data is written. The destination can be a Kinesis data stream or a Kinesis Data Firehose delivery stream.\n\nOutputId -> (string)\n\nA unique identifier for the output configuration.\n\nName -> (string)\n\nThe name of the in-application stream that is configured as output.\n\nKinesisStreamsOutputDescription -> (structure)\n\nDescribes the Kinesis data stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseOutputDescription -> (structure)\n\nDescribes the Kinesis Data Firehose delivery stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nLambdaOutputDescription -> (structure)\n\nDescribes the Lambda function that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the destination Lambda function.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to write to the destination function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nDestinationSchema -> (structure)\n\nThe data format used for writing data to the destination.\n\nRecordFormatType -> (string)\n\nSpecifies the format of the records on the output stream.\n\nReferenceDataSourceDescriptions -> (list)\n\nThe array of ReferenceDataSourceDescription objects describing the reference data sources used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the reference data source configured for an application.\n\nReferenceId -> (string)\n\nThe ID of the reference data source. This is the ID that Kinesis Data Analytics assigns when you add the reference data source to your application using the CreateApplication or UpdateApplication operation.\n\nTableName -> (string)\n\nThe in-application table name created by the specific reference data source configuration.\n\nS3ReferenceDataSourceDescription -> (structure)\n\nProvides the Amazon S3 bucket name, the object key name that contains the reference data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nFileKey -> (string)\n\nAmazon S3 object key name.\n\nReferenceRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to read the Amazon S3 object on your behalf to populate the in-application reference table.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nReferenceSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns created in the in-application stream.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nApplicationCodeConfigurationDescription -> (structure)\n\nThe details about the application code for a Flink-based Kinesis Data Analytics application.\n\nCodeContentType -> (string)\n\nSpecifies whether the code content is in text or zip format.\n\nCodeContentDescription -> (structure)\n\nDescribes details about the location and format of the application code.\n\nTextContent -> (string)\n\nThe text-format code\n\nCodeMD5 -> (string)\n\nThe checksum that can be used to validate zip-format code.\n\nCodeSize -> (long)\n\nThe size in bytes of the application code. Can be used to validate zip-format code.\n\nS3ApplicationCodeLocationDescription -> (structure)\n\nThe S3 bucket Amazon Resource Name (ARN), file key, and object version of the application code stored in Amazon S3.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nRunConfigurationDescription -> (structure)\n\nThe details about the starting properties for a Kinesis Data Analytics application.\n\nApplicationRestoreConfigurationDescription -> (structure)\n\nDescribes the restore behavior of a restarting application.\n\nApplicationRestoreType -> (string)\n\nSpecifies how the application should be restored.\n\nSnapshotName -> (string)\n\nThe identifier of an existing snapshot of application state to use to restart an application. The application uses this value if RESTORE_FROM_CUSTOM_SNAPSHOT is specified for the ApplicationRestoreType .\n\nFlinkRunConfigurationDescription -> (structure)\n\nDescribes the starting parameters for a Flink-based Kinesis Data Analytics application.\n\nAllowNonRestoredState -> (boolean)\n\nWhen restoring from a snapshot, specifies whether the runtime is allowed to skip a state that cannot be mapped to the new program. This will happen if the program is updated between snapshots to remove stateful parameters, and state data in the snapshot no longer corresponds to valid application data. For more information, see Allowing Non-Restored State in the Apache Flink documentation .\n\nNote\n\nThis value defaults to false . If you update your application without specifying this parameter, AllowNonRestoredState will be set to false , even if it was previously set to true .\n\nFlinkApplicationConfigurationDescription -> (structure)\n\nThe details about a Flink-based Kinesis Data Analytics application.\n\nCheckpointConfigurationDescription -> (structure)\n\nDescribes an application’s checkpointing configuration. Checkpointing is the process of persisting application state for fault tolerance.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default checkpointing behavior in Kinesis Data Analytics.\n\nNote\n\nIf this value is set to DEFAULT , the application will use the following values, even if they are set to other values using APIs or application code:\n\nCheckpointingEnabled: true\n\nCheckpointInterval: 60000\n\nMinPauseBetweenCheckpoints: 5000\n\nCheckpointingEnabled -> (boolean)\n\nDescribes whether checkpointing is enabled for a Flink-based Kinesis Data Analytics application.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointingEnabled value of true , even if this value is set to another value using this API or in application code.\n\nCheckpointInterval -> (long)\n\nDescribes the interval in milliseconds between checkpoint operations.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointInterval value of 60000, even if this value is set to another value using this API or in application code.\n\nMinPauseBetweenCheckpoints -> (long)\n\nDescribes the minimum time in milliseconds after a checkpoint operation completes that a new checkpoint operation can start.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a MinPauseBetweenCheckpoints value of 5000, even if this value is set using this API or in application code.\n\nMonitoringConfigurationDescription -> (structure)\n\nDescribes configuration parameters for Amazon CloudWatch logging for an application.\n\nConfigurationType -> (string)\n\nDescribes whether to use the default CloudWatch logging configuration for an application.\n\nMetricsLevel -> (string)\n\nDescribes the granularity of the CloudWatch Logs for an application.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nParallelismConfigurationDescription -> (structure)\n\nDescribes parameters for how an application executes multiple tasks simultaneously.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default parallelism for the Kinesis Data Analytics service.\n\nParallelism -> (integer)\n\nDescribes the initial number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, then Kinesis Data Analytics can increase the CurrentParallelism value in response to application load. The service can increase CurrentParallelism up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nParallelismPerKPU -> (integer)\n\nDescribes the number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform per Kinesis Processing Unit (KPU) used by the application.\n\nCurrentParallelism -> (integer)\n\nDescribes the current number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, Kinesis Data Analytics can increase this value in response to application load. The service can increase this value up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nAutoScalingEnabled -> (boolean)\n\nDescribes whether the Kinesis Data Analytics service can increase the parallelism of the application in response to increased throughput.\n\nJobPlanDescription -> (string)\n\nThe job plan for an application. For more information about the job plan, see Jobs and Scheduling in the Apache Flink Documentation . To retrieve the job plan for the application, use the DescribeApplicationRequest$IncludeAdditionalDetails parameter of the DescribeApplication operation.\n\nEnvironmentPropertyDescriptions -> (structure)\n\nDescribes execution properties for a Flink-based Kinesis Data Analytics application.\n\nPropertyGroupDescriptions -> (list)\n\nDescribes the execution property groups.\n\n(structure)\n\nProperty key-value pairs passed into an application.\n\nPropertyGroupId -> (string)\n\nDescribes the key of an application execution property key-value pair.\n\nPropertyMap -> (map)\n\nDescribes the value of an application execution property key-value pair.\n\nkey -> (string)\n\nvalue -> (string)\n\nApplicationSnapshotConfigurationDescription -> (structure)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nSnapshotsEnabled -> (boolean)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nVpcConfigurationDescriptions -> (list)\n\nThe array of descriptions of VPC configurations available to the application.\n\n(structure)\n\nDescribes the parameters of a VPC used by the application.\n\nVpcConfigurationId -> (string)\n\nThe ID of the VPC configuration.\n\nVpcId -> (string)\n\nThe ID of the associated VPC.\n\nSubnetIds -> (list)\n\nThe array of Subnet IDs used by the VPC configuration.\n\n(string)\n\nSecurityGroupIds -> (list)\n\nThe array of SecurityGroup IDs used by the VPC configuration.\n\n(string)\n\nZeppelinApplicationConfigurationDescription -> (structure)\n\nThe configuration parameters for a Kinesis Data Analytics Studio notebook.\n\nMonitoringConfigurationDescription -> (structure)\n\nThe monitoring configuration of a Kinesis Data Analytics Studio notebook.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nCatalogConfigurationDescription -> (structure)\n\nThe Amazon Glue Data Catalog that is associated with the Kinesis Data Analytics Studio notebook.\n\nGlueDataCatalogConfigurationDescription -> (structure)\n\nThe configuration parameters for the default Amazon Glue database. You use this database for SQL queries that you write in a Kinesis Data Analytics Studio notebook.\n\nDatabaseARN -> (string)\n\nThe Amazon Resource Name (ARN) of the database.\n\nDeployAsApplicationConfigurationDescription -> (structure)\n\nThe parameters required to deploy a Kinesis Data Analytics Studio notebook as an application with durable state.\n\nS3ContentLocationDescription -> (structure)\n\nThe location that holds the data required to specify an Amazon Data Analytics application.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nBasePath -> (string)\n\nThe base path for the S3 bucket.\n\nCustomArtifactsConfigurationDescription -> (list)\n\nCustom artifacts are dependency JARs and user-defined functions (UDF).\n\n(structure)\n\nSpecifies a dependency JAR or a JAR of user-defined functions.\n\nArtifactType -> (string)\n\nUDF stands for user-defined functions. This type of artifact must be in an S3 bucket. A DEPENDENCY_JAR can be in either Maven or an S3 bucket.\n\nS3ContentLocationDescription -> (structure)\n\nFor a Kinesis Data Analytics application provides a description of an Amazon S3 object, including the Amazon Resource Name (ARN) of the S3 bucket, the name of the Amazon S3 object that contains the data, and the version number of the Amazon S3 object that contains the data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nMavenReferenceDescription -> (structure)\n\nThe parameters that are required to specify a Maven dependency.\n\nGroupId -> (string)\n\nThe group ID of the Maven reference.\n\nArtifactId -> (string)\n\nThe artifact ID of the Maven reference.\n\nVersion -> (string)\n\nThe version of the Maven reference.\n\nCloudWatchLoggingOptionDescriptions -> (list)\n\nDescribes the application Amazon CloudWatch logging options.\n\n(structure)\n\nDescribes the Amazon CloudWatch logging option.\n\nCloudWatchLoggingOptionId -> (string)\n\nThe ID of the CloudWatch logging option description.\n\nLogStreamARN -> (string)\n\nThe Amazon Resource Name (ARN) of the CloudWatch log to receive application messages.\n\nRoleARN -> (string)\n\nThe IAM ARN of the role to use to send application messages.\n\nNote\n\nProvided for backward compatibility. Applications created with the current API version have an application-level service execution role rather than a resource-level role.\n\nApplicationMaintenanceConfigurationDescription -> (structure)\n\nThe details of the maintenance configuration for the application.\n\nApplicationMaintenanceWindowStartTime -> (string)\n\nThe start time for the maintenance window.\n\nApplicationMaintenanceWindowEndTime -> (string)\n\nThe end time for the maintenance window.\n\nApplicationVersionUpdatedFrom -> (long)\n\nThe previous application version before the latest application update. RollbackApplication reverts the application to this version.\n\nApplicationVersionRolledBackFrom -> (long)\n\nIf you reverted the application using RollbackApplication , the application version when RollbackApplication was called.\n\nConditionalToken -> (string)\n\nA value you use to implement strong concurrency for application updates.\n\nApplicationVersionRolledBackTo -> (long)\n\nThe version to which you want to roll back the application.\n\nApplicationMode -> (string)\n\nTo create a Kinesis Data Analytics Studio notebook, you must set the mode to INTERACTIVE . However, for a Kinesis Data Analytics for Apache Flink application, the mode is optional."
    },
    {
      "command_name": "describe-application-snapshot",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/describe-application-snapshot.html",
      "command_description": "Description\n\nReturns information about a snapshot of application state data.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-application-snapshot\n--application-name <value>\n--snapshot-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--snapshot-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of an existing application.\n\n--snapshot-name (string)\n\nThe identifier of an application snapshot. You can retrieve this value using .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nSnapshotDetails -> (structure)\n\nAn object containing information about the application snapshot.\n\nSnapshotName -> (string)\n\nThe identifier for the application snapshot.\n\nSnapshotStatus -> (string)\n\nThe status of the application snapshot.\n\nApplicationVersionId -> (long)\n\nThe current application version ID when the snapshot was created.\n\nSnapshotCreationTimestamp -> (timestamp)\n\nThe timestamp of the application snapshot."
    },
    {
      "command_name": "describe-application-version",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/describe-application-version.html",
      "command_description": "Description\n\nProvides a detailed description of a specified version of the application. To see a list of all the versions of an application, invoke the ListApplicationVersions operation.\n\nNote\n\nThis operation is supported only for Amazon Kinesis Data Analytics for Apache Flink.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-application-version\n--application-name <value>\n--application-version-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--application-version-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application for which you want to get the version description.\n\n--application-version-id (long)\n\nThe ID of the application version for which you want to get the description.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationVersionDetail -> (structure)\n\nDescribes the application, including the application Amazon Resource Name (ARN), status, latest version, and input and output configurations.\n\nApplicationARN -> (string)\n\nThe ARN of the application.\n\nApplicationDescription -> (string)\n\nThe description of the application.\n\nApplicationName -> (string)\n\nThe name of the application.\n\nRuntimeEnvironment -> (string)\n\nThe runtime environment for the application (SQL-1_0 , FLINK-1_6 , FLINK-1_8 , or FLINK-1_11 ).\n\nServiceExecutionRole -> (string)\n\nSpecifies the IAM role that the application uses to access external resources.\n\nApplicationStatus -> (string)\n\nThe status of the application.\n\nApplicationVersionId -> (long)\n\nProvides the current application version. Kinesis Data Analytics updates the ApplicationVersionId each time you update the application.\n\nCreateTimestamp -> (timestamp)\n\nThe current timestamp when the application was created.\n\nLastUpdateTimestamp -> (timestamp)\n\nThe current timestamp when the application was last updated.\n\nApplicationConfigurationDescription -> (structure)\n\nDescribes details about the application code and starting parameters for a Kinesis Data Analytics application.\n\nSqlApplicationConfigurationDescription -> (structure)\n\nThe details about inputs, outputs, and reference data sources for a SQL-based Kinesis Data Analytics application.\n\nInputDescriptions -> (list)\n\nThe array of InputDescription objects describing the input streams used by the application.\n\n(structure)\n\nDescribes the application input configuration for a SQL-based Kinesis Data Analytics application.\n\nInputId -> (string)\n\nThe input ID that is associated with the application input. This is the ID that Kinesis Data Analytics assigns to each input configuration that you add to your application.\n\nNamePrefix -> (string)\n\nThe in-application name prefix.\n\nInAppStreamNames -> (list)\n\nReturns the in-application stream names that are mapped to the stream source.\n\n(string)\n\nInputProcessingConfigurationDescription -> (structure)\n\nThe description of the preprocessor that executes on records in this input before the application’s code is run.\n\nInputLambdaProcessorDescription -> (structure)\n\nProvides configuration information about the associated InputLambdaProcessorDescription\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that is used to preprocess the records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that is used to access the Amazon Lambda function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisStreamsInputDescription -> (structure)\n\nIf a Kinesis data stream is configured as a streaming source, provides the Kinesis data stream’s Amazon Resource Name (ARN).\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseInputDescription -> (structure)\n\nIf a Kinesis Data Firehose delivery stream is configured as a streaming source, provides the delivery stream’s ARN.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics assumes to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nInputSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns in the in-application stream that is being created.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nInputParallelism -> (structure)\n\nDescribes the configured parallelism (number of in-application streams mapped to the streaming source).\n\nCount -> (integer)\n\nThe number of in-application streams to create.\n\nInputStartingPositionConfiguration -> (structure)\n\nThe point at which the application is configured to read from the input stream.\n\nInputStartingPosition -> (string)\n\nThe starting position on the stream.\n\nNOW - Start reading just after the most recent record in the stream, and start at the request timestamp that the customer issued.\n\nTRIM_HORIZON - Start reading at the last untrimmed record in the stream, which is the oldest record available in the stream. This option is not available for an Amazon Kinesis Data Firehose delivery stream.\n\nLAST_STOPPED_POINT - Resume reading from where the application last stopped reading.\n\nOutputDescriptions -> (list)\n\nThe array of OutputDescription objects describing the destination streams used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the application output configuration, which includes the in-application stream name and the destination where the stream data is written. The destination can be a Kinesis data stream or a Kinesis Data Firehose delivery stream.\n\nOutputId -> (string)\n\nA unique identifier for the output configuration.\n\nName -> (string)\n\nThe name of the in-application stream that is configured as output.\n\nKinesisStreamsOutputDescription -> (structure)\n\nDescribes the Kinesis data stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseOutputDescription -> (structure)\n\nDescribes the Kinesis Data Firehose delivery stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nLambdaOutputDescription -> (structure)\n\nDescribes the Lambda function that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the destination Lambda function.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to write to the destination function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nDestinationSchema -> (structure)\n\nThe data format used for writing data to the destination.\n\nRecordFormatType -> (string)\n\nSpecifies the format of the records on the output stream.\n\nReferenceDataSourceDescriptions -> (list)\n\nThe array of ReferenceDataSourceDescription objects describing the reference data sources used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the reference data source configured for an application.\n\nReferenceId -> (string)\n\nThe ID of the reference data source. This is the ID that Kinesis Data Analytics assigns when you add the reference data source to your application using the CreateApplication or UpdateApplication operation.\n\nTableName -> (string)\n\nThe in-application table name created by the specific reference data source configuration.\n\nS3ReferenceDataSourceDescription -> (structure)\n\nProvides the Amazon S3 bucket name, the object key name that contains the reference data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nFileKey -> (string)\n\nAmazon S3 object key name.\n\nReferenceRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to read the Amazon S3 object on your behalf to populate the in-application reference table.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nReferenceSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns created in the in-application stream.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nApplicationCodeConfigurationDescription -> (structure)\n\nThe details about the application code for a Flink-based Kinesis Data Analytics application.\n\nCodeContentType -> (string)\n\nSpecifies whether the code content is in text or zip format.\n\nCodeContentDescription -> (structure)\n\nDescribes details about the location and format of the application code.\n\nTextContent -> (string)\n\nThe text-format code\n\nCodeMD5 -> (string)\n\nThe checksum that can be used to validate zip-format code.\n\nCodeSize -> (long)\n\nThe size in bytes of the application code. Can be used to validate zip-format code.\n\nS3ApplicationCodeLocationDescription -> (structure)\n\nThe S3 bucket Amazon Resource Name (ARN), file key, and object version of the application code stored in Amazon S3.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nRunConfigurationDescription -> (structure)\n\nThe details about the starting properties for a Kinesis Data Analytics application.\n\nApplicationRestoreConfigurationDescription -> (structure)\n\nDescribes the restore behavior of a restarting application.\n\nApplicationRestoreType -> (string)\n\nSpecifies how the application should be restored.\n\nSnapshotName -> (string)\n\nThe identifier of an existing snapshot of application state to use to restart an application. The application uses this value if RESTORE_FROM_CUSTOM_SNAPSHOT is specified for the ApplicationRestoreType .\n\nFlinkRunConfigurationDescription -> (structure)\n\nDescribes the starting parameters for a Flink-based Kinesis Data Analytics application.\n\nAllowNonRestoredState -> (boolean)\n\nWhen restoring from a snapshot, specifies whether the runtime is allowed to skip a state that cannot be mapped to the new program. This will happen if the program is updated between snapshots to remove stateful parameters, and state data in the snapshot no longer corresponds to valid application data. For more information, see Allowing Non-Restored State in the Apache Flink documentation .\n\nNote\n\nThis value defaults to false . If you update your application without specifying this parameter, AllowNonRestoredState will be set to false , even if it was previously set to true .\n\nFlinkApplicationConfigurationDescription -> (structure)\n\nThe details about a Flink-based Kinesis Data Analytics application.\n\nCheckpointConfigurationDescription -> (structure)\n\nDescribes an application’s checkpointing configuration. Checkpointing is the process of persisting application state for fault tolerance.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default checkpointing behavior in Kinesis Data Analytics.\n\nNote\n\nIf this value is set to DEFAULT , the application will use the following values, even if they are set to other values using APIs or application code:\n\nCheckpointingEnabled: true\n\nCheckpointInterval: 60000\n\nMinPauseBetweenCheckpoints: 5000\n\nCheckpointingEnabled -> (boolean)\n\nDescribes whether checkpointing is enabled for a Flink-based Kinesis Data Analytics application.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointingEnabled value of true , even if this value is set to another value using this API or in application code.\n\nCheckpointInterval -> (long)\n\nDescribes the interval in milliseconds between checkpoint operations.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointInterval value of 60000, even if this value is set to another value using this API or in application code.\n\nMinPauseBetweenCheckpoints -> (long)\n\nDescribes the minimum time in milliseconds after a checkpoint operation completes that a new checkpoint operation can start.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a MinPauseBetweenCheckpoints value of 5000, even if this value is set using this API or in application code.\n\nMonitoringConfigurationDescription -> (structure)\n\nDescribes configuration parameters for Amazon CloudWatch logging for an application.\n\nConfigurationType -> (string)\n\nDescribes whether to use the default CloudWatch logging configuration for an application.\n\nMetricsLevel -> (string)\n\nDescribes the granularity of the CloudWatch Logs for an application.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nParallelismConfigurationDescription -> (structure)\n\nDescribes parameters for how an application executes multiple tasks simultaneously.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default parallelism for the Kinesis Data Analytics service.\n\nParallelism -> (integer)\n\nDescribes the initial number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, then Kinesis Data Analytics can increase the CurrentParallelism value in response to application load. The service can increase CurrentParallelism up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nParallelismPerKPU -> (integer)\n\nDescribes the number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform per Kinesis Processing Unit (KPU) used by the application.\n\nCurrentParallelism -> (integer)\n\nDescribes the current number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, Kinesis Data Analytics can increase this value in response to application load. The service can increase this value up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nAutoScalingEnabled -> (boolean)\n\nDescribes whether the Kinesis Data Analytics service can increase the parallelism of the application in response to increased throughput.\n\nJobPlanDescription -> (string)\n\nThe job plan for an application. For more information about the job plan, see Jobs and Scheduling in the Apache Flink Documentation . To retrieve the job plan for the application, use the DescribeApplicationRequest$IncludeAdditionalDetails parameter of the DescribeApplication operation.\n\nEnvironmentPropertyDescriptions -> (structure)\n\nDescribes execution properties for a Flink-based Kinesis Data Analytics application.\n\nPropertyGroupDescriptions -> (list)\n\nDescribes the execution property groups.\n\n(structure)\n\nProperty key-value pairs passed into an application.\n\nPropertyGroupId -> (string)\n\nDescribes the key of an application execution property key-value pair.\n\nPropertyMap -> (map)\n\nDescribes the value of an application execution property key-value pair.\n\nkey -> (string)\n\nvalue -> (string)\n\nApplicationSnapshotConfigurationDescription -> (structure)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nSnapshotsEnabled -> (boolean)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nVpcConfigurationDescriptions -> (list)\n\nThe array of descriptions of VPC configurations available to the application.\n\n(structure)\n\nDescribes the parameters of a VPC used by the application.\n\nVpcConfigurationId -> (string)\n\nThe ID of the VPC configuration.\n\nVpcId -> (string)\n\nThe ID of the associated VPC.\n\nSubnetIds -> (list)\n\nThe array of Subnet IDs used by the VPC configuration.\n\n(string)\n\nSecurityGroupIds -> (list)\n\nThe array of SecurityGroup IDs used by the VPC configuration.\n\n(string)\n\nZeppelinApplicationConfigurationDescription -> (structure)\n\nThe configuration parameters for a Kinesis Data Analytics Studio notebook.\n\nMonitoringConfigurationDescription -> (structure)\n\nThe monitoring configuration of a Kinesis Data Analytics Studio notebook.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nCatalogConfigurationDescription -> (structure)\n\nThe Amazon Glue Data Catalog that is associated with the Kinesis Data Analytics Studio notebook.\n\nGlueDataCatalogConfigurationDescription -> (structure)\n\nThe configuration parameters for the default Amazon Glue database. You use this database for SQL queries that you write in a Kinesis Data Analytics Studio notebook.\n\nDatabaseARN -> (string)\n\nThe Amazon Resource Name (ARN) of the database.\n\nDeployAsApplicationConfigurationDescription -> (structure)\n\nThe parameters required to deploy a Kinesis Data Analytics Studio notebook as an application with durable state.\n\nS3ContentLocationDescription -> (structure)\n\nThe location that holds the data required to specify an Amazon Data Analytics application.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nBasePath -> (string)\n\nThe base path for the S3 bucket.\n\nCustomArtifactsConfigurationDescription -> (list)\n\nCustom artifacts are dependency JARs and user-defined functions (UDF).\n\n(structure)\n\nSpecifies a dependency JAR or a JAR of user-defined functions.\n\nArtifactType -> (string)\n\nUDF stands for user-defined functions. This type of artifact must be in an S3 bucket. A DEPENDENCY_JAR can be in either Maven or an S3 bucket.\n\nS3ContentLocationDescription -> (structure)\n\nFor a Kinesis Data Analytics application provides a description of an Amazon S3 object, including the Amazon Resource Name (ARN) of the S3 bucket, the name of the Amazon S3 object that contains the data, and the version number of the Amazon S3 object that contains the data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nMavenReferenceDescription -> (structure)\n\nThe parameters that are required to specify a Maven dependency.\n\nGroupId -> (string)\n\nThe group ID of the Maven reference.\n\nArtifactId -> (string)\n\nThe artifact ID of the Maven reference.\n\nVersion -> (string)\n\nThe version of the Maven reference.\n\nCloudWatchLoggingOptionDescriptions -> (list)\n\nDescribes the application Amazon CloudWatch logging options.\n\n(structure)\n\nDescribes the Amazon CloudWatch logging option.\n\nCloudWatchLoggingOptionId -> (string)\n\nThe ID of the CloudWatch logging option description.\n\nLogStreamARN -> (string)\n\nThe Amazon Resource Name (ARN) of the CloudWatch log to receive application messages.\n\nRoleARN -> (string)\n\nThe IAM ARN of the role to use to send application messages.\n\nNote\n\nProvided for backward compatibility. Applications created with the current API version have an application-level service execution role rather than a resource-level role.\n\nApplicationMaintenanceConfigurationDescription -> (structure)\n\nThe details of the maintenance configuration for the application.\n\nApplicationMaintenanceWindowStartTime -> (string)\n\nThe start time for the maintenance window.\n\nApplicationMaintenanceWindowEndTime -> (string)\n\nThe end time for the maintenance window.\n\nApplicationVersionUpdatedFrom -> (long)\n\nThe previous application version before the latest application update. RollbackApplication reverts the application to this version.\n\nApplicationVersionRolledBackFrom -> (long)\n\nIf you reverted the application using RollbackApplication , the application version when RollbackApplication was called.\n\nConditionalToken -> (string)\n\nA value you use to implement strong concurrency for application updates.\n\nApplicationVersionRolledBackTo -> (long)\n\nThe version to which you want to roll back the application.\n\nApplicationMode -> (string)\n\nTo create a Kinesis Data Analytics Studio notebook, you must set the mode to INTERACTIVE . However, for a Kinesis Data Analytics for Apache Flink application, the mode is optional."
    },
    {
      "command_name": "discover-input-schema",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/discover-input-schema.html",
      "command_description": "Description\n\nInfers a schema for a SQL-based Kinesis Data Analytics application by evaluating sample records on the specified streaming source (Kinesis data stream or Kinesis Data Firehose delivery stream) or Amazon S3 object. In the response, the operation returns the inferred schema and also the sample records that the operation used to infer the schema.\n\nYou can use the inferred schema when configuring a streaming source for your application. When you create an application using the Kinesis Data Analytics console, the console uses this operation to infer a schema and show it in the console user interface.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  discover-input-schema\n[--resource-arn <value>]\n--service-execution-role <value>\n[--input-starting-position-configuration <value>]\n[--s3-configuration <value>]\n[--input-processing-configuration <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--resource-arn <value>]",
        "--service-execution-role <value>",
        "[--input-starting-position-configuration <value>]",
        "[--s3-configuration <value>]",
        "[--input-processing-configuration <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe Amazon Resource Name (ARN) of the streaming source.\n\n--service-execution-role (string)\n\nThe ARN of the role that is used to access the streaming source.\n\n--input-starting-position-configuration (structure)\n\nThe point at which you want Kinesis Data Analytics to start reading records from the specified streaming source discovery purposes.\n\nInputStartingPosition -> (string)\n\nThe starting position on the stream.\n\nNOW - Start reading just after the most recent record in the stream, and start at the request timestamp that the customer issued.\n\nTRIM_HORIZON - Start reading at the last untrimmed record in the stream, which is the oldest record available in the stream. This option is not available for an Amazon Kinesis Data Firehose delivery stream.\n\nLAST_STOPPED_POINT - Resume reading from where the application last stopped reading.\n\nShorthand Syntax:\n\nInputStartingPosition=string\n\n\nJSON Syntax:\n\n{\n  \"InputStartingPosition\": \"NOW\"|\"TRIM_HORIZON\"|\"LAST_STOPPED_POINT\"\n}\n\n\n--s3-configuration (structure)\n\nSpecify this parameter to discover a schema from data in an Amazon S3 object.\n\nBucketARN -> (string)\n\nThe ARN of the S3 bucket that contains the data.\n\nFileKey -> (string)\n\nThe name of the object that contains the data.\n\nShorthand Syntax:\n\nBucketARN=string,FileKey=string\n\n\nJSON Syntax:\n\n{\n  \"BucketARN\": \"string\",\n  \"FileKey\": \"string\"\n}\n\n\n--input-processing-configuration (structure)\n\nThe InputProcessingConfiguration to use to preprocess the records before discovering the schema of the records.\n\nInputLambdaProcessor -> (structure)\n\nThe InputLambdaProcessor that is used to preprocess the records in the stream before being processed by your application code.\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that operates on records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nShorthand Syntax:\n\nInputLambdaProcessor={ResourceARN=string}\n\n\nJSON Syntax:\n\n{\n  \"InputLambdaProcessor\": {\n    \"ResourceARN\": \"string\"\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nInputSchema -> (structure)\n\nThe schema inferred from the streaming source. It identifies the format of the data in the streaming source and how each data element maps to corresponding columns in the in-application stream that you can create.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nParsedInputRecords -> (list)\n\nAn array of elements, where each element corresponds to a row in a stream record (a stream record can have more than one row).\n\n(list)\n\n(string)\n\nProcessedInputRecords -> (list)\n\nThe stream data that was modified by the processor specified in the InputProcessingConfiguration parameter.\n\n(string)\n\nRawInputRecords -> (list)\n\nThe raw stream data that was sampled to infer the schema.\n\n(string)"
    },
    {
      "command_name": "list-application-snapshots",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/list-application-snapshots.html",
      "command_description": "Description\n\nLists information about the current application snapshots.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-application-snapshots is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: SnapshotSummaries",
      "command_synopsis": "Synopsis\n  list-application-snapshots\n--application-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of an existing application.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nSnapshotSummaries -> (list)\n\nA collection of objects containing information about the application snapshots.\n\n(structure)\n\nProvides details about a snapshot of application state.\n\nSnapshotName -> (string)\n\nThe identifier for the application snapshot.\n\nSnapshotStatus -> (string)\n\nThe status of the application snapshot.\n\nApplicationVersionId -> (long)\n\nThe current application version ID when the snapshot was created.\n\nSnapshotCreationTimestamp -> (timestamp)\n\nThe timestamp of the application snapshot.\n\nNextToken -> (string)\n\nThe token for the next set of results, or null if there are no additional results."
    },
    {
      "command_name": "list-application-versions",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/list-application-versions.html",
      "command_description": "Description\n\nLists all the versions for the specified application, including versions that were rolled back. The response also includes a summary of the configuration associated with each version.\n\nTo get the complete description of a specific application version, invoke the DescribeApplicationVersion operation.\n\nNote\n\nThis operation is supported only for Amazon Kinesis Data Analytics for Apache Flink.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-application-versions\n--application-name <value>\n[--limit <value>]\n[--next-token <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--limit <value>]",
        "[--next-token <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application for which you want to list all versions.\n\n--limit (integer)\n\nThe maximum number of versions to list in this invocation of the operation.\n\n--next-token (string)\n\nIf a previous invocation of this operation returned a pagination token, pass it into this value to retrieve the next set of results. For more information about pagination, see Using the Amazon Command Line Interface’s Pagination Options .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationVersionSummaries -> (list)\n\nA list of the application versions and the associated configuration summaries. The list includes application versions that were rolled back.\n\nTo get the complete description of a specific application version, invoke the DescribeApplicationVersion operation.\n\n(structure)\n\nThe summary of the application version.\n\nApplicationVersionId -> (long)\n\nThe ID of the application version. Kinesis Data Analytics updates the ApplicationVersionId each time you update the application.\n\nApplicationStatus -> (string)\n\nThe status of the application.\n\nNextToken -> (string)\n\nThe pagination token for the next set of results, or null if there are no additional results. To retrieve the next set of items, pass this token into a subsequent invocation of this operation. For more information about pagination, see Using the Amazon Command Line Interface’s Pagination Options ."
    },
    {
      "command_name": "list-applications",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/list-applications.html",
      "command_description": "Description\n\nReturns a list of Kinesis Data Analytics applications in your account. For each application, the response includes the application name, Amazon Resource Name (ARN), and status.\n\nIf you want detailed information about a specific application, use DescribeApplication .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-applications is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: ApplicationSummaries",
      "command_synopsis": "Synopsis\n  list-applications\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationSummaries -> (list)\n\nA list of ApplicationSummary objects.\n\n(structure)\n\nProvides application summary information, including the application Amazon Resource Name (ARN), name, and status.\n\nApplicationName -> (string)\n\nThe name of the application.\n\nApplicationARN -> (string)\n\nThe ARN of the application.\n\nApplicationStatus -> (string)\n\nThe status of the application.\n\nApplicationVersionId -> (long)\n\nProvides the current application version.\n\nRuntimeEnvironment -> (string)\n\nThe runtime environment for the application.\n\nApplicationMode -> (string)\n\nFor a Kinesis Data Analytics for Apache Flink application, the mode is STREAMING . For a Kinesis Data Analytics Studio notebook, it is INTERACTIVE .\n\nNextToken -> (string)\n\nThe pagination token for the next set of results, or null if there are no additional results. Pass this token into a subsequent command to retrieve the next set of items For more information about pagination, see Using the Amazon Command Line Interface’s Pagination Options ."
    },
    {
      "command_name": "list-tags-for-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/list-tags-for-resource.html",
      "command_description": "Description\n\nRetrieves the list of key-value tags assigned to the application. For more information, see Using Tagging .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-tags-for-resource\n--resource-arn <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe ARN of the application for which to retrieve tags.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nTags -> (list)\n\nThe key-value tags assigned to the application.\n\n(structure)\n\nA key-value pair (the value is optional) that you can define and assign to Amazon resources. If you specify a tag that already exists, the tag value is replaced with the value that you specify in the request. Note that the maximum number of application tags includes system tags. The maximum number of user-defined application tags is 50. For more information, see Using Tagging .\n\nKey -> (string)\n\nThe key of the key-value tag.\n\nValue -> (string)\n\nThe value of the key-value tag. The value is optional."
    },
    {
      "command_name": "rollback-application",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/rollback-application.html",
      "command_description": "Description\n\nReverts the application to the previous running version. You can roll back an application if you suspect it is stuck in a transient status.\n\nYou can roll back an application only if it is in the UPDATING or AUTOSCALING status.\n\nWhen you rollback an application, it loads state data from the last successful snapshot. If the application has no snapshots, Kinesis Data Analytics rejects the rollback request.\n\nThis action is not supported for Kinesis Data Analytics for SQL applications.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  rollback-application\n--application-name <value>\n--current-application-version-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--current-application-version-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application.\n\n--current-application-version-id (long)\n\nThe current application version ID. You can retrieve the application version ID using DescribeApplication .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationDetail -> (structure)\n\nDescribes the application, including the application Amazon Resource Name (ARN), status, latest version, and input and output configurations.\n\nApplicationARN -> (string)\n\nThe ARN of the application.\n\nApplicationDescription -> (string)\n\nThe description of the application.\n\nApplicationName -> (string)\n\nThe name of the application.\n\nRuntimeEnvironment -> (string)\n\nThe runtime environment for the application (SQL-1_0 , FLINK-1_6 , FLINK-1_8 , or FLINK-1_11 ).\n\nServiceExecutionRole -> (string)\n\nSpecifies the IAM role that the application uses to access external resources.\n\nApplicationStatus -> (string)\n\nThe status of the application.\n\nApplicationVersionId -> (long)\n\nProvides the current application version. Kinesis Data Analytics updates the ApplicationVersionId each time you update the application.\n\nCreateTimestamp -> (timestamp)\n\nThe current timestamp when the application was created.\n\nLastUpdateTimestamp -> (timestamp)\n\nThe current timestamp when the application was last updated.\n\nApplicationConfigurationDescription -> (structure)\n\nDescribes details about the application code and starting parameters for a Kinesis Data Analytics application.\n\nSqlApplicationConfigurationDescription -> (structure)\n\nThe details about inputs, outputs, and reference data sources for a SQL-based Kinesis Data Analytics application.\n\nInputDescriptions -> (list)\n\nThe array of InputDescription objects describing the input streams used by the application.\n\n(structure)\n\nDescribes the application input configuration for a SQL-based Kinesis Data Analytics application.\n\nInputId -> (string)\n\nThe input ID that is associated with the application input. This is the ID that Kinesis Data Analytics assigns to each input configuration that you add to your application.\n\nNamePrefix -> (string)\n\nThe in-application name prefix.\n\nInAppStreamNames -> (list)\n\nReturns the in-application stream names that are mapped to the stream source.\n\n(string)\n\nInputProcessingConfigurationDescription -> (structure)\n\nThe description of the preprocessor that executes on records in this input before the application’s code is run.\n\nInputLambdaProcessorDescription -> (structure)\n\nProvides configuration information about the associated InputLambdaProcessorDescription\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that is used to preprocess the records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that is used to access the Amazon Lambda function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisStreamsInputDescription -> (structure)\n\nIf a Kinesis data stream is configured as a streaming source, provides the Kinesis data stream’s Amazon Resource Name (ARN).\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseInputDescription -> (structure)\n\nIf a Kinesis Data Firehose delivery stream is configured as a streaming source, provides the delivery stream’s ARN.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics assumes to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nInputSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns in the in-application stream that is being created.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nInputParallelism -> (structure)\n\nDescribes the configured parallelism (number of in-application streams mapped to the streaming source).\n\nCount -> (integer)\n\nThe number of in-application streams to create.\n\nInputStartingPositionConfiguration -> (structure)\n\nThe point at which the application is configured to read from the input stream.\n\nInputStartingPosition -> (string)\n\nThe starting position on the stream.\n\nNOW - Start reading just after the most recent record in the stream, and start at the request timestamp that the customer issued.\n\nTRIM_HORIZON - Start reading at the last untrimmed record in the stream, which is the oldest record available in the stream. This option is not available for an Amazon Kinesis Data Firehose delivery stream.\n\nLAST_STOPPED_POINT - Resume reading from where the application last stopped reading.\n\nOutputDescriptions -> (list)\n\nThe array of OutputDescription objects describing the destination streams used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the application output configuration, which includes the in-application stream name and the destination where the stream data is written. The destination can be a Kinesis data stream or a Kinesis Data Firehose delivery stream.\n\nOutputId -> (string)\n\nA unique identifier for the output configuration.\n\nName -> (string)\n\nThe name of the in-application stream that is configured as output.\n\nKinesisStreamsOutputDescription -> (structure)\n\nDescribes the Kinesis data stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseOutputDescription -> (structure)\n\nDescribes the Kinesis Data Firehose delivery stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nLambdaOutputDescription -> (structure)\n\nDescribes the Lambda function that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the destination Lambda function.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to write to the destination function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nDestinationSchema -> (structure)\n\nThe data format used for writing data to the destination.\n\nRecordFormatType -> (string)\n\nSpecifies the format of the records on the output stream.\n\nReferenceDataSourceDescriptions -> (list)\n\nThe array of ReferenceDataSourceDescription objects describing the reference data sources used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the reference data source configured for an application.\n\nReferenceId -> (string)\n\nThe ID of the reference data source. This is the ID that Kinesis Data Analytics assigns when you add the reference data source to your application using the CreateApplication or UpdateApplication operation.\n\nTableName -> (string)\n\nThe in-application table name created by the specific reference data source configuration.\n\nS3ReferenceDataSourceDescription -> (structure)\n\nProvides the Amazon S3 bucket name, the object key name that contains the reference data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nFileKey -> (string)\n\nAmazon S3 object key name.\n\nReferenceRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to read the Amazon S3 object on your behalf to populate the in-application reference table.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nReferenceSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns created in the in-application stream.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nApplicationCodeConfigurationDescription -> (structure)\n\nThe details about the application code for a Flink-based Kinesis Data Analytics application.\n\nCodeContentType -> (string)\n\nSpecifies whether the code content is in text or zip format.\n\nCodeContentDescription -> (structure)\n\nDescribes details about the location and format of the application code.\n\nTextContent -> (string)\n\nThe text-format code\n\nCodeMD5 -> (string)\n\nThe checksum that can be used to validate zip-format code.\n\nCodeSize -> (long)\n\nThe size in bytes of the application code. Can be used to validate zip-format code.\n\nS3ApplicationCodeLocationDescription -> (structure)\n\nThe S3 bucket Amazon Resource Name (ARN), file key, and object version of the application code stored in Amazon S3.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nRunConfigurationDescription -> (structure)\n\nThe details about the starting properties for a Kinesis Data Analytics application.\n\nApplicationRestoreConfigurationDescription -> (structure)\n\nDescribes the restore behavior of a restarting application.\n\nApplicationRestoreType -> (string)\n\nSpecifies how the application should be restored.\n\nSnapshotName -> (string)\n\nThe identifier of an existing snapshot of application state to use to restart an application. The application uses this value if RESTORE_FROM_CUSTOM_SNAPSHOT is specified for the ApplicationRestoreType .\n\nFlinkRunConfigurationDescription -> (structure)\n\nDescribes the starting parameters for a Flink-based Kinesis Data Analytics application.\n\nAllowNonRestoredState -> (boolean)\n\nWhen restoring from a snapshot, specifies whether the runtime is allowed to skip a state that cannot be mapped to the new program. This will happen if the program is updated between snapshots to remove stateful parameters, and state data in the snapshot no longer corresponds to valid application data. For more information, see Allowing Non-Restored State in the Apache Flink documentation .\n\nNote\n\nThis value defaults to false . If you update your application without specifying this parameter, AllowNonRestoredState will be set to false , even if it was previously set to true .\n\nFlinkApplicationConfigurationDescription -> (structure)\n\nThe details about a Flink-based Kinesis Data Analytics application.\n\nCheckpointConfigurationDescription -> (structure)\n\nDescribes an application’s checkpointing configuration. Checkpointing is the process of persisting application state for fault tolerance.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default checkpointing behavior in Kinesis Data Analytics.\n\nNote\n\nIf this value is set to DEFAULT , the application will use the following values, even if they are set to other values using APIs or application code:\n\nCheckpointingEnabled: true\n\nCheckpointInterval: 60000\n\nMinPauseBetweenCheckpoints: 5000\n\nCheckpointingEnabled -> (boolean)\n\nDescribes whether checkpointing is enabled for a Flink-based Kinesis Data Analytics application.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointingEnabled value of true , even if this value is set to another value using this API or in application code.\n\nCheckpointInterval -> (long)\n\nDescribes the interval in milliseconds between checkpoint operations.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointInterval value of 60000, even if this value is set to another value using this API or in application code.\n\nMinPauseBetweenCheckpoints -> (long)\n\nDescribes the minimum time in milliseconds after a checkpoint operation completes that a new checkpoint operation can start.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a MinPauseBetweenCheckpoints value of 5000, even if this value is set using this API or in application code.\n\nMonitoringConfigurationDescription -> (structure)\n\nDescribes configuration parameters for Amazon CloudWatch logging for an application.\n\nConfigurationType -> (string)\n\nDescribes whether to use the default CloudWatch logging configuration for an application.\n\nMetricsLevel -> (string)\n\nDescribes the granularity of the CloudWatch Logs for an application.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nParallelismConfigurationDescription -> (structure)\n\nDescribes parameters for how an application executes multiple tasks simultaneously.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default parallelism for the Kinesis Data Analytics service.\n\nParallelism -> (integer)\n\nDescribes the initial number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, then Kinesis Data Analytics can increase the CurrentParallelism value in response to application load. The service can increase CurrentParallelism up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nParallelismPerKPU -> (integer)\n\nDescribes the number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform per Kinesis Processing Unit (KPU) used by the application.\n\nCurrentParallelism -> (integer)\n\nDescribes the current number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, Kinesis Data Analytics can increase this value in response to application load. The service can increase this value up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nAutoScalingEnabled -> (boolean)\n\nDescribes whether the Kinesis Data Analytics service can increase the parallelism of the application in response to increased throughput.\n\nJobPlanDescription -> (string)\n\nThe job plan for an application. For more information about the job plan, see Jobs and Scheduling in the Apache Flink Documentation . To retrieve the job plan for the application, use the DescribeApplicationRequest$IncludeAdditionalDetails parameter of the DescribeApplication operation.\n\nEnvironmentPropertyDescriptions -> (structure)\n\nDescribes execution properties for a Flink-based Kinesis Data Analytics application.\n\nPropertyGroupDescriptions -> (list)\n\nDescribes the execution property groups.\n\n(structure)\n\nProperty key-value pairs passed into an application.\n\nPropertyGroupId -> (string)\n\nDescribes the key of an application execution property key-value pair.\n\nPropertyMap -> (map)\n\nDescribes the value of an application execution property key-value pair.\n\nkey -> (string)\n\nvalue -> (string)\n\nApplicationSnapshotConfigurationDescription -> (structure)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nSnapshotsEnabled -> (boolean)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nVpcConfigurationDescriptions -> (list)\n\nThe array of descriptions of VPC configurations available to the application.\n\n(structure)\n\nDescribes the parameters of a VPC used by the application.\n\nVpcConfigurationId -> (string)\n\nThe ID of the VPC configuration.\n\nVpcId -> (string)\n\nThe ID of the associated VPC.\n\nSubnetIds -> (list)\n\nThe array of Subnet IDs used by the VPC configuration.\n\n(string)\n\nSecurityGroupIds -> (list)\n\nThe array of SecurityGroup IDs used by the VPC configuration.\n\n(string)\n\nZeppelinApplicationConfigurationDescription -> (structure)\n\nThe configuration parameters for a Kinesis Data Analytics Studio notebook.\n\nMonitoringConfigurationDescription -> (structure)\n\nThe monitoring configuration of a Kinesis Data Analytics Studio notebook.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nCatalogConfigurationDescription -> (structure)\n\nThe Amazon Glue Data Catalog that is associated with the Kinesis Data Analytics Studio notebook.\n\nGlueDataCatalogConfigurationDescription -> (structure)\n\nThe configuration parameters for the default Amazon Glue database. You use this database for SQL queries that you write in a Kinesis Data Analytics Studio notebook.\n\nDatabaseARN -> (string)\n\nThe Amazon Resource Name (ARN) of the database.\n\nDeployAsApplicationConfigurationDescription -> (structure)\n\nThe parameters required to deploy a Kinesis Data Analytics Studio notebook as an application with durable state.\n\nS3ContentLocationDescription -> (structure)\n\nThe location that holds the data required to specify an Amazon Data Analytics application.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nBasePath -> (string)\n\nThe base path for the S3 bucket.\n\nCustomArtifactsConfigurationDescription -> (list)\n\nCustom artifacts are dependency JARs and user-defined functions (UDF).\n\n(structure)\n\nSpecifies a dependency JAR or a JAR of user-defined functions.\n\nArtifactType -> (string)\n\nUDF stands for user-defined functions. This type of artifact must be in an S3 bucket. A DEPENDENCY_JAR can be in either Maven or an S3 bucket.\n\nS3ContentLocationDescription -> (structure)\n\nFor a Kinesis Data Analytics application provides a description of an Amazon S3 object, including the Amazon Resource Name (ARN) of the S3 bucket, the name of the Amazon S3 object that contains the data, and the version number of the Amazon S3 object that contains the data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nMavenReferenceDescription -> (structure)\n\nThe parameters that are required to specify a Maven dependency.\n\nGroupId -> (string)\n\nThe group ID of the Maven reference.\n\nArtifactId -> (string)\n\nThe artifact ID of the Maven reference.\n\nVersion -> (string)\n\nThe version of the Maven reference.\n\nCloudWatchLoggingOptionDescriptions -> (list)\n\nDescribes the application Amazon CloudWatch logging options.\n\n(structure)\n\nDescribes the Amazon CloudWatch logging option.\n\nCloudWatchLoggingOptionId -> (string)\n\nThe ID of the CloudWatch logging option description.\n\nLogStreamARN -> (string)\n\nThe Amazon Resource Name (ARN) of the CloudWatch log to receive application messages.\n\nRoleARN -> (string)\n\nThe IAM ARN of the role to use to send application messages.\n\nNote\n\nProvided for backward compatibility. Applications created with the current API version have an application-level service execution role rather than a resource-level role.\n\nApplicationMaintenanceConfigurationDescription -> (structure)\n\nThe details of the maintenance configuration for the application.\n\nApplicationMaintenanceWindowStartTime -> (string)\n\nThe start time for the maintenance window.\n\nApplicationMaintenanceWindowEndTime -> (string)\n\nThe end time for the maintenance window.\n\nApplicationVersionUpdatedFrom -> (long)\n\nThe previous application version before the latest application update. RollbackApplication reverts the application to this version.\n\nApplicationVersionRolledBackFrom -> (long)\n\nIf you reverted the application using RollbackApplication , the application version when RollbackApplication was called.\n\nConditionalToken -> (string)\n\nA value you use to implement strong concurrency for application updates.\n\nApplicationVersionRolledBackTo -> (long)\n\nThe version to which you want to roll back the application.\n\nApplicationMode -> (string)\n\nTo create a Kinesis Data Analytics Studio notebook, you must set the mode to INTERACTIVE . However, for a Kinesis Data Analytics for Apache Flink application, the mode is optional."
    },
    {
      "command_name": "start-application",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/start-application.html",
      "command_description": "Description\n\nStarts the specified Kinesis Data Analytics application. After creating an application, you must exclusively call this operation to start your application.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-application\n--application-name <value>\n[--run-configuration <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--run-configuration <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application.\n\n--run-configuration (structure)\n\nIdentifies the run configuration (start parameters) of a Kinesis Data Analytics application.\n\nFlinkRunConfiguration -> (structure)\n\nDescribes the starting parameters for a Flink-based Kinesis Data Analytics application.\n\nAllowNonRestoredState -> (boolean)\n\nWhen restoring from a snapshot, specifies whether the runtime is allowed to skip a state that cannot be mapped to the new program. This will happen if the program is updated between snapshots to remove stateful parameters, and state data in the snapshot no longer corresponds to valid application data. For more information, see Allowing Non-Restored State in the Apache Flink documentation .\n\nNote\n\nThis value defaults to false . If you update your application without specifying this parameter, AllowNonRestoredState will be set to false , even if it was previously set to true .\n\nSqlRunConfigurations -> (list)\n\nDescribes the starting parameters for a SQL-based Kinesis Data Analytics application application.\n\n(structure)\n\nDescribes the starting parameters for a SQL-based Kinesis Data Analytics application.\n\nInputId -> (string)\n\nThe input source ID. You can get this ID by calling the DescribeApplication operation.\n\nInputStartingPositionConfiguration -> (structure)\n\nThe point at which you want the application to start processing records from the streaming source.\n\nInputStartingPosition -> (string)\n\nThe starting position on the stream.\n\nNOW - Start reading just after the most recent record in the stream, and start at the request timestamp that the customer issued.\n\nTRIM_HORIZON - Start reading at the last untrimmed record in the stream, which is the oldest record available in the stream. This option is not available for an Amazon Kinesis Data Firehose delivery stream.\n\nLAST_STOPPED_POINT - Resume reading from where the application last stopped reading.\n\nApplicationRestoreConfiguration -> (structure)\n\nDescribes the restore behavior of a restarting application.\n\nApplicationRestoreType -> (string)\n\nSpecifies how the application should be restored.\n\nSnapshotName -> (string)\n\nThe identifier of an existing snapshot of application state to use to restart an application. The application uses this value if RESTORE_FROM_CUSTOM_SNAPSHOT is specified for the ApplicationRestoreType .\n\nJSON Syntax:\n\n{\n  \"FlinkRunConfiguration\": {\n    \"AllowNonRestoredState\": true|false\n  },\n  \"SqlRunConfigurations\": [\n    {\n      \"InputId\": \"string\",\n      \"InputStartingPositionConfiguration\": {\n        \"InputStartingPosition\": \"NOW\"|\"TRIM_HORIZON\"|\"LAST_STOPPED_POINT\"\n      }\n    }\n    ...\n  ],\n  \"ApplicationRestoreConfiguration\": {\n    \"ApplicationRestoreType\": \"SKIP_RESTORE_FROM_SNAPSHOT\"|\"RESTORE_FROM_LATEST_SNAPSHOT\"|\"RESTORE_FROM_CUSTOM_SNAPSHOT\",\n    \"SnapshotName\": \"string\"\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "stop-application",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/stop-application.html",
      "command_description": "Description\n\nStops the application from processing data. You can stop an application only if it is in the running status, unless you set the Force parameter to true .\n\nYou can use the DescribeApplication operation to find the application status.\n\nKinesis Data Analytics takes a snapshot when the application is stopped, unless Force is set to true .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  stop-application\n--application-name <value>\n[--force | --no-force]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--force | --no-force]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the running application to stop.\n\n--force | --no-force (boolean)\n\nSet to true to force the application to stop. If you set Force to true , Kinesis Data Analytics stops the application without taking a snapshot.\n\nNote\n\nForce-stopping your application may lead to data loss or duplication. To prevent data loss or duplicate processing of data during application restarts, we recommend you to take frequent snapshots of your application.\n\nYou can only force stop a Flink-based Kinesis Data Analytics application. You can’t force stop a SQL-based Kinesis Data Analytics application.\n\nThe application must be in the STARTING , UPDATING , STOPPING , AUTOSCALING , or RUNNING status.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "tag-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/tag-resource.html",
      "command_description": "Description\n\nAdds one or more key-value tags to a Kinesis Data Analytics application. Note that the maximum number of application tags includes system tags. The maximum number of user-defined application tags is 50. For more information, see Using Tagging .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  tag-resource\n--resource-arn <value>\n--tags <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "--tags <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe ARN of the application to assign the tags.\n\n--tags (list)\n\nThe key-value tags to assign to the application.\n\n(structure)\n\nA key-value pair (the value is optional) that you can define and assign to Amazon resources. If you specify a tag that already exists, the tag value is replaced with the value that you specify in the request. Note that the maximum number of application tags includes system tags. The maximum number of user-defined application tags is 50. For more information, see Using Tagging .\n\nKey -> (string)\n\nThe key of the key-value tag.\n\nValue -> (string)\n\nThe value of the key-value tag. The value is optional.\n\nShorthand Syntax:\n\nKey=string,Value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Key\": \"string\",\n    \"Value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "untag-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/untag-resource.html",
      "command_description": "Description\n\nRemoves one or more tags from a Kinesis Data Analytics application. For more information, see Using Tagging .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  untag-resource\n--resource-arn <value>\n--tag-keys <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "--tag-keys <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe ARN of the Kinesis Data Analytics application from which to remove the tags.\n\n--tag-keys (list)\n\nA list of keys of tags to remove from the specified application.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "update-application",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/update-application.html",
      "command_description": "Description\n\nUpdates an existing Kinesis Data Analytics application. Using this operation, you can update application code, input configuration, and output configuration.\n\nKinesis Data Analytics updates the ApplicationVersionId each time you update your application.\n\nNote\n\nYou cannot update the RuntimeEnvironment of an existing application. If you need to update an application’s RuntimeEnvironment , you must delete the application and create it again.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-application\n--application-name <value>\n[--current-application-version-id <value>]\n[--application-configuration-update <value>]\n[--service-execution-role-update <value>]\n[--run-configuration-update <value>]\n[--cloud-watch-logging-option-updates <value>]\n[--conditional-token <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "[--current-application-version-id <value>]",
        "[--application-configuration-update <value>]",
        "[--service-execution-role-update <value>]",
        "[--run-configuration-update <value>]",
        "[--cloud-watch-logging-option-updates <value>]",
        "[--conditional-token <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application to update.\n\n--current-application-version-id (long)\n\nThe current application version ID. You must provide the CurrentApplicationVersionId or the ConditionalToken .You can retrieve the application version ID using DescribeApplication . For better concurrency support, use the ConditionalToken parameter instead of CurrentApplicationVersionId .\n\n--application-configuration-update (structure)\n\nDescribes application configuration updates.\n\nSqlApplicationConfigurationUpdate -> (structure)\n\nDescribes updates to a SQL-based Kinesis Data Analytics application’s configuration.\n\nInputUpdates -> (list)\n\nThe array of InputUpdate objects describing the new input streams used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes updates to a specific input configuration (identified by the InputId of an application).\n\nInputId -> (string)\n\nThe input ID of the application input to be updated.\n\nNamePrefixUpdate -> (string)\n\nThe name prefix for in-application streams that Kinesis Data Analytics creates for the specific streaming source.\n\nInputProcessingConfigurationUpdate -> (structure)\n\nDescribes updates to an InputProcessingConfiguration .\n\nInputLambdaProcessorUpdate -> (structure)\n\nProvides update information for an InputLambdaProcessor .\n\nResourceARNUpdate -> (string)\n\nThe Amazon Resource Name (ARN) of the new Amazon Lambda function that is used to preprocess the records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nKinesisStreamsInputUpdate -> (structure)\n\nIf a Kinesis data stream is the streaming source to be updated, provides an updated stream Amazon Resource Name (ARN).\n\nResourceARNUpdate -> (string)\n\nThe Amazon Resource Name (ARN) of the input Kinesis data stream to read.\n\nKinesisFirehoseInputUpdate -> (structure)\n\nIf a Kinesis Data Firehose delivery stream is the streaming source to be updated, provides an updated stream ARN.\n\nResourceARNUpdate -> (string)\n\nThe Amazon Resource Name (ARN) of the input delivery stream to read.\n\nInputSchemaUpdate -> (structure)\n\nDescribes the data format on the streaming source, and how record elements on the streaming source map to columns of the in-application stream that is created.\n\nRecordFormatUpdate -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncodingUpdate -> (string)\n\nSpecifies the encoding of the records in the streaming source; for example, UTF-8.\n\nRecordColumnUpdates -> (list)\n\nA list of RecordColumn objects. Each object describes the mapping of the streaming source element to the corresponding column in the in-application stream.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nInputParallelismUpdate -> (structure)\n\nDescribes the parallelism updates (the number of in-application streams Kinesis Data Analytics creates for the specific streaming source).\n\nCountUpdate -> (integer)\n\nThe number of in-application streams to create for the specified streaming source.\n\nOutputUpdates -> (list)\n\nThe array of OutputUpdate objects describing the new destination streams used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes updates to the output configuration identified by the OutputId .\n\nOutputId -> (string)\n\nIdentifies the specific output configuration that you want to update.\n\nNameUpdate -> (string)\n\nIf you want to specify a different in-application stream for this output configuration, use this field to specify the new in-application stream name.\n\nKinesisStreamsOutputUpdate -> (structure)\n\nDescribes a Kinesis data stream as the destination for the output.\n\nResourceARNUpdate -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream where you want to write the output.\n\nKinesisFirehoseOutputUpdate -> (structure)\n\nDescribes a Kinesis Data Firehose delivery stream as the destination for the output.\n\nResourceARNUpdate -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream to write to.\n\nLambdaOutputUpdate -> (structure)\n\nDescribes an Amazon Lambda function as the destination for the output.\n\nResourceARNUpdate -> (string)\n\nThe Amazon Resource Name (ARN) of the destination Amazon Lambda function.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nDestinationSchemaUpdate -> (structure)\n\nDescribes the data format when records are written to the destination.\n\nRecordFormatType -> (string)\n\nSpecifies the format of the records on the output stream.\n\nReferenceDataSourceUpdates -> (list)\n\nThe array of ReferenceDataSourceUpdate objects describing the new reference data sources used by the application.\n\n(structure)\n\nWhen you update a reference data source configuration for a SQL-based Kinesis Data Analytics application, this object provides all the updated values (such as the source bucket name and object key name), the in-application table name that is created, and updated mapping information that maps the data in the Amazon S3 object to the in-application reference table that is created.\n\nReferenceId -> (string)\n\nThe ID of the reference data source that is being updated. You can use the DescribeApplication operation to get this value.\n\nTableNameUpdate -> (string)\n\nThe in-application table name that is created by this update.\n\nS3ReferenceDataSourceUpdate -> (structure)\n\nDescribes the S3 bucket name, object key name, and IAM role that Kinesis Data Analytics can assume to read the Amazon S3 object on your behalf and populate the in-application reference table.\n\nBucketARNUpdate -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nFileKeyUpdate -> (string)\n\nThe object key name.\n\nReferenceSchemaUpdate -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns created in the in-application stream.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nApplicationCodeConfigurationUpdate -> (structure)\n\nDescribes updates to an application’s code configuration.\n\nCodeContentTypeUpdate -> (string)\n\nDescribes updates to the code content type.\n\nCodeContentUpdate -> (structure)\n\nDescribes updates to the code content of an application.\n\nTextContentUpdate -> (string)\n\nDescribes an update to the text code for an application.\n\nZipFileContentUpdate -> (blob)\n\nDescribes an update to the zipped code for an application.\n\nS3ContentLocationUpdate -> (structure)\n\nDescribes an update to the location of code for an application.\n\nBucketARNUpdate -> (string)\n\nThe new Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKeyUpdate -> (string)\n\nThe new file key for the object containing the application code.\n\nObjectVersionUpdate -> (string)\n\nThe new version of the object containing the application code.\n\nFlinkApplicationConfigurationUpdate -> (structure)\n\nDescribes updates to a Flink-based Kinesis Data Analytics application’s configuration.\n\nCheckpointConfigurationUpdate -> (structure)\n\nDescribes updates to an application’s checkpointing configuration. Checkpointing is the process of persisting application state for fault tolerance.\n\nConfigurationTypeUpdate -> (string)\n\nDescribes updates to whether the application uses the default checkpointing behavior of Kinesis Data Analytics. You must set this property to CUSTOM in order to set the CheckpointingEnabled , CheckpointInterval , or MinPauseBetweenCheckpoints parameters.\n\nNote\n\nIf this value is set to DEFAULT , the application will use the following values, even if they are set to other values using APIs or application code:\n\nCheckpointingEnabled: true\n\nCheckpointInterval: 60000\n\nMinPauseBetweenCheckpoints: 5000\n\nCheckpointingEnabledUpdate -> (boolean)\n\nDescribes updates to whether checkpointing is enabled for an application.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointingEnabled value of true , even if this value is set to another value using this API or in application code.\n\nCheckpointIntervalUpdate -> (long)\n\nDescribes updates to the interval in milliseconds between checkpoint operations.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointInterval value of 60000, even if this value is set to another value using this API or in application code.\n\nMinPauseBetweenCheckpointsUpdate -> (long)\n\nDescribes updates to the minimum time in milliseconds after a checkpoint operation completes that a new checkpoint operation can start.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a MinPauseBetweenCheckpoints value of 5000, even if this value is set using this API or in application code.\n\nMonitoringConfigurationUpdate -> (structure)\n\nDescribes updates to the configuration parameters for Amazon CloudWatch logging for an application.\n\nConfigurationTypeUpdate -> (string)\n\nDescribes updates to whether to use the default CloudWatch logging configuration for an application. You must set this property to CUSTOM in order to set the LogLevel or MetricsLevel parameters.\n\nMetricsLevelUpdate -> (string)\n\nDescribes updates to the granularity of the CloudWatch Logs for an application. The Parallelism level is not recommended for applications with a Parallelism over 64 due to excessive costs.\n\nLogLevelUpdate -> (string)\n\nDescribes updates to the verbosity of the CloudWatch Logs for an application.\n\nParallelismConfigurationUpdate -> (structure)\n\nDescribes updates to the parameters for how an application executes multiple tasks simultaneously.\n\nConfigurationTypeUpdate -> (string)\n\nDescribes updates to whether the application uses the default parallelism for the Kinesis Data Analytics service, or if a custom parallelism is used. You must set this property to CUSTOM in order to change your application’s AutoScalingEnabled , Parallelism , or ParallelismPerKPU properties.\n\nParallelismUpdate -> (integer)\n\nDescribes updates to the initial number of parallel tasks an application can perform. If AutoScalingEnabled is set to True, then Kinesis Data Analytics can increase the CurrentParallelism value in response to application load. The service can increase CurrentParallelism up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service will reduce CurrentParallelism down to the Parallelism setting.\n\nParallelismPerKPUUpdate -> (integer)\n\nDescribes updates to the number of parallel tasks an application can perform per Kinesis Processing Unit (KPU) used by the application.\n\nAutoScalingEnabledUpdate -> (boolean)\n\nDescribes updates to whether the Kinesis Data Analytics service can increase the parallelism of a Flink-based Kinesis Data Analytics application in response to increased throughput.\n\nEnvironmentPropertyUpdates -> (structure)\n\nDescribes updates to the environment properties for a Flink-based Kinesis Data Analytics application.\n\nPropertyGroups -> (list)\n\nDescribes updates to the execution property groups.\n\n(structure)\n\nProperty key-value pairs passed into an application.\n\nPropertyGroupId -> (string)\n\nDescribes the key of an application execution property key-value pair.\n\nPropertyMap -> (map)\n\nDescribes the value of an application execution property key-value pair.\n\nkey -> (string)\n\nvalue -> (string)\n\nApplicationSnapshotConfigurationUpdate -> (structure)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nSnapshotsEnabledUpdate -> (boolean)\n\nDescribes updates to whether snapshots are enabled for an application.\n\nVpcConfigurationUpdates -> (list)\n\nUpdates to the array of descriptions of VPC configurations available to the application.\n\n(structure)\n\nDescribes updates to the VPC configuration used by the application.\n\nVpcConfigurationId -> (string)\n\nDescribes an update to the ID of the VPC configuration.\n\nSubnetIdUpdates -> (list)\n\nDescribes updates to the array of Subnet IDs used by the VPC configuration.\n\n(string)\n\nSecurityGroupIdUpdates -> (list)\n\nDescribes updates to the array of SecurityGroup IDs used by the VPC configuration.\n\n(string)\n\nZeppelinApplicationConfigurationUpdate -> (structure)\n\nUpdates to the configuration of a Kinesis Data Analytics Studio notebook.\n\nMonitoringConfigurationUpdate -> (structure)\n\nUpdates to the monitoring configuration of a Kinesis Data Analytics Studio notebook.\n\nLogLevelUpdate -> (string)\n\nUpdates to the logging level for Apache Zeppelin within a Kinesis Data Analytics Studio notebook.\n\nCatalogConfigurationUpdate -> (structure)\n\nUpdates to the configuration of the Amazon Glue Data Catalog that is associated with the Kinesis Data Analytics Studio notebook.\n\nGlueDataCatalogConfigurationUpdate -> (structure)\n\nUpdates to the configuration parameters for the default Amazon Glue database. You use this database for SQL queries that you write in a Kinesis Data Analytics Studio notebook.\n\nDatabaseARNUpdate -> (string)\n\nThe updated Amazon Resource Name (ARN) of the database.\n\nDeployAsApplicationConfigurationUpdate -> (structure)\n\nUpdates to the configuration information required to deploy an Amazon Data Analytics Studio notebook as an application with durable state.\n\nS3ContentLocationUpdate -> (structure)\n\nUpdates to the location that holds the data required to specify an Amazon Data Analytics application.\n\nBucketARNUpdate -> (string)\n\nThe updated Amazon Resource Name (ARN) of the S3 bucket.\n\nBasePathUpdate -> (string)\n\nThe updated S3 bucket path.\n\nCustomArtifactsConfigurationUpdate -> (list)\n\nUpdates to the customer artifacts. Custom artifacts are dependency JAR files and user-defined functions (UDF).\n\n(structure)\n\nSpecifies dependency JARs, as well as JAR files that contain user-defined functions (UDF).\n\nArtifactType -> (string)\n\nUDF stands for user-defined functions. This type of artifact must be in an S3 bucket. A DEPENDENCY_JAR can be in either Maven or an S3 bucket.\n\nS3ContentLocation -> (structure)\n\nFor a Kinesis Data Analytics application provides a description of an Amazon S3 object, including the Amazon Resource Name (ARN) of the S3 bucket, the name of the Amazon S3 object that contains the data, and the version number of the Amazon S3 object that contains the data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nMavenReference -> (structure)\n\nThe parameters required to fully specify a Maven reference.\n\nGroupId -> (string)\n\nThe group ID of the Maven reference.\n\nArtifactId -> (string)\n\nThe artifact ID of the Maven reference.\n\nVersion -> (string)\n\nThe version of the Maven reference.\n\nJSON Syntax:\n\n{\n  \"SqlApplicationConfigurationUpdate\": {\n    \"InputUpdates\": [\n      {\n        \"InputId\": \"string\",\n        \"NamePrefixUpdate\": \"string\",\n        \"InputProcessingConfigurationUpdate\": {\n          \"InputLambdaProcessorUpdate\": {\n            \"ResourceARNUpdate\": \"string\"\n          }\n        },\n        \"KinesisStreamsInputUpdate\": {\n          \"ResourceARNUpdate\": \"string\"\n        },\n        \"KinesisFirehoseInputUpdate\": {\n          \"ResourceARNUpdate\": \"string\"\n        },\n        \"InputSchemaUpdate\": {\n          \"RecordFormatUpdate\": {\n            \"RecordFormatType\": \"JSON\"|\"CSV\",\n            \"MappingParameters\": {\n              \"JSONMappingParameters\": {\n                \"RecordRowPath\": \"string\"\n              },\n              \"CSVMappingParameters\": {\n                \"RecordRowDelimiter\": \"string\",\n                \"RecordColumnDelimiter\": \"string\"\n              }\n            }\n          },\n          \"RecordEncodingUpdate\": \"string\",\n          \"RecordColumnUpdates\": [\n            {\n              \"Name\": \"string\",\n              \"Mapping\": \"string\",\n              \"SqlType\": \"string\"\n            }\n            ...\n          ]\n        },\n        \"InputParallelismUpdate\": {\n          \"CountUpdate\": integer\n        }\n      }\n      ...\n    ],\n    \"OutputUpdates\": [\n      {\n        \"OutputId\": \"string\",\n        \"NameUpdate\": \"string\",\n        \"KinesisStreamsOutputUpdate\": {\n          \"ResourceARNUpdate\": \"string\"\n        },\n        \"KinesisFirehoseOutputUpdate\": {\n          \"ResourceARNUpdate\": \"string\"\n        },\n        \"LambdaOutputUpdate\": {\n          \"ResourceARNUpdate\": \"string\"\n        },\n        \"DestinationSchemaUpdate\": {\n          \"RecordFormatType\": \"JSON\"|\"CSV\"\n        }\n      }\n      ...\n    ],\n    \"ReferenceDataSourceUpdates\": [\n      {\n        \"ReferenceId\": \"string\",\n        \"TableNameUpdate\": \"string\",\n        \"S3ReferenceDataSourceUpdate\": {\n          \"BucketARNUpdate\": \"string\",\n          \"FileKeyUpdate\": \"string\"\n        },\n        \"ReferenceSchemaUpdate\": {\n          \"RecordFormat\": {\n            \"RecordFormatType\": \"JSON\"|\"CSV\",\n            \"MappingParameters\": {\n              \"JSONMappingParameters\": {\n                \"RecordRowPath\": \"string\"\n              },\n              \"CSVMappingParameters\": {\n                \"RecordRowDelimiter\": \"string\",\n                \"RecordColumnDelimiter\": \"string\"\n              }\n            }\n          },\n          \"RecordEncoding\": \"string\",\n          \"RecordColumns\": [\n            {\n              \"Name\": \"string\",\n              \"Mapping\": \"string\",\n              \"SqlType\": \"string\"\n            }\n            ...\n          ]\n        }\n      }\n      ...\n    ]\n  },\n  \"ApplicationCodeConfigurationUpdate\": {\n    \"CodeContentTypeUpdate\": \"PLAINTEXT\"|\"ZIPFILE\",\n    \"CodeContentUpdate\": {\n      \"TextContentUpdate\": \"string\",\n      \"ZipFileContentUpdate\": blob,\n      \"S3ContentLocationUpdate\": {\n        \"BucketARNUpdate\": \"string\",\n        \"FileKeyUpdate\": \"string\",\n        \"ObjectVersionUpdate\": \"string\"\n      }\n    }\n  },\n  \"FlinkApplicationConfigurationUpdate\": {\n    \"CheckpointConfigurationUpdate\": {\n      \"ConfigurationTypeUpdate\": \"DEFAULT\"|\"CUSTOM\",\n      \"CheckpointingEnabledUpdate\": true|false,\n      \"CheckpointIntervalUpdate\": long,\n      \"MinPauseBetweenCheckpointsUpdate\": long\n    },\n    \"MonitoringConfigurationUpdate\": {\n      \"ConfigurationTypeUpdate\": \"DEFAULT\"|\"CUSTOM\",\n      \"MetricsLevelUpdate\": \"APPLICATION\"|\"TASK\"|\"OPERATOR\"|\"PARALLELISM\",\n      \"LogLevelUpdate\": \"INFO\"|\"WARN\"|\"ERROR\"|\"DEBUG\"\n    },\n    \"ParallelismConfigurationUpdate\": {\n      \"ConfigurationTypeUpdate\": \"DEFAULT\"|\"CUSTOM\",\n      \"ParallelismUpdate\": integer,\n      \"ParallelismPerKPUUpdate\": integer,\n      \"AutoScalingEnabledUpdate\": true|false\n    }\n  },\n  \"EnvironmentPropertyUpdates\": {\n    \"PropertyGroups\": [\n      {\n        \"PropertyGroupId\": \"string\",\n        \"PropertyMap\": {\"string\": \"string\"\n          ...}\n      }\n      ...\n    ]\n  },\n  \"ApplicationSnapshotConfigurationUpdate\": {\n    \"SnapshotsEnabledUpdate\": true|false\n  },\n  \"VpcConfigurationUpdates\": [\n    {\n      \"VpcConfigurationId\": \"string\",\n      \"SubnetIdUpdates\": [\"string\", ...],\n      \"SecurityGroupIdUpdates\": [\"string\", ...]\n    }\n    ...\n  ],\n  \"ZeppelinApplicationConfigurationUpdate\": {\n    \"MonitoringConfigurationUpdate\": {\n      \"LogLevelUpdate\": \"INFO\"|\"WARN\"|\"ERROR\"|\"DEBUG\"\n    },\n    \"CatalogConfigurationUpdate\": {\n      \"GlueDataCatalogConfigurationUpdate\": {\n        \"DatabaseARNUpdate\": \"string\"\n      }\n    },\n    \"DeployAsApplicationConfigurationUpdate\": {\n      \"S3ContentLocationUpdate\": {\n        \"BucketARNUpdate\": \"string\",\n        \"BasePathUpdate\": \"string\"\n      }\n    },\n    \"CustomArtifactsConfigurationUpdate\": [\n      {\n        \"ArtifactType\": \"UDF\"|\"DEPENDENCY_JAR\",\n        \"S3ContentLocation\": {\n          \"BucketARN\": \"string\",\n          \"FileKey\": \"string\",\n          \"ObjectVersion\": \"string\"\n        },\n        \"MavenReference\": {\n          \"GroupId\": \"string\",\n          \"ArtifactId\": \"string\",\n          \"Version\": \"string\"\n        }\n      }\n      ...\n    ]\n  }\n}\n\n\n--service-execution-role-update (string)\n\nDescribes updates to the service execution role.\n\n--run-configuration-update (structure)\n\nDescribes updates to the application’s starting parameters.\n\nFlinkRunConfiguration -> (structure)\n\nDescribes the starting parameters for a Flink-based Kinesis Data Analytics application.\n\nAllowNonRestoredState -> (boolean)\n\nWhen restoring from a snapshot, specifies whether the runtime is allowed to skip a state that cannot be mapped to the new program. This will happen if the program is updated between snapshots to remove stateful parameters, and state data in the snapshot no longer corresponds to valid application data. For more information, see Allowing Non-Restored State in the Apache Flink documentation .\n\nNote\n\nThis value defaults to false . If you update your application without specifying this parameter, AllowNonRestoredState will be set to false , even if it was previously set to true .\n\nApplicationRestoreConfiguration -> (structure)\n\nDescribes updates to the restore behavior of a restarting application.\n\nApplicationRestoreType -> (string)\n\nSpecifies how the application should be restored.\n\nSnapshotName -> (string)\n\nThe identifier of an existing snapshot of application state to use to restart an application. The application uses this value if RESTORE_FROM_CUSTOM_SNAPSHOT is specified for the ApplicationRestoreType .\n\nShorthand Syntax:\n\nFlinkRunConfiguration={AllowNonRestoredState=boolean},ApplicationRestoreConfiguration={ApplicationRestoreType=string,SnapshotName=string}\n\n\nJSON Syntax:\n\n{\n  \"FlinkRunConfiguration\": {\n    \"AllowNonRestoredState\": true|false\n  },\n  \"ApplicationRestoreConfiguration\": {\n    \"ApplicationRestoreType\": \"SKIP_RESTORE_FROM_SNAPSHOT\"|\"RESTORE_FROM_LATEST_SNAPSHOT\"|\"RESTORE_FROM_CUSTOM_SNAPSHOT\",\n    \"SnapshotName\": \"string\"\n  }\n}\n\n\n--cloud-watch-logging-option-updates (list)\n\nDescribes application Amazon CloudWatch logging option updates. You can only update existing CloudWatch logging options with this action. To add a new CloudWatch logging option, use AddApplicationCloudWatchLoggingOption .\n\n(structure)\n\nDescribes the Amazon CloudWatch logging option updates.\n\nCloudWatchLoggingOptionId -> (string)\n\nThe ID of the CloudWatch logging option to update\n\nLogStreamARNUpdate -> (string)\n\nThe Amazon Resource Name (ARN) of the CloudWatch log to receive application messages.\n\nShorthand Syntax:\n\nCloudWatchLoggingOptionId=string,LogStreamARNUpdate=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"CloudWatchLoggingOptionId\": \"string\",\n    \"LogStreamARNUpdate\": \"string\"\n  }\n  ...\n]\n\n\n--conditional-token (string)\n\nA value you use to implement strong concurrency for application updates. You must provide the CurrentApplicationVersionId or the ConditionalToken . You get the application’s current ConditionalToken using DescribeApplication . For better concurrency support, use the ConditionalToken parameter instead of CurrentApplicationVersionId .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationDetail -> (structure)\n\nDescribes application updates.\n\nApplicationARN -> (string)\n\nThe ARN of the application.\n\nApplicationDescription -> (string)\n\nThe description of the application.\n\nApplicationName -> (string)\n\nThe name of the application.\n\nRuntimeEnvironment -> (string)\n\nThe runtime environment for the application (SQL-1_0 , FLINK-1_6 , FLINK-1_8 , or FLINK-1_11 ).\n\nServiceExecutionRole -> (string)\n\nSpecifies the IAM role that the application uses to access external resources.\n\nApplicationStatus -> (string)\n\nThe status of the application.\n\nApplicationVersionId -> (long)\n\nProvides the current application version. Kinesis Data Analytics updates the ApplicationVersionId each time you update the application.\n\nCreateTimestamp -> (timestamp)\n\nThe current timestamp when the application was created.\n\nLastUpdateTimestamp -> (timestamp)\n\nThe current timestamp when the application was last updated.\n\nApplicationConfigurationDescription -> (structure)\n\nDescribes details about the application code and starting parameters for a Kinesis Data Analytics application.\n\nSqlApplicationConfigurationDescription -> (structure)\n\nThe details about inputs, outputs, and reference data sources for a SQL-based Kinesis Data Analytics application.\n\nInputDescriptions -> (list)\n\nThe array of InputDescription objects describing the input streams used by the application.\n\n(structure)\n\nDescribes the application input configuration for a SQL-based Kinesis Data Analytics application.\n\nInputId -> (string)\n\nThe input ID that is associated with the application input. This is the ID that Kinesis Data Analytics assigns to each input configuration that you add to your application.\n\nNamePrefix -> (string)\n\nThe in-application name prefix.\n\nInAppStreamNames -> (list)\n\nReturns the in-application stream names that are mapped to the stream source.\n\n(string)\n\nInputProcessingConfigurationDescription -> (structure)\n\nThe description of the preprocessor that executes on records in this input before the application’s code is run.\n\nInputLambdaProcessorDescription -> (structure)\n\nProvides configuration information about the associated InputLambdaProcessorDescription\n\nResourceARN -> (string)\n\nThe ARN of the Amazon Lambda function that is used to preprocess the records in the stream.\n\nNote\n\nTo specify an earlier version of the Lambda function than the latest, include the Lambda function version in the Lambda function ARN. For more information about Lambda ARNs, see Example ARNs: Amazon Lambda\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that is used to access the Amazon Lambda function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisStreamsInputDescription -> (structure)\n\nIf a Kinesis data stream is configured as a streaming source, provides the Kinesis data stream’s Amazon Resource Name (ARN).\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseInputDescription -> (structure)\n\nIf a Kinesis Data Firehose delivery stream is configured as a streaming source, provides the delivery stream’s ARN.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics assumes to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nInputSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns in the in-application stream that is being created.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nInputParallelism -> (structure)\n\nDescribes the configured parallelism (number of in-application streams mapped to the streaming source).\n\nCount -> (integer)\n\nThe number of in-application streams to create.\n\nInputStartingPositionConfiguration -> (structure)\n\nThe point at which the application is configured to read from the input stream.\n\nInputStartingPosition -> (string)\n\nThe starting position on the stream.\n\nNOW - Start reading just after the most recent record in the stream, and start at the request timestamp that the customer issued.\n\nTRIM_HORIZON - Start reading at the last untrimmed record in the stream, which is the oldest record available in the stream. This option is not available for an Amazon Kinesis Data Firehose delivery stream.\n\nLAST_STOPPED_POINT - Resume reading from where the application last stopped reading.\n\nOutputDescriptions -> (list)\n\nThe array of OutputDescription objects describing the destination streams used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the application output configuration, which includes the in-application stream name and the destination where the stream data is written. The destination can be a Kinesis data stream or a Kinesis Data Firehose delivery stream.\n\nOutputId -> (string)\n\nA unique identifier for the output configuration.\n\nName -> (string)\n\nThe name of the in-application stream that is configured as output.\n\nKinesisStreamsOutputDescription -> (structure)\n\nDescribes the Kinesis data stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the Kinesis data stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nKinesisFirehoseOutputDescription -> (structure)\n\nDescribes the Kinesis Data Firehose delivery stream that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the delivery stream.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to access the stream.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nLambdaOutputDescription -> (structure)\n\nDescribes the Lambda function that is configured as the destination where output is written.\n\nResourceARN -> (string)\n\nThe Amazon Resource Name (ARN) of the destination Lambda function.\n\nRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to write to the destination function.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nDestinationSchema -> (structure)\n\nThe data format used for writing data to the destination.\n\nRecordFormatType -> (string)\n\nSpecifies the format of the records on the output stream.\n\nReferenceDataSourceDescriptions -> (list)\n\nThe array of ReferenceDataSourceDescription objects describing the reference data sources used by the application.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the reference data source configured for an application.\n\nReferenceId -> (string)\n\nThe ID of the reference data source. This is the ID that Kinesis Data Analytics assigns when you add the reference data source to your application using the CreateApplication or UpdateApplication operation.\n\nTableName -> (string)\n\nThe in-application table name created by the specific reference data source configuration.\n\nS3ReferenceDataSourceDescription -> (structure)\n\nProvides the Amazon S3 bucket name, the object key name that contains the reference data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nFileKey -> (string)\n\nAmazon S3 object key name.\n\nReferenceRoleARN -> (string)\n\nThe ARN of the IAM role that Kinesis Data Analytics can assume to read the Amazon S3 object on your behalf to populate the in-application reference table.\n\nNote\n\nProvided for backward compatibility. Applications that are created with the current API version have an application-level service execution role rather than a resource-level role.\n\nReferenceSchema -> (structure)\n\nDescribes the format of the data in the streaming source, and how each data element maps to corresponding columns created in the in-application stream.\n\nRecordFormat -> (structure)\n\nSpecifies the format of the records on the streaming source.\n\nRecordFormatType -> (string)\n\nThe type of record format.\n\nMappingParameters -> (structure)\n\nWhen you configure application input at the time of creating or updating an application, provides additional mapping information specific to the record format (such as JSON, CSV, or record fields delimited by some delimiter) on the streaming source.\n\nJSONMappingParameters -> (structure)\n\nProvides additional mapping information when JSON is the record format on the streaming source.\n\nRecordRowPath -> (string)\n\nThe path to the top-level parent that contains the records.\n\nCSVMappingParameters -> (structure)\n\nProvides additional mapping information when the record format uses delimiters (for example, CSV).\n\nRecordRowDelimiter -> (string)\n\nThe row delimiter. For example, in a CSV format, ‘n’ is the typical row delimiter.\n\nRecordColumnDelimiter -> (string)\n\nThe column delimiter. For example, in a CSV format, a comma (“,”) is the typical column delimiter.\n\nRecordEncoding -> (string)\n\nSpecifies the encoding of the records in the streaming source. For example, UTF-8.\n\nRecordColumns -> (list)\n\nA list of RecordColumn objects.\n\n(structure)\n\nFor a SQL-based Kinesis Data Analytics application, describes the mapping of each data element in the streaming source to the corresponding column in the in-application stream.\n\nAlso used to describe the format of the reference data source.\n\nName -> (string)\n\nThe name of the column that is created in the in-application input stream or reference table.\n\nMapping -> (string)\n\nA reference to the data element in the streaming input or the reference data source.\n\nSqlType -> (string)\n\nThe type of column created in the in-application input stream or reference table.\n\nApplicationCodeConfigurationDescription -> (structure)\n\nThe details about the application code for a Flink-based Kinesis Data Analytics application.\n\nCodeContentType -> (string)\n\nSpecifies whether the code content is in text or zip format.\n\nCodeContentDescription -> (structure)\n\nDescribes details about the location and format of the application code.\n\nTextContent -> (string)\n\nThe text-format code\n\nCodeMD5 -> (string)\n\nThe checksum that can be used to validate zip-format code.\n\nCodeSize -> (long)\n\nThe size in bytes of the application code. Can be used to validate zip-format code.\n\nS3ApplicationCodeLocationDescription -> (structure)\n\nThe S3 bucket Amazon Resource Name (ARN), file key, and object version of the application code stored in Amazon S3.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nRunConfigurationDescription -> (structure)\n\nThe details about the starting properties for a Kinesis Data Analytics application.\n\nApplicationRestoreConfigurationDescription -> (structure)\n\nDescribes the restore behavior of a restarting application.\n\nApplicationRestoreType -> (string)\n\nSpecifies how the application should be restored.\n\nSnapshotName -> (string)\n\nThe identifier of an existing snapshot of application state to use to restart an application. The application uses this value if RESTORE_FROM_CUSTOM_SNAPSHOT is specified for the ApplicationRestoreType .\n\nFlinkRunConfigurationDescription -> (structure)\n\nDescribes the starting parameters for a Flink-based Kinesis Data Analytics application.\n\nAllowNonRestoredState -> (boolean)\n\nWhen restoring from a snapshot, specifies whether the runtime is allowed to skip a state that cannot be mapped to the new program. This will happen if the program is updated between snapshots to remove stateful parameters, and state data in the snapshot no longer corresponds to valid application data. For more information, see Allowing Non-Restored State in the Apache Flink documentation .\n\nNote\n\nThis value defaults to false . If you update your application without specifying this parameter, AllowNonRestoredState will be set to false , even if it was previously set to true .\n\nFlinkApplicationConfigurationDescription -> (structure)\n\nThe details about a Flink-based Kinesis Data Analytics application.\n\nCheckpointConfigurationDescription -> (structure)\n\nDescribes an application’s checkpointing configuration. Checkpointing is the process of persisting application state for fault tolerance.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default checkpointing behavior in Kinesis Data Analytics.\n\nNote\n\nIf this value is set to DEFAULT , the application will use the following values, even if they are set to other values using APIs or application code:\n\nCheckpointingEnabled: true\n\nCheckpointInterval: 60000\n\nMinPauseBetweenCheckpoints: 5000\n\nCheckpointingEnabled -> (boolean)\n\nDescribes whether checkpointing is enabled for a Flink-based Kinesis Data Analytics application.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointingEnabled value of true , even if this value is set to another value using this API or in application code.\n\nCheckpointInterval -> (long)\n\nDescribes the interval in milliseconds between checkpoint operations.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a CheckpointInterval value of 60000, even if this value is set to another value using this API or in application code.\n\nMinPauseBetweenCheckpoints -> (long)\n\nDescribes the minimum time in milliseconds after a checkpoint operation completes that a new checkpoint operation can start.\n\nNote\n\nIf CheckpointConfiguration.ConfigurationType is DEFAULT , the application will use a MinPauseBetweenCheckpoints value of 5000, even if this value is set using this API or in application code.\n\nMonitoringConfigurationDescription -> (structure)\n\nDescribes configuration parameters for Amazon CloudWatch logging for an application.\n\nConfigurationType -> (string)\n\nDescribes whether to use the default CloudWatch logging configuration for an application.\n\nMetricsLevel -> (string)\n\nDescribes the granularity of the CloudWatch Logs for an application.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nParallelismConfigurationDescription -> (structure)\n\nDescribes parameters for how an application executes multiple tasks simultaneously.\n\nConfigurationType -> (string)\n\nDescribes whether the application uses the default parallelism for the Kinesis Data Analytics service.\n\nParallelism -> (integer)\n\nDescribes the initial number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, then Kinesis Data Analytics can increase the CurrentParallelism value in response to application load. The service can increase CurrentParallelism up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nParallelismPerKPU -> (integer)\n\nDescribes the number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform per Kinesis Processing Unit (KPU) used by the application.\n\nCurrentParallelism -> (integer)\n\nDescribes the current number of parallel tasks that a Flink-based Kinesis Data Analytics application can perform. If AutoScalingEnabled is set to True, Kinesis Data Analytics can increase this value in response to application load. The service can increase this value up to the maximum parallelism, which is ParalellismPerKPU times the maximum KPUs for the application. The maximum KPUs for an application is 32 by default, and can be increased by requesting a limit increase. If application load is reduced, the service can reduce the CurrentParallelism value down to the Parallelism setting.\n\nAutoScalingEnabled -> (boolean)\n\nDescribes whether the Kinesis Data Analytics service can increase the parallelism of the application in response to increased throughput.\n\nJobPlanDescription -> (string)\n\nThe job plan for an application. For more information about the job plan, see Jobs and Scheduling in the Apache Flink Documentation . To retrieve the job plan for the application, use the DescribeApplicationRequest$IncludeAdditionalDetails parameter of the DescribeApplication operation.\n\nEnvironmentPropertyDescriptions -> (structure)\n\nDescribes execution properties for a Flink-based Kinesis Data Analytics application.\n\nPropertyGroupDescriptions -> (list)\n\nDescribes the execution property groups.\n\n(structure)\n\nProperty key-value pairs passed into an application.\n\nPropertyGroupId -> (string)\n\nDescribes the key of an application execution property key-value pair.\n\nPropertyMap -> (map)\n\nDescribes the value of an application execution property key-value pair.\n\nkey -> (string)\n\nvalue -> (string)\n\nApplicationSnapshotConfigurationDescription -> (structure)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nSnapshotsEnabled -> (boolean)\n\nDescribes whether snapshots are enabled for a Flink-based Kinesis Data Analytics application.\n\nVpcConfigurationDescriptions -> (list)\n\nThe array of descriptions of VPC configurations available to the application.\n\n(structure)\n\nDescribes the parameters of a VPC used by the application.\n\nVpcConfigurationId -> (string)\n\nThe ID of the VPC configuration.\n\nVpcId -> (string)\n\nThe ID of the associated VPC.\n\nSubnetIds -> (list)\n\nThe array of Subnet IDs used by the VPC configuration.\n\n(string)\n\nSecurityGroupIds -> (list)\n\nThe array of SecurityGroup IDs used by the VPC configuration.\n\n(string)\n\nZeppelinApplicationConfigurationDescription -> (structure)\n\nThe configuration parameters for a Kinesis Data Analytics Studio notebook.\n\nMonitoringConfigurationDescription -> (structure)\n\nThe monitoring configuration of a Kinesis Data Analytics Studio notebook.\n\nLogLevel -> (string)\n\nDescribes the verbosity of the CloudWatch Logs for an application.\n\nCatalogConfigurationDescription -> (structure)\n\nThe Amazon Glue Data Catalog that is associated with the Kinesis Data Analytics Studio notebook.\n\nGlueDataCatalogConfigurationDescription -> (structure)\n\nThe configuration parameters for the default Amazon Glue database. You use this database for SQL queries that you write in a Kinesis Data Analytics Studio notebook.\n\nDatabaseARN -> (string)\n\nThe Amazon Resource Name (ARN) of the database.\n\nDeployAsApplicationConfigurationDescription -> (structure)\n\nThe parameters required to deploy a Kinesis Data Analytics Studio notebook as an application with durable state.\n\nS3ContentLocationDescription -> (structure)\n\nThe location that holds the data required to specify an Amazon Data Analytics application.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) of the S3 bucket.\n\nBasePath -> (string)\n\nThe base path for the S3 bucket.\n\nCustomArtifactsConfigurationDescription -> (list)\n\nCustom artifacts are dependency JARs and user-defined functions (UDF).\n\n(structure)\n\nSpecifies a dependency JAR or a JAR of user-defined functions.\n\nArtifactType -> (string)\n\nUDF stands for user-defined functions. This type of artifact must be in an S3 bucket. A DEPENDENCY_JAR can be in either Maven or an S3 bucket.\n\nS3ContentLocationDescription -> (structure)\n\nFor a Kinesis Data Analytics application provides a description of an Amazon S3 object, including the Amazon Resource Name (ARN) of the S3 bucket, the name of the Amazon S3 object that contains the data, and the version number of the Amazon S3 object that contains the data.\n\nBucketARN -> (string)\n\nThe Amazon Resource Name (ARN) for the S3 bucket containing the application code.\n\nFileKey -> (string)\n\nThe file key for the object containing the application code.\n\nObjectVersion -> (string)\n\nThe version of the object containing the application code.\n\nMavenReferenceDescription -> (structure)\n\nThe parameters that are required to specify a Maven dependency.\n\nGroupId -> (string)\n\nThe group ID of the Maven reference.\n\nArtifactId -> (string)\n\nThe artifact ID of the Maven reference.\n\nVersion -> (string)\n\nThe version of the Maven reference.\n\nCloudWatchLoggingOptionDescriptions -> (list)\n\nDescribes the application Amazon CloudWatch logging options.\n\n(structure)\n\nDescribes the Amazon CloudWatch logging option.\n\nCloudWatchLoggingOptionId -> (string)\n\nThe ID of the CloudWatch logging option description.\n\nLogStreamARN -> (string)\n\nThe Amazon Resource Name (ARN) of the CloudWatch log to receive application messages.\n\nRoleARN -> (string)\n\nThe IAM ARN of the role to use to send application messages.\n\nNote\n\nProvided for backward compatibility. Applications created with the current API version have an application-level service execution role rather than a resource-level role.\n\nApplicationMaintenanceConfigurationDescription -> (structure)\n\nThe details of the maintenance configuration for the application.\n\nApplicationMaintenanceWindowStartTime -> (string)\n\nThe start time for the maintenance window.\n\nApplicationMaintenanceWindowEndTime -> (string)\n\nThe end time for the maintenance window.\n\nApplicationVersionUpdatedFrom -> (long)\n\nThe previous application version before the latest application update. RollbackApplication reverts the application to this version.\n\nApplicationVersionRolledBackFrom -> (long)\n\nIf you reverted the application using RollbackApplication , the application version when RollbackApplication was called.\n\nConditionalToken -> (string)\n\nA value you use to implement strong concurrency for application updates.\n\nApplicationVersionRolledBackTo -> (long)\n\nThe version to which you want to roll back the application.\n\nApplicationMode -> (string)\n\nTo create a Kinesis Data Analytics Studio notebook, you must set the mode to INTERACTIVE . However, for a Kinesis Data Analytics for Apache Flink application, the mode is optional."
    },
    {
      "command_name": "update-application-maintenance-configuration",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/kinesisanalyticsv2/update-application-maintenance-configuration.html",
      "command_description": "Description\n\nUpdates the maintenance configuration of the Kinesis Data Analytics application.\n\nYou can invoke this operation on an application that is in one of the two following states: READY or RUNNING . If you invoke it when the application is in a state other than these two states, it throws a ResourceInUseException . The service makes use of the updated configuration the next time it schedules maintenance for the application. If you invoke this operation after the service schedules maintenance, the service will apply the configuration update the next time it schedules maintenance for the application. This means that you might not see the maintenance configuration update applied to the maintenance process that follows a successful invocation of this operation, but to the following maintenance process instead.\n\nTo see the current maintenance configuration of your application, invoke the DescribeApplication operation.\n\nFor information about application maintenance, see Kinesis Data Analytics for Apache Flink Maintenance .\n\nNote\n\nThis operation is supported only for Amazon Kinesis Data Analytics for Apache Flink.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-application-maintenance-configuration\n--application-name <value>\n--application-maintenance-configuration-update <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--application-name <value>",
        "--application-maintenance-configuration-update <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--application-name (string)\n\nThe name of the application for which you want to update the maintenance configuration.\n\n--application-maintenance-configuration-update (structure)\n\nDescribes the application maintenance configuration update.\n\nApplicationMaintenanceWindowStartTimeUpdate -> (string)\n\nThe updated start time for the maintenance window.\n\nShorthand Syntax:\n\nApplicationMaintenanceWindowStartTimeUpdate=string\n\n\nJSON Syntax:\n\n{\n  \"ApplicationMaintenanceWindowStartTimeUpdate\": \"string\"\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nApplicationARN -> (string)\n\nThe Amazon Resource Name (ARN) of the application.\n\nApplicationMaintenanceConfigurationDescription -> (structure)\n\nThe application maintenance configuration description after the update.\n\nApplicationMaintenanceWindowStartTime -> (string)\n\nThe start time for the maintenance window.\n\nApplicationMaintenanceWindowEndTime -> (string)\n\nThe end time for the maintenance window."
    }
  ],
  "service_description": "Description\n\nAmazon Kinesis Data Analytics is a fully managed service that you can use to process and analyze streaming data using Java, SQL, or Scala. The service enables you to quickly author and run Java, SQL, or Scala code against streaming sources to perform time series analytics, feed real-time dashboards, and create real-time metrics."
}