{
  "service_name": "textract",
  "service_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/textract/index.html",
  "service_commands": [
    {
      "command_name": "analyze-document",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/textract/analyze-document.html",
      "command_description": "Description\n\nAnalyzes an input document for relationships between detected items.\n\nThe types of information returned are as follows:\n\nForm data (key-value pairs). The related information is returned in two Block objects, each of type KEY_VALUE_SET : a KEY Block object and a VALUE Block object. For example, Name: Ana Silva Carolina contains a key and value. Name: is the key. Ana Silva Carolina is the value.\n\nTable and table cell data. A TABLE Block object contains information about a detected table. A CELL Block object is returned for each cell in a table.\n\nLines and words of text. A LINE Block object contains one or more WORD Block objects. All lines and words that are detected in the document are returned (including text that doesn’t have a relationship with the value of FeatureTypes ).\n\nSelection elements such as check boxes and option buttons (radio buttons) can be detected in form data and in tables. A SELECTION_ELEMENT Block object contains information about a selection element, including the selection status.\n\nYou can choose which type of analysis to perform by specifying the FeatureTypes list.\n\nThe output is returned in a list of Block objects.\n\nAnalyzeDocument is a synchronous operation. To analyze documents asynchronously, use StartDocumentAnalysis .\n\nFor more information, see Document Text Analysis .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  analyze-document\n--document <value>\n--feature-types <value>\n[--human-loop-config <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--document <value>",
        "--feature-types <value>",
        "[--human-loop-config <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--document (structure)\n\nThe input document as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Textract operations, you can’t pass image bytes. The document must be an image in JPEG or PNG format.\n\nIf you’re using an AWS SDK to call Amazon Textract, you might not need to base64-encode image bytes that are passed using the Bytes field.\n\nBytes -> (blob)\n\nA blob of base64-encoded document bytes. The maximum size of a document that’s provided in a blob of bytes is 5 MB. The document bytes must be in PNG or JPEG format.\n\nIf you’re using an AWS SDK to call Amazon Textract, you might not need to base64-encode image bytes passed using the Bytes field.\n\nS3Object -> (structure)\n\nIdentifies an S3 object as the document source. The maximum size of a document that’s stored in an S3 bucket is 5 MB.\n\nBucket -> (string)\n\nThe name of the S3 bucket. Note that the # character is not valid in the file name.\n\nName -> (string)\n\nThe file name of the input document. Synchronous operations can use image files that are in JPEG or PNG format. Asynchronous operations also support PDF and TIFF format files.\n\nVersion -> (string)\n\nIf the bucket has versioning enabled, you can specify the object version.\n\nShorthand Syntax:\n\nBytes=blob,S3Object={Bucket=string,Name=string,Version=string}\n\n\nJSON Syntax:\n\n{\n  \"Bytes\": blob,\n  \"S3Object\": {\n    \"Bucket\": \"string\",\n    \"Name\": \"string\",\n    \"Version\": \"string\"\n  }\n}\n\n\n--feature-types (list)\n\nA list of the types of analysis to perform. Add TABLES to the list to return information about the tables that are detected in the input document. Add FORMS to return detected form data. To perform both types of analysis, add TABLES and FORMS to FeatureTypes . All lines and words detected in the document are included in the response (including text that isn’t related to the value of FeatureTypes ).\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  TABLES\n  FORMS\n\n\n--human-loop-config (structure)\n\nSets the configuration for the human in the loop workflow for analyzing documents.\n\nHumanLoopName -> (string)\n\nThe name of the human workflow used for this image. This should be kept unique within a region.\n\nFlowDefinitionArn -> (string)\n\nThe Amazon Resource Name (ARN) of the flow definition.\n\nDataAttributes -> (structure)\n\nSets attributes of the input data.\n\nContentClassifiers -> (list)\n\nSets whether the input image is free of personally identifiable information or adult content.\n\n(string)\n\nShorthand Syntax:\n\nHumanLoopName=string,FlowDefinitionArn=string,DataAttributes={ContentClassifiers=[string,string]}\n\n\nJSON Syntax:\n\n{\n  \"HumanLoopName\": \"string\",\n  \"FlowDefinitionArn\": \"string\",\n  \"DataAttributes\": {\n    \"ContentClassifiers\": [\"FreeOfPersonallyIdentifiableInformation\"|\"FreeOfAdultContent\", ...]\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nDocumentMetadata -> (structure)\n\nMetadata about the analyzed document. An example is the number of pages.\n\nPages -> (integer)\n\nThe number of pages that are detected in the document.\n\nBlocks -> (list)\n\nThe items that are detected and analyzed by AnalyzeDocument .\n\n(structure)\n\nA Block represents items that are recognized in a document within a group of pixels close to each other. The information returned in a Block object depends on the type of operation. In text detection for documents (for example DetectDocumentText ), you get information about the detected words and lines of text. In text analysis (for example AnalyzeDocument ), you can also get information about the fields, tables, and selection elements that are detected in the document.\n\nAn array of Block objects is returned by both synchronous and asynchronous operations. In synchronous operations, such as DetectDocumentText , the array of Block objects is the entire set of results. In asynchronous operations, such as GetDocumentAnalysis , the array is returned over one or more responses.\n\nFor more information, see How Amazon Textract Works .\n\nBlockType -> (string)\n\nThe type of text item that’s recognized. In operations for text detection, the following types are returned:\n\nPAGE - Contains a list of the LINE Block objects that are detected on a document page.\n\nWORD - A word detected on a document page. A word is one or more ISO basic Latin script characters that aren’t separated by spaces.\n\nLINE - A string of tab-delimited, contiguous words that are detected on a document page.\n\nIn text analysis operations, the following types are returned:\n\nPAGE - Contains a list of child Block objects that are detected on a document page.\n\nKEY_VALUE_SET - Stores the KEY and VALUE Block objects for linked text that’s detected on a document page. Use the EntityType field to determine if a KEY_VALUE_SET object is a KEY Block object or a VALUE Block object.\n\nWORD - A word that’s detected on a document page. A word is one or more ISO basic Latin script characters that aren’t separated by spaces.\n\nLINE - A string of tab-delimited, contiguous words that are detected on a document page.\n\nTABLE - A table that’s detected on a document page. A table is grid-based information with two or more rows or columns, with a cell span of one row and one column each.\n\nCELL - A cell within a detected table. The cell is the parent of the block that contains the text in the cell.\n\nSELECTION_ELEMENT - A selection element such as an option button (radio button) or a check box that’s detected on a document page. Use the value of SelectionStatus to determine the status of the selection element.\n\nConfidence -> (float)\n\nThe confidence score that Amazon Textract has in the accuracy of the recognized text and the accuracy of the geometry points around the recognized text.\n\nText -> (string)\n\nThe word or line of text that’s recognized by Amazon Textract.\n\nTextType -> (string)\n\nThe kind of text that Amazon Textract has detected. Can check for handwritten text and printed text.\n\nRowIndex -> (integer)\n\nThe row in which a table cell is located. The first row position is 1. RowIndex isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nColumnIndex -> (integer)\n\nThe column in which a table cell appears. The first column position is 1. ColumnIndex isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nRowSpan -> (integer)\n\nThe number of rows that a table cell spans. Currently this value is always 1, even if the number of rows spanned is greater than 1. RowSpan isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nColumnSpan -> (integer)\n\nThe number of columns that a table cell spans. Currently this value is always 1, even if the number of columns spanned is greater than 1. ColumnSpan isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nGeometry -> (structure)\n\nThe location of the recognized text on the image. It includes an axis-aligned, coarse bounding box that surrounds the text, and a finer-grain polygon for more accurate spatial information.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nId -> (string)\n\nThe identifier for the recognized text. The identifier is only unique for a single operation.\n\nRelationships -> (list)\n\nA list of child blocks of the current block. For example, a LINE object has child blocks for each WORD block that’s part of the line of text. There aren’t Relationship objects in the list for relationships that don’t exist, such as when the current block has no child blocks. The list size can be the following:\n\n0 - The block has no child blocks.\n\n1 - The block has child blocks.\n\n(structure)\n\nInformation about how blocks are related to each other. A Block object contains 0 or more Relation objects in a list, Relationships . For more information, see Block .\n\nThe Type element provides the type of the relationship for all blocks in the IDs array.\n\nType -> (string)\n\nThe type of relationship that the blocks in the IDs array have with the current block. The relationship can be VALUE or CHILD . A relationship of type VALUE is a list that contains the ID of the VALUE block that’s associated with the KEY of a key-value pair. A relationship of type CHILD is a list of IDs that identify WORD blocks in the case of lines Cell blocks in the case of Tables, and WORD blocks in the case of Selection Elements.\n\nIds -> (list)\n\nAn array of IDs for related blocks. You can get the type of the relationship from the Type element.\n\n(string)\n\nEntityTypes -> (list)\n\nThe type of entity. The following can be returned:\n\nKEY - An identifier for a field on the document.\n\nVALUE - The field text.\n\nEntityTypes isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\n(string)\n\nSelectionStatus -> (string)\n\nThe selection status of a selection element, such as an option button or check box.\n\nPage -> (integer)\n\nThe page on which a block was detected. Page is returned by asynchronous operations. Page values greater than 1 are only returned for multipage documents that are in PDF or TIFF format. A scanned image (JPEG/PNG), even if it contains multiple document pages, is considered to be a single-page document. The value of Page is always 1. Synchronous operations don’t return Page because every input document is considered to be a single-page document.\n\nHumanLoopActivationOutput -> (structure)\n\nShows the results of the human in the loop evaluation.\n\nHumanLoopArn -> (string)\n\nThe Amazon Resource Name (ARN) of the HumanLoop created.\n\nHumanLoopActivationReasons -> (list)\n\nShows if and why human review was needed.\n\n(string)\n\nHumanLoopActivationConditionsEvaluationResults -> (string)\n\nShows the result of condition evaluations, including those conditions which activated a human review.\n\nAnalyzeDocumentModelVersion -> (string)\n\nThe version of the model used to analyze the document.",
      "command_examples": "Examples\n\nTo analyze text in a document\n\nThe following analyze-document example shows how to analyze text in a document.\n\naws textract analyze-document --document '{\"S3Object\":{\"Bucket\":\"bucket\",\"Name\":\"document\"}}' --feature-types '[\"TABLES\",\"FORMS\"]'\n\n\nOutput\n\n{\n    \"Blocks\": [\n        {\n            \"Geometry\": {\n                \"BoundingBox\": {\n                    \"Width\": 1.0,\n                    \"Top\": 0.0,\n                    \"Left\": 0.0,\n                    \"Height\": 1.0\n                },\n                \"Polygon\": [\n                    {\n                        \"Y\": 0.0,\n                        \"X\": 0.0\n                    },\n                    {\n                        \"Y\": 0.0,\n                        \"X\": 1.0\n                    },\n                    {\n                        \"Y\": 1.0,\n                        \"X\": 1.0\n                    },\n                    {\n                        \"Y\": 1.0,\n                        \"X\": 0.0\n                    }\n                ]\n            },\n            \"Relationships\": [\n                {\n                    \"Type\": \"CHILD\",\n                    \"Ids\": [\n                        \"87586964-d50d-43e2-ace5-8a890657b9a0\",\n                        \"a1e72126-21d9-44f4-a8d6-5c385f9002ba\",\n                        \"e889d012-8a6b-4d2e-b7cd-7a8b327d876a\"\n                    ]\n                }\n            ],\n            \"BlockType\": \"PAGE\",\n            \"Id\": \"c2227f12-b25d-4e1f-baea-1ee180d926b2\"\n        }\n    ],\n    \"DocumentMetadata\": {\n        \"Pages\": 1\n    }\n}\n\n\nFor more information, see Analyzing Document Text with Amazon Textract in the Amazon Textract Developers Guide"
    },
    {
      "command_name": "analyze-expense",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/textract/analyze-expense.html",
      "command_description": "Description\n\nAnalyzes an input document for financially related relationships between text.\n\nInformation is returned as ExpenseDocuments and seperated as follows.\n\nLineItemGroups - A data set containing LineItems which store information about the lines of text, such as an item purchased and its price on a receipt.\n\nSummaryFields - Contains all other information a receipt, such as header information or the vendors name.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  analyze-expense\n--document <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--document <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--document (structure)\n\nThe input document, either as bytes or as an S3 object.\n\nYou pass image bytes to an Amazon Textract API operation by using the Bytes property. For example, you would use the Bytes property to pass a document loaded from a local file system. Image bytes passed by using the Bytes property must be base64 encoded. Your code might not need to encode document file bytes if you’re using an AWS SDK to call Amazon Textract API operations.\n\nYou pass images stored in an S3 bucket to an Amazon Textract API operation by using the S3Object property. Documents stored in an S3 bucket don’t need to be base64 encoded.\n\nThe AWS Region for the S3 bucket that contains the S3 object must match the AWS Region that you use for Amazon Textract operations.\n\nIf you use the AWS CLI to call Amazon Textract operations, passing image bytes using the Bytes property isn’t supported. You must first upload the document to an Amazon S3 bucket, and then call the operation using the S3Object property.\n\nFor Amazon Textract to process an S3 object, the user must have permission to access the S3 object.\n\nBytes -> (blob)\n\nA blob of base64-encoded document bytes. The maximum size of a document that’s provided in a blob of bytes is 5 MB. The document bytes must be in PNG or JPEG format.\n\nIf you’re using an AWS SDK to call Amazon Textract, you might not need to base64-encode image bytes passed using the Bytes field.\n\nS3Object -> (structure)\n\nIdentifies an S3 object as the document source. The maximum size of a document that’s stored in an S3 bucket is 5 MB.\n\nBucket -> (string)\n\nThe name of the S3 bucket. Note that the # character is not valid in the file name.\n\nName -> (string)\n\nThe file name of the input document. Synchronous operations can use image files that are in JPEG or PNG format. Asynchronous operations also support PDF and TIFF format files.\n\nVersion -> (string)\n\nIf the bucket has versioning enabled, you can specify the object version.\n\nShorthand Syntax:\n\nBytes=blob,S3Object={Bucket=string,Name=string,Version=string}\n\n\nJSON Syntax:\n\n{\n  \"Bytes\": blob,\n  \"S3Object\": {\n    \"Bucket\": \"string\",\n    \"Name\": \"string\",\n    \"Version\": \"string\"\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nDocumentMetadata -> (structure)\n\nInformation about the input document.\n\nPages -> (integer)\n\nThe number of pages that are detected in the document.\n\nExpenseDocuments -> (list)\n\nThe expenses detected by Amazon Textract.\n\n(structure)\n\nThe structure holding all the information returned by AnalyzeExpense\n\nExpenseIndex -> (integer)\n\nDenotes which invoice or receipt in the document the information is coming from. First document will be 1, the second 2, and so on.\n\nSummaryFields -> (list)\n\nAny information found outside of a table by Amazon Textract.\n\n(structure)\n\nBreakdown of detected information, seperated into the catagories Type, LableDetection, and ValueDetection\n\nType -> (structure)\n\nThe implied label of a detected element. Present alongside LabelDetection for explicit elements.\n\nText -> (string)\n\nThe word or line of text detected by Amazon Textract.\n\nConfidence -> (float)\n\nThe confidence of accuracy, as a percentage.\n\nLabelDetection -> (structure)\n\nThe explicitly stated label of a detected element.\n\nText -> (string)\n\nThe word or line of text recognized by Amazon Textract\n\nGeometry -> (structure)\n\nInformation about where the following items are located on a document page: detected page, text, key-value pairs, tables, table cells, and selection elements.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nConfidence -> (float)\n\nThe confidence in detection, as a percentage\n\nValueDetection -> (structure)\n\nThe value of a detected element. Present in explicit and implicit elements.\n\nText -> (string)\n\nThe word or line of text recognized by Amazon Textract\n\nGeometry -> (structure)\n\nInformation about where the following items are located on a document page: detected page, text, key-value pairs, tables, table cells, and selection elements.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nConfidence -> (float)\n\nThe confidence in detection, as a percentage\n\nPageNumber -> (integer)\n\nThe page number the value was detected on.\n\nLineItemGroups -> (list)\n\nInformation detected on each table of a document, seperated into LineItems .\n\n(structure)\n\nA grouping of tables which contain LineItems, with each table identified by the table’s LineItemGroupIndex .\n\nLineItemGroupIndex -> (integer)\n\nThe number used to identify a specific table in a document. The first table encountered will have a LineItemGroupIndex of 1, the second 2, etc.\n\nLineItems -> (list)\n\nThe breakdown of information on a particular line of a table.\n\n(structure)\n\nA structure that holds information about the different lines found in a document’s tables.\n\nLineItemExpenseFields -> (list)\n\nExpenseFields used to show information from detected lines on a table.\n\n(structure)\n\nBreakdown of detected information, seperated into the catagories Type, LableDetection, and ValueDetection\n\nType -> (structure)\n\nThe implied label of a detected element. Present alongside LabelDetection for explicit elements.\n\nText -> (string)\n\nThe word or line of text detected by Amazon Textract.\n\nConfidence -> (float)\n\nThe confidence of accuracy, as a percentage.\n\nLabelDetection -> (structure)\n\nThe explicitly stated label of a detected element.\n\nText -> (string)\n\nThe word or line of text recognized by Amazon Textract\n\nGeometry -> (structure)\n\nInformation about where the following items are located on a document page: detected page, text, key-value pairs, tables, table cells, and selection elements.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nConfidence -> (float)\n\nThe confidence in detection, as a percentage\n\nValueDetection -> (structure)\n\nThe value of a detected element. Present in explicit and implicit elements.\n\nText -> (string)\n\nThe word or line of text recognized by Amazon Textract\n\nGeometry -> (structure)\n\nInformation about where the following items are located on a document page: detected page, text, key-value pairs, tables, table cells, and selection elements.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nConfidence -> (float)\n\nThe confidence in detection, as a percentage\n\nPageNumber -> (integer)\n\nThe page number the value was detected on."
    },
    {
      "command_name": "detect-document-text",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/textract/detect-document-text.html",
      "command_description": "Description\n\nDetects text in the input document. Amazon Textract can detect lines of text and the words that make up a line of text. The input document must be an image in JPEG or PNG format. DetectDocumentText returns the detected text in an array of Block objects.\n\nEach document page has as an associated Block of type PAGE. Each PAGE Block object is the parent of LINE Block objects that represent the lines of detected text on a page. A LINE Block object is a parent for each word that makes up the line. Words are represented by Block objects of type WORD.\n\nDetectDocumentText is a synchronous operation. To analyze documents asynchronously, use StartDocumentTextDetection .\n\nFor more information, see Document Text Detection .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  detect-document-text\n--document <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--document <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--document (structure)\n\nThe input document as base64-encoded bytes or an Amazon S3 object. If you use the AWS CLI to call Amazon Textract operations, you can’t pass image bytes. The document must be an image in JPEG or PNG format.\n\nIf you’re using an AWS SDK to call Amazon Textract, you might not need to base64-encode image bytes that are passed using the Bytes field.\n\nBytes -> (blob)\n\nA blob of base64-encoded document bytes. The maximum size of a document that’s provided in a blob of bytes is 5 MB. The document bytes must be in PNG or JPEG format.\n\nIf you’re using an AWS SDK to call Amazon Textract, you might not need to base64-encode image bytes passed using the Bytes field.\n\nS3Object -> (structure)\n\nIdentifies an S3 object as the document source. The maximum size of a document that’s stored in an S3 bucket is 5 MB.\n\nBucket -> (string)\n\nThe name of the S3 bucket. Note that the # character is not valid in the file name.\n\nName -> (string)\n\nThe file name of the input document. Synchronous operations can use image files that are in JPEG or PNG format. Asynchronous operations also support PDF and TIFF format files.\n\nVersion -> (string)\n\nIf the bucket has versioning enabled, you can specify the object version.\n\nShorthand Syntax:\n\nBytes=blob,S3Object={Bucket=string,Name=string,Version=string}\n\n\nJSON Syntax:\n\n{\n  \"Bytes\": blob,\n  \"S3Object\": {\n    \"Bucket\": \"string\",\n    \"Name\": \"string\",\n    \"Version\": \"string\"\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nDocumentMetadata -> (structure)\n\nMetadata about the document. It contains the number of pages that are detected in the document.\n\nPages -> (integer)\n\nThe number of pages that are detected in the document.\n\nBlocks -> (list)\n\nAn array of Block objects that contain the text that’s detected in the document.\n\n(structure)\n\nA Block represents items that are recognized in a document within a group of pixels close to each other. The information returned in a Block object depends on the type of operation. In text detection for documents (for example DetectDocumentText ), you get information about the detected words and lines of text. In text analysis (for example AnalyzeDocument ), you can also get information about the fields, tables, and selection elements that are detected in the document.\n\nAn array of Block objects is returned by both synchronous and asynchronous operations. In synchronous operations, such as DetectDocumentText , the array of Block objects is the entire set of results. In asynchronous operations, such as GetDocumentAnalysis , the array is returned over one or more responses.\n\nFor more information, see How Amazon Textract Works .\n\nBlockType -> (string)\n\nThe type of text item that’s recognized. In operations for text detection, the following types are returned:\n\nPAGE - Contains a list of the LINE Block objects that are detected on a document page.\n\nWORD - A word detected on a document page. A word is one or more ISO basic Latin script characters that aren’t separated by spaces.\n\nLINE - A string of tab-delimited, contiguous words that are detected on a document page.\n\nIn text analysis operations, the following types are returned:\n\nPAGE - Contains a list of child Block objects that are detected on a document page.\n\nKEY_VALUE_SET - Stores the KEY and VALUE Block objects for linked text that’s detected on a document page. Use the EntityType field to determine if a KEY_VALUE_SET object is a KEY Block object or a VALUE Block object.\n\nWORD - A word that’s detected on a document page. A word is one or more ISO basic Latin script characters that aren’t separated by spaces.\n\nLINE - A string of tab-delimited, contiguous words that are detected on a document page.\n\nTABLE - A table that’s detected on a document page. A table is grid-based information with two or more rows or columns, with a cell span of one row and one column each.\n\nCELL - A cell within a detected table. The cell is the parent of the block that contains the text in the cell.\n\nSELECTION_ELEMENT - A selection element such as an option button (radio button) or a check box that’s detected on a document page. Use the value of SelectionStatus to determine the status of the selection element.\n\nConfidence -> (float)\n\nThe confidence score that Amazon Textract has in the accuracy of the recognized text and the accuracy of the geometry points around the recognized text.\n\nText -> (string)\n\nThe word or line of text that’s recognized by Amazon Textract.\n\nTextType -> (string)\n\nThe kind of text that Amazon Textract has detected. Can check for handwritten text and printed text.\n\nRowIndex -> (integer)\n\nThe row in which a table cell is located. The first row position is 1. RowIndex isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nColumnIndex -> (integer)\n\nThe column in which a table cell appears. The first column position is 1. ColumnIndex isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nRowSpan -> (integer)\n\nThe number of rows that a table cell spans. Currently this value is always 1, even if the number of rows spanned is greater than 1. RowSpan isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nColumnSpan -> (integer)\n\nThe number of columns that a table cell spans. Currently this value is always 1, even if the number of columns spanned is greater than 1. ColumnSpan isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nGeometry -> (structure)\n\nThe location of the recognized text on the image. It includes an axis-aligned, coarse bounding box that surrounds the text, and a finer-grain polygon for more accurate spatial information.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nId -> (string)\n\nThe identifier for the recognized text. The identifier is only unique for a single operation.\n\nRelationships -> (list)\n\nA list of child blocks of the current block. For example, a LINE object has child blocks for each WORD block that’s part of the line of text. There aren’t Relationship objects in the list for relationships that don’t exist, such as when the current block has no child blocks. The list size can be the following:\n\n0 - The block has no child blocks.\n\n1 - The block has child blocks.\n\n(structure)\n\nInformation about how blocks are related to each other. A Block object contains 0 or more Relation objects in a list, Relationships . For more information, see Block .\n\nThe Type element provides the type of the relationship for all blocks in the IDs array.\n\nType -> (string)\n\nThe type of relationship that the blocks in the IDs array have with the current block. The relationship can be VALUE or CHILD . A relationship of type VALUE is a list that contains the ID of the VALUE block that’s associated with the KEY of a key-value pair. A relationship of type CHILD is a list of IDs that identify WORD blocks in the case of lines Cell blocks in the case of Tables, and WORD blocks in the case of Selection Elements.\n\nIds -> (list)\n\nAn array of IDs for related blocks. You can get the type of the relationship from the Type element.\n\n(string)\n\nEntityTypes -> (list)\n\nThe type of entity. The following can be returned:\n\nKEY - An identifier for a field on the document.\n\nVALUE - The field text.\n\nEntityTypes isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\n(string)\n\nSelectionStatus -> (string)\n\nThe selection status of a selection element, such as an option button or check box.\n\nPage -> (integer)\n\nThe page on which a block was detected. Page is returned by asynchronous operations. Page values greater than 1 are only returned for multipage documents that are in PDF or TIFF format. A scanned image (JPEG/PNG), even if it contains multiple document pages, is considered to be a single-page document. The value of Page is always 1. Synchronous operations don’t return Page because every input document is considered to be a single-page document.\n\nDetectDocumentTextModelVersion -> (string)",
      "command_examples": "Examples\n\nTo detect text in a document\n\nThe following detect-document-text The following example shows how to detect text in a document.\n\naws textract detect-document-text --document '{\"S3Object\":{\"Bucket\":\"bucket\",\"Name\":\"document\"}}'\n\n\nOutput\n\n{\n    \"Blocks\": [\n        {\n            \"Geometry\": {\n                \"BoundingBox\": {\n                    \"Width\": 1.0,\n                    \"Top\": 0.0,\n                    \"Left\": 0.0,\n                    \"Height\": 1.0\n                },\n                \"Polygon\": [\n                    {\n                        \"Y\": 0.0,\n                        \"X\": 0.0\n                    },\n                    {\n                        \"Y\": 0.0,\n                        \"X\": 1.0\n                    },\n                    {\n                        \"Y\": 1.0,\n                        \"X\": 1.0\n                    },\n                    {\n                        \"Y\": 1.0,\n                        \"X\": 0.0\n                    }\n                ]\n            },\n            \"Relationships\": [\n                {\n                    \"Type\": \"CHILD\",\n                    \"Ids\": [\n                        \"896a9f10-9e70-4412-81ce-49ead73ed881\",\n                        \"0da18623-dc4c-463d-a3d1-9ac050e9e720\",\n                        \"167338d7-d38c-4760-91f1-79a8ec457bb2\"\n                    ]\n                }\n            ],\n            \"BlockType\": \"PAGE\",\n            \"Id\": \"21f0535e-60d5-4bc7-adf2-c05dd851fa25\"\n        },\n        {\n            \"Relationships\": [\n                {\n                    \"Type\": \"CHILD\",\n                    \"Ids\": [\n                        \"62490c26-37ea-49fa-8034-7a9ff9369c9c\",\n                        \"1e4f3f21-05bd-4da9-ba10-15d01e66604c\"\n                    ]\n                }\n            ],\n            \"Confidence\": 89.11581420898438,\n            \"Geometry\": {\n                \"BoundingBox\": {\n                    \"Width\": 0.33642634749412537,\n                    \"Top\": 0.17169663310050964,\n                    \"Left\": 0.13885067403316498,\n                    \"Height\": 0.49159330129623413\n                },\n                \"Polygon\": [\n                    {\n                        \"Y\": 0.17169663310050964,\n                        \"X\": 0.13885067403316498\n                    },\n                    {\n                        \"Y\": 0.17169663310050964,\n                        \"X\": 0.47527703642845154\n                    },\n                    {\n                        \"Y\": 0.6632899641990662,\n                        \"X\": 0.47527703642845154\n                    },\n                    {\n                        \"Y\": 0.6632899641990662,\n                        \"X\": 0.13885067403316498\n                    }\n                ]\n            },\n            \"Text\": \"He llo,\",\n            \"BlockType\": \"LINE\",\n            \"Id\": \"896a9f10-9e70-4412-81ce-49ead73ed881\"\n        },\n        {\n            \"Relationships\": [\n                {\n                    \"Type\": \"CHILD\",\n                    \"Ids\": [\n                        \"19b28058-9516-4352-b929-64d7cef29daf\"\n                    ]\n                }\n            ],\n            \"Confidence\": 85.5694351196289,\n            \"Geometry\": {\n                \"BoundingBox\": {\n                    \"Width\": 0.33182239532470703,\n                    \"Top\": 0.23131252825260162,\n                    \"Left\": 0.5091826915740967,\n                    \"Height\": 0.3766750991344452\n                },\n                \"Polygon\": [\n                    {\n                        \"Y\": 0.23131252825260162,\n                        \"X\": 0.5091826915740967\n                    },\n                    {\n                        \"Y\": 0.23131252825260162,\n                        \"X\": 0.8410050868988037\n                    },\n                    {\n                        \"Y\": 0.607987642288208,\n                        \"X\": 0.8410050868988037\n                    },\n                    {\n                        \"Y\": 0.607987642288208,\n                        \"X\": 0.5091826915740967\n                    }\n                ]\n            },\n            \"Text\": \"worlc\",\n            \"BlockType\": \"LINE\",\n            \"Id\": \"0da18623-dc4c-463d-a3d1-9ac050e9e720\"\n        }\n    ],\n    \"DocumentMetadata\": {\n        \"Pages\": 1\n    }\n}\n\n\nFor more information, see Detecting Document Text with Amazon Textract in the Amazon Textract Developers Guide"
    },
    {
      "command_name": "get-document-analysis",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/textract/get-document-analysis.html",
      "command_description": "Description\n\nGets the results for an Amazon Textract asynchronous operation that analyzes text in a document.\n\nYou start asynchronous text analysis by calling StartDocumentAnalysis , which returns a job identifier (JobId ). When the text analysis operation finishes, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that’s registered in the initial call to StartDocumentAnalysis . To get the results of the text-detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED . If so, call GetDocumentAnalysis , and pass the job identifier (JobId ) from the initial call to StartDocumentAnalysis .\n\nGetDocumentAnalysis returns an array of Block objects. The following types of information are returned:\n\nForm data (key-value pairs). The related information is returned in two Block objects, each of type KEY_VALUE_SET : a KEY Block object and a VALUE Block object. For example, Name: Ana Silva Carolina contains a key and value. Name: is the key. Ana Silva Carolina is the value.\n\nTable and table cell data. A TABLE Block object contains information about a detected table. A CELL Block object is returned for each cell in a table.\n\nLines and words of text. A LINE Block object contains one or more WORD Block objects. All lines and words that are detected in the document are returned (including text that doesn’t have a relationship with the value of the StartDocumentAnalysis FeatureTypes input parameter).\n\nSelection elements such as check boxes and option buttons (radio buttons) can be detected in form data and in tables. A SELECTION_ELEMENT Block object contains information about a selection element, including the selection status.\n\nUse the MaxResults parameter to limit the number of blocks that are returned. If there are more results than specified in MaxResults , the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetDocumentAnalysis , and populate the NextToken request parameter with the token value that’s returned from the previous call to GetDocumentAnalysis .\n\nFor more information, see Document Text Analysis .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-document-analysis\n--job-id <value>\n[--max-results <value>]\n[--next-token <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--job-id <value>",
        "[--max-results <value>]",
        "[--next-token <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--job-id (string)\n\nA unique identifier for the text-detection job. The JobId is returned from StartDocumentAnalysis . A JobId value is only valid for 7 days.\n\n--max-results (integer)\n\nThe maximum number of results to return per paginated call. The largest value that you can specify is 1,000. If you specify a value greater than 1,000, a maximum of 1,000 results is returned. The default value is 1,000.\n\n--next-token (string)\n\nIf the previous response was incomplete (because there are more blocks to retrieve), Amazon Textract returns a pagination token in the response. You can use this pagination token to retrieve the next set of blocks.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nDocumentMetadata -> (structure)\n\nInformation about a document that Amazon Textract processed. DocumentMetadata is returned in every page of paginated responses from an Amazon Textract video operation.\n\nPages -> (integer)\n\nThe number of pages that are detected in the document.\n\nJobStatus -> (string)\n\nThe current status of the text detection job.\n\nNextToken -> (string)\n\nIf the response is truncated, Amazon Textract returns this token. You can use this token in the subsequent request to retrieve the next set of text detection results.\n\nBlocks -> (list)\n\nThe results of the text-analysis operation.\n\n(structure)\n\nA Block represents items that are recognized in a document within a group of pixels close to each other. The information returned in a Block object depends on the type of operation. In text detection for documents (for example DetectDocumentText ), you get information about the detected words and lines of text. In text analysis (for example AnalyzeDocument ), you can also get information about the fields, tables, and selection elements that are detected in the document.\n\nAn array of Block objects is returned by both synchronous and asynchronous operations. In synchronous operations, such as DetectDocumentText , the array of Block objects is the entire set of results. In asynchronous operations, such as GetDocumentAnalysis , the array is returned over one or more responses.\n\nFor more information, see How Amazon Textract Works .\n\nBlockType -> (string)\n\nThe type of text item that’s recognized. In operations for text detection, the following types are returned:\n\nPAGE - Contains a list of the LINE Block objects that are detected on a document page.\n\nWORD - A word detected on a document page. A word is one or more ISO basic Latin script characters that aren’t separated by spaces.\n\nLINE - A string of tab-delimited, contiguous words that are detected on a document page.\n\nIn text analysis operations, the following types are returned:\n\nPAGE - Contains a list of child Block objects that are detected on a document page.\n\nKEY_VALUE_SET - Stores the KEY and VALUE Block objects for linked text that’s detected on a document page. Use the EntityType field to determine if a KEY_VALUE_SET object is a KEY Block object or a VALUE Block object.\n\nWORD - A word that’s detected on a document page. A word is one or more ISO basic Latin script characters that aren’t separated by spaces.\n\nLINE - A string of tab-delimited, contiguous words that are detected on a document page.\n\nTABLE - A table that’s detected on a document page. A table is grid-based information with two or more rows or columns, with a cell span of one row and one column each.\n\nCELL - A cell within a detected table. The cell is the parent of the block that contains the text in the cell.\n\nSELECTION_ELEMENT - A selection element such as an option button (radio button) or a check box that’s detected on a document page. Use the value of SelectionStatus to determine the status of the selection element.\n\nConfidence -> (float)\n\nThe confidence score that Amazon Textract has in the accuracy of the recognized text and the accuracy of the geometry points around the recognized text.\n\nText -> (string)\n\nThe word or line of text that’s recognized by Amazon Textract.\n\nTextType -> (string)\n\nThe kind of text that Amazon Textract has detected. Can check for handwritten text and printed text.\n\nRowIndex -> (integer)\n\nThe row in which a table cell is located. The first row position is 1. RowIndex isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nColumnIndex -> (integer)\n\nThe column in which a table cell appears. The first column position is 1. ColumnIndex isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nRowSpan -> (integer)\n\nThe number of rows that a table cell spans. Currently this value is always 1, even if the number of rows spanned is greater than 1. RowSpan isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nColumnSpan -> (integer)\n\nThe number of columns that a table cell spans. Currently this value is always 1, even if the number of columns spanned is greater than 1. ColumnSpan isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nGeometry -> (structure)\n\nThe location of the recognized text on the image. It includes an axis-aligned, coarse bounding box that surrounds the text, and a finer-grain polygon for more accurate spatial information.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nId -> (string)\n\nThe identifier for the recognized text. The identifier is only unique for a single operation.\n\nRelationships -> (list)\n\nA list of child blocks of the current block. For example, a LINE object has child blocks for each WORD block that’s part of the line of text. There aren’t Relationship objects in the list for relationships that don’t exist, such as when the current block has no child blocks. The list size can be the following:\n\n0 - The block has no child blocks.\n\n1 - The block has child blocks.\n\n(structure)\n\nInformation about how blocks are related to each other. A Block object contains 0 or more Relation objects in a list, Relationships . For more information, see Block .\n\nThe Type element provides the type of the relationship for all blocks in the IDs array.\n\nType -> (string)\n\nThe type of relationship that the blocks in the IDs array have with the current block. The relationship can be VALUE or CHILD . A relationship of type VALUE is a list that contains the ID of the VALUE block that’s associated with the KEY of a key-value pair. A relationship of type CHILD is a list of IDs that identify WORD blocks in the case of lines Cell blocks in the case of Tables, and WORD blocks in the case of Selection Elements.\n\nIds -> (list)\n\nAn array of IDs for related blocks. You can get the type of the relationship from the Type element.\n\n(string)\n\nEntityTypes -> (list)\n\nThe type of entity. The following can be returned:\n\nKEY - An identifier for a field on the document.\n\nVALUE - The field text.\n\nEntityTypes isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\n(string)\n\nSelectionStatus -> (string)\n\nThe selection status of a selection element, such as an option button or check box.\n\nPage -> (integer)\n\nThe page on which a block was detected. Page is returned by asynchronous operations. Page values greater than 1 are only returned for multipage documents that are in PDF or TIFF format. A scanned image (JPEG/PNG), even if it contains multiple document pages, is considered to be a single-page document. The value of Page is always 1. Synchronous operations don’t return Page because every input document is considered to be a single-page document.\n\nWarnings -> (list)\n\nA list of warnings that occurred during the document-analysis operation.\n\n(structure)\n\nA warning about an issue that occurred during asynchronous text analysis ( StartDocumentAnalysis ) or asynchronous document text detection ( StartDocumentTextDetection ).\n\nErrorCode -> (string)\n\nThe error code for the warning.\n\nPages -> (list)\n\nA list of the pages that the warning applies to.\n\n(integer)\n\nStatusMessage -> (string)\n\nReturns if the detection job could not be completed. Contains explanation for what error occured.\n\nAnalyzeDocumentModelVersion -> (string)",
      "command_examples": "Examples\n\nTo get the results of asynchronous text analysis of a multi-page document\n\nThe following get-document-analysis example shows how to get the results of asynchronous text analysis of a multi-page document.\n\naws textract get-document-analysis --job-id df7cf32ebbd2a5de113535fcf4d921926a701b09b4e7d089f3aebadb41e0712b --max-results 1000\n\n\nOutput\n\n{\n    \"Blocks\": [\n        {\n            \"Geometry\": {\n                \"BoundingBox\": {\n                    \"Width\": 1.0,\n                    \"Top\": 0.0,\n                    \"Left\": 0.0,\n                    \"Height\": 1.0\n                },\n                \"Polygon\": [\n                    {\n                        \"Y\": 0.0,\n                        \"X\": 0.0\n                    },\n                    {\n                        \"Y\": 0.0,\n                        \"X\": 1.0\n                    },\n                    {\n                        \"Y\": 1.0,\n                        \"X\": 1.0\n                    },\n                    {\n                        \"Y\": 1.0,\n                        \"X\": 0.0\n                    }\n                ]\n            },\n            \"Relationships\": [\n                {\n                    \"Type\": \"CHILD\",\n                    \"Ids\": [\n                        \"75966e64-81c2-4540-9649-d66ec341cd8f\",\n                        \"bb099c24-8282-464c-a179-8a9fa0a057f0\",\n                        \"5ebf522d-f9e4-4dc7-bfae-a288dc094595\"\n                    ]\n                }\n            ],\n            \"BlockType\": \"PAGE\",\n            \"Id\": \"247c28ee-b63d-4aeb-9af0-5f7ea8ba109e\",\n            \"Page\": 1\n        }\n    ],\n    \"NextToken\": \"cY1W3eTFvoB0cH7YrKVudI4Gb0H8J0xAYLo8xI/JunCIPWCthaKQ+07n/ElyutsSy0+1VOImoTRmP1zw4P0RFtaeV9Bzhnfedpx1YqwB4xaGDA==\",\n    \"DocumentMetadata\": {\n        \"Pages\": 1\n    },\n    \"JobStatus\": \"SUCCEEDED\"\n}\n\n\nFor more information, see Detecting and Analyzing Text in Multi-Page Documents in the Amazon Textract Developers Guide"
    },
    {
      "command_name": "get-document-text-detection",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/textract/get-document-text-detection.html",
      "command_description": "Description\n\nGets the results for an Amazon Textract asynchronous operation that detects text in a document. Amazon Textract can detect lines of text and the words that make up a line of text.\n\nYou start asynchronous text detection by calling StartDocumentTextDetection , which returns a job identifier (JobId ). When the text detection operation finishes, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that’s registered in the initial call to StartDocumentTextDetection . To get the results of the text-detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED . If so, call GetDocumentTextDetection , and pass the job identifier (JobId ) from the initial call to StartDocumentTextDetection .\n\nGetDocumentTextDetection returns an array of Block objects.\n\nEach document page has as an associated Block of type PAGE. Each PAGE Block object is the parent of LINE Block objects that represent the lines of detected text on a page. A LINE Block object is a parent for each word that makes up the line. Words are represented by Block objects of type WORD.\n\nUse the MaxResults parameter to limit the number of blocks that are returned. If there are more results than specified in MaxResults , the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetDocumentTextDetection , and populate the NextToken request parameter with the token value that’s returned from the previous call to GetDocumentTextDetection .\n\nFor more information, see Document Text Detection .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-document-text-detection\n--job-id <value>\n[--max-results <value>]\n[--next-token <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--job-id <value>",
        "[--max-results <value>]",
        "[--next-token <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--job-id (string)\n\nA unique identifier for the text detection job. The JobId is returned from StartDocumentTextDetection . A JobId value is only valid for 7 days.\n\n--max-results (integer)\n\nThe maximum number of results to return per paginated call. The largest value you can specify is 1,000. If you specify a value greater than 1,000, a maximum of 1,000 results is returned. The default value is 1,000.\n\n--next-token (string)\n\nIf the previous response was incomplete (because there are more blocks to retrieve), Amazon Textract returns a pagination token in the response. You can use this pagination token to retrieve the next set of blocks.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nDocumentMetadata -> (structure)\n\nInformation about a document that Amazon Textract processed. DocumentMetadata is returned in every page of paginated responses from an Amazon Textract video operation.\n\nPages -> (integer)\n\nThe number of pages that are detected in the document.\n\nJobStatus -> (string)\n\nThe current status of the text detection job.\n\nNextToken -> (string)\n\nIf the response is truncated, Amazon Textract returns this token. You can use this token in the subsequent request to retrieve the next set of text-detection results.\n\nBlocks -> (list)\n\nThe results of the text-detection operation.\n\n(structure)\n\nA Block represents items that are recognized in a document within a group of pixels close to each other. The information returned in a Block object depends on the type of operation. In text detection for documents (for example DetectDocumentText ), you get information about the detected words and lines of text. In text analysis (for example AnalyzeDocument ), you can also get information about the fields, tables, and selection elements that are detected in the document.\n\nAn array of Block objects is returned by both synchronous and asynchronous operations. In synchronous operations, such as DetectDocumentText , the array of Block objects is the entire set of results. In asynchronous operations, such as GetDocumentAnalysis , the array is returned over one or more responses.\n\nFor more information, see How Amazon Textract Works .\n\nBlockType -> (string)\n\nThe type of text item that’s recognized. In operations for text detection, the following types are returned:\n\nPAGE - Contains a list of the LINE Block objects that are detected on a document page.\n\nWORD - A word detected on a document page. A word is one or more ISO basic Latin script characters that aren’t separated by spaces.\n\nLINE - A string of tab-delimited, contiguous words that are detected on a document page.\n\nIn text analysis operations, the following types are returned:\n\nPAGE - Contains a list of child Block objects that are detected on a document page.\n\nKEY_VALUE_SET - Stores the KEY and VALUE Block objects for linked text that’s detected on a document page. Use the EntityType field to determine if a KEY_VALUE_SET object is a KEY Block object or a VALUE Block object.\n\nWORD - A word that’s detected on a document page. A word is one or more ISO basic Latin script characters that aren’t separated by spaces.\n\nLINE - A string of tab-delimited, contiguous words that are detected on a document page.\n\nTABLE - A table that’s detected on a document page. A table is grid-based information with two or more rows or columns, with a cell span of one row and one column each.\n\nCELL - A cell within a detected table. The cell is the parent of the block that contains the text in the cell.\n\nSELECTION_ELEMENT - A selection element such as an option button (radio button) or a check box that’s detected on a document page. Use the value of SelectionStatus to determine the status of the selection element.\n\nConfidence -> (float)\n\nThe confidence score that Amazon Textract has in the accuracy of the recognized text and the accuracy of the geometry points around the recognized text.\n\nText -> (string)\n\nThe word or line of text that’s recognized by Amazon Textract.\n\nTextType -> (string)\n\nThe kind of text that Amazon Textract has detected. Can check for handwritten text and printed text.\n\nRowIndex -> (integer)\n\nThe row in which a table cell is located. The first row position is 1. RowIndex isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nColumnIndex -> (integer)\n\nThe column in which a table cell appears. The first column position is 1. ColumnIndex isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nRowSpan -> (integer)\n\nThe number of rows that a table cell spans. Currently this value is always 1, even if the number of rows spanned is greater than 1. RowSpan isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nColumnSpan -> (integer)\n\nThe number of columns that a table cell spans. Currently this value is always 1, even if the number of columns spanned is greater than 1. ColumnSpan isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\nGeometry -> (structure)\n\nThe location of the recognized text on the image. It includes an axis-aligned, coarse bounding box that surrounds the text, and a finer-grain polygon for more accurate spatial information.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nId -> (string)\n\nThe identifier for the recognized text. The identifier is only unique for a single operation.\n\nRelationships -> (list)\n\nA list of child blocks of the current block. For example, a LINE object has child blocks for each WORD block that’s part of the line of text. There aren’t Relationship objects in the list for relationships that don’t exist, such as when the current block has no child blocks. The list size can be the following:\n\n0 - The block has no child blocks.\n\n1 - The block has child blocks.\n\n(structure)\n\nInformation about how blocks are related to each other. A Block object contains 0 or more Relation objects in a list, Relationships . For more information, see Block .\n\nThe Type element provides the type of the relationship for all blocks in the IDs array.\n\nType -> (string)\n\nThe type of relationship that the blocks in the IDs array have with the current block. The relationship can be VALUE or CHILD . A relationship of type VALUE is a list that contains the ID of the VALUE block that’s associated with the KEY of a key-value pair. A relationship of type CHILD is a list of IDs that identify WORD blocks in the case of lines Cell blocks in the case of Tables, and WORD blocks in the case of Selection Elements.\n\nIds -> (list)\n\nAn array of IDs for related blocks. You can get the type of the relationship from the Type element.\n\n(string)\n\nEntityTypes -> (list)\n\nThe type of entity. The following can be returned:\n\nKEY - An identifier for a field on the document.\n\nVALUE - The field text.\n\nEntityTypes isn’t returned by DetectDocumentText and GetDocumentTextDetection .\n\n(string)\n\nSelectionStatus -> (string)\n\nThe selection status of a selection element, such as an option button or check box.\n\nPage -> (integer)\n\nThe page on which a block was detected. Page is returned by asynchronous operations. Page values greater than 1 are only returned for multipage documents that are in PDF or TIFF format. A scanned image (JPEG/PNG), even if it contains multiple document pages, is considered to be a single-page document. The value of Page is always 1. Synchronous operations don’t return Page because every input document is considered to be a single-page document.\n\nWarnings -> (list)\n\nA list of warnings that occurred during the text-detection operation for the document.\n\n(structure)\n\nA warning about an issue that occurred during asynchronous text analysis ( StartDocumentAnalysis ) or asynchronous document text detection ( StartDocumentTextDetection ).\n\nErrorCode -> (string)\n\nThe error code for the warning.\n\nPages -> (list)\n\nA list of the pages that the warning applies to.\n\n(integer)\n\nStatusMessage -> (string)\n\nReturns if the detection job could not be completed. Contains explanation for what error occured.\n\nDetectDocumentTextModelVersion -> (string)",
      "command_examples": "Examples\n\nTo get the results of asynchronous text detection in a multi-page document\n\nThe following get-document-text-detection example shows how to get the results of asynchronous text detection in a multi-page document.\n\naws textract get-document-text-detection --job-id 57849a3dc627d4df74123dca269d69f7b89329c870c65bb16c9fd63409d200b9 --max-results 1000\n\n\nOutput\n\n{\n    \"Blocks\": [\n        {\n            \"Geometry\": {\n                \"BoundingBox\": {\n                    \"Width\": 1.0,\n                    \"Top\": 0.0,\n                    \"Left\": 0.0,\n                    \"Height\": 1.0\n                },\n                \"Polygon\": [\n                    {\n                        \"Y\": 0.0,\n                        \"X\": 0.0\n                    },\n                    {\n                        \"Y\": 0.0,\n                        \"X\": 1.0\n                    },\n                    {\n                        \"Y\": 1.0,\n                        \"X\": 1.0\n                    },\n                    {\n                        \"Y\": 1.0,\n                        \"X\": 0.0\n                    }\n                ]\n            },\n            \"Relationships\": [\n                {\n                    \"Type\": \"CHILD\",\n                    \"Ids\": [\n                        \"1b926a34-0357-407b-ac8f-ec473160c6a9\",\n                        \"0c35dc17-3605-4c9d-af1a-d9451059df51\",\n                        \"dea3db8a-52c2-41c0-b50c-81f66f4aa758\"\n                    ]\n                }\n            ],\n            \"BlockType\": \"PAGE\",\n            \"Id\": \"84671a5e-8c99-43be-a9d1-6838965da33e\",\n            \"Page\": 1\n        }\n    ],\n    \"NextToken\": \"GcqyoAJuZwujOT35EN4LCI3EUzMtiLq3nKyFFHvU5q1SaIdEBcSty+njNgoWwuMP/muqc96S4o5NzDqehhXvhkodMyVO5OJGyms5lsrCxibWJw==\",\n    \"DocumentMetadata\": {\n        \"Pages\": 1\n    },\n    \"JobStatus\": \"SUCCEEDED\"\n}\n\n\nFor more information, see Detecting and Analyzing Text in Multi-Page Documents in the Amazon Textract Developers Guide"
    },
    {
      "command_name": "get-expense-analysis",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/textract/get-expense-analysis.html",
      "command_description": "Description\n\nGets the results for an Amazon Textract asynchronous operation that analyzes invoices and receipts. Amazon Textract finds contact information, items purchased, and vendor name, from input invoices and receipts.\n\nYou start asynchronous invoice/receipt analysis by calling StartExpenseAnalysis , which returns a job identifier (JobId ). Upon completion of the invoice/receipt analysis, Amazon Textract publishes the completion status to the Amazon Simple Notification Service (Amazon SNS) topic. This topic must be registered in the initial call to StartExpenseAnalysis . To get the results of the invoice/receipt analysis operation, first ensure that the status value published to the Amazon SNS topic is SUCCEEDED . If so, call GetExpenseAnalysis , and pass the job identifier (JobId ) from the initial call to StartExpenseAnalysis .\n\nUse the MaxResults parameter to limit the number of blocks that are returned. If there are more results than specified in MaxResults , the value of NextToken in the operation response contains a pagination token for getting the next set of results. To get the next page of results, call GetExpenseAnalysis , and populate the NextToken request parameter with the token value that’s returned from the previous call to GetExpenseAnalysis .\n\nFor more information, see Analyzing Invoices and Receipts .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-expense-analysis\n--job-id <value>\n[--max-results <value>]\n[--next-token <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--job-id <value>",
        "[--max-results <value>]",
        "[--next-token <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--job-id (string)\n\nA unique identifier for the text detection job. The JobId is returned from StartExpenseAnalysis . A JobId value is only valid for 7 days.\n\n--max-results (integer)\n\nThe maximum number of results to return per paginated call. The largest value you can specify is 20. If you specify a value greater than 20, a maximum of 20 results is returned. The default value is 20.\n\n--next-token (string)\n\nIf the previous response was incomplete (because there are more blocks to retrieve), Amazon Textract returns a pagination token in the response. You can use this pagination token to retrieve the next set of blocks.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nDocumentMetadata -> (structure)\n\nInformation about a document that Amazon Textract processed. DocumentMetadata is returned in every page of paginated responses from an Amazon Textract operation.\n\nPages -> (integer)\n\nThe number of pages that are detected in the document.\n\nJobStatus -> (string)\n\nThe current status of the text detection job.\n\nNextToken -> (string)\n\nIf the response is truncated, Amazon Textract returns this token. You can use this token in the subsequent request to retrieve the next set of text-detection results.\n\nExpenseDocuments -> (list)\n\nThe expenses detected by Amazon Textract.\n\n(structure)\n\nThe structure holding all the information returned by AnalyzeExpense\n\nExpenseIndex -> (integer)\n\nDenotes which invoice or receipt in the document the information is coming from. First document will be 1, the second 2, and so on.\n\nSummaryFields -> (list)\n\nAny information found outside of a table by Amazon Textract.\n\n(structure)\n\nBreakdown of detected information, seperated into the catagories Type, LableDetection, and ValueDetection\n\nType -> (structure)\n\nThe implied label of a detected element. Present alongside LabelDetection for explicit elements.\n\nText -> (string)\n\nThe word or line of text detected by Amazon Textract.\n\nConfidence -> (float)\n\nThe confidence of accuracy, as a percentage.\n\nLabelDetection -> (structure)\n\nThe explicitly stated label of a detected element.\n\nText -> (string)\n\nThe word or line of text recognized by Amazon Textract\n\nGeometry -> (structure)\n\nInformation about where the following items are located on a document page: detected page, text, key-value pairs, tables, table cells, and selection elements.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nConfidence -> (float)\n\nThe confidence in detection, as a percentage\n\nValueDetection -> (structure)\n\nThe value of a detected element. Present in explicit and implicit elements.\n\nText -> (string)\n\nThe word or line of text recognized by Amazon Textract\n\nGeometry -> (structure)\n\nInformation about where the following items are located on a document page: detected page, text, key-value pairs, tables, table cells, and selection elements.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nConfidence -> (float)\n\nThe confidence in detection, as a percentage\n\nPageNumber -> (integer)\n\nThe page number the value was detected on.\n\nLineItemGroups -> (list)\n\nInformation detected on each table of a document, seperated into LineItems .\n\n(structure)\n\nA grouping of tables which contain LineItems, with each table identified by the table’s LineItemGroupIndex .\n\nLineItemGroupIndex -> (integer)\n\nThe number used to identify a specific table in a document. The first table encountered will have a LineItemGroupIndex of 1, the second 2, etc.\n\nLineItems -> (list)\n\nThe breakdown of information on a particular line of a table.\n\n(structure)\n\nA structure that holds information about the different lines found in a document’s tables.\n\nLineItemExpenseFields -> (list)\n\nExpenseFields used to show information from detected lines on a table.\n\n(structure)\n\nBreakdown of detected information, seperated into the catagories Type, LableDetection, and ValueDetection\n\nType -> (structure)\n\nThe implied label of a detected element. Present alongside LabelDetection for explicit elements.\n\nText -> (string)\n\nThe word or line of text detected by Amazon Textract.\n\nConfidence -> (float)\n\nThe confidence of accuracy, as a percentage.\n\nLabelDetection -> (structure)\n\nThe explicitly stated label of a detected element.\n\nText -> (string)\n\nThe word or line of text recognized by Amazon Textract\n\nGeometry -> (structure)\n\nInformation about where the following items are located on a document page: detected page, text, key-value pairs, tables, table cells, and selection elements.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nConfidence -> (float)\n\nThe confidence in detection, as a percentage\n\nValueDetection -> (structure)\n\nThe value of a detected element. Present in explicit and implicit elements.\n\nText -> (string)\n\nThe word or line of text recognized by Amazon Textract\n\nGeometry -> (structure)\n\nInformation about where the following items are located on a document page: detected page, text, key-value pairs, tables, table cells, and selection elements.\n\nBoundingBox -> (structure)\n\nAn axis-aligned coarse representation of the location of the recognized item on the document page.\n\nWidth -> (float)\n\nThe width of the bounding box as a ratio of the overall document page width.\n\nHeight -> (float)\n\nThe height of the bounding box as a ratio of the overall document page height.\n\nLeft -> (float)\n\nThe left coordinate of the bounding box as a ratio of overall document page width.\n\nTop -> (float)\n\nThe top coordinate of the bounding box as a ratio of overall document page height.\n\nPolygon -> (list)\n\nWithin the bounding box, a fine-grained polygon around the recognized item.\n\n(structure)\n\nThe X and Y coordinates of a point on a document page. The X and Y values that are returned are ratios of the overall document page size. For example, if the input document is 700 x 200 and the operation returns X=0.5 and Y=0.25, then the point is at the (350,50) pixel coordinate on the document page.\n\nAn array of Point objects, Polygon , is returned by DetectDocumentText . Polygon represents a fine-grained polygon around detected text. For more information, see Geometry in the Amazon Textract Developer Guide.\n\nX -> (float)\n\nThe value of the X coordinate for a point on a Polygon .\n\nY -> (float)\n\nThe value of the Y coordinate for a point on a Polygon .\n\nConfidence -> (float)\n\nThe confidence in detection, as a percentage\n\nPageNumber -> (integer)\n\nThe page number the value was detected on.\n\nWarnings -> (list)\n\nA list of warnings that occurred during the text-detection operation for the document.\n\n(structure)\n\nA warning about an issue that occurred during asynchronous text analysis ( StartDocumentAnalysis ) or asynchronous document text detection ( StartDocumentTextDetection ).\n\nErrorCode -> (string)\n\nThe error code for the warning.\n\nPages -> (list)\n\nA list of the pages that the warning applies to.\n\n(integer)\n\nStatusMessage -> (string)\n\nReturns if the detection job could not be completed. Contains explanation for what error occured.\n\nAnalyzeExpenseModelVersion -> (string)\n\nThe current model version of AnalyzeExpense."
    },
    {
      "command_name": "start-document-analysis",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/textract/start-document-analysis.html",
      "command_description": "Description\n\nStarts the asynchronous analysis of an input document for relationships between detected items such as key-value pairs, tables, and selection elements.\n\nStartDocumentAnalysis can analyze text in documents that are in JPEG, PNG, TIFF, and PDF format. The documents are stored in an Amazon S3 bucket. Use DocumentLocation to specify the bucket name and file name of the document.\n\nStartDocumentAnalysis returns a job identifier (JobId ) that you use to get the results of the operation. When text analysis is finished, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that you specify in NotificationChannel . To get the results of the text analysis operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED . If so, call GetDocumentAnalysis , and pass the job identifier (JobId ) from the initial call to StartDocumentAnalysis .\n\nFor more information, see Document Text Analysis .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-document-analysis\n--document-location <value>\n--feature-types <value>\n[--client-request-token <value>]\n[--job-tag <value>]\n[--notification-channel <value>]\n[--output-config <value>]\n[--kms-key-id <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--document-location <value>",
        "--feature-types <value>",
        "[--client-request-token <value>]",
        "[--job-tag <value>]",
        "[--notification-channel <value>]",
        "[--output-config <value>]",
        "[--kms-key-id <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--document-location (structure)\n\nThe location of the document to be processed.\n\nS3Object -> (structure)\n\nThe Amazon S3 bucket that contains the input document.\n\nBucket -> (string)\n\nThe name of the S3 bucket. Note that the # character is not valid in the file name.\n\nName -> (string)\n\nThe file name of the input document. Synchronous operations can use image files that are in JPEG or PNG format. Asynchronous operations also support PDF and TIFF format files.\n\nVersion -> (string)\n\nIf the bucket has versioning enabled, you can specify the object version.\n\nShorthand Syntax:\n\nS3Object={Bucket=string,Name=string,Version=string}\n\n\nJSON Syntax:\n\n{\n  \"S3Object\": {\n    \"Bucket\": \"string\",\n    \"Name\": \"string\",\n    \"Version\": \"string\"\n  }\n}\n\n\n--feature-types (list)\n\nA list of the types of analysis to perform. Add TABLES to the list to return information about the tables that are detected in the input document. Add FORMS to return detected form data. To perform both types of analysis, add TABLES and FORMS to FeatureTypes . All lines and words detected in the document are included in the response (including text that isn’t related to the value of FeatureTypes ).\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  TABLES\n  FORMS\n\n\n--client-request-token (string)\n\nThe idempotent token that you use to identify the start request. If you use the same token with multiple StartDocumentAnalysis requests, the same JobId is returned. Use ClientRequestToken to prevent the same job from being accidentally started more than once. For more information, see Calling Amazon Textract Asynchronous Operations .\n\n--job-tag (string)\n\nAn identifier that you specify that’s included in the completion notification published to the Amazon SNS topic. For example, you can use JobTag to identify the type of document that the completion notification corresponds to (such as a tax form or a receipt).\n\n--notification-channel (structure)\n\nThe Amazon SNS topic ARN that you want Amazon Textract to publish the completion status of the operation to.\n\nSNSTopicArn -> (string)\n\nThe Amazon SNS topic that Amazon Textract posts the completion status to.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of an IAM role that gives Amazon Textract publishing permissions to the Amazon SNS topic.\n\nShorthand Syntax:\n\nSNSTopicArn=string,RoleArn=string\n\n\nJSON Syntax:\n\n{\n  \"SNSTopicArn\": \"string\",\n  \"RoleArn\": \"string\"\n}\n\n\n--output-config (structure)\n\nSets if the output will go to a customer defined bucket. By default, Amazon Textract will save the results internally to be accessed by the GetDocumentAnalysis operation.\n\nS3Bucket -> (string)\n\nThe name of the bucket your output will go to.\n\nS3Prefix -> (string)\n\nThe prefix of the object key that the output will be saved to. When not enabled, the prefix will be “textract_output”.\n\nShorthand Syntax:\n\nS3Bucket=string,S3Prefix=string\n\n\nJSON Syntax:\n\n{\n  \"S3Bucket\": \"string\",\n  \"S3Prefix\": \"string\"\n}\n\n\n--kms-key-id (string)\n\nThe KMS key used to encrypt the inference results. This can be in either Key ID or Key Alias format. When a KMS key is provided, the KMS key will be used for server-side encryption of the objects in the customer bucket. When this parameter is not enabled, the result will be encrypted server side,using SSE-S3.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nJobId -> (string)\n\nThe identifier for the document text detection job. Use JobId to identify the job in a subsequent call to GetDocumentAnalysis . A JobId value is only valid for 7 days.",
      "command_examples": "Examples\n\nTo start analyzing text in a multi-page document\n\nThe following start-document-analysis example shows how to start asynchronous analysis of text in a multi-page document.\n\naws textract start-document-analysis --document-location '{\"S3Object\":{\"Bucket\":\"reescheastv\",\"Name\":\"doctest.png\"}}' --feature-types '[\"TABLES\",\"FORMS\"]' --notification-channel \"SNSTopicArn=arn:snsTopic,RoleArn=roleArn\"\n\n\nOutput\n\n{\n    \"JobId\": \"df7cf32ebbd2a5de113535fcf4d921926a701b09b4e7d089f3aebadb41e0712b\"\n}\n\n\nFor more information, see Detecting and Analyzing Text in Multi-Page Documents in the Amazon Textract Developers Guide"
    },
    {
      "command_name": "start-document-text-detection",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/textract/start-document-text-detection.html",
      "command_description": "Description\n\nStarts the asynchronous detection of text in a document. Amazon Textract can detect lines of text and the words that make up a line of text.\n\nStartDocumentTextDetection can analyze text in documents that are in JPEG, PNG, TIFF, and PDF format. The documents are stored in an Amazon S3 bucket. Use DocumentLocation to specify the bucket name and file name of the document.\n\nStartTextDetection returns a job identifier (JobId ) that you use to get the results of the operation. When text detection is finished, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that you specify in NotificationChannel . To get the results of the text detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED . If so, call GetDocumentTextDetection , and pass the job identifier (JobId ) from the initial call to StartDocumentTextDetection .\n\nFor more information, see Document Text Detection .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-document-text-detection\n--document-location <value>\n[--client-request-token <value>]\n[--job-tag <value>]\n[--notification-channel <value>]\n[--output-config <value>]\n[--kms-key-id <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--document-location <value>",
        "[--client-request-token <value>]",
        "[--job-tag <value>]",
        "[--notification-channel <value>]",
        "[--output-config <value>]",
        "[--kms-key-id <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--document-location (structure)\n\nThe location of the document to be processed.\n\nS3Object -> (structure)\n\nThe Amazon S3 bucket that contains the input document.\n\nBucket -> (string)\n\nThe name of the S3 bucket. Note that the # character is not valid in the file name.\n\nName -> (string)\n\nThe file name of the input document. Synchronous operations can use image files that are in JPEG or PNG format. Asynchronous operations also support PDF and TIFF format files.\n\nVersion -> (string)\n\nIf the bucket has versioning enabled, you can specify the object version.\n\nShorthand Syntax:\n\nS3Object={Bucket=string,Name=string,Version=string}\n\n\nJSON Syntax:\n\n{\n  \"S3Object\": {\n    \"Bucket\": \"string\",\n    \"Name\": \"string\",\n    \"Version\": \"string\"\n  }\n}\n\n\n--client-request-token (string)\n\nThe idempotent token that’s used to identify the start request. If you use the same token with multiple StartDocumentTextDetection requests, the same JobId is returned. Use ClientRequestToken to prevent the same job from being accidentally started more than once. For more information, see Calling Amazon Textract Asynchronous Operations .\n\n--job-tag (string)\n\nAn identifier that you specify that’s included in the completion notification published to the Amazon SNS topic. For example, you can use JobTag to identify the type of document that the completion notification corresponds to (such as a tax form or a receipt).\n\n--notification-channel (structure)\n\nThe Amazon SNS topic ARN that you want Amazon Textract to publish the completion status of the operation to.\n\nSNSTopicArn -> (string)\n\nThe Amazon SNS topic that Amazon Textract posts the completion status to.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of an IAM role that gives Amazon Textract publishing permissions to the Amazon SNS topic.\n\nShorthand Syntax:\n\nSNSTopicArn=string,RoleArn=string\n\n\nJSON Syntax:\n\n{\n  \"SNSTopicArn\": \"string\",\n  \"RoleArn\": \"string\"\n}\n\n\n--output-config (structure)\n\nSets if the output will go to a customer defined bucket. By default Amazon Textract will save the results internally to be accessed with the GetDocumentTextDetection operation.\n\nS3Bucket -> (string)\n\nThe name of the bucket your output will go to.\n\nS3Prefix -> (string)\n\nThe prefix of the object key that the output will be saved to. When not enabled, the prefix will be “textract_output”.\n\nShorthand Syntax:\n\nS3Bucket=string,S3Prefix=string\n\n\nJSON Syntax:\n\n{\n  \"S3Bucket\": \"string\",\n  \"S3Prefix\": \"string\"\n}\n\n\n--kms-key-id (string)\n\nThe KMS key used to encrypt the inference results. This can be in either Key ID or Key Alias format. When a KMS key is provided, the KMS key will be used for server-side encryption of the objects in the customer bucket. When this parameter is not enabled, the result will be encrypted server side,using SSE-S3.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nJobId -> (string)\n\nThe identifier of the text detection job for the document. Use JobId to identify the job in a subsequent call to GetDocumentTextDetection . A JobId value is only valid for 7 days.",
      "command_examples": "Examples\n\nTo start detecting text in a multi-page document\n\nThe following start-document-text-detection example shows how to start asynchronous detection of text in a multi-page document.\n\naws textract start-document-text-detection --document-location '{\"S3Object\":{\"Bucket\":\"reescheastv\",\"Name\":\"doctest.png\"}}' --notification-channel \"SNSTopicArn=topicARN,RoleArn=roleARN\"\n\n\nThe command returns output similar to the following.\n\n{\n    \"JobId\": \"57849a3dc627d4df74123dca269d69f7b89329c870c65bb16c9fd63409d200b9\"\n}\n\n\nFor more information, see Detecting and Analyzing Text in Multi-Page Documents in the Amazon Textract Developers Guide"
    },
    {
      "command_name": "start-expense-analysis",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/textract/start-expense-analysis.html",
      "command_description": "Description\n\nStarts the asynchronous analysis of invoices or receipts for data like contact information, items purchased, and vendor names.\n\nStartExpenseAnalysis can analyze text in documents that are in JPEG, PNG, and PDF format. The documents must be stored in an Amazon S3 bucket. Use the DocumentLocation parameter to specify the name of your S3 bucket and the name of the document in that bucket.\n\nStartExpenseAnalysis returns a job identifier (JobId ) that you will provide to GetExpenseAnalysis to retrieve the results of the operation. When the analysis of the input invoices/receipts is finished, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that you provide to the NotificationChannel . To obtain the results of the invoice and receipt analysis operation, ensure that the status value published to the Amazon SNS topic is SUCCEEDED . If so, call GetExpenseAnalysis , and pass the job identifier (JobId ) that was returned by your call to StartExpenseAnalysis .\n\nFor more information, see Analyzing Invoices and Receipts .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-expense-analysis\n--document-location <value>\n[--client-request-token <value>]\n[--job-tag <value>]\n[--notification-channel <value>]\n[--output-config <value>]\n[--kms-key-id <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--document-location <value>",
        "[--client-request-token <value>]",
        "[--job-tag <value>]",
        "[--notification-channel <value>]",
        "[--output-config <value>]",
        "[--kms-key-id <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--document-location (structure)\n\nThe location of the document to be processed.\n\nS3Object -> (structure)\n\nThe Amazon S3 bucket that contains the input document.\n\nBucket -> (string)\n\nThe name of the S3 bucket. Note that the # character is not valid in the file name.\n\nName -> (string)\n\nThe file name of the input document. Synchronous operations can use image files that are in JPEG or PNG format. Asynchronous operations also support PDF and TIFF format files.\n\nVersion -> (string)\n\nIf the bucket has versioning enabled, you can specify the object version.\n\nShorthand Syntax:\n\nS3Object={Bucket=string,Name=string,Version=string}\n\n\nJSON Syntax:\n\n{\n  \"S3Object\": {\n    \"Bucket\": \"string\",\n    \"Name\": \"string\",\n    \"Version\": \"string\"\n  }\n}\n\n\n--client-request-token (string)\n\nThe idempotent token that’s used to identify the start request. If you use the same token with multiple StartDocumentTextDetection requests, the same JobId is returned. Use ClientRequestToken to prevent the same job from being accidentally started more than once. For more information, see Calling Amazon Textract Asynchronous Operations\n\n--job-tag (string)\n\nAn identifier you specify that’s included in the completion notification published to the Amazon SNS topic. For example, you can use JobTag to identify the type of document that the completion notification corresponds to (such as a tax form or a receipt).\n\n--notification-channel (structure)\n\nThe Amazon SNS topic ARN that you want Amazon Textract to publish the completion status of the operation to.\n\nSNSTopicArn -> (string)\n\nThe Amazon SNS topic that Amazon Textract posts the completion status to.\n\nRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of an IAM role that gives Amazon Textract publishing permissions to the Amazon SNS topic.\n\nShorthand Syntax:\n\nSNSTopicArn=string,RoleArn=string\n\n\nJSON Syntax:\n\n{\n  \"SNSTopicArn\": \"string\",\n  \"RoleArn\": \"string\"\n}\n\n\n--output-config (structure)\n\nSets if the output will go to a customer defined bucket. By default, Amazon Textract will save the results internally to be accessed by the GetExpenseAnalysis operation.\n\nS3Bucket -> (string)\n\nThe name of the bucket your output will go to.\n\nS3Prefix -> (string)\n\nThe prefix of the object key that the output will be saved to. When not enabled, the prefix will be “textract_output”.\n\nShorthand Syntax:\n\nS3Bucket=string,S3Prefix=string\n\n\nJSON Syntax:\n\n{\n  \"S3Bucket\": \"string\",\n  \"S3Prefix\": \"string\"\n}\n\n\n--kms-key-id (string)\n\nThe KMS key used to encrypt the inference results. This can be in either Key ID or Key Alias format. When a KMS key is provided, the KMS key will be used for server-side encryption of the objects in the customer bucket. When this parameter is not enabled, the result will be encrypted server side,using SSE-S3.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nJobId -> (string)\n\nA unique identifier for the text detection job. The JobId is returned from StartExpenseAnalysis . A JobId value is only valid for 7 days."
    }
  ],
  "service_description": "Description\n\nAmazon Textract detects and analyzes text in documents and converts it into machine-readable text. This is the API reference documentation for Amazon Textract."
}