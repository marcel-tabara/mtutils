{
  "service_name": "transcribe",
  "service_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/index.html",
  "service_commands": [
    {
      "command_name": "create-call-analytics-category",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/create-call-analytics-category.html",
      "command_description": "Description\n\nCreates an analytics category. Amazon Transcribe applies the conditions specified by your analytics categories to your call analytics jobs. For each analytics category, you specify one or more rules. For example, you can specify a rule that the customer sentiment was neutral or negative within that category. If you start a call analytics job, Amazon Transcribe applies the category to the analytics job that you’ve specified.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-call-analytics-category\n--category-name <value>\n--rules <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--category-name <value>",
        "--rules <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--category-name (string)\n\nThe name that you choose for your category when you create it.\n\n--rules (list)\n\nTo create a category, you must specify between 1 and 20 rules. For each rule, you specify a filter to be applied to the attributes of the call. For example, you can specify a sentiment filter to detect if the customer’s sentiment was negative or neutral.\n\n(structure)\n\nA condition in the call between the customer and the agent that you want to filter for.\n\nNonTalkTimeFilter -> (structure)\n\nA condition for a time period when neither the customer nor the agent was talking.\n\nThreshold -> (long)\n\nThe duration of the period when neither the customer nor agent was talking.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when no one is talking. For example, you could specify a time period between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was silence. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period when people were talking.\n\nInterruptionFilter -> (structure)\n\nA condition for a time period when either the customer or agent was interrupting the other person.\n\nThreshold -> (long)\n\nThe duration of the interruption.\n\nParticipantRole -> (string)\n\nIndicates whether the caller or customer was interrupting.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when you’d want to find the interruption. For example, you could search for an interruption between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was a interruption. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period where there was no interruption.\n\nTranscriptFilter -> (structure)\n\nA condition that catches particular words or phrases based on a exact match. For example, if you set the phrase “I want to speak to the manager”, only that exact phrase will be returned.\n\nTranscriptFilterType -> (string)\n\nMatches the phrase to the transcription output in a word for word fashion. For example, if you specify the phrase “I want to speak to the manager.” Amazon Transcribe attempts to match that specific phrase to the transcription.\n\nAbsoluteTimeRange -> (structure)\n\nA time range, set in seconds, between two points in the call.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where you would like to apply a filter. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nDetermines whether the customer or the agent is speaking the phrases that you’ve specified.\n\nNegate -> (boolean)\n\nIf TRUE , the rule that you specify is applied to everything except for the phrases that you specify.\n\nTargets -> (list)\n\nThe phrases that you’re specifying for the transcript filter to match.\n\n(string)\n\nSentimentFilter -> (structure)\n\nA condition that is applied to a particular customer sentiment.\n\nSentiments -> (list)\n\nAn array that enables you to specify sentiments for the customer or agent. You can specify one or more values.\n\n(string)\n\nAbsoluteTimeRange -> (structure)\n\nThe time range, measured in seconds, of the sentiment.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nThe time range, set in percentages, that correspond to proportion of the call.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nA value that determines whether the sentiment belongs to the customer or the agent.\n\nNegate -> (boolean)\n\nSet to TRUE to look for sentiments that weren’t specified in the request.\n\nShorthand Syntax:\n\nNonTalkTimeFilter={Threshold=long,AbsoluteTimeRange={StartTime=long,EndTime=long,First=long,Last=long},RelativeTimeRange={StartPercentage=integer,EndPercentage=integer,First=integer,Last=integer},Negate=boolean},InterruptionFilter={Threshold=long,ParticipantRole=string,AbsoluteTimeRange={StartTime=long,EndTime=long,First=long,Last=long},RelativeTimeRange={StartPercentage=integer,EndPercentage=integer,First=integer,Last=integer},Negate=boolean},TranscriptFilter={TranscriptFilterType=string,AbsoluteTimeRange={StartTime=long,EndTime=long,First=long,Last=long},RelativeTimeRange={StartPercentage=integer,EndPercentage=integer,First=integer,Last=integer},ParticipantRole=string,Negate=boolean,Targets=[string,string]},SentimentFilter={Sentiments=[string,string],AbsoluteTimeRange={StartTime=long,EndTime=long,First=long,Last=long},RelativeTimeRange={StartPercentage=integer,EndPercentage=integer,First=integer,Last=integer},ParticipantRole=string,Negate=boolean} ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"NonTalkTimeFilter\": {\n      \"Threshold\": long,\n      \"AbsoluteTimeRange\": {\n        \"StartTime\": long,\n        \"EndTime\": long,\n        \"First\": long,\n        \"Last\": long\n      },\n      \"RelativeTimeRange\": {\n        \"StartPercentage\": integer,\n        \"EndPercentage\": integer,\n        \"First\": integer,\n        \"Last\": integer\n      },\n      \"Negate\": true|false\n    },\n    \"InterruptionFilter\": {\n      \"Threshold\": long,\n      \"ParticipantRole\": \"AGENT\"|\"CUSTOMER\",\n      \"AbsoluteTimeRange\": {\n        \"StartTime\": long,\n        \"EndTime\": long,\n        \"First\": long,\n        \"Last\": long\n      },\n      \"RelativeTimeRange\": {\n        \"StartPercentage\": integer,\n        \"EndPercentage\": integer,\n        \"First\": integer,\n        \"Last\": integer\n      },\n      \"Negate\": true|false\n    },\n    \"TranscriptFilter\": {\n      \"TranscriptFilterType\": \"EXACT\",\n      \"AbsoluteTimeRange\": {\n        \"StartTime\": long,\n        \"EndTime\": long,\n        \"First\": long,\n        \"Last\": long\n      },\n      \"RelativeTimeRange\": {\n        \"StartPercentage\": integer,\n        \"EndPercentage\": integer,\n        \"First\": integer,\n        \"Last\": integer\n      },\n      \"ParticipantRole\": \"AGENT\"|\"CUSTOMER\",\n      \"Negate\": true|false,\n      \"Targets\": [\"string\", ...]\n    },\n    \"SentimentFilter\": {\n      \"Sentiments\": [\"POSITIVE\"|\"NEGATIVE\"|\"NEUTRAL\"|\"MIXED\", ...],\n      \"AbsoluteTimeRange\": {\n        \"StartTime\": long,\n        \"EndTime\": long,\n        \"First\": long,\n        \"Last\": long\n      },\n      \"RelativeTimeRange\": {\n        \"StartPercentage\": integer,\n        \"EndPercentage\": integer,\n        \"First\": integer,\n        \"Last\": integer\n      },\n      \"ParticipantRole\": \"AGENT\"|\"CUSTOMER\",\n      \"Negate\": true|false\n    }\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nCategoryProperties -> (structure)\n\nThe rules and associated metadata used to create a category.\n\nCategoryName -> (string)\n\nThe name of the call analytics category.\n\nRules -> (list)\n\nThe rules used to create a call analytics category.\n\n(structure)\n\nA condition in the call between the customer and the agent that you want to filter for.\n\nNonTalkTimeFilter -> (structure)\n\nA condition for a time period when neither the customer nor the agent was talking.\n\nThreshold -> (long)\n\nThe duration of the period when neither the customer nor agent was talking.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when no one is talking. For example, you could specify a time period between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was silence. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period when people were talking.\n\nInterruptionFilter -> (structure)\n\nA condition for a time period when either the customer or agent was interrupting the other person.\n\nThreshold -> (long)\n\nThe duration of the interruption.\n\nParticipantRole -> (string)\n\nIndicates whether the caller or customer was interrupting.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when you’d want to find the interruption. For example, you could search for an interruption between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was a interruption. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period where there was no interruption.\n\nTranscriptFilter -> (structure)\n\nA condition that catches particular words or phrases based on a exact match. For example, if you set the phrase “I want to speak to the manager”, only that exact phrase will be returned.\n\nTranscriptFilterType -> (string)\n\nMatches the phrase to the transcription output in a word for word fashion. For example, if you specify the phrase “I want to speak to the manager.” Amazon Transcribe attempts to match that specific phrase to the transcription.\n\nAbsoluteTimeRange -> (structure)\n\nA time range, set in seconds, between two points in the call.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where you would like to apply a filter. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nDetermines whether the customer or the agent is speaking the phrases that you’ve specified.\n\nNegate -> (boolean)\n\nIf TRUE , the rule that you specify is applied to everything except for the phrases that you specify.\n\nTargets -> (list)\n\nThe phrases that you’re specifying for the transcript filter to match.\n\n(string)\n\nSentimentFilter -> (structure)\n\nA condition that is applied to a particular customer sentiment.\n\nSentiments -> (list)\n\nAn array that enables you to specify sentiments for the customer or agent. You can specify one or more values.\n\n(string)\n\nAbsoluteTimeRange -> (structure)\n\nThe time range, measured in seconds, of the sentiment.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nThe time range, set in percentages, that correspond to proportion of the call.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nA value that determines whether the sentiment belongs to the customer or the agent.\n\nNegate -> (boolean)\n\nSet to TRUE to look for sentiments that weren’t specified in the request.\n\nCreateTime -> (timestamp)\n\nA timestamp that shows when the call analytics category was created.\n\nLastUpdateTime -> (timestamp)\n\nA timestamp that shows when the call analytics category was most recently updated."
    },
    {
      "command_name": "create-language-model",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/create-language-model.html",
      "command_description": "Description\n\nCreates a new custom language model. Use Amazon S3 prefixes to provide the location of your input files. The time it takes to create your model depends on the size of your training data.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-language-model\n--language-code <value>\n--base-model-name <value>\n--model-name <value>\n--input-data-config <value>\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--language-code <value>",
        "--base-model-name <value>",
        "--model-name <value>",
        "--input-data-config <value>",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--language-code (string)\n\nThe language of the input text you’re using to train your custom language model.\n\nPossible values:\n\nen-US\n\nhi-IN\n\nes-US\n\nen-GB\n\nen-AU\n\n--base-model-name (string)\n\nThe Amazon Transcribe standard language model, or base model used to create your custom language model.\n\nIf you want to use your custom language model to transcribe audio with a sample rate of 16,000 Hz or greater, choose Wideband .\n\nIf you want to use your custom language model to transcribe audio with a sample rate that is less than 16,000 Hz, choose Narrowband .\n\nPossible values:\n\nNarrowBand\n\nWideBand\n\n--model-name (string)\n\nThe name you choose for your custom language model when you create it.\n\n--input-data-config (structure)\n\nContains the data access role and the Amazon S3 prefixes to read the required input files to create a custom language model.\n\nS3Uri -> (string)\n\nThe Amazon S3 prefix you specify to access the plain text files that you use to train your custom language model.\n\nTuningDataS3Uri -> (string)\n\nThe Amazon S3 prefix you specify to access the plain text files that you use to tune your custom language model.\n\nDataAccessRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) that uniquely identifies the permissions you’ve given Amazon Transcribe to access your Amazon S3 buckets containing your media files or text data.\n\nShorthand Syntax:\n\nS3Uri=string,TuningDataS3Uri=string,DataAccessRoleArn=string\n\n\nJSON Syntax:\n\n{\n  \"S3Uri\": \"string\",\n  \"TuningDataS3Uri\": \"string\",\n  \"DataAccessRoleArn\": \"string\"\n}\n\n\n--tags (list)\n\nAdds one or more tags, each in the form of a key:value pair, to a new language model at the time you create this new model.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.\n\nShorthand Syntax:\n\nKey=string,Value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Key\": \"string\",\n    \"Value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nLanguageCode -> (string)\n\nThe language code of the text you’ve used to create a custom language model.\n\nBaseModelName -> (string)\n\nThe Amazon Transcribe standard language model, or base model you’ve used to create a custom language model.\n\nModelName -> (string)\n\nThe name you’ve chosen for your custom language model.\n\nInputDataConfig -> (structure)\n\nThe data access role and Amazon S3 prefixes you’ve chosen to create your custom language model.\n\nS3Uri -> (string)\n\nThe Amazon S3 prefix you specify to access the plain text files that you use to train your custom language model.\n\nTuningDataS3Uri -> (string)\n\nThe Amazon S3 prefix you specify to access the plain text files that you use to tune your custom language model.\n\nDataAccessRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) that uniquely identifies the permissions you’ve given Amazon Transcribe to access your Amazon S3 buckets containing your media files or text data.\n\nModelStatus -> (string)\n\nThe status of the custom language model. When the status is COMPLETED the model is ready to use.",
      "command_examples": "Examples\n\nExample 1: To create a custom language model using both training and tuning data.\n\nThe following create-language-model example creates a custom language model. You can use a custom language model to improve transcription performance for domains such as legal, hospitality, finance, and insurance. For language-code, enter a valid language code. For base-model-name, specify a base model that is best suited for the sample rate of the audio that you want to transcribe with your custom language model. For model-name, specify the name that you want to call the custom language model.\n\naws transcribe create-language-model \\\n    --language-code language-code \\\n    --base-model-name base-model-name \\\n    --model-name cli-clm-example \\\n    --input-data-config S3Uri=\"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix-for-training-data\",TuningDataS3Uri=\"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix-for-tuning-data\",DataAccessRoleArn=\"arn:aws:iam::AWS-account-number:role/IAM-role-with-permissions-to-create-a-custom-language-model\"\n\n\nOutput:\n\n{\n    \"LanguageCode\": \"language-code\",\n    \"BaseModelName\": \"base-model-name\",\n    \"ModelName\": \"cli-clm-example\",\n    \"InputDataConfig\": {\n        \"S3Uri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix/\",\n        \"TuningDataS3Uri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix/\",\n        \"DataAccessRoleArn\": \"arn:aws:iam::AWS-account-number:role/IAM-role-with-permissions-create-a-custom-language-model\"\n    },\n    \"ModelStatus\": \"IN_PROGRESS\"\n}\n\n\nFor more information, see Improving Domain-Specific Transcription Accuracy with Custom Language Models in the Amazon Transcribe Developer Guide.\n\nExample 2: To create a custom language model using only training data.\n\nThe following create-language-model example transcribes your audio file. You can use a custom language model to improve transcription performance for domains such as legal, hospitality, finance, and insurance. For language-code, enter a valid language code. For base-model-name, specify a base model that is best suited for the sample rate of the audio that you want to transcribe with your custom language model. For model-name, specify the name that you want to call the custom language model.\n\naws transcribe create-language-model \\\n    --language-code en-US \\\n    --base-model-name base-model-name \\\n    --model-name cli-clm-example \\\n    --input-data-config S3Uri=\"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix-For-Training-Data\",DataAccessRoleArn=\"arn:aws:iam::AWS-account-number:role/IAM-role-with-permissions-to-create-a-custom-language-model\"\n\n\nOutput:\n\n{\n    \"LanguageCode\": \"en-US\",\n    \"BaseModelName\": \"base-model-name\",\n    \"ModelName\": \"cli-clm-example\",\n    \"InputDataConfig\": {\n        \"S3Uri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix-For-Training-Data/\",\n        \"DataAccessRoleArn\": \"arn:aws:iam::your-AWS-account-number:role/IAM-role-with-permissions-to-create-a-custom-language-model\"\n    },\n    \"ModelStatus\": \"IN_PROGRESS\"\n}\n\n\nFor more information, see Improving Domain-Specific Transcription Accuracy with Custom Language Models in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "create-medical-vocabulary",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/create-medical-vocabulary.html",
      "command_description": "Description\n\nCreates a new custom vocabulary that you can use to modify how Amazon Transcribe Medical transcribes your audio file.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-medical-vocabulary\n--vocabulary-name <value>\n--language-code <value>\n--vocabulary-file-uri <value>\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-name <value>",
        "--language-code <value>",
        "--vocabulary-file-uri <value>",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-name (string)\n\nThe name of the custom vocabulary. This case-sensitive name must be unique within an Amazon Web Services account. If you try to create a vocabulary with the same name as a previous vocabulary, you get a ConflictException error.\n\n--language-code (string)\n\nThe language code for the language used for the entries in your custom vocabulary. The language code of your custom vocabulary must match the language code of your transcription job. US English (en-US) is the only language code available for Amazon Transcribe Medical.\n\nPossible values:\n\naf-ZA\n\nar-AE\n\nar-SA\n\ncy-GB\n\nda-DK\n\nde-CH\n\nde-DE\n\nen-AB\n\nen-AU\n\nen-GB\n\nen-IE\n\nen-IN\n\nen-US\n\nen-WL\n\nes-ES\n\nes-US\n\nfa-IR\n\nfr-CA\n\nfr-FR\n\nga-IE\n\ngd-GB\n\nhe-IL\n\nhi-IN\n\nid-ID\n\nit-IT\n\nja-JP\n\nko-KR\n\nms-MY\n\nnl-NL\n\npt-BR\n\npt-PT\n\nru-RU\n\nta-IN\n\nte-IN\n\ntr-TR\n\nzh-CN\n\nzh-TW\n\nth-TH\n\nen-ZA\n\nen-NZ\n\n--vocabulary-file-uri (string)\n\nThe location in Amazon S3 of the text file you use to define your custom vocabulary. The URI must be in the same Amazon Web Services Region as the resource that you’re calling. Enter information about your VocabularyFileUri in the following format:\n\nhttps://s3.<aws-region>.amazonaws.com/<bucket-name>/<keyprefix>/<objectkey>\n\nThe following is an example URI for a vocabulary file that is stored in Amazon S3:\n\nhttps://s3.us-east-1.amazonaws.com/AWSDOC-EXAMPLE-BUCKET/vocab.txt\n\nFor more information about Amazon S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nFor more information about custom vocabularies, see Medical Custom Vocabularies .\n\n--tags (list)\n\nAdds one or more tags, each in the form of a key:value pair, to a new medical vocabulary at the time you create this new vocabulary.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.\n\nShorthand Syntax:\n\nKey=string,Value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Key\": \"string\",\n    \"Value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nVocabularyName -> (string)\n\nThe name of the vocabulary. The name must be unique within an Amazon Web Services account and is case sensitive.\n\nLanguageCode -> (string)\n\nThe language code for the entries in your custom vocabulary. US English (en-US) is the only valid language code for Amazon Transcribe Medical.\n\nVocabularyState -> (string)\n\nThe processing state of your custom vocabulary in Amazon Transcribe Medical. If the state is READY , you can use the vocabulary in a StartMedicalTranscriptionJob request.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that you created the vocabulary.\n\nFailureReason -> (string)\n\nIf the VocabularyState field is FAILED , this field contains information about why the job failed.",
      "command_examples": "Examples\n\nTo create a medical custom vocabulary\n\nThe following create-medical-vocabulary example creates a custom vocabulary. To create a custom vocabulary, you must have created a text file with all the terms that you want to transcribe more accurately. For vocabulary-file-uri, specify the Amazon Simple Storage Service (Amazon S3) URI of that text file. For language-code, specify a language code corresponding to the language of your custom vocabulary. For vocabulary-name, specify what you want to call your custom vocabulary.\n\naws transcribe create-medical-vocabulary \\\n    --vocabulary-name cli-medical-vocab-example \\\n    --language-code language-code \\\n    --vocabulary-file-uri https://DOC-EXAMPLE-BUCKET.AWS-Region.amazonaws.com/the-text-file-for-the-medical-custom-vocabulary.txt\n\n\nOutput:\n\n{\n    \"VocabularyName\": \"cli-medical-vocab-example\",\n    \"LanguageCode\": \"language-code\",\n    \"VocabularyState\": \"PENDING\"\n}\n\n\nFor more information, see Medical Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "create-vocabulary",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/create-vocabulary.html",
      "command_description": "Description\n\nCreates a new custom vocabulary that you can use to change the way Amazon Transcribe handles transcription of an audio file.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-vocabulary\n--vocabulary-name <value>\n--language-code <value>\n[--phrases <value>]\n[--vocabulary-file-uri <value>]\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-name <value>",
        "--language-code <value>",
        "[--phrases <value>]",
        "[--vocabulary-file-uri <value>]",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-name (string)\n\nThe name of the vocabulary. The name must be unique within an Amazon Web Services account. The name is case sensitive. If you try to create a vocabulary with the same name as a previous vocabulary you will receive a ConflictException error.\n\n--language-code (string)\n\nThe language code of the vocabulary entries. For a list of languages and their corresponding language codes, see transcribe-whatis .\n\nPossible values:\n\naf-ZA\n\nar-AE\n\nar-SA\n\ncy-GB\n\nda-DK\n\nde-CH\n\nde-DE\n\nen-AB\n\nen-AU\n\nen-GB\n\nen-IE\n\nen-IN\n\nen-US\n\nen-WL\n\nes-ES\n\nes-US\n\nfa-IR\n\nfr-CA\n\nfr-FR\n\nga-IE\n\ngd-GB\n\nhe-IL\n\nhi-IN\n\nid-ID\n\nit-IT\n\nja-JP\n\nko-KR\n\nms-MY\n\nnl-NL\n\npt-BR\n\npt-PT\n\nru-RU\n\nta-IN\n\nte-IN\n\ntr-TR\n\nzh-CN\n\nzh-TW\n\nth-TH\n\nen-ZA\n\nen-NZ\n\n--phrases (list)\n\nAn array of strings that contains the vocabulary entries.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--vocabulary-file-uri (string)\n\nThe S3 location of the text file that contains the definition of the custom vocabulary. The URI must be in the same region as the API endpoint that you are calling. The general form is:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nFor more information about custom vocabularies, see Custom vocabularies .\n\n--tags (list)\n\nAdds one or more tags, each in the form of a key:value pair, to a new Amazon Transcribe vocabulary at the time you create this new vocabulary.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.\n\nShorthand Syntax:\n\nKey=string,Value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Key\": \"string\",\n    \"Value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nVocabularyName -> (string)\n\nThe name of the vocabulary.\n\nLanguageCode -> (string)\n\nThe language code of the vocabulary entries.\n\nVocabularyState -> (string)\n\nThe processing state of the vocabulary. When the VocabularyState field contains READY the vocabulary is ready to be used in a StartTranscriptionJob request.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the vocabulary was created.\n\nFailureReason -> (string)\n\nIf the VocabularyState field is FAILED , this field contains information about why the job failed.",
      "command_examples": "Examples\n\nTo create a custom vocabulary\n\nThe following create-vocabulary example creates a custom vocabulary. To create a custom vocabulary, you must have created a text file with all the terms that you want to transcribe more accurately. For vocabulary-file-uri, specify the Amazon Simple Storage Service (Amazon S3) URI of that text file. For language-code, specify a language code corresponding to the language of your custom vocabulary. For vocabulary-name, specify what you want to call your custom vocabulary.\n\naws transcribe create-vocabulary \\\n    --language-code language-code \\\n    --vocabulary-name cli-vocab-example \\\n    --vocabulary-file-uri s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/the-text-file-for-the-custom-vocabulary.txt\n\n\nOutput:\n\n{\n    \"VocabularyName\": \"cli-vocab-example\",\n    \"LanguageCode\": \"language-code\",\n    \"VocabularyState\": \"PENDING\"\n}\n\n\nFor more information, see Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "create-vocabulary-filter",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/create-vocabulary-filter.html",
      "command_description": "Description\n\nCreates a new vocabulary filter that you can use to filter words, such as profane words, from the output of a transcription job.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-vocabulary-filter\n--vocabulary-filter-name <value>\n--language-code <value>\n[--words <value>]\n[--vocabulary-filter-file-uri <value>]\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-filter-name <value>",
        "--language-code <value>",
        "[--words <value>]",
        "[--vocabulary-filter-file-uri <value>]",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-filter-name (string)\n\nThe vocabulary filter name. The name must be unique within the account that contains it. If you try to create a vocabulary filter with the same name as another vocabulary filter, you get a ConflictException error.\n\n--language-code (string)\n\nThe language code of the words in the vocabulary filter. All words in the filter must be in the same language. The vocabulary filter can only be used with transcription jobs in the specified language.\n\nPossible values:\n\naf-ZA\n\nar-AE\n\nar-SA\n\ncy-GB\n\nda-DK\n\nde-CH\n\nde-DE\n\nen-AB\n\nen-AU\n\nen-GB\n\nen-IE\n\nen-IN\n\nen-US\n\nen-WL\n\nes-ES\n\nes-US\n\nfa-IR\n\nfr-CA\n\nfr-FR\n\nga-IE\n\ngd-GB\n\nhe-IL\n\nhi-IN\n\nid-ID\n\nit-IT\n\nja-JP\n\nko-KR\n\nms-MY\n\nnl-NL\n\npt-BR\n\npt-PT\n\nru-RU\n\nta-IN\n\nte-IN\n\ntr-TR\n\nzh-CN\n\nzh-TW\n\nth-TH\n\nen-ZA\n\nen-NZ\n\n--words (list)\n\nThe words to use in the vocabulary filter. Only use characters from the character set defined for custom vocabularies. For a list of character sets, see Character Sets for Custom Vocabularies .\n\nIf you provide a list of words in the Words parameter, you can’t use the VocabularyFilterFileUri parameter.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--vocabulary-filter-file-uri (string)\n\nThe Amazon S3 location of a text file used as input to create the vocabulary filter. Only use characters from the character set defined for custom vocabularies. For a list of character sets, see Character Sets for Custom Vocabularies .\n\nThe specified file must be less than 50 KB of UTF-8 characters.\n\nIf you provide the location of a list of words in the VocabularyFilterFileUri parameter, you can’t use the Words parameter.\n\n--tags (list)\n\nAdds one or more tags, each in the form of a key:value pair, to a new Amazon Transcribe vocabulary filter at the time you create this new vocabulary filter.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.\n\nShorthand Syntax:\n\nKey=string,Value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Key\": \"string\",\n    \"Value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nVocabularyFilterName -> (string)\n\nThe name of the vocabulary filter.\n\nLanguageCode -> (string)\n\nThe language code of the words in the collection.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the vocabulary filter was modified.",
      "command_examples": "Examples\n\nTo create a vocabulary filter\n\nThe following create-vocabulary-filter example creates a vocabulary filter that uses a text file that contains a list of words that you wouldn’t want to appear in a transcription. For language-code, specify the language code corresponding to the language of your vocabulary filter. For vocabulary-filter-file-uri, specify the Amazon Simple Storage Service (Amazon S3) URI of the text file. For vocabulary-filter-name, specify the name of your vocabulary filter.\n\naws transcribe create-vocabulary-filter \\\n    --language-code language-code \\\n    --vocabulary-filter-file-uri s3://DOC-EXAMPLE-BUCKET/vocabulary-filter.txt \\\n    --vocabulary-filter-name cli-vocabulary-filter-example\n\n\nOutput:\n\n{\n    \"VocabularyFilterName\": \"cli-vocabulary-filter-example\",\n    \"LanguageCode\": \"language-code\"\n}\n\n\nFor more information, see Filtering Unwanted Words in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "delete-call-analytics-category",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/delete-call-analytics-category.html",
      "command_description": "Description\n\nDeletes a call analytics category using its name.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-call-analytics-category\n--category-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--category-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--category-name (string)\n\nThe name of the call analytics category that you’re choosing to delete. The value is case sensitive.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "delete-call-analytics-job",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/delete-call-analytics-job.html",
      "command_description": "Description\n\nDeletes a call analytics job using its name.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-call-analytics-job\n--call-analytics-job-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--call-analytics-job-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--call-analytics-job-name (string)\n\nThe name of the call analytics job you want to delete.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "delete-language-model",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/delete-language-model.html",
      "command_description": "Description\n\nDeletes a custom language model using its name.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-language-model\n--model-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--model-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--model-name (string)\n\nThe name of the model you’re choosing to delete.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo delete a custom language model\n\nThe following delete-language-model example deletes a custom language model.\n\naws transcribe delete-language-model \\\n    --model-name model-name\n\n\nThis command produces no output.\n\nFor more information, see Improving Domain-Specific Transcription Accuracy with Custom Language Models in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "delete-medical-transcription-job",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/delete-medical-transcription-job.html",
      "command_description": "Description\n\nDeletes a transcription job generated by Amazon Transcribe Medical and any related information.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-medical-transcription-job\n--medical-transcription-job-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--medical-transcription-job-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--medical-transcription-job-name (string)\n\nThe name you provide to the DeleteMedicalTranscriptionJob object to delete a transcription job.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo delete a medical transcription job\n\nThe following delete-medical-transcription-job example deletes a medical transcription job.\n\naws transcribe delete-medical-transcription-job \\\n    --medical-transcription-job-name medical-transcription-job-name\n\n\nThis command produces no output.\n\nFor more information, see DeleteMedicalTranscriptionJob in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "delete-medical-vocabulary",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/delete-medical-vocabulary.html",
      "command_description": "Description\n\nDeletes a vocabulary from Amazon Transcribe Medical.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-medical-vocabulary\n--vocabulary-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-name (string)\n\nThe name of the vocabulary that you want to delete.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo delete a medical custom vocabulary\n\nThe following delete-medical-vocabulary example deletes a medical custom vocabulary. For vocabulary-name, specify the name of the medical custom vocabulary.\n\naws transcribe delete-vocabulary \\\n    --vocabulary-name medical-custom-vocabulary-name\n\n\nThis command produces no output.\n\nFor more information, see Medical Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "delete-transcription-job",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/delete-transcription-job.html",
      "command_description": "Description\n\nDeletes a previously submitted transcription job along with any other generated results such as the transcription, models, and so on.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-transcription-job\n--transcription-job-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--transcription-job-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--transcription-job-name (string)\n\nThe name of the transcription job to be deleted.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo delete one of your transcription jobs\n\nThe following delete-transcription-job example deletes one of your transcription jobs.\n\naws transcribe delete-transcription-job \\\n    --transcription-job-name your-transcription-job\n\n\nThis command produces no output.\n\nFor more information, see DeleteTranscriptionJob in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "delete-vocabulary",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/delete-vocabulary.html",
      "command_description": "Description\n\nDeletes a vocabulary from Amazon Transcribe.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-vocabulary\n--vocabulary-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-name (string)\n\nThe name of the vocabulary to delete.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo delete a custom vocabulary\n\nThe following delete-vocabulary example deletes a custom vocabulary.\n\naws transcribe delete-vocabulary \\\n    --vocabulary-name vocabulary-name\n\n\nThis command produces no output.\n\nFor more information, see Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "delete-vocabulary-filter",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/delete-vocabulary-filter.html",
      "command_description": "Description\n\nRemoves a vocabulary filter.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-vocabulary-filter\n--vocabulary-filter-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-filter-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-filter-name (string)\n\nThe name of the vocabulary filter to remove.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo delete a vocabulary filter\n\nThe following delete-vocabulary-filter example deletes a vocabulary filter.\n\naws transcribe delete-vocabulary-filter \\\n    --vocabulary-filter-name vocabulary-filter-name\n\n\nThis command produces no output.\n\nFor more information, see Filtering Unwanted Words in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "describe-language-model",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/describe-language-model.html",
      "command_description": "Description\n\nGets information about a single custom language model. Use this information to see details about the language model in your Amazon Web Services account. You can also see whether the base language model used to create your custom language model has been updated. If Amazon Transcribe has updated the base model, you can create a new custom language model using the updated base model. If the language model wasn’t created, you can use this operation to understand why Amazon Transcribe couldn’t create it.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-language-model\n--model-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--model-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--model-name (string)\n\nThe name of the custom language model you submit to get more information.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nLanguageModel -> (structure)\n\nThe name of the custom language model you requested more information about.\n\nModelName -> (string)\n\nThe name of the custom language model.\n\nCreateTime -> (timestamp)\n\nThe time the custom language model was created.\n\nLastModifiedTime -> (timestamp)\n\nThe most recent time the custom language model was modified.\n\nLanguageCode -> (string)\n\nThe language code you used to create your custom language model.\n\nBaseModelName -> (string)\n\nThe Amazon Transcribe standard language model, or base model used to create the custom language model.\n\nModelStatus -> (string)\n\nThe creation status of a custom language model. When the status is COMPLETED the model is ready for use.\n\nUpgradeAvailability -> (boolean)\n\nWhether the base model used for the custom language model is up to date. If this field is true then you are running the most up-to-date version of the base model in your custom language model.\n\nFailureReason -> (string)\n\nThe reason why the custom language model couldn’t be created.\n\nInputDataConfig -> (structure)\n\nThe data access role and Amazon S3 prefixes for the input files used to train the custom language model.\n\nS3Uri -> (string)\n\nThe Amazon S3 prefix you specify to access the plain text files that you use to train your custom language model.\n\nTuningDataS3Uri -> (string)\n\nThe Amazon S3 prefix you specify to access the plain text files that you use to tune your custom language model.\n\nDataAccessRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) that uniquely identifies the permissions you’ve given Amazon Transcribe to access your Amazon S3 buckets containing your media files or text data.",
      "command_examples": "Examples\n\nTo get information about a specific custom language model\n\nThe following describe-language-model example gets information about a specific custom language model. For example, under BaseModelName you can see whether your model is trained using a NarrowBand or WideBand model. Custom language models with a NarrowBand base model can transcribe audio with a sample rate less than 16 kHz. Language models using a WideBand base model can transcribe audio with a sample rate greater than 16 kHz. The S3Uri parameter indicates the Amazon S3 prefix you’ve used to access the training data to create the custom language model.\n\naws transcribe describe-language-model \\\n    --model-name cli-clm-example\n\n\nOutput:\n\n{\n    \"LanguageModel\": {\n        \"ModelName\": \"cli-clm-example\",\n        \"CreateTime\": \"2020-09-25T17:57:38.504000+00:00\",\n        \"LastModifiedTime\": \"2020-09-25T17:57:48.585000+00:00\",\n        \"LanguageCode\": \"language-code\",\n        \"BaseModelName\": \"base-model-name\",\n        \"ModelStatus\": \"IN_PROGRESS\",\n        \"UpgradeAvailability\": false,\n        \"InputDataConfig\": {\n            \"S3Uri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix/\",\n            \"TuningDataS3Uri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix/\",\n            \"DataAccessRoleArn\": \"arn:aws:iam::AWS-account-number:role/IAM-role-with-permissions-to-create-a-custom-language-model\"\n        }\n    }\n}\n\n\nFor more information, see Improving Domain-Specific Transcription Accuracy with Custom Language Models in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "get-call-analytics-category",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/get-call-analytics-category.html",
      "command_description": "Description\n\nRetrieves information about a call analytics category.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-call-analytics-category\n--category-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--category-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--category-name (string)\n\nThe name of the category you want information about. This value is case sensitive.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nCategoryProperties -> (structure)\n\nThe rules you’ve defined for a category.\n\nCategoryName -> (string)\n\nThe name of the call analytics category.\n\nRules -> (list)\n\nThe rules used to create a call analytics category.\n\n(structure)\n\nA condition in the call between the customer and the agent that you want to filter for.\n\nNonTalkTimeFilter -> (structure)\n\nA condition for a time period when neither the customer nor the agent was talking.\n\nThreshold -> (long)\n\nThe duration of the period when neither the customer nor agent was talking.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when no one is talking. For example, you could specify a time period between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was silence. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period when people were talking.\n\nInterruptionFilter -> (structure)\n\nA condition for a time period when either the customer or agent was interrupting the other person.\n\nThreshold -> (long)\n\nThe duration of the interruption.\n\nParticipantRole -> (string)\n\nIndicates whether the caller or customer was interrupting.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when you’d want to find the interruption. For example, you could search for an interruption between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was a interruption. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period where there was no interruption.\n\nTranscriptFilter -> (structure)\n\nA condition that catches particular words or phrases based on a exact match. For example, if you set the phrase “I want to speak to the manager”, only that exact phrase will be returned.\n\nTranscriptFilterType -> (string)\n\nMatches the phrase to the transcription output in a word for word fashion. For example, if you specify the phrase “I want to speak to the manager.” Amazon Transcribe attempts to match that specific phrase to the transcription.\n\nAbsoluteTimeRange -> (structure)\n\nA time range, set in seconds, between two points in the call.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where you would like to apply a filter. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nDetermines whether the customer or the agent is speaking the phrases that you’ve specified.\n\nNegate -> (boolean)\n\nIf TRUE , the rule that you specify is applied to everything except for the phrases that you specify.\n\nTargets -> (list)\n\nThe phrases that you’re specifying for the transcript filter to match.\n\n(string)\n\nSentimentFilter -> (structure)\n\nA condition that is applied to a particular customer sentiment.\n\nSentiments -> (list)\n\nAn array that enables you to specify sentiments for the customer or agent. You can specify one or more values.\n\n(string)\n\nAbsoluteTimeRange -> (structure)\n\nThe time range, measured in seconds, of the sentiment.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nThe time range, set in percentages, that correspond to proportion of the call.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nA value that determines whether the sentiment belongs to the customer or the agent.\n\nNegate -> (boolean)\n\nSet to TRUE to look for sentiments that weren’t specified in the request.\n\nCreateTime -> (timestamp)\n\nA timestamp that shows when the call analytics category was created.\n\nLastUpdateTime -> (timestamp)\n\nA timestamp that shows when the call analytics category was most recently updated."
    },
    {
      "command_name": "get-call-analytics-job",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/get-call-analytics-job.html",
      "command_description": "Description\n\nReturns information about a call analytics job. To see the status of the job, check the CallAnalyticsJobStatus field. If the status is COMPLETED , the job is finished and you can find the results at the location specified in the TranscriptFileUri field. If you enable personally identifiable information (PII) redaction, the redacted transcript appears in the RedactedTranscriptFileUri field.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-call-analytics-job\n--call-analytics-job-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--call-analytics-job-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--call-analytics-job-name (string)\n\nThe name of the analytics job you want information about. This value is case sensitive.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nCallAnalyticsJob -> (structure)\n\nAn object that contains the results of your call analytics job.\n\nCallAnalyticsJobName -> (string)\n\nThe name of the call analytics job.\n\nCallAnalyticsJobStatus -> (string)\n\nThe status of the analytics job.\n\nLanguageCode -> (string)\n\nIf you know the language spoken between the customer and the agent, specify a language code for this field.\n\nIf you don’t know the language, you can leave this field blank, and Amazon Transcribe will use machine learning to automatically identify the language. To improve the accuracy of language identification, you can provide an array containing the possible language codes for the language spoken in your audio. Refer to Supported languages and language-specific features for additional information.\n\nMediaSampleRateHertz -> (integer)\n\nThe sample rate, in Hertz, of the audio.\n\nMediaFormat -> (string)\n\nThe format of the input audio file. Note: for call analytics jobs, only the following media formats are supported: MP3, MP4, WAV, FLAC, OGG, and WebM.\n\nMedia -> (structure)\n\nDescribes the input media file in a transcription request.\n\nMediaFileUri -> (string)\n\nThe S3 object location of the input media file. The URI must be in the same region as the API endpoint that you are calling. The general form is:\n\nFor example:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nRedactedMediaFileUri -> (string)\n\nThe S3 object location for your redacted output media file. This is only supported for call analytics jobs.\n\nTranscript -> (structure)\n\nIdentifies the location of a transcription.\n\nTranscriptFileUri -> (string)\n\nThe S3 object location of the transcript.\n\nUse this URI to access the transcript. If you specified an S3 bucket in the OutputBucketName field when you created the job, this is the URI of that bucket. If you chose to store the transcript in Amazon Transcribe, this is a shareable URL that provides secure access to that location.\n\nRedactedTranscriptFileUri -> (string)\n\nThe S3 object location of the redacted transcript.\n\nUse this URI to access the redacted transcript. If you specified an S3 bucket in the OutputBucketName field when you created the job, this is the URI of that bucket. If you chose to store the transcript in Amazon Transcribe, this is a shareable URL that provides secure access to that location.\n\nStartTime -> (timestamp)\n\nA timestamp that shows when the analytics job started processing.\n\nCreationTime -> (timestamp)\n\nA timestamp that shows when the analytics job was created.\n\nCompletionTime -> (timestamp)\n\nA timestamp that shows when the analytics job was completed.\n\nFailureReason -> (string)\n\nIf the AnalyticsJobStatus is FAILED , this field contains information about why the job failed.\n\nThe FailureReason field can contain one of the following values:\n\nUnsupported media format : The media format specified in the MediaFormat field of the request isn’t valid. See the description of the MediaFormat field for a list of valid values.\n\nThe media format provided does not match the detected media format : The media format of the audio file doesn’t match the format specified in the MediaFormat field in the request. Check the media format of your media file and make sure the two values match.\n\nInvalid sample rate for audio file : The sample rate specified in the MediaSampleRateHertz of the request isn’t valid. The sample rate must be between 8,000 and 48,000 Hertz.\n\nThe sample rate provided does not match the detected sample rate : The sample rate in the audio file doesn’t match the sample rate specified in the MediaSampleRateHertz field in the request. Check the sample rate of your media file and make sure that the two values match.\n\nInvalid file size: file size too large : The size of your audio file is larger than what Amazon Transcribe Medical can process. For more information, see Guidelines and Quotas in the Amazon Transcribe Medical Guide.\n\nInvalid number of channels: number of channels too large : Your audio contains more channels than Amazon Transcribe Medical is configured to process. To request additional channels, see Amazon Transcribe Medical Endpoints and Quotas in the Amazon Web Services General Reference .\n\nDataAccessRoleArn -> (string)\n\nThe Amazon Resource Number (ARN) that you use to get access to the analytics job.\n\nIdentifiedLanguageScore -> (float)\n\nA value between zero and one that Amazon Transcribe assigned to the language that it identified in the source audio. This value appears only when you don’t provide a single language code. Larger values indicate that Amazon Transcribe has higher confidence in the language that it identified\n\nSettings -> (structure)\n\nProvides information about the settings used to run a transcription job.\n\nVocabularyName -> (string)\n\nThe name of a vocabulary to use when processing the call analytics job.\n\nVocabularyFilterName -> (string)\n\nThe name of the vocabulary filter to use when running a call analytics job. The filter that you specify must have the same language code as the analytics job.\n\nVocabularyFilterMethod -> (string)\n\nSet to mask to remove filtered text from the transcript and replace it with three asterisks (“***”) as placeholder text. Set to remove to remove filtered text from the transcript without using placeholder text. Set to tag to mark the word in the transcription output that matches the vocabulary filter. When you set the filter method to tag , the words matching your vocabulary filter are not masked or removed.\n\nLanguageModelName -> (string)\n\nThe structure used to describe a custom language model.\n\nContentRedaction -> (structure)\n\nSettings for content redaction within a transcription job.\n\nRedactionType -> (string)\n\nRequest parameter that defines the entities to be redacted. The only accepted value is PII .\n\nRedactionOutput -> (string)\n\nThe output transcript file stored in either the default S3 bucket or in a bucket you specify.\n\nWhen you choose redacted Amazon Transcribe outputs only the redacted transcript.\n\nWhen you choose redacted_and_unredacted Amazon Transcribe outputs both the redacted and unredacted transcripts.\n\nLanguageOptions -> (list)\n\nWhen you run a call analytics job, you can specify the language spoken in the audio, or you can have Amazon Transcribe identify the language for you.\n\nTo specify a language, specify an array with one language code. If you don’t know the language, you can leave this field blank and Amazon Transcribe will use machine learning to identify the language for you. To improve the ability of Amazon Transcribe to correctly identify the language, you can provide an array of the languages that can be present in the audio. Refer to Supported languages and language-specific features for additional information.\n\n(string)\n\nChannelDefinitions -> (list)\n\nShows numeric values to indicate the channel assigned to the agent’s audio and the channel assigned to the customer’s audio.\n\n(structure)\n\nFor a call analytics job, an object that indicates the audio channel that belongs to the agent and the audio channel that belongs to the customer.\n\nChannelId -> (integer)\n\nA value that indicates the audio channel.\n\nParticipantRole -> (string)\n\nIndicates whether the person speaking on the audio channel is the agent or customer."
    },
    {
      "command_name": "get-medical-transcription-job",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/get-medical-transcription-job.html",
      "command_description": "Description\n\nReturns information about a transcription job from Amazon Transcribe Medical. To see the status of the job, check the TranscriptionJobStatus field. If the status is COMPLETED , the job is finished. You find the results of the completed job in the TranscriptFileUri field.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-medical-transcription-job\n--medical-transcription-job-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--medical-transcription-job-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--medical-transcription-job-name (string)\n\nThe name of the medical transcription job.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nMedicalTranscriptionJob -> (structure)\n\nAn object that contains the results of the medical transcription job.\n\nMedicalTranscriptionJobName -> (string)\n\nThe name for a given medical transcription job.\n\nTranscriptionJobStatus -> (string)\n\nThe completion status of a medical transcription job.\n\nLanguageCode -> (string)\n\nThe language code for the language spoken in the source audio file. US English (en-US) is the only supported language for medical transcriptions. Any other value you enter for language code results in a BadRequestException error.\n\nMediaSampleRateHertz -> (integer)\n\nThe sample rate, in Hertz, of the source audio containing medical information.\n\nIf you don’t specify the sample rate, Amazon Transcribe Medical determines it for you. If you choose to specify the sample rate, it must match the rate detected by Amazon Transcribe Medical. In most cases, you should leave the MedicalMediaSampleHertz blank and let Amazon Transcribe Medical determine the sample rate.\n\nMediaFormat -> (string)\n\nThe format of the input media file.\n\nMedia -> (structure)\n\nDescribes the input media file in a transcription request.\n\nMediaFileUri -> (string)\n\nThe S3 object location of the input media file. The URI must be in the same region as the API endpoint that you are calling. The general form is:\n\nFor example:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nRedactedMediaFileUri -> (string)\n\nThe S3 object location for your redacted output media file. This is only supported for call analytics jobs.\n\nTranscript -> (structure)\n\nAn object that contains the MedicalTranscript . The MedicalTranscript contains the TranscriptFileUri .\n\nTranscriptFileUri -> (string)\n\nThe S3 object location of the medical transcript.\n\nUse this URI to access the medical transcript. This URI points to the S3 bucket you created to store the medical transcript.\n\nStartTime -> (timestamp)\n\nA timestamp that shows when the job started processing.\n\nCreationTime -> (timestamp)\n\nA timestamp that shows when the job was created.\n\nCompletionTime -> (timestamp)\n\nA timestamp that shows when the job was completed.\n\nFailureReason -> (string)\n\nIf the TranscriptionJobStatus field is FAILED , this field contains information about why the job failed.\n\nThe FailureReason field contains one of the following values:\n\nUnsupported media format - The media format specified in the MediaFormat field of the request isn’t valid. See the description of the MediaFormat field for a list of valid values.\n\nThe media format provided does not match the detected media format - The media format of the audio file doesn’t match the format specified in the MediaFormat field in the request. Check the media format of your media file and make sure the two values match.\n\nInvalid sample rate for audio file - The sample rate specified in the MediaSampleRateHertz of the request isn’t valid. The sample rate must be between 8,000 and 48,000 Hertz.\n\nThe sample rate provided does not match the detected sample rate - The sample rate in the audio file doesn’t match the sample rate specified in the MediaSampleRateHertz field in the request. Check the sample rate of your media file and make sure that the two values match.\n\nInvalid file size: file size too large - The size of your audio file is larger than what Amazon Transcribe Medical can process. For more information, see Guidelines and Quotas in the Amazon Transcribe Medical Guide\n\nInvalid number of channels: number of channels too large - Your audio contains more channels than Amazon Transcribe Medical is configured to process. To request additional channels, see Amazon Transcribe Medical Endpoints and Quotas in the Amazon Web Services General Reference\n\nSettings -> (structure)\n\nObject that contains object.\n\nShowSpeakerLabels -> (boolean)\n\nDetermines whether the transcription job uses speaker recognition to identify different speakers in the input audio. Speaker recognition labels individual speakers in the audio file. If you set the ShowSpeakerLabels field to true, you must also set the maximum number of speaker labels in the MaxSpeakerLabels field.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException .\n\nMaxSpeakerLabels -> (integer)\n\nThe maximum number of speakers to identify in the input audio. If there are more speakers in the audio than this number, multiple speakers are identified as a single speaker. If you specify the MaxSpeakerLabels field, you must set the ShowSpeakerLabels field to true.\n\nChannelIdentification -> (boolean)\n\nInstructs Amazon Transcribe Medical to process each audio channel separately and then merge the transcription output of each channel into a single transcription.\n\nAmazon Transcribe Medical also produces a transcription of each item detected on an audio channel, including the start time and end time of the item and alternative transcriptions of item. The alternative transcriptions also come with confidence scores provided by Amazon Transcribe Medical.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException\n\nShowAlternatives -> (boolean)\n\nDetermines whether alternative transcripts are generated along with the transcript that has the highest confidence. If you set ShowAlternatives field to true, you must also set the maximum number of alternatives to return in the MaxAlternatives field.\n\nMaxAlternatives -> (integer)\n\nThe maximum number of alternatives that you tell the service to return. If you specify the MaxAlternatives field, you must set the ShowAlternatives field to true.\n\nVocabularyName -> (string)\n\nThe name of the vocabulary to use when processing a medical transcription job.\n\nContentIdentificationType -> (string)\n\nShows the type of content that you’ve configured Amazon Transcribe Medical to identify in a transcription job. If the value is PHI , you’ve configured the job to identify personal health information (PHI) in the transcription output.\n\nSpecialty -> (string)\n\nThe medical specialty of any clinicians providing a dictation or having a conversation. Refer to Transcribing a medical conversation for a list of supported specialties.\n\nType -> (string)\n\nThe type of speech in the transcription job. CONVERSATION is generally used for patient-physician dialogues. DICTATION is the setting for physicians speaking their notes after seeing a patient. For more information, see What is Amazon Transcribe Medical? .\n\nTags -> (list)\n\nA key:value pair assigned to a given medical transcription job.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.",
      "command_examples": "Examples\n\nTo get information about a specific medical transcription job\n\nThe following get-medical-transcription-job example gets information about a specific medical transcription job. To access the transcription results, use the TranscriptFileUri parameter. If you’ve enabled additional features for the transcription job, you can see them in the Settings object. The Specialty parameter shows the medical specialty of the provider. The Type parameter indicates whether the speech in the transcription job is of a medical conversation, or a medical dictation.\n\naws transcribe get-medical-transcription-job \\\n    --medical-transcription-job-name vocabulary-dictation-medical-transcription-job\n\n\nOutput:\n\n{\n    \"MedicalTranscriptionJob\": {\n        \"MedicalTranscriptionJobName\": \"vocabulary-dictation-medical-transcription-job\",\n        \"TranscriptionJobStatus\": \"COMPLETED\",\n        \"LanguageCode\": \"en-US\",\n        \"MediaSampleRateHertz\": 48000,\n        \"MediaFormat\": \"mp4\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://Amazon-S3-Prefix/your-audio-file.file-extension\"\n        },\n        \"Transcript\": {\n            \"TranscriptFileUri\": \"https://s3.Region.amazonaws.com/Amazon-S3-Prefix/vocabulary-dictation-medical-transcription-job.json\"\n        },\n        \"StartTime\": \"2020-09-21T21:17:27.045000+00:00\",\n        \"CreationTime\": \"2020-09-21T21:17:27.016000+00:00\",\n        \"CompletionTime\": \"2020-09-21T21:17:59.561000+00:00\",\n        \"Settings\": {\n            \"ChannelIdentification\": false,\n            \"ShowAlternatives\": false,\n            \"VocabularyName\": \"cli-medical-vocab-example\"\n        },\n        \"Specialty\": \"PRIMARYCARE\",\n        \"Type\": \"DICTATION\"\n    }\n}\n\n\nFor more information, see Batch Transcription in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "get-medical-vocabulary",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/get-medical-vocabulary.html",
      "command_description": "Description\n\nRetrieves information about a medical vocabulary.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-medical-vocabulary\n--vocabulary-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-name (string)\n\nThe name of the vocabulary that you want information about. The value is case sensitive.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nVocabularyName -> (string)\n\nThe name of the vocabulary returned by Amazon Transcribe Medical.\n\nLanguageCode -> (string)\n\nThe valid language code for your vocabulary entries.\n\nVocabularyState -> (string)\n\nThe processing state of the vocabulary. If the VocabularyState is READY then you can use it in the StartMedicalTranscriptionJob operation.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the vocabulary was last modified with a text file different from the one that was previously used.\n\nFailureReason -> (string)\n\nIf the VocabularyState is FAILED , this field contains information about why the job failed.\n\nDownloadUri -> (string)\n\nThe location in Amazon S3 where the vocabulary is stored. Use this URI to get the contents of the vocabulary. You can download your vocabulary from the URI for a limited time.",
      "command_examples": "Examples\n\nTo get information about a medical custom vocabulary\n\nThe following get-medical-vocabulary example gets information on a medical custom vocabulary. You can use the VocabularyState parameter to see the processing state of the vocabulary. If it’s READY, you can use it in the StartMedicalTranscriptionJob operation.:\n\naws transcribe get-medical-vocabulary \\\n    --vocabulary-name medical-vocab-example\n\n\nOutput:\n\n{\n    \"VocabularyName\": \"medical-vocab-example\",\n    \"LanguageCode\": \"en-US\",\n    \"VocabularyState\": \"READY\",\n    \"LastModifiedTime\": \"2020-09-19T23:59:04.349000+00:00\",\n    \"DownloadUri\": \"https://link-to-download-the-text-file-used-to-create-your-medical-custom-vocabulary\"\n}\n\n\nFor more information, see Medical Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "get-transcription-job",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/get-transcription-job.html",
      "command_description": "Description\n\nReturns information about a transcription job. To see the status of the job, check the TranscriptionJobStatus field. If the status is COMPLETED , the job is finished and you can find the results at the location specified in the TranscriptFileUri field. If you enable content redaction, the redacted transcript appears in RedactedTranscriptFileUri .\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-transcription-job\n--transcription-job-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--transcription-job-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--transcription-job-name (string)\n\nThe name of the job.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nTranscriptionJob -> (structure)\n\nAn object that contains the results of the transcription job.\n\nTranscriptionJobName -> (string)\n\nThe name of the transcription job.\n\nTranscriptionJobStatus -> (string)\n\nThe status of the transcription job.\n\nLanguageCode -> (string)\n\nThe language code for the input speech.\n\nMediaSampleRateHertz -> (integer)\n\nThe sample rate, in Hertz, of the audio track in the input media file.\n\nMediaFormat -> (string)\n\nThe format of the input media file.\n\nMedia -> (structure)\n\nAn object that describes the input media for the transcription job.\n\nMediaFileUri -> (string)\n\nThe S3 object location of the input media file. The URI must be in the same region as the API endpoint that you are calling. The general form is:\n\nFor example:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nRedactedMediaFileUri -> (string)\n\nThe S3 object location for your redacted output media file. This is only supported for call analytics jobs.\n\nTranscript -> (structure)\n\nAn object that describes the output of the transcription job.\n\nTranscriptFileUri -> (string)\n\nThe S3 object location of the transcript.\n\nUse this URI to access the transcript. If you specified an S3 bucket in the OutputBucketName field when you created the job, this is the URI of that bucket. If you chose to store the transcript in Amazon Transcribe, this is a shareable URL that provides secure access to that location.\n\nRedactedTranscriptFileUri -> (string)\n\nThe S3 object location of the redacted transcript.\n\nUse this URI to access the redacted transcript. If you specified an S3 bucket in the OutputBucketName field when you created the job, this is the URI of that bucket. If you chose to store the transcript in Amazon Transcribe, this is a shareable URL that provides secure access to that location.\n\nStartTime -> (timestamp)\n\nA timestamp that shows when the job started processing.\n\nCreationTime -> (timestamp)\n\nA timestamp that shows when the job was created.\n\nCompletionTime -> (timestamp)\n\nA timestamp that shows when the job completed.\n\nFailureReason -> (string)\n\nIf the TranscriptionJobStatus field is FAILED , this field contains information about why the job failed.\n\nThe FailureReason field can contain one of the following values:\n\nUnsupported media format - The media format specified in the MediaFormat field of the request isn’t valid. See the description of the MediaFormat field for a list of valid values.\n\nThe media format provided does not match the detected media format - The media format of the audio file doesn’t match the format specified in the MediaFormat field in the request. Check the media format of your media file and make sure that the two values match.\n\nInvalid sample rate for audio file - The sample rate specified in the MediaSampleRateHertz of the request isn’t valid. The sample rate must be between 8,000 and 48,000 Hertz.\n\nThe sample rate provided does not match the detected sample rate - The sample rate in the audio file doesn’t match the sample rate specified in the MediaSampleRateHertz field in the request. Check the sample rate of your media file and make sure that the two values match.\n\nInvalid file size: file size too large - The size of your audio file is larger than Amazon Transcribe can process. For more information, see Limits in the Amazon Transcribe Developer Guide .\n\nInvalid number of channels: number of channels too large - Your audio contains more channels than Amazon Transcribe is configured to process. To request additional channels, see Amazon Transcribe Limits in the Amazon Web Services General Reference .\n\nSettings -> (structure)\n\nOptional settings for the transcription job. Use these settings to turn on speaker recognition, to set the maximum number of speakers that should be identified and to specify a custom vocabulary to use when processing the transcription job.\n\nVocabularyName -> (string)\n\nThe name of a vocabulary to use when processing the transcription job.\n\nShowSpeakerLabels -> (boolean)\n\nDetermines whether the transcription job uses speaker recognition to identify different speakers in the input audio. Speaker recognition labels individual speakers in the audio file. If you set the ShowSpeakerLabels field to true, you must also set the maximum number of speaker labels MaxSpeakerLabels field.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException .\n\nMaxSpeakerLabels -> (integer)\n\nThe maximum number of speakers to identify in the input audio. If there are more speakers in the audio than this number, multiple speakers are identified as a single speaker. If you specify the MaxSpeakerLabels field, you must set the ShowSpeakerLabels field to true.\n\nChannelIdentification -> (boolean)\n\nInstructs Amazon Transcribe to process each audio channel separately and then merge the transcription output of each channel into a single transcription.\n\nAmazon Transcribe also produces a transcription of each item detected on an audio channel, including the start time and end time of the item and alternative transcriptions of the item including the confidence that Amazon Transcribe has in the transcription.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException .\n\nShowAlternatives -> (boolean)\n\nDetermines whether the transcription contains alternative transcriptions. If you set the ShowAlternatives field to true, you must also set the maximum number of alternatives to return in the MaxAlternatives field.\n\nMaxAlternatives -> (integer)\n\nThe number of alternative transcriptions that the service should return. If you specify the MaxAlternatives field, you must set the ShowAlternatives field to true.\n\nVocabularyFilterName -> (string)\n\nThe name of the vocabulary filter to use when transcribing the audio. The filter that you specify must have the same language code as the transcription job.\n\nVocabularyFilterMethod -> (string)\n\nSet to mask to remove filtered text from the transcript and replace it with three asterisks (“***”) as placeholder text. Set to remove to remove filtered text from the transcript without using placeholder text. Set to tag to mark the word in the transcription output that matches the vocabulary filter. When you set the filter method to tag , the words matching your vocabulary filter are not masked or removed.\n\nModelSettings -> (structure)\n\nAn object containing the details of your custom language model.\n\nLanguageModelName -> (string)\n\nThe name of your custom language model.\n\nJobExecutionSettings -> (structure)\n\nProvides information about how a transcription job is executed.\n\nAllowDeferredExecution -> (boolean)\n\nIndicates whether a job should be queued by Amazon Transcribe when the concurrent execution limit is exceeded. When the AllowDeferredExecution field is true, jobs are queued and executed when the number of executing jobs falls below the concurrent execution limit. If the field is false, Amazon Transcribe returns a LimitExceededException exception.\n\nNote that job queuing is enabled by default for call analytics jobs.\n\nIf you specify the AllowDeferredExecution field, you must specify the DataAccessRoleArn field.\n\nDataAccessRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of a role that has access to the S3 bucket that contains the input files. Amazon Transcribe assumes this role to read queued media files. If you have specified an output S3 bucket for the transcription results, this role should have access to the output bucket as well.\n\nIf you specify the AllowDeferredExecution field, you must specify the DataAccessRoleArn field.\n\nContentRedaction -> (structure)\n\nAn object that describes content redaction settings for the transcription job.\n\nRedactionType -> (string)\n\nRequest parameter that defines the entities to be redacted. The only accepted value is PII .\n\nRedactionOutput -> (string)\n\nThe output transcript file stored in either the default S3 bucket or in a bucket you specify.\n\nWhen you choose redacted Amazon Transcribe outputs only the redacted transcript.\n\nWhen you choose redacted_and_unredacted Amazon Transcribe outputs both the redacted and unredacted transcripts.\n\nIdentifyLanguage -> (boolean)\n\nA value that shows if automatic language identification was enabled for a transcription job.\n\nLanguageOptions -> (list)\n\nAn object that shows the optional array of languages inputted for transcription jobs with automatic language identification enabled.\n\n(string)\n\nIdentifiedLanguageScore -> (float)\n\nA value between zero and one that Amazon Transcribe assigned to the language that it identified in the source audio. Larger values indicate that Amazon Transcribe has higher confidence in the language it identified.\n\nTags -> (list)\n\nA key:value pair assigned to a given transcription job.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.\n\nSubtitles -> (structure)\n\nGenerate subtitles for your batch transcription job.\n\nFormats -> (list)\n\nSpecify the output format for your subtitle file; if you select both SRT and VTT formats, two output files are genereated.\n\n(string)\n\nSubtitleFileUris -> (list)\n\nChoose the output location for your subtitle file. This location must be an S3 bucket.\n\n(string)",
      "command_examples": "Examples\n\nTo get information about a specific transcription job\n\nThe following get-transcription-job example gets information about a specific transcription job. To access the transcription results, use the TranscriptFileUri parameter. Use the MediaFileUri parameter to see which audio file you transcribed with this job. You can use the Settings object to see the optional features you’ve enabled in the transcription job.\n\naws transcribe get-transcription-job \\\n    --transcription-job-name your-transcription-job\n\n\nOutput:\n\n{\n    \"TranscriptionJob\": {\n        \"TranscriptionJobName\": \"your-transcription-job\",\n        \"TranscriptionJobStatus\": \"COMPLETED\",\n        \"LanguageCode\": \"language-code\",\n        \"MediaSampleRateHertz\": 48000,\n        \"MediaFormat\": \"mp4\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.file-extension\"\n        },\n        \"Transcript\": {\n            \"TranscriptFileUri\": \"https://Amazon-S3-file-location-of-transcription-output\"\n        },\n        \"StartTime\": \"2020-09-18T22:27:23.970000+00:00\",\n        \"CreationTime\": \"2020-09-18T22:27:23.948000+00:00\",\n        \"CompletionTime\": \"2020-09-18T22:28:21.197000+00:00\",\n        \"Settings\": {\n            \"ChannelIdentification\": false,\n            \"ShowAlternatives\": false\n        },\n        \"IdentifyLanguage\": true,\n        \"IdentifiedLanguageScore\": 0.8672199249267578\n    }\n}\n\n\nFor more information, see Getting Started (AWS Command Line Interface) in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "get-vocabulary",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/get-vocabulary.html",
      "command_description": "Description\n\nGets information about a vocabulary.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-vocabulary\n--vocabulary-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-name (string)\n\nThe name of the vocabulary to return information about. The name is case sensitive.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nVocabularyName -> (string)\n\nThe name of the vocabulary to return.\n\nLanguageCode -> (string)\n\nThe language code of the vocabulary entries.\n\nVocabularyState -> (string)\n\nThe processing state of the vocabulary.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the vocabulary was last modified.\n\nFailureReason -> (string)\n\nIf the VocabularyState field is FAILED , this field contains information about why the job failed.\n\nDownloadUri -> (string)\n\nThe S3 location where the vocabulary is stored. Use this URI to get the contents of the vocabulary. The URI is available for a limited time.",
      "command_examples": "Examples\n\nTo get information about a custom vocabulary\n\nThe following get-vocabulary example gets information on a previously created custom vocabulary.\n\naws transcribe get-vocabulary \\\n    --vocabulary-name cli-vocab-1\n\n\nOutput:\n\n{\n    \"VocabularyName\": \"cli-vocab-1\",\n    \"LanguageCode\": \"language-code\",\n    \"VocabularyState\": \"READY\",\n    \"LastModifiedTime\": \"2020-09-19T23:22:32.836000+00:00\",\n    \"DownloadUri\": \"https://link-to-download-the-text-file-used-to-create-your-custom-vocabulary\"\n}\n\n\nFor more information, see Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "get-vocabulary-filter",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/get-vocabulary-filter.html",
      "command_description": "Description\n\nReturns information about a vocabulary filter.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-vocabulary-filter\n--vocabulary-filter-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-filter-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-filter-name (string)\n\nThe name of the vocabulary filter for which to return information.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nVocabularyFilterName -> (string)\n\nThe name of the vocabulary filter.\n\nLanguageCode -> (string)\n\nThe language code of the words in the vocabulary filter.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the contents of the vocabulary filter were updated.\n\nDownloadUri -> (string)\n\nThe URI of the list of words in the vocabulary filter. You can use this URI to get the list of words.",
      "command_examples": "Examples\n\nTo get information about a vocabulary filter\n\nThe following get-vocabulary-filter example gets information about a vocabulary filter. You can use the DownloadUri parameter to get the list of words you used to create the vocabulary filter.\n\naws transcribe get-vocabulary-filter \\\n    --vocabulary-filter-name testFilter\n\n\nOutput:\n\n{\n    \"VocabularyFilterName\": \"testFilter\",\n    \"LanguageCode\": \"language-code\",\n    \"LastModifiedTime\": \"2020-05-07T22:39:32.147000+00:00\",\n    \"DownloadUri\": \"https://Amazon-S3-location-to-download-your-vocabulary-filter\"\n}\n\n\nFor more information, see Filter Unwanted Words in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "list-call-analytics-categories",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/list-call-analytics-categories.html",
      "command_description": "Description\n\nProvides more information about the call analytics categories that you’ve created. You can use the information in this list to find a specific category. You can then use the operation to get more information about it.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-call-analytics-categories\n[--next-token <value>]\n[--max-results <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--next-token <value>]",
        "[--max-results <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--next-token (string)\n\nWhen included, NextToken fetches the next set of categories if the result of the previous request was truncated.\n\n--max-results (integer)\n\nThe maximum number of categories to return in each page of results. If there are fewer results than the value you specify, only the actual results are returned. If you do not specify a value, the default of 5 is used.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNextToken -> (string)\n\nThe operation returns a page of jobs at a time. The maximum size of the list is set by the MaxResults parameter. If there are more categories in the list than the page size, Amazon Transcribe returns the NextPage token. Include the token in the next request to the operation to return the next page of analytics categories.\n\nCategories -> (list)\n\nA list of objects containing information about analytics categories.\n\n(structure)\n\nAn object that contains the rules and additional information about a call analytics category.\n\nCategoryName -> (string)\n\nThe name of the call analytics category.\n\nRules -> (list)\n\nThe rules used to create a call analytics category.\n\n(structure)\n\nA condition in the call between the customer and the agent that you want to filter for.\n\nNonTalkTimeFilter -> (structure)\n\nA condition for a time period when neither the customer nor the agent was talking.\n\nThreshold -> (long)\n\nThe duration of the period when neither the customer nor agent was talking.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when no one is talking. For example, you could specify a time period between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was silence. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period when people were talking.\n\nInterruptionFilter -> (structure)\n\nA condition for a time period when either the customer or agent was interrupting the other person.\n\nThreshold -> (long)\n\nThe duration of the interruption.\n\nParticipantRole -> (string)\n\nIndicates whether the caller or customer was interrupting.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when you’d want to find the interruption. For example, you could search for an interruption between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was a interruption. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period where there was no interruption.\n\nTranscriptFilter -> (structure)\n\nA condition that catches particular words or phrases based on a exact match. For example, if you set the phrase “I want to speak to the manager”, only that exact phrase will be returned.\n\nTranscriptFilterType -> (string)\n\nMatches the phrase to the transcription output in a word for word fashion. For example, if you specify the phrase “I want to speak to the manager.” Amazon Transcribe attempts to match that specific phrase to the transcription.\n\nAbsoluteTimeRange -> (structure)\n\nA time range, set in seconds, between two points in the call.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where you would like to apply a filter. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nDetermines whether the customer or the agent is speaking the phrases that you’ve specified.\n\nNegate -> (boolean)\n\nIf TRUE , the rule that you specify is applied to everything except for the phrases that you specify.\n\nTargets -> (list)\n\nThe phrases that you’re specifying for the transcript filter to match.\n\n(string)\n\nSentimentFilter -> (structure)\n\nA condition that is applied to a particular customer sentiment.\n\nSentiments -> (list)\n\nAn array that enables you to specify sentiments for the customer or agent. You can specify one or more values.\n\n(string)\n\nAbsoluteTimeRange -> (structure)\n\nThe time range, measured in seconds, of the sentiment.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nThe time range, set in percentages, that correspond to proportion of the call.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nA value that determines whether the sentiment belongs to the customer or the agent.\n\nNegate -> (boolean)\n\nSet to TRUE to look for sentiments that weren’t specified in the request.\n\nCreateTime -> (timestamp)\n\nA timestamp that shows when the call analytics category was created.\n\nLastUpdateTime -> (timestamp)\n\nA timestamp that shows when the call analytics category was most recently updated."
    },
    {
      "command_name": "list-call-analytics-jobs",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/list-call-analytics-jobs.html",
      "command_description": "Description\n\nList call analytics jobs with a specified status or substring that matches their names.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-call-analytics-jobs\n[--status <value>]\n[--job-name-contains <value>]\n[--next-token <value>]\n[--max-results <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--status <value>]",
        "[--job-name-contains <value>]",
        "[--next-token <value>]",
        "[--max-results <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--status (string)\n\nWhen specified, returns only call analytics jobs with the specified status. Jobs are ordered by creation date, with the most recent jobs returned first. If you don’t specify a status, Amazon Transcribe returns all analytics jobs ordered by creation date.\n\nPossible values:\n\nQUEUED\n\nIN_PROGRESS\n\nFAILED\n\nCOMPLETED\n\n--job-name-contains (string)\n\nWhen specified, the jobs returned in the list are limited to jobs whose name contains the specified string.\n\n--next-token (string)\n\nIf you receive a truncated result in the previous request of , include NextToken to fetch the next set of jobs.\n\n--max-results (integer)\n\nThe maximum number of call analytics jobs to return in each page of results. If there are fewer results than the value you specify, only the actual results are returned. If you do not specify a value, the default of 5 is used.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nStatus -> (string)\n\nWhen specified, returns only call analytics jobs with that status. Jobs are ordered by creation date, with the most recent jobs returned first. If you don’t specify a status, Amazon Transcribe returns all transcription jobs ordered by creation date.\n\nNextToken -> (string)\n\nThe operation returns a page of jobs at a time. The maximum size of the page is set by the MaxResults parameter. If there are more jobs in the list than the page size, Amazon Transcribe returns the NextPage token. Include the token in your next request to the operation to return next page of jobs.\n\nCallAnalyticsJobSummaries -> (list)\n\nA list of objects containing summary information for a transcription job.\n\n(structure)\n\nProvides summary information about a call analytics job.\n\nCallAnalyticsJobName -> (string)\n\nThe name of the call analytics job.\n\nCreationTime -> (timestamp)\n\nA timestamp that shows when the call analytics job was created.\n\nStartTime -> (timestamp)\n\nA timestamp that shows when the job began processing.\n\nCompletionTime -> (timestamp)\n\nA timestamp that shows when the job was completed.\n\nLanguageCode -> (string)\n\nThe language of the transcript in the source audio file.\n\nCallAnalyticsJobStatus -> (string)\n\nThe status of the call analytics job.\n\nFailureReason -> (string)\n\nIf the CallAnalyticsJobStatus is FAILED , a description of the error."
    },
    {
      "command_name": "list-language-models",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/list-language-models.html",
      "command_description": "Description\n\nProvides more information about the custom language models you’ve created. You can use the information in this list to find a specific custom language model. You can then use the operation to get more information about it.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-language-models\n[--status-equals <value>]\n[--name-contains <value>]\n[--next-token <value>]\n[--max-results <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--status-equals <value>]",
        "[--name-contains <value>]",
        "[--next-token <value>]",
        "[--max-results <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--status-equals (string)\n\nWhen specified, returns only custom language models with the specified status. Language models are ordered by creation date, with the newest models first. If you don’t specify a status, Amazon Transcribe returns all custom language models ordered by date.\n\nPossible values:\n\nIN_PROGRESS\n\nFAILED\n\nCOMPLETED\n\n--name-contains (string)\n\nWhen specified, the custom language model names returned contain the substring you’ve specified.\n\n--next-token (string)\n\nWhen included, fetches the next set of jobs if the result of the previous request was truncated.\n\n--max-results (integer)\n\nThe maximum number of language models to return in each page of results. If there are fewer results than the value you specify, only the actual results are returned. If you do not specify a value, the default of 5 is used.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNextToken -> (string)\n\nThe operation returns a page of jobs at a time. The maximum size of the list is set by the MaxResults parameter. If there are more language models in the list than the page size, Amazon Transcribe returns the NextPage token. Include the token in the next request to the operation to return the next page of language models.\n\nModels -> (list)\n\nA list of objects containing information about custom language models.\n\n(structure)\n\nThe structure used to describe a custom language model.\n\nModelName -> (string)\n\nThe name of the custom language model.\n\nCreateTime -> (timestamp)\n\nThe time the custom language model was created.\n\nLastModifiedTime -> (timestamp)\n\nThe most recent time the custom language model was modified.\n\nLanguageCode -> (string)\n\nThe language code you used to create your custom language model.\n\nBaseModelName -> (string)\n\nThe Amazon Transcribe standard language model, or base model used to create the custom language model.\n\nModelStatus -> (string)\n\nThe creation status of a custom language model. When the status is COMPLETED the model is ready for use.\n\nUpgradeAvailability -> (boolean)\n\nWhether the base model used for the custom language model is up to date. If this field is true then you are running the most up-to-date version of the base model in your custom language model.\n\nFailureReason -> (string)\n\nThe reason why the custom language model couldn’t be created.\n\nInputDataConfig -> (structure)\n\nThe data access role and Amazon S3 prefixes for the input files used to train the custom language model.\n\nS3Uri -> (string)\n\nThe Amazon S3 prefix you specify to access the plain text files that you use to train your custom language model.\n\nTuningDataS3Uri -> (string)\n\nThe Amazon S3 prefix you specify to access the plain text files that you use to tune your custom language model.\n\nDataAccessRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) that uniquely identifies the permissions you’ve given Amazon Transcribe to access your Amazon S3 buckets containing your media files or text data.",
      "command_examples": "Examples\n\nTo list your custom language models\n\nThe following list-language-models example lists the custom language models associated with your AWS account and Region. You can use the S3Uri and TuningDataS3Uri parameters to find the Amazon S3 prefixes you’ve used as your training data, or your tuning data. The BaseModelName tells you whether you’ve used a NarrowBand, or WideBand model to create a custom language model. You can transcribe audio with a sample rate of less than 16 kHz with a custom language model using a NarrowBand base model. You can transcribe audio 16 kHz or greater with a custom language model using a WideBand base model. The ModelStatus parameter shows whether you can use the custom language model in a transcription job. If the value is COMPLETED, you can use it in a transcription job.\n\naws transcribe list-language-models\n\n\nOutput:\n\n{\n    \"Models\": [\n        {\n            \"ModelName\": \"cli-clm-2\",\n            \"CreateTime\": \"2020-09-25T17:57:38.504000+00:00\",\n            \"LastModifiedTime\": \"2020-09-25T17:57:48.585000+00:00\",\n            \"LanguageCode\": \"language-code\",\n            \"BaseModelName\": \"WideBand\",\n            \"ModelStatus\": \"IN_PROGRESS\",\n            \"UpgradeAvailability\": false,\n            \"InputDataConfig\": {\n                \"S3Uri\": \"s3://DOC-EXAMPLE-BUCKET/clm-training-data/\",\n                \"TuningDataS3Uri\": \"s3://DOC-EXAMPLE-BUCKET/clm-tuning-data/\",\n                \"DataAccessRoleArn\": \"arn:aws:iam::AWS-account-number:role/IAM-role-used-to-create-the-custom-language-model\"\n            }\n        },\n        {\n            \"ModelName\": \"cli-clm-1\",\n            \"CreateTime\": \"2020-09-25T17:16:01.835000+00:00\",\n            \"LastModifiedTime\": \"2020-09-25T17:16:15.555000+00:00\",\n            \"LanguageCode\": \"language-code\",\n            \"BaseModelName\": \"WideBand\",\n            \"ModelStatus\": \"IN_PROGRESS\",\n            \"UpgradeAvailability\": false,\n            \"InputDataConfig\": {\n                \"S3Uri\": \"s3://DOC-EXAMPLE-BUCKET/clm-training-data/\",\n                \"DataAccessRoleArn\": \"arn:aws:iam::AWS-account-number:role/IAM-role-used-to-create-the-custom-language-model\"\n            }\n        },\n        {\n            \"ModelName\": \"clm-console-1\",\n            \"CreateTime\": \"2020-09-24T19:26:28.076000+00:00\",\n            \"LastModifiedTime\": \"2020-09-25T04:25:22.271000+00:00\",\n            \"LanguageCode\": \"language-code\",\n            \"BaseModelName\": \"NarrowBand\",\n            \"ModelStatus\": \"COMPLETED\",\n            \"UpgradeAvailability\": false,\n            \"InputDataConfig\": {\n                \"S3Uri\": \"s3://DOC-EXAMPLE-BUCKET/clm-training-data/\",\n                \"DataAccessRoleArn\": \"arn:aws:iam::AWS-account-number:role/IAM-role-used-to-create-the-custom-language-model\"\n            }\n        }\n    ]\n}\n\n\nFor more information, see Improving Domain-Specific Transcription Accuracy with Custom Language Models in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "list-medical-transcription-jobs",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/list-medical-transcription-jobs.html",
      "command_description": "Description\n\nLists medical transcription jobs with a specified status or substring that matches their names.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-medical-transcription-jobs\n[--status <value>]\n[--job-name-contains <value>]\n[--next-token <value>]\n[--max-results <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--status <value>]",
        "[--job-name-contains <value>]",
        "[--next-token <value>]",
        "[--max-results <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--status (string)\n\nWhen specified, returns only medical transcription jobs with the specified status. Jobs are ordered by creation date, with the newest jobs returned first. If you don’t specify a status, Amazon Transcribe Medical returns all transcription jobs ordered by creation date.\n\nPossible values:\n\nQUEUED\n\nIN_PROGRESS\n\nFAILED\n\nCOMPLETED\n\n--job-name-contains (string)\n\nWhen specified, the jobs returned in the list are limited to jobs whose name contains the specified string.\n\n--next-token (string)\n\nIf you a receive a truncated result in the previous request of ListMedicalTranscriptionJobs , include NextToken to fetch the next set of jobs.\n\n--max-results (integer)\n\nThe maximum number of medical transcription jobs to return in each page of results. If there are fewer results than the value you specify, only the actual results are returned. If you do not specify a value, the default of 5 is used.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nStatus -> (string)\n\nThe requested status of the medical transcription jobs returned.\n\nNextToken -> (string)\n\nThe ListMedicalTranscriptionJobs operation returns a page of jobs at a time. The maximum size of the page is set by the MaxResults parameter. If the number of jobs exceeds what can fit on a page, Amazon Transcribe Medical returns the NextPage token. Include the token in the next request to the ListMedicalTranscriptionJobs operation to return in the next page of jobs.\n\nMedicalTranscriptionJobSummaries -> (list)\n\nA list of objects containing summary information for a transcription job.\n\n(structure)\n\nProvides summary information about a transcription job.\n\nMedicalTranscriptionJobName -> (string)\n\nThe name of a medical transcription job.\n\nCreationTime -> (timestamp)\n\nA timestamp that shows when the medical transcription job was created.\n\nStartTime -> (timestamp)\n\nA timestamp that shows when the job began processing.\n\nCompletionTime -> (timestamp)\n\nA timestamp that shows when the job was completed.\n\nLanguageCode -> (string)\n\nThe language of the transcript in the source audio file.\n\nTranscriptionJobStatus -> (string)\n\nThe status of the medical transcription job.\n\nFailureReason -> (string)\n\nIf the TranscriptionJobStatus field is FAILED , a description of the error.\n\nOutputLocationType -> (string)\n\nIndicates the location of the transcription job’s output. This field must be the path of an S3 bucket; if you don’t already have an S3 bucket, one is created based on the path you add.\n\nSpecialty -> (string)\n\nThe medical specialty of the transcription job. Refer to Transcribing a medical conversation for a list of supported specialties.\n\nContentIdentificationType -> (string)\n\nShows the type of information you’ve configured Amazon Transcribe Medical to identify in a transcription job. If the value is PHI , you’ve configured the transcription job to identify personal health information (PHI).\n\nType -> (string)\n\nThe speech of the clinician in the input audio.",
      "command_examples": "Examples\n\nTo list your medical transcription jobs\n\nThe following list-medical-transcription-jobs example lists the medical transcription jobs associated with your AWS account and Region. To get more information about a particular transcription job, copy the value of a MedicalTranscriptionJobName parameter in the transcription output, and specify that value for the MedicalTranscriptionJobName option of the get-medical-transcription-job command. To see more of your transcription jobs, copy the value of the NextToken parameter, run the list-medical-transcription-jobs command again, and specify that value in the --next-token option.\n\naws transcribe list-medical-transcription-jobs\n\n\nOutput:\n\n{\n    \"NextToken\": \"3/PblzkiGhzjER3KHuQt2fmbPLF7cDYafjFMEoGn44ON/gsuUSTIkGyanvRE6WMXFd/ZTEc2EZj+P9eii/z1O2FDYli6RLI0WoRX4RwMisVrh9G0Kie0Y8ikBCdtqlZB10Wa9McC+ebOl+LaDtZPC4u6ttoHLRlEfzqstHXSgapXg3tEBtm9piIaPB6MOM5BB6t86+qtmocTR/qrteHZBBudhTfbCwhsxaqujHiiUvFdm3BQbKKWIW06yV9b+4f38oD2lVIan+vfUs3gBYAl5VTDmXXzQPBQOHPjtwmFI+IWX15nSUjWuN3TUylHgPWzDaYT8qBtu0Z+3UG4V6b+K2CC0XszXg5rBq9hYgNzy4XoFh/6s5DoSnzq49Q9xHgHdT2yBADFmvFK7myZBsj75+2vQZOSVpWUPy3WT/32zFAcoELHR4unuWhXPwjbKU+mFYfUjtTZ8n/jq7aQEjQ42A+X/7K6JgOcdVPtEg8PlDr5kgYYG3q3OmYXX37U3FZuJmnTI63VtIXsNnOU5eGoYObtpk00Nq9UkzgSJxqj84ZD5n+S0EGy9ZUYBJRRcGeYUM3Q4DbSJfUwSAqcFdLIWZdp8qIREMQIBWy7BLwSdyqsQo2vRrd53hm5aWM7SVf6pPq6X/IXR5+1eUOOD8/coaTT4ES2DerbV6RkV4o0VT1d0SdVX/MmtkNG8nYj8PqU07w7988quh1ZP6D80veJS1q73tUUR9MjnGernW2tAnvnLNhdefBcD+sZVfYq3iBMFY7wTy1P1G6NqW9GrYDYoX3tTPWlD7phpbVSyKrh/PdYrps5UxnsGoA1b7L/FfAXDfUoGrGUB4N3JsPYXX9D++g+6gV1qBBs/WfF934aKqfD6UTggm/zV3GAOWiBpfvAZRvEb924i6yGHyMC7y54O1ZAwSBupmI+FFd13CaPO4kN1vJlth6aM5vUPXg4BpyUhtbRhwD/KxCvf9K0tLJGyL1A==\",\n    \"MedicalTranscriptionJobSummaries\": [\n        {\n            \"MedicalTranscriptionJobName\": \"vocabulary-dictation-medical-transcription-job\",\n            \"CreationTime\": \"2020-09-21T21:17:27.016000+00:00\",\n            \"StartTime\": \"2020-09-21T21:17:27.045000+00:00\",\n            \"CompletionTime\": \"2020-09-21T21:17:59.561000+00:00\",\n            \"LanguageCode\": \"en-US\",\n            \"TranscriptionJobStatus\": \"COMPLETED\",\n            \"OutputLocationType\": \"CUSTOMER_BUCKET\",\n            \"Specialty\": \"PRIMARYCARE\",\n            \"Type\": \"DICTATION\"\n        },\n        {\n            \"MedicalTranscriptionJobName\": \"alternatives-dictation-medical-transcription-job\",\n            \"CreationTime\": \"2020-09-21T21:01:14.569000+00:00\",\n            \"StartTime\": \"2020-09-21T21:01:14.592000+00:00\",\n            \"CompletionTime\": \"2020-09-21T21:01:43.606000+00:00\",\n            \"LanguageCode\": \"en-US\",\n            \"TranscriptionJobStatus\": \"COMPLETED\",\n            \"OutputLocationType\": \"CUSTOMER_BUCKET\",\n            \"Specialty\": \"PRIMARYCARE\",\n            \"Type\": \"DICTATION\"\n        },\n        {\n            \"MedicalTranscriptionJobName\": \"alternatives-conversation-medical-transcription-job\",\n            \"CreationTime\": \"2020-09-21T19:09:18.171000+00:00\",\n            \"StartTime\": \"2020-09-21T19:09:18.199000+00:00\",\n            \"CompletionTime\": \"2020-09-21T19:10:22.516000+00:00\",\n            \"LanguageCode\": \"en-US\",\n            \"TranscriptionJobStatus\": \"COMPLETED\",\n            \"OutputLocationType\": \"CUSTOMER_BUCKET\",\n            \"Specialty\": \"PRIMARYCARE\",\n            \"Type\": \"CONVERSATION\"\n        },\n        {\n            \"MedicalTranscriptionJobName\": \"speaker-id-conversation-medical-transcription-job\",\n            \"CreationTime\": \"2020-09-21T18:43:37.157000+00:00\",\n            \"StartTime\": \"2020-09-21T18:43:37.265000+00:00\",\n            \"CompletionTime\": \"2020-09-21T18:44:21.192000+00:00\",\n            \"LanguageCode\": \"en-US\",\n            \"TranscriptionJobStatus\": \"COMPLETED\",\n            \"OutputLocationType\": \"CUSTOMER_BUCKET\",\n            \"Specialty\": \"PRIMARYCARE\",\n            \"Type\": \"CONVERSATION\"\n        },\n        {\n            \"MedicalTranscriptionJobName\": \"multichannel-conversation-medical-transcription-job\",\n            \"CreationTime\": \"2020-09-20T23:46:44.053000+00:00\",\n            \"StartTime\": \"2020-09-20T23:46:44.081000+00:00\",\n            \"CompletionTime\": \"2020-09-20T23:47:35.851000+00:00\",\n            \"LanguageCode\": \"en-US\",\n            \"TranscriptionJobStatus\": \"COMPLETED\",\n            \"OutputLocationType\": \"CUSTOMER_BUCKET\",\n            \"Specialty\": \"PRIMARYCARE\",\n            \"Type\": \"CONVERSATION\"\n        }\n    ]\n}\n\n\nFor more information, see `https://docs.aws.amazon.com/transcribe/latest/dg/batch-med-transcription.html>`__ in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "list-medical-vocabularies",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/list-medical-vocabularies.html",
      "command_description": "Description\n\nReturns a list of vocabularies that match the specified criteria. If you don’t enter a value in any of the request parameters, returns the entire list of vocabularies.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-medical-vocabularies\n[--next-token <value>]\n[--max-results <value>]\n[--state-equals <value>]\n[--name-contains <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--next-token <value>]",
        "[--max-results <value>]",
        "[--state-equals <value>]",
        "[--name-contains <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--next-token (string)\n\nIf the result of your previous request to ListMedicalVocabularies was truncated, include the NextToken to fetch the next set of vocabularies.\n\n--max-results (integer)\n\nThe maximum number of vocabularies to return in each page of results. If there are fewer results than the value you specify, only the actual results are returned. If you do not specify a value, the default of 5 is used.\n\n--state-equals (string)\n\nWhen specified, returns only vocabularies with the VocabularyState equal to the specified vocabulary state. Use this field to see which vocabularies are ready for your medical transcription jobs.\n\nPossible values:\n\nPENDING\n\nREADY\n\nFAILED\n\n--name-contains (string)\n\nReturns vocabularies whose names contain the specified string. The search is not case sensitive. ListMedicalVocabularies returns both “vocabularyname ” and “VocabularyName “.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nStatus -> (string)\n\nThe requested vocabulary state.\n\nNextToken -> (string)\n\nThe ListMedicalVocabularies operation returns a page of vocabularies at a time. You set the maximum number of vocabularies to return on a page with the MaxResults parameter. If there are more jobs in the list will fit on a page, Amazon Transcribe Medical returns the NextPage token. To return the next page of vocabularies, include the token in the next request to the ListMedicalVocabularies operation .\n\nVocabularies -> (list)\n\nA list of objects that describe the vocabularies that match your search criteria.\n\n(structure)\n\nProvides information about a custom vocabulary.\n\nVocabularyName -> (string)\n\nThe name of the vocabulary.\n\nLanguageCode -> (string)\n\nThe language code of the vocabulary entries.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the vocabulary was last modified.\n\nVocabularyState -> (string)\n\nThe processing state of the vocabulary. If the state is READY you can use the vocabulary in a StartTranscriptionJob request.",
      "command_examples": "Examples\n\nTo list your medical custom vocabularies\n\nThe following list-medical-vocabularies example lists the medical custom vocabularies associated with your AWS account and Region. To get more information about a particular transcription job, copy the value of a MedicalTranscriptionJobName parameter in the transcription output, and specify that value for the MedicalTranscriptionJobName option of the get-medical-transcription-job command. To see more of your transcription jobs, copy the value of the NextToken parameter, run the list-medical-transcription-jobs command again, and specify that value in the --next-token option.\n\naws transcribe list-medical-vocabularies\n\n\nOutput:\n\n{\n    \"Vocabularies\": [\n        {\n            \"VocabularyName\": \"cli-medical-vocab-2\",\n            \"LanguageCode\": \"en-US\",\n            \"LastModifiedTime\": \"2020-09-21T21:44:59.521000+00:00\",\n            \"VocabularyState\": \"READY\"\n        },\n        {\n            \"VocabularyName\": \"cli-medical-vocab-1\",\n            \"LanguageCode\": \"en-US\",\n            \"LastModifiedTime\": \"2020-09-19T23:59:04.349000+00:00\",\n            \"VocabularyState\": \"READY\"\n        }\n    ]\n}\n\n\nFor more information, see Medical Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "list-tags-for-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/list-tags-for-resource.html",
      "command_description": "Description\n\nLists all tags associated with a given transcription job, vocabulary, or resource.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-tags-for-resource\n--resource-arn <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nLists all tags associated with a given Amazon Resource Name (ARN).\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nResourceArn -> (string)\n\nLists all tags associated with the given Amazon Resource Name (ARN).\n\nTags -> (list)\n\nLists all tags associated with the given transcription job, vocabulary, or resource.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’."
    },
    {
      "command_name": "list-transcription-jobs",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/list-transcription-jobs.html",
      "command_description": "Description\n\nLists transcription jobs with the specified status.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-transcription-jobs\n[--status <value>]\n[--job-name-contains <value>]\n[--next-token <value>]\n[--max-results <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--status <value>]",
        "[--job-name-contains <value>]",
        "[--next-token <value>]",
        "[--max-results <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--status (string)\n\nWhen specified, returns only transcription jobs with the specified status. Jobs are ordered by creation date, with the newest jobs returned first. If you don’t specify a status, Amazon Transcribe returns all transcription jobs ordered by creation date.\n\nPossible values:\n\nQUEUED\n\nIN_PROGRESS\n\nFAILED\n\nCOMPLETED\n\n--job-name-contains (string)\n\nWhen specified, the jobs returned in the list are limited to jobs whose name contains the specified string.\n\n--next-token (string)\n\nIf the result of the previous request to ListTranscriptionJobs is truncated, include the NextToken to fetch the next set of jobs.\n\n--max-results (integer)\n\nThe maximum number of jobs to return in each page of results. If there are fewer results than the value you specify, only the actual results are returned. If you do not specify a value, the default of 5 is used.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nStatus -> (string)\n\nThe requested status of the jobs returned.\n\nNextToken -> (string)\n\nThe ListTranscriptionJobs operation returns a page of jobs at a time. The maximum size of the page is set by the MaxResults parameter. If there are more jobs in the list than the page size, Amazon Transcribe returns the NextPage token. Include the token in the next request to the ListTranscriptionJobs operation to return in the next page of jobs.\n\nTranscriptionJobSummaries -> (list)\n\nA list of objects containing summary information for a transcription job.\n\n(structure)\n\nProvides a summary of information about a transcription job.\n\nTranscriptionJobName -> (string)\n\nThe name of the transcription job.\n\nCreationTime -> (timestamp)\n\nA timestamp that shows when the job was created.\n\nStartTime -> (timestamp)\n\nA timestamp that shows when the job started processing.\n\nCompletionTime -> (timestamp)\n\nA timestamp that shows when the job was completed.\n\nLanguageCode -> (string)\n\nThe language code for the input speech.\n\nTranscriptionJobStatus -> (string)\n\nThe status of the transcription job. When the status is COMPLETED , use the GetTranscriptionJob operation to get the results of the transcription.\n\nFailureReason -> (string)\n\nIf the TranscriptionJobStatus field is FAILED , a description of the error.\n\nOutputLocationType -> (string)\n\nIndicates the location of the output of the transcription job.\n\nIf the value is CUSTOMER_BUCKET then the location is the S3 bucket specified in the outputBucketName field when the transcription job was started with the StartTranscriptionJob operation.\n\nIf the value is SERVICE_BUCKET then the output is stored by Amazon Transcribe and can be retrieved using the URI in the GetTranscriptionJob response’s TranscriptFileUri field.\n\nContentRedaction -> (structure)\n\nThe content redaction settings of the transcription job.\n\nRedactionType -> (string)\n\nRequest parameter that defines the entities to be redacted. The only accepted value is PII .\n\nRedactionOutput -> (string)\n\nThe output transcript file stored in either the default S3 bucket or in a bucket you specify.\n\nWhen you choose redacted Amazon Transcribe outputs only the redacted transcript.\n\nWhen you choose redacted_and_unredacted Amazon Transcribe outputs both the redacted and unredacted transcripts.\n\nModelSettings -> (structure)\n\nThe object used to call your custom language model to your transcription job.\n\nLanguageModelName -> (string)\n\nThe name of your custom language model.\n\nIdentifyLanguage -> (boolean)\n\nWhether automatic language identification was enabled for a transcription job.\n\nIdentifiedLanguageScore -> (float)\n\nA value between zero and one that Amazon Transcribe assigned to the language it identified in the source audio. A higher score indicates that Amazon Transcribe is more confident in the language it identified.",
      "command_examples": "Examples\n\nTo list your transcription jobs\n\nThe following list-transcription-jobs example lists the transcription jobs associated with your AWS account and Region.\n\naws transcribe list-transcription-jobs\n\n\nOutput:\n\n{\n    \"NextToken\": \"NextToken\",\n    \"TranscriptionJobSummaries\": [\n        {\n            \"TranscriptionJobName\": \"speak-id-job-1\",\n            \"CreationTime\": \"2020-08-17T21:06:15.391000+00:00\",\n            \"StartTime\": \"2020-08-17T21:06:15.416000+00:00\",\n            \"CompletionTime\": \"2020-08-17T21:07:05.098000+00:00\",\n            \"LanguageCode\": \"language-code\",\n            \"TranscriptionJobStatus\": \"COMPLETED\",\n            \"OutputLocationType\": \"SERVICE_BUCKET\"\n        },\n        {\n            \"TranscriptionJobName\": \"job-1\",\n            \"CreationTime\": \"2020-08-17T20:50:24.207000+00:00\",\n            \"StartTime\": \"2020-08-17T20:50:24.230000+00:00\",\n            \"CompletionTime\": \"2020-08-17T20:52:18.737000+00:00\",\n            \"LanguageCode\": \"language-code\",\n            \"TranscriptionJobStatus\": \"COMPLETED\",\n            \"OutputLocationType\": \"SERVICE_BUCKET\"\n        },\n        {\n            \"TranscriptionJobName\": \"sdk-test-job-4\",\n            \"CreationTime\": \"2020-08-17T20:32:27.917000+00:00\",\n            \"StartTime\": \"2020-08-17T20:32:27.956000+00:00\",\n            \"CompletionTime\": \"2020-08-17T20:33:15.126000+00:00\",\n            \"LanguageCode\": \"language-code\",\n            \"TranscriptionJobStatus\": \"COMPLETED\",\n            \"OutputLocationType\": \"SERVICE_BUCKET\"\n        },\n        {\n            \"TranscriptionJobName\": \"Diarization-speak-id\",\n            \"CreationTime\": \"2020-08-10T22:10:09.066000+00:00\",\n            \"StartTime\": \"2020-08-10T22:10:09.116000+00:00\",\n            \"CompletionTime\": \"2020-08-10T22:26:48.172000+00:00\",\n            \"LanguageCode\": \"language-code\",\n            \"TranscriptionJobStatus\": \"COMPLETED\",\n            \"OutputLocationType\": \"SERVICE_BUCKET\"\n        },\n        {\n            \"TranscriptionJobName\": \"your-transcription-job-name\",\n            \"CreationTime\": \"2020-07-29T17:45:09.791000+00:00\",\n            \"StartTime\": \"2020-07-29T17:45:09.826000+00:00\",\n            \"CompletionTime\": \"2020-07-29T17:46:20.831000+00:00\",\n            \"LanguageCode\": \"language-code\",\n            \"TranscriptionJobStatus\": \"COMPLETED\",\n            \"OutputLocationType\": \"SERVICE_BUCKET\"\n        }\n    ]\n}\n\n\nFor more information, see Getting Started (AWS Command Line Interface) in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "list-vocabularies",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/list-vocabularies.html",
      "command_description": "Description\n\nReturns a list of vocabularies that match the specified criteria. If no criteria are specified, returns the entire list of vocabularies.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-vocabularies\n[--next-token <value>]\n[--max-results <value>]\n[--state-equals <value>]\n[--name-contains <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--next-token <value>]",
        "[--max-results <value>]",
        "[--state-equals <value>]",
        "[--name-contains <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--next-token (string)\n\nIf the result of the previous request to ListVocabularies was truncated, include the NextToken to fetch the next set of jobs.\n\n--max-results (integer)\n\nThe maximum number of vocabularies to return in each page of results. If there are fewer results than the value you specify, only the actual results are returned. If you do not specify a value, the default of 5 is used.\n\n--state-equals (string)\n\nWhen specified, only returns vocabularies with the VocabularyState field equal to the specified state.\n\nPossible values:\n\nPENDING\n\nREADY\n\nFAILED\n\n--name-contains (string)\n\nWhen specified, the vocabularies returned in the list are limited to vocabularies whose name contains the specified string. The search is not case sensitive, ListVocabularies returns both “vocabularyname” and “VocabularyName” in the response list.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nStatus -> (string)\n\nThe requested vocabulary state.\n\nNextToken -> (string)\n\nThe ListVocabularies operation returns a page of vocabularies at a time. The maximum size of the page is set in the MaxResults parameter. If there are more jobs in the list than will fit on the page, Amazon Transcribe returns the NextPage token. To return in the next page of jobs, include the token in the next request to the ListVocabularies operation.\n\nVocabularies -> (list)\n\nA list of objects that describe the vocabularies that match the search criteria in the request.\n\n(structure)\n\nProvides information about a custom vocabulary.\n\nVocabularyName -> (string)\n\nThe name of the vocabulary.\n\nLanguageCode -> (string)\n\nThe language code of the vocabulary entries.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the vocabulary was last modified.\n\nVocabularyState -> (string)\n\nThe processing state of the vocabulary. If the state is READY you can use the vocabulary in a StartTranscriptionJob request.",
      "command_examples": "Examples\n\nTo list your custom vocabularies\n\nThe following list-vocabularies example lists the custom vocabularies associated with your AWS account and Region.\n\naws transcribe list-vocabularies\n\n\nOutput:\n\n{\n    \"NextToken\": \"NextToken\",\n    \"Vocabularies\": [\n        {\n            \"VocabularyName\": \"ards-test-1\",\n            \"LanguageCode\": \"language-code\",\n            \"LastModifiedTime\": \"2020-04-27T22:00:27.330000+00:00\",\n            \"VocabularyState\": \"READY\"\n        },\n        {\n            \"VocabularyName\": \"sample-test\",\n            \"LanguageCode\": \"language-code\",\n            \"LastModifiedTime\": \"2020-04-24T23:04:11.044000+00:00\",\n            \"VocabularyState\": \"READY\"\n        },\n        {\n            \"VocabularyName\": \"CRLF-to-LF-test-3-1\",\n            \"LanguageCode\": \"language-code\",\n            \"LastModifiedTime\": \"2020-04-24T22:12:22.277000+00:00\",\n            \"VocabularyState\": \"READY\"\n        },\n        {\n            \"VocabularyName\": \"CRLF-to-LF-test-2\",\n            \"LanguageCode\": \"language-code\",\n            \"LastModifiedTime\": \"2020-04-24T21:53:50.455000+00:00\",\n            \"VocabularyState\": \"READY\"\n        },\n        {\n            \"VocabularyName\": \"CRLF-to-LF-1-1\",\n            \"LanguageCode\": \"language-code\",\n            \"LastModifiedTime\": \"2020-04-24T21:39:33.356000+00:00\",\n            \"VocabularyState\": \"READY\"\n        }\n    ]\n}\n\n\nFor more information, see Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "list-vocabulary-filters",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/list-vocabulary-filters.html",
      "command_description": "Description\n\nGets information about vocabulary filters.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-vocabulary-filters\n[--next-token <value>]\n[--max-results <value>]\n[--name-contains <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--next-token <value>]",
        "[--max-results <value>]",
        "[--name-contains <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--next-token (string)\n\nIf the result of the previous request to ListVocabularyFilters was truncated, include the NextToken to fetch the next set of collections.\n\n--max-results (integer)\n\nThe maximum number of filters to return in each page of results. If there are fewer results than the value you specify, only the actual results are returned. If you do not specify a value, the default of 5 is used.\n\n--name-contains (string)\n\nFilters the response so that it only contains vocabulary filters whose name contains the specified string.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNextToken -> (string)\n\nThe ListVocabularyFilters operation returns a page of collections at a time. The maximum size of the page is set by the MaxResults parameter. If there are more jobs in the list than the page size, Amazon Transcribe returns the NextPage token. Include the token in the next request to the ListVocabularyFilters operation to return in the next page of jobs.\n\nVocabularyFilters -> (list)\n\nThe list of vocabulary filters. It contains at most MaxResults number of filters. If there are more filters, call the ListVocabularyFilters operation again with the NextToken parameter in the request set to the value of the NextToken field in the response.\n\n(structure)\n\nProvides information about a vocabulary filter.\n\nVocabularyFilterName -> (string)\n\nThe name of the vocabulary filter. The name must be unique in the account that holds the filter.\n\nLanguageCode -> (string)\n\nThe language code of the words in the vocabulary filter.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the vocabulary was last updated.",
      "command_examples": "Examples\n\nTo list your vocabulary filters\n\nThe following list-vocabulary-filters example lists the vocabulary filters associated with your AWS account and Region.\n\naws transcribe list-vocabulary-filters\n\n\nOutput:\n\n{\n    \"NextToken\": \"NextToken\": [\n        {\n            \"VocabularyFilterName\": \"testFilter\",\n            \"LanguageCode\": \"language-code\",\n            \"LastModifiedTime\": \"2020-05-07T22:39:32.147000+00:00\"\n        },\n        {\n            \"VocabularyFilterName\": \"testFilter2\",\n            \"LanguageCode\": \"language-code\",\n            \"LastModifiedTime\": \"2020-05-21T23:29:35.174000+00:00\"\n        },\n        {\n            \"VocabularyFilterName\": \"filter2\",\n            \"LanguageCode\": \"language-code\",\n            \"LastModifiedTime\": \"2020-05-08T20:18:26.426000+00:00\"\n        },\n        {\n            \"VocabularyFilterName\": \"filter-review\",\n            \"LanguageCode\": \"language-code\",\n            \"LastModifiedTime\": \"2020-06-03T18:52:30.448000+00:00\"\n        },\n        {\n            \"VocabularyFilterName\": \"crlf-filt\",\n            \"LanguageCode\": \"language-code\",\n            \"LastModifiedTime\": \"2020-05-22T19:42:42.737000+00:00\"\n        }\n    ]\n}\n\n\nFor more information, see Filtering Unwanted Words in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "start-call-analytics-job",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/start-call-analytics-job.html",
      "command_description": "Description\n\nStarts an asynchronous analytics job that not only transcribes the audio recording of a caller and agent, but also returns additional insights. These insights include how quickly or loudly the caller or agent was speaking. To retrieve additional insights with your analytics jobs, create categories. A category is a way to classify analytics jobs based on attributes, such as a customer’s sentiment or a particular phrase being used during the call. For more information, see the operation.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-call-analytics-job\n--call-analytics-job-name <value>\n--media <value>\n[--output-location <value>]\n[--output-encryption-kms-key-id <value>]\n--data-access-role-arn <value>\n[--settings <value>]\n[--channel-definitions <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--call-analytics-job-name <value>",
        "--media <value>",
        "[--output-location <value>]",
        "[--output-encryption-kms-key-id <value>]",
        "--data-access-role-arn <value>",
        "[--settings <value>]",
        "[--channel-definitions <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--call-analytics-job-name (string)\n\nThe name of the call analytics job. You can’t use the string “.” or “..” by themselves as the job name. The name must also be unique within an Amazon Web Services account. If you try to create a call analytics job with the same name as a previous call analytics job, you get a ConflictException error.\n\n--media (structure)\n\nDescribes the input media file in a transcription request.\n\nMediaFileUri -> (string)\n\nThe S3 object location of the input media file. The URI must be in the same region as the API endpoint that you are calling. The general form is:\n\nFor example:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nRedactedMediaFileUri -> (string)\n\nThe S3 object location for your redacted output media file. This is only supported for call analytics jobs.\n\nShorthand Syntax:\n\nMediaFileUri=string,RedactedMediaFileUri=string\n\n\nJSON Syntax:\n\n{\n  \"MediaFileUri\": \"string\",\n  \"RedactedMediaFileUri\": \"string\"\n}\n\n\n--output-location (string)\n\nThe Amazon S3 location where the output of the call analytics job is stored. You can provide the following location types to store the output of call analytics job:\n\ns3://DOC-EXAMPLE-BUCKET1 If you specify a bucket, Amazon Transcribe saves the output of the analytics job as a JSON file at the root level of the bucket.\n\ns3://DOC-EXAMPLE-BUCKET1/folder/ f you specify a path, Amazon Transcribe saves the output of the analytics job as s3://DOC-EXAMPLE-BUCKET1/folder/your-transcription-job-name.json If you specify a folder, you must provide a trailing slash.\n\ns3://DOC-EXAMPLE-BUCKET1/folder/filename.json If you provide a path that has the filename specified, Amazon Transcribe saves the output of the analytics job as s3://DOC-EXAMPLEBUCKET1/folder/filename.json\n\nYou can specify an Amazon Web Services Key Management Service (KMS) key to encrypt the output of our analytics job using the OutputEncryptionKMSKeyId parameter. If you don’t specify a KMS key, Amazon Transcribe uses the default Amazon S3 key for server-side encryption of the analytics job output that is placed in your S3 bucket.\n\n--output-encryption-kms-key-id (string)\n\nThe Amazon Resource Name (ARN) of the Amazon Web Services Key Management Service key used to encrypt the output of the call analytics job. The user calling the operation must have permission to use the specified KMS key.\n\nYou use either of the following to identify an Amazon Web Services KMS key in the current account:\n\nKMS Key ID: “1234abcd-12ab-34cd-56ef-1234567890ab”\n\nKMS Key Alias: “alias/ExampleAlias”\n\nYou can use either of the following to identify a KMS key in the current account or another account:\n\nAmazon Resource Name (ARN) of a KMS key in the current account or another account: “arn:aws:kms:region:account ID:key/1234abcd-12ab-34cd-56ef1234567890ab”\n\nARN of a KMS Key Alias: “arn:aws:kms:region:account ID:alias/ExampleAlias”\n\nIf you don’t specify an encryption key, the output of the call analytics job is encrypted with the default Amazon S3 key (SSE-S3).\n\nIf you specify a KMS key to encrypt your output, you must also specify an output location in the OutputLocation parameter.\n\n--data-access-role-arn (string)\n\nThe Amazon Resource Name (ARN) of a role that has access to the S3 bucket that contains your input files. Amazon Transcribe assumes this role to read queued audio files. If you have specified an output S3 bucket for your transcription results, this role should have access to the output bucket as well.\n\n--settings (structure)\n\nA Settings object that provides optional settings for a call analytics job.\n\nVocabularyName -> (string)\n\nThe name of a vocabulary to use when processing the call analytics job.\n\nVocabularyFilterName -> (string)\n\nThe name of the vocabulary filter to use when running a call analytics job. The filter that you specify must have the same language code as the analytics job.\n\nVocabularyFilterMethod -> (string)\n\nSet to mask to remove filtered text from the transcript and replace it with three asterisks (“***”) as placeholder text. Set to remove to remove filtered text from the transcript without using placeholder text. Set to tag to mark the word in the transcription output that matches the vocabulary filter. When you set the filter method to tag , the words matching your vocabulary filter are not masked or removed.\n\nLanguageModelName -> (string)\n\nThe structure used to describe a custom language model.\n\nContentRedaction -> (structure)\n\nSettings for content redaction within a transcription job.\n\nRedactionType -> (string)\n\nRequest parameter that defines the entities to be redacted. The only accepted value is PII .\n\nRedactionOutput -> (string)\n\nThe output transcript file stored in either the default S3 bucket or in a bucket you specify.\n\nWhen you choose redacted Amazon Transcribe outputs only the redacted transcript.\n\nWhen you choose redacted_and_unredacted Amazon Transcribe outputs both the redacted and unredacted transcripts.\n\nLanguageOptions -> (list)\n\nWhen you run a call analytics job, you can specify the language spoken in the audio, or you can have Amazon Transcribe identify the language for you.\n\nTo specify a language, specify an array with one language code. If you don’t know the language, you can leave this field blank and Amazon Transcribe will use machine learning to identify the language for you. To improve the ability of Amazon Transcribe to correctly identify the language, you can provide an array of the languages that can be present in the audio. Refer to Supported languages and language-specific features for additional information.\n\n(string)\n\nShorthand Syntax:\n\nVocabularyName=string,VocabularyFilterName=string,VocabularyFilterMethod=string,LanguageModelName=string,ContentRedaction={RedactionType=string,RedactionOutput=string},LanguageOptions=string,string\n\n\nJSON Syntax:\n\n{\n  \"VocabularyName\": \"string\",\n  \"VocabularyFilterName\": \"string\",\n  \"VocabularyFilterMethod\": \"remove\"|\"mask\"|\"tag\",\n  \"LanguageModelName\": \"string\",\n  \"ContentRedaction\": {\n    \"RedactionType\": \"PII\",\n    \"RedactionOutput\": \"redacted\"|\"redacted_and_unredacted\"\n  },\n  \"LanguageOptions\": [\"af-ZA\"|\"ar-AE\"|\"ar-SA\"|\"cy-GB\"|\"da-DK\"|\"de-CH\"|\"de-DE\"|\"en-AB\"|\"en-AU\"|\"en-GB\"|\"en-IE\"|\"en-IN\"|\"en-US\"|\"en-WL\"|\"es-ES\"|\"es-US\"|\"fa-IR\"|\"fr-CA\"|\"fr-FR\"|\"ga-IE\"|\"gd-GB\"|\"he-IL\"|\"hi-IN\"|\"id-ID\"|\"it-IT\"|\"ja-JP\"|\"ko-KR\"|\"ms-MY\"|\"nl-NL\"|\"pt-BR\"|\"pt-PT\"|\"ru-RU\"|\"ta-IN\"|\"te-IN\"|\"tr-TR\"|\"zh-CN\"|\"zh-TW\"|\"th-TH\"|\"en-ZA\"|\"en-NZ\", ...]\n}\n\n\n--channel-definitions (list)\n\nWhen you start a call analytics job, you must pass an array that maps the agent and the customer to specific audio channels. The values you can assign to a channel are 0 and 1. The agent and the customer must each have their own channel. You can’t assign more than one channel to an agent or customer.\n\n(structure)\n\nFor a call analytics job, an object that indicates the audio channel that belongs to the agent and the audio channel that belongs to the customer.\n\nChannelId -> (integer)\n\nA value that indicates the audio channel.\n\nParticipantRole -> (string)\n\nIndicates whether the person speaking on the audio channel is the agent or customer.\n\nShorthand Syntax:\n\nChannelId=integer,ParticipantRole=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"ChannelId\": integer,\n    \"ParticipantRole\": \"AGENT\"|\"CUSTOMER\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nCallAnalyticsJob -> (structure)\n\nAn object containing the details of the asynchronous call analytics job.\n\nCallAnalyticsJobName -> (string)\n\nThe name of the call analytics job.\n\nCallAnalyticsJobStatus -> (string)\n\nThe status of the analytics job.\n\nLanguageCode -> (string)\n\nIf you know the language spoken between the customer and the agent, specify a language code for this field.\n\nIf you don’t know the language, you can leave this field blank, and Amazon Transcribe will use machine learning to automatically identify the language. To improve the accuracy of language identification, you can provide an array containing the possible language codes for the language spoken in your audio. Refer to Supported languages and language-specific features for additional information.\n\nMediaSampleRateHertz -> (integer)\n\nThe sample rate, in Hertz, of the audio.\n\nMediaFormat -> (string)\n\nThe format of the input audio file. Note: for call analytics jobs, only the following media formats are supported: MP3, MP4, WAV, FLAC, OGG, and WebM.\n\nMedia -> (structure)\n\nDescribes the input media file in a transcription request.\n\nMediaFileUri -> (string)\n\nThe S3 object location of the input media file. The URI must be in the same region as the API endpoint that you are calling. The general form is:\n\nFor example:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nRedactedMediaFileUri -> (string)\n\nThe S3 object location for your redacted output media file. This is only supported for call analytics jobs.\n\nTranscript -> (structure)\n\nIdentifies the location of a transcription.\n\nTranscriptFileUri -> (string)\n\nThe S3 object location of the transcript.\n\nUse this URI to access the transcript. If you specified an S3 bucket in the OutputBucketName field when you created the job, this is the URI of that bucket. If you chose to store the transcript in Amazon Transcribe, this is a shareable URL that provides secure access to that location.\n\nRedactedTranscriptFileUri -> (string)\n\nThe S3 object location of the redacted transcript.\n\nUse this URI to access the redacted transcript. If you specified an S3 bucket in the OutputBucketName field when you created the job, this is the URI of that bucket. If you chose to store the transcript in Amazon Transcribe, this is a shareable URL that provides secure access to that location.\n\nStartTime -> (timestamp)\n\nA timestamp that shows when the analytics job started processing.\n\nCreationTime -> (timestamp)\n\nA timestamp that shows when the analytics job was created.\n\nCompletionTime -> (timestamp)\n\nA timestamp that shows when the analytics job was completed.\n\nFailureReason -> (string)\n\nIf the AnalyticsJobStatus is FAILED , this field contains information about why the job failed.\n\nThe FailureReason field can contain one of the following values:\n\nUnsupported media format : The media format specified in the MediaFormat field of the request isn’t valid. See the description of the MediaFormat field for a list of valid values.\n\nThe media format provided does not match the detected media format : The media format of the audio file doesn’t match the format specified in the MediaFormat field in the request. Check the media format of your media file and make sure the two values match.\n\nInvalid sample rate for audio file : The sample rate specified in the MediaSampleRateHertz of the request isn’t valid. The sample rate must be between 8,000 and 48,000 Hertz.\n\nThe sample rate provided does not match the detected sample rate : The sample rate in the audio file doesn’t match the sample rate specified in the MediaSampleRateHertz field in the request. Check the sample rate of your media file and make sure that the two values match.\n\nInvalid file size: file size too large : The size of your audio file is larger than what Amazon Transcribe Medical can process. For more information, see Guidelines and Quotas in the Amazon Transcribe Medical Guide.\n\nInvalid number of channels: number of channels too large : Your audio contains more channels than Amazon Transcribe Medical is configured to process. To request additional channels, see Amazon Transcribe Medical Endpoints and Quotas in the Amazon Web Services General Reference .\n\nDataAccessRoleArn -> (string)\n\nThe Amazon Resource Number (ARN) that you use to get access to the analytics job.\n\nIdentifiedLanguageScore -> (float)\n\nA value between zero and one that Amazon Transcribe assigned to the language that it identified in the source audio. This value appears only when you don’t provide a single language code. Larger values indicate that Amazon Transcribe has higher confidence in the language that it identified\n\nSettings -> (structure)\n\nProvides information about the settings used to run a transcription job.\n\nVocabularyName -> (string)\n\nThe name of a vocabulary to use when processing the call analytics job.\n\nVocabularyFilterName -> (string)\n\nThe name of the vocabulary filter to use when running a call analytics job. The filter that you specify must have the same language code as the analytics job.\n\nVocabularyFilterMethod -> (string)\n\nSet to mask to remove filtered text from the transcript and replace it with three asterisks (“***”) as placeholder text. Set to remove to remove filtered text from the transcript without using placeholder text. Set to tag to mark the word in the transcription output that matches the vocabulary filter. When you set the filter method to tag , the words matching your vocabulary filter are not masked or removed.\n\nLanguageModelName -> (string)\n\nThe structure used to describe a custom language model.\n\nContentRedaction -> (structure)\n\nSettings for content redaction within a transcription job.\n\nRedactionType -> (string)\n\nRequest parameter that defines the entities to be redacted. The only accepted value is PII .\n\nRedactionOutput -> (string)\n\nThe output transcript file stored in either the default S3 bucket or in a bucket you specify.\n\nWhen you choose redacted Amazon Transcribe outputs only the redacted transcript.\n\nWhen you choose redacted_and_unredacted Amazon Transcribe outputs both the redacted and unredacted transcripts.\n\nLanguageOptions -> (list)\n\nWhen you run a call analytics job, you can specify the language spoken in the audio, or you can have Amazon Transcribe identify the language for you.\n\nTo specify a language, specify an array with one language code. If you don’t know the language, you can leave this field blank and Amazon Transcribe will use machine learning to identify the language for you. To improve the ability of Amazon Transcribe to correctly identify the language, you can provide an array of the languages that can be present in the audio. Refer to Supported languages and language-specific features for additional information.\n\n(string)\n\nChannelDefinitions -> (list)\n\nShows numeric values to indicate the channel assigned to the agent’s audio and the channel assigned to the customer’s audio.\n\n(structure)\n\nFor a call analytics job, an object that indicates the audio channel that belongs to the agent and the audio channel that belongs to the customer.\n\nChannelId -> (integer)\n\nA value that indicates the audio channel.\n\nParticipantRole -> (string)\n\nIndicates whether the person speaking on the audio channel is the agent or customer."
    },
    {
      "command_name": "start-medical-transcription-job",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/start-medical-transcription-job.html",
      "command_description": "Description\n\nStarts a batch job to transcribe medical speech to text.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-medical-transcription-job\n--medical-transcription-job-name <value>\n--language-code <value>\n[--media-sample-rate-hertz <value>]\n[--media-format <value>]\n--media <value>\n--output-bucket-name <value>\n[--output-key <value>]\n[--output-encryption-kms-key-id <value>]\n[--kms-encryption-context <value>]\n[--settings <value>]\n[--content-identification-type <value>]\n--specialty <value>\n--type <value>\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--medical-transcription-job-name <value>",
        "--language-code <value>",
        "[--media-sample-rate-hertz <value>]",
        "[--media-format <value>]",
        "--media <value>",
        "--output-bucket-name <value>",
        "[--output-key <value>]",
        "[--output-encryption-kms-key-id <value>]",
        "[--kms-encryption-context <value>]",
        "[--settings <value>]",
        "[--content-identification-type <value>]",
        "--specialty <value>",
        "--type <value>",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--medical-transcription-job-name (string)\n\nThe name of the medical transcription job. You can’t use the strings “. ” or “.. ” by themselves as the job name. The name must also be unique within an Amazon Web Services account. If you try to create a medical transcription job with the same name as a previous medical transcription job, you get a ConflictException error.\n\n--language-code (string)\n\nThe language code for the language spoken in the input media file. US English (en-US) is the valid value for medical transcription jobs. Any other value you enter for language code results in a BadRequestException error.\n\nPossible values:\n\naf-ZA\n\nar-AE\n\nar-SA\n\ncy-GB\n\nda-DK\n\nde-CH\n\nde-DE\n\nen-AB\n\nen-AU\n\nen-GB\n\nen-IE\n\nen-IN\n\nen-US\n\nen-WL\n\nes-ES\n\nes-US\n\nfa-IR\n\nfr-CA\n\nfr-FR\n\nga-IE\n\ngd-GB\n\nhe-IL\n\nhi-IN\n\nid-ID\n\nit-IT\n\nja-JP\n\nko-KR\n\nms-MY\n\nnl-NL\n\npt-BR\n\npt-PT\n\nru-RU\n\nta-IN\n\nte-IN\n\ntr-TR\n\nzh-CN\n\nzh-TW\n\nth-TH\n\nen-ZA\n\nen-NZ\n\n--media-sample-rate-hertz (integer)\n\nThe sample rate, in Hertz, of the audio track in the input media file.\n\nIf you do not specify the media sample rate, Amazon Transcribe Medical determines the sample rate. If you specify the sample rate, it must match the rate detected by Amazon Transcribe Medical. In most cases, you should leave the MediaSampleRateHertz field blank and let Amazon Transcribe Medical determine the sample rate.\n\n--media-format (string)\n\nThe audio format of the input media file.\n\nPossible values:\n\nmp3\n\nmp4\n\nwav\n\nflac\n\nogg\n\namr\n\nwebm\n\n--media (structure)\n\nDescribes the input media file in a transcription request.\n\nMediaFileUri -> (string)\n\nThe S3 object location of the input media file. The URI must be in the same region as the API endpoint that you are calling. The general form is:\n\nFor example:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nRedactedMediaFileUri -> (string)\n\nThe S3 object location for your redacted output media file. This is only supported for call analytics jobs.\n\nShorthand Syntax:\n\nMediaFileUri=string,RedactedMediaFileUri=string\n\n\nJSON Syntax:\n\n{\n  \"MediaFileUri\": \"string\",\n  \"RedactedMediaFileUri\": \"string\"\n}\n\n\n--output-bucket-name (string)\n\nThe Amazon S3 location where the transcription is stored.\n\nYou must set OutputBucketName for Amazon Transcribe Medical to store the transcription results. Your transcript appears in the S3 location you specify. When you call the GetMedicalTranscriptionJob , the operation returns this location in the TranscriptFileUri field. The S3 bucket must have permissions that allow Amazon Transcribe Medical to put files in the bucket. For more information, see Permissions Required for IAM User Roles .\n\nYou can specify an Amazon Web Services Key Management Service (KMS) key to encrypt the output of your transcription using the OutputEncryptionKMSKeyId parameter. If you don’t specify a KMS key, Amazon Transcribe Medical uses the default Amazon S3 key for server-side encryption of transcripts that are placed in your S3 bucket.\n\n--output-key (string)\n\nYou can specify a location in an Amazon S3 bucket to store the output of your medical transcription job.\n\nIf you don’t specify an output key, Amazon Transcribe Medical stores the output of your transcription job in the Amazon S3 bucket you specified. By default, the object key is “your-transcription-job-name.json”.\n\nYou can use output keys to specify the Amazon S3 prefix and file name of the transcription output. For example, specifying the Amazon S3 prefix, “folder1/folder2/”, as an output key would lead to the output being stored as “folder1/folder2/your-transcription-job-name.json”. If you specify “my-other-job-name.json” as the output key, the object key is changed to “my-other-job-name.json”. You can use an output key to change both the prefix and the file name, for example “folder/my-other-job-name.json”.\n\nIf you specify an output key, you must also specify an S3 bucket in the OutputBucketName parameter.\n\n--output-encryption-kms-key-id (string)\n\nThe Amazon Resource Name (ARN) of the Amazon Web Services Key Management Service (KMS) key used to encrypt the output of the transcription job. The user calling the StartMedicalTranscriptionJob operation must have permission to use the specified KMS key.\n\nYou use either of the following to identify a KMS key in the current account:\n\nKMS Key ID: “1234abcd-12ab-34cd-56ef-1234567890ab”\n\nKMS Key Alias: “alias/ExampleAlias”\n\nYou can use either of the following to identify a KMS key in the current account or another account:\n\nAmazon Resource Name (ARN) of a KMS key in the current account or another account: “arn:aws:kms:region:account ID:key/1234abcd-12ab-34cd-56ef-1234567890ab”\n\nARN of a KMS Key Alias: “arn:aws:kms:region:account ID:alias/ExampleAlias”\n\nIf you don’t specify an encryption key, the output of the medical transcription job is encrypted with the default Amazon S3 key (SSE-S3).\n\nIf you specify a KMS key to encrypt your output, you must also specify an output location in the OutputBucketName parameter.\n\n--kms-encryption-context (map)\n\nA map of plain text, non-secret key:value pairs, known as encryption context pairs, that provide an added layer of security for your data.\n\nkey -> (string)\n\nvalue -> (string)\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--settings (structure)\n\nOptional settings for the medical transcription job.\n\nShowSpeakerLabels -> (boolean)\n\nDetermines whether the transcription job uses speaker recognition to identify different speakers in the input audio. Speaker recognition labels individual speakers in the audio file. If you set the ShowSpeakerLabels field to true, you must also set the maximum number of speaker labels in the MaxSpeakerLabels field.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException .\n\nMaxSpeakerLabels -> (integer)\n\nThe maximum number of speakers to identify in the input audio. If there are more speakers in the audio than this number, multiple speakers are identified as a single speaker. If you specify the MaxSpeakerLabels field, you must set the ShowSpeakerLabels field to true.\n\nChannelIdentification -> (boolean)\n\nInstructs Amazon Transcribe Medical to process each audio channel separately and then merge the transcription output of each channel into a single transcription.\n\nAmazon Transcribe Medical also produces a transcription of each item detected on an audio channel, including the start time and end time of the item and alternative transcriptions of item. The alternative transcriptions also come with confidence scores provided by Amazon Transcribe Medical.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException\n\nShowAlternatives -> (boolean)\n\nDetermines whether alternative transcripts are generated along with the transcript that has the highest confidence. If you set ShowAlternatives field to true, you must also set the maximum number of alternatives to return in the MaxAlternatives field.\n\nMaxAlternatives -> (integer)\n\nThe maximum number of alternatives that you tell the service to return. If you specify the MaxAlternatives field, you must set the ShowAlternatives field to true.\n\nVocabularyName -> (string)\n\nThe name of the vocabulary to use when processing a medical transcription job.\n\nShorthand Syntax:\n\nShowSpeakerLabels=boolean,MaxSpeakerLabels=integer,ChannelIdentification=boolean,ShowAlternatives=boolean,MaxAlternatives=integer,VocabularyName=string\n\n\nJSON Syntax:\n\n{\n  \"ShowSpeakerLabels\": true|false,\n  \"MaxSpeakerLabels\": integer,\n  \"ChannelIdentification\": true|false,\n  \"ShowAlternatives\": true|false,\n  \"MaxAlternatives\": integer,\n  \"VocabularyName\": \"string\"\n}\n\n\n--content-identification-type (string)\n\nYou can configure Amazon Transcribe Medical to label content in the transcription output. If you specify PHI , Amazon Transcribe Medical labels the personal health information (PHI) that it identifies in the transcription output.\n\nPossible values:\n\nPHI\n\n--specialty (string)\n\nThe medical specialty of any clinician speaking in the input media.\n\nPossible values:\n\nPRIMARYCARE\n\n--type (string)\n\nThe type of speech in the input audio. CONVERSATION refers to conversations between two or more speakers, e.g., a conversations between doctors and patients. DICTATION refers to single-speaker dictated speech, such as clinical notes.\n\nPossible values:\n\nCONVERSATION\n\nDICTATION\n\n--tags (list)\n\nAdd tags to an Amazon Transcribe medical transcription job.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.\n\nShorthand Syntax:\n\nKey=string,Value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Key\": \"string\",\n    \"Value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nMedicalTranscriptionJob -> (structure)\n\nA batch job submitted to transcribe medical speech to text.\n\nMedicalTranscriptionJobName -> (string)\n\nThe name for a given medical transcription job.\n\nTranscriptionJobStatus -> (string)\n\nThe completion status of a medical transcription job.\n\nLanguageCode -> (string)\n\nThe language code for the language spoken in the source audio file. US English (en-US) is the only supported language for medical transcriptions. Any other value you enter for language code results in a BadRequestException error.\n\nMediaSampleRateHertz -> (integer)\n\nThe sample rate, in Hertz, of the source audio containing medical information.\n\nIf you don’t specify the sample rate, Amazon Transcribe Medical determines it for you. If you choose to specify the sample rate, it must match the rate detected by Amazon Transcribe Medical. In most cases, you should leave the MedicalMediaSampleHertz blank and let Amazon Transcribe Medical determine the sample rate.\n\nMediaFormat -> (string)\n\nThe format of the input media file.\n\nMedia -> (structure)\n\nDescribes the input media file in a transcription request.\n\nMediaFileUri -> (string)\n\nThe S3 object location of the input media file. The URI must be in the same region as the API endpoint that you are calling. The general form is:\n\nFor example:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nRedactedMediaFileUri -> (string)\n\nThe S3 object location for your redacted output media file. This is only supported for call analytics jobs.\n\nTranscript -> (structure)\n\nAn object that contains the MedicalTranscript . The MedicalTranscript contains the TranscriptFileUri .\n\nTranscriptFileUri -> (string)\n\nThe S3 object location of the medical transcript.\n\nUse this URI to access the medical transcript. This URI points to the S3 bucket you created to store the medical transcript.\n\nStartTime -> (timestamp)\n\nA timestamp that shows when the job started processing.\n\nCreationTime -> (timestamp)\n\nA timestamp that shows when the job was created.\n\nCompletionTime -> (timestamp)\n\nA timestamp that shows when the job was completed.\n\nFailureReason -> (string)\n\nIf the TranscriptionJobStatus field is FAILED , this field contains information about why the job failed.\n\nThe FailureReason field contains one of the following values:\n\nUnsupported media format - The media format specified in the MediaFormat field of the request isn’t valid. See the description of the MediaFormat field for a list of valid values.\n\nThe media format provided does not match the detected media format - The media format of the audio file doesn’t match the format specified in the MediaFormat field in the request. Check the media format of your media file and make sure the two values match.\n\nInvalid sample rate for audio file - The sample rate specified in the MediaSampleRateHertz of the request isn’t valid. The sample rate must be between 8,000 and 48,000 Hertz.\n\nThe sample rate provided does not match the detected sample rate - The sample rate in the audio file doesn’t match the sample rate specified in the MediaSampleRateHertz field in the request. Check the sample rate of your media file and make sure that the two values match.\n\nInvalid file size: file size too large - The size of your audio file is larger than what Amazon Transcribe Medical can process. For more information, see Guidelines and Quotas in the Amazon Transcribe Medical Guide\n\nInvalid number of channels: number of channels too large - Your audio contains more channels than Amazon Transcribe Medical is configured to process. To request additional channels, see Amazon Transcribe Medical Endpoints and Quotas in the Amazon Web Services General Reference\n\nSettings -> (structure)\n\nObject that contains object.\n\nShowSpeakerLabels -> (boolean)\n\nDetermines whether the transcription job uses speaker recognition to identify different speakers in the input audio. Speaker recognition labels individual speakers in the audio file. If you set the ShowSpeakerLabels field to true, you must also set the maximum number of speaker labels in the MaxSpeakerLabels field.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException .\n\nMaxSpeakerLabels -> (integer)\n\nThe maximum number of speakers to identify in the input audio. If there are more speakers in the audio than this number, multiple speakers are identified as a single speaker. If you specify the MaxSpeakerLabels field, you must set the ShowSpeakerLabels field to true.\n\nChannelIdentification -> (boolean)\n\nInstructs Amazon Transcribe Medical to process each audio channel separately and then merge the transcription output of each channel into a single transcription.\n\nAmazon Transcribe Medical also produces a transcription of each item detected on an audio channel, including the start time and end time of the item and alternative transcriptions of item. The alternative transcriptions also come with confidence scores provided by Amazon Transcribe Medical.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException\n\nShowAlternatives -> (boolean)\n\nDetermines whether alternative transcripts are generated along with the transcript that has the highest confidence. If you set ShowAlternatives field to true, you must also set the maximum number of alternatives to return in the MaxAlternatives field.\n\nMaxAlternatives -> (integer)\n\nThe maximum number of alternatives that you tell the service to return. If you specify the MaxAlternatives field, you must set the ShowAlternatives field to true.\n\nVocabularyName -> (string)\n\nThe name of the vocabulary to use when processing a medical transcription job.\n\nContentIdentificationType -> (string)\n\nShows the type of content that you’ve configured Amazon Transcribe Medical to identify in a transcription job. If the value is PHI , you’ve configured the job to identify personal health information (PHI) in the transcription output.\n\nSpecialty -> (string)\n\nThe medical specialty of any clinicians providing a dictation or having a conversation. Refer to Transcribing a medical conversation for a list of supported specialties.\n\nType -> (string)\n\nThe type of speech in the transcription job. CONVERSATION is generally used for patient-physician dialogues. DICTATION is the setting for physicians speaking their notes after seeing a patient. For more information, see What is Amazon Transcribe Medical? .\n\nTags -> (list)\n\nA key:value pair assigned to a given medical transcription job.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.",
      "command_examples": "Examples\n\nExample 1: To transcribe a medical dictation stored as an audio file\n\nThe following start-medical-transcription-job example transcribes an audio file. You specify the location of the transcription output in the OutputBucketName parameter.\n\naws transcribe start-medical-transcription-job \\\n    --cli-input-json file://myfile.json\n\n\nContents of myfile.json:\n\n{\n    \"MedicalTranscriptionJobName\": \"simple-dictation-medical-transcription-job\",\n    \"LanguageCode\": \"language-code\",\n    \"Specialty\": \"PRIMARYCARE\",\n    \"Type\": \"DICTATION\",\n    \"OutputBucketName\":\"DOC-EXAMPLE-BUCKET\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n    }\n}\n\n\nOutput:\n\n{\n    \"MedicalTranscriptionJob\": {\n        \"MedicalTranscriptionJobName\": \"simple-dictation-medical-transcription-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"language-code\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n        },\n        \"StartTime\": \"2020-09-20T00:35:22.256000+00:00\",\n        \"CreationTime\": \"2020-09-20T00:35:22.218000+00:00\",\n        \"Specialty\": \"PRIMARYCARE\",\n        \"Type\": \"DICTATION\"\n    }\n}\n\n\nFor more information, see Batch Transcription Overview in the Amazon Transcribe Developer Guide.\n\nExample 2: To transcribe a clinician-patient dialogue stored as an audio file\n\nThe following start-medical-transcription-job example transcribes an audio file containing a clinician-patient dialogue. You specify the location of the transcription output in the OutputBucketName parameter.\n\naws transcribe start-medical-transcription-job \\\n    --cli-input-json file://mysecondfile.json\n\n\nContents of mysecondfile.json:\n\n{\n    \"MedicalTranscriptionJobName\": \"simple-dictation-medical-transcription-job\",\n    \"LanguageCode\": \"language-code\",\n    \"Specialty\": \"PRIMARYCARE\",\n    \"Type\": \"CONVERSATION\",\n    \"OutputBucketName\":\"DOC-EXAMPLE-BUCKET\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n    }\n}\n\n\nOutput:\n\n{\n    \"MedicalTranscriptionJob\": {\n        \"MedicalTranscriptionJobName\": \"simple-conversation-medical-transcription-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"language-code\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n        },\n        \"StartTime\": \"2020-09-20T23:19:49.965000+00:00\",\n        \"CreationTime\": \"2020-09-20T23:19:49.941000+00:00\",\n        \"Specialty\": \"PRIMARYCARE\",\n        \"Type\": \"CONVERSATION\"\n    }\n}\n\n\nFor more information, see Batch Transcription Overview in the Amazon Transcribe Developer Guide.\n\nExample 3: To transcribe a multichannel audio file of a clinician-patient dialogue\n\nThe following start-medical-transcription-job example transcribes the audio from each channel in the audio file and merges the separate transcriptions from each channel into a single transcription output. You specify the location of the transcription output in the OutputBucketName parameter.\n\naws transcribe start-medical-transcription-job \\\n    --cli-input-json file://mythirdfile.json\n\n\nContents of mythirdfile.json:\n\n{\n    \"MedicalTranscriptionJobName\": \"multichannel-conversation-medical-transcription-job\",\n    \"LanguageCode\": \"language-code\",\n    \"Specialty\": \"PRIMARYCARE\",\n    \"Type\": \"CONVERSATION\",\n    \"OutputBucketName\":\"DOC-EXAMPLE-BUCKET\",\n        \"Media\": {\n          \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n        },\n        \"Settings\":{\n          \"ChannelIdentification\": true\n        }\n}\n\n\nOutput:\n\n{\n    \"MedicalTranscriptionJob\": {\n        \"MedicalTranscriptionJobName\": \"multichannel-conversation-medical-transcription-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"language-code\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n        },\n        \"StartTime\": \"2020-09-20T23:46:44.081000+00:00\",\n        \"CreationTime\": \"2020-09-20T23:46:44.053000+00:00\",\n        \"Settings\": {\n            \"ChannelIdentification\": true\n        },\n        \"Specialty\": \"PRIMARYCARE\",\n        \"Type\": \"CONVERSATION\"\n    }\n}\n\n\nFor more information, see Channel Identification in the Amazon Transcribe Developer Guide.\n\nExample 4: To transcribe an audio file of a clinician-patient dialogue and identify the speakers in the transcription output\n\nThe following start-medical-transcription-job example transcribes an audio file and labels the speech of each speaker in the transcription output. You specify the location of the transcription output in the OutputBucketName parameter.\n\naws transcribe start-medical-transcription-job \\\n    --cli-input-json file://myfourthfile.json\n\n\nContents of myfourthfile.json:\n\n{\n    \"MedicalTranscriptionJobName\": \"speaker-id-conversation-medical-transcription-job\",\n    \"LanguageCode\": \"language-code\",\n    \"Specialty\": \"PRIMARYCARE\",\n    \"Type\": \"CONVERSATION\",\n    \"OutputBucketName\":\"DOC-EXAMPLE-BUCKET\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n        },\n    \"Settings\":{\n        \"ShowSpeakerLabels\": true,\n        \"MaxSpeakerLabels\": 2\n        }\n}\n\n\nOutput:\n\n{\n    \"MedicalTranscriptionJob\": {\n        \"MedicalTranscriptionJobName\": \"speaker-id-conversation-medical-transcription-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"language-code\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n        },\n        \"StartTime\": \"2020-09-21T18:43:37.265000+00:00\",\n        \"CreationTime\": \"2020-09-21T18:43:37.157000+00:00\",\n        \"Settings\": {\n            \"ShowSpeakerLabels\": true,\n            \"MaxSpeakerLabels\": 2\n        },\n        \"Specialty\": \"PRIMARYCARE\",\n        \"Type\": \"CONVERSATION\"\n    }\n}\n\n\nFor more information, see Identifying Speakers in the Amazon Transcribe Developer Guide.\n\nExample 5: To transcribe a medical conversation stored as an audio file with up to two transcription alternatives\n\nThe following start-medical-transcription-job example creates up to two alternative transcriptions from a single audio file. Every transcriptions has a level of confidence associated with it. By default, Amazon Transcribe returns the transcription with the highest confidence level. You can specify that Amazon Transcribe return additional transcriptions with lower confidence levels. You specify the location of the transcription output in the OutputBucketName parameter.\n\naws transcribe start-medical-transcription-job \\\n    --cli-input-json file://myfifthfile.json\n\n\nContents of myfifthfile.json:\n\n{\n    \"MedicalTranscriptionJobName\": \"alternatives-conversation-medical-transcription-job\",\n    \"LanguageCode\": \"language-code\",\n    \"Specialty\": \"PRIMARYCARE\",\n    \"Type\": \"CONVERSATION\",\n    \"OutputBucketName\":\"DOC-EXAMPLE-BUCKET\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n    },\n    \"Settings\":{\n        \"ShowAlternatives\": true,\n        \"MaxAlternatives\": 2\n    }\n}\n\n\nOutput:\n\n{\n    \"MedicalTranscriptionJob\": {\n        \"MedicalTranscriptionJobName\": \"alternatives-conversation-medical-transcription-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"language-code\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n        },\n        \"StartTime\": \"2020-09-21T19:09:18.199000+00:00\",\n        \"CreationTime\": \"2020-09-21T19:09:18.171000+00:00\",\n        \"Settings\": {\n            \"ShowAlternatives\": true,\n            \"MaxAlternatives\": 2\n        },\n        \"Specialty\": \"PRIMARYCARE\",\n        \"Type\": \"CONVERSATION\"\n    }\n}\n\n\nFor more information, see Alternative Transcriptions in the Amazon Transcribe Developer Guide.\n\nExample 6: To transcribe an audio file of a medical dictation with up to two alternative transcriptions\n\nThe following start-medical-transcription-job example transcribes an audio file and uses a vocabulary filter to mask any unwanted words. You specify the location of the transcription output in the OutputBucketName parameter.\n\naws transcribe start-medical-transcription-job \\\n    --cli-input-json file://mysixthfile.json\n\n\nContents of mysixthfile.json:\n\n{\n    \"MedicalTranscriptionJobName\": \"alternatives-conversation-medical-transcription-job\",\n    \"LanguageCode\": \"language-code\",\n    \"Specialty\": \"PRIMARYCARE\",\n    \"Type\": \"DICTATION\",\n    \"OutputBucketName\":\"DOC-EXAMPLE-BUCKET\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n    },\n    \"Settings\":{\n          \"ShowAlternatives\": true,\n          \"MaxAlternatives\": 2\n    }\n}\n\n\nOutput:\n\n{\n    \"MedicalTranscriptionJob\": {\n        \"MedicalTranscriptionJobName\": \"alternatives-dictation-medical-transcription-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"language-code\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n        },\n        \"StartTime\": \"2020-09-21T21:01:14.592000+00:00\",\n        \"CreationTime\": \"2020-09-21T21:01:14.569000+00:00\",\n        \"Settings\": {\n            \"ShowAlternatives\": true,\n            \"MaxAlternatives\": 2\n        },\n        \"Specialty\": \"PRIMARYCARE\",\n        \"Type\": \"DICTATION\"\n    }\n}\n\n\nFor more information, see Alternative Transcriptions in the Amazon Transcribe Developer Guide.\n\nExample 7: To transcribe an audio file of a medical dictation with increased accuracy by using a custom vocabulary\n\nThe following start-medical-transcription-job example transcribes an audio file and uses a medical custom vocabulary you’ve previously created to increase the transcription accuracy. You specify the location of the transcription output in the OutputBucketName parameter.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://myseventhfile.json\n\n\nContents of mysixthfile.json:\n\n{\n    \"MedicalTranscriptionJobName\": \"vocabulary-dictation-medical-transcription-job\",\n    \"LanguageCode\": \"language-code\",\n    \"Specialty\": \"PRIMARYCARE\",\n    \"Type\": \"DICTATION\",\n    \"OutputBucketName\":\"DOC-EXAMPLE-BUCKET\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n    },\n    \"Settings\":{\n        \"VocabularyName\": \"cli-medical-vocab-1\"\n    }\n}\n\n\nOutput:\n\n{\n    \"MedicalTranscriptionJob\": {\n        \"MedicalTranscriptionJobName\": \"vocabulary-dictation-medical-transcription-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"language-code\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.extension\"\n        },\n        \"StartTime\": \"2020-09-21T21:17:27.045000+00:00\",\n        \"CreationTime\": \"2020-09-21T21:17:27.016000+00:00\",\n        \"Settings\": {\n            \"VocabularyName\": \"cli-medical-vocab-1\"\n        },\n        \"Specialty\": \"PRIMARYCARE\",\n        \"Type\": \"DICTATION\"\n    }\n}\n\n\nFor more information, see Medical Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "start-transcription-job",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/start-transcription-job.html",
      "command_description": "Description\n\nStarts an asynchronous job to transcribe speech to text.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-transcription-job\n--transcription-job-name <value>\n[--language-code <value>]\n[--media-sample-rate-hertz <value>]\n[--media-format <value>]\n--media <value>\n[--output-bucket-name <value>]\n[--output-key <value>]\n[--output-encryption-kms-key-id <value>]\n[--kms-encryption-context <value>]\n[--settings <value>]\n[--model-settings <value>]\n[--job-execution-settings <value>]\n[--content-redaction <value>]\n[--identify-language | --no-identify-language]\n[--language-options <value>]\n[--subtitles <value>]\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--transcription-job-name <value>",
        "[--language-code <value>]",
        "[--media-sample-rate-hertz <value>]",
        "[--media-format <value>]",
        "--media <value>",
        "[--output-bucket-name <value>]",
        "[--output-key <value>]",
        "[--output-encryption-kms-key-id <value>]",
        "[--kms-encryption-context <value>]",
        "[--settings <value>]",
        "[--model-settings <value>]",
        "[--job-execution-settings <value>]",
        "[--content-redaction <value>]",
        "[--identify-language | --no-identify-language]",
        "[--language-options <value>]",
        "[--subtitles <value>]",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--transcription-job-name (string)\n\nThe name of the job. You can’t use the strings “. ” or “.. ” by themselves as the job name. The name must also be unique within an Amazon Web Services account. If you try to create a transcription job with the same name as a previous transcription job, you get a ConflictException error.\n\n--language-code (string)\n\nThe language code for the language used in the input media file.\n\nTo transcribe speech in Modern Standard Arabic (ar-SA), your audio or video file must be encoded at a sample rate of 16,000 Hz or higher.\n\nPossible values:\n\naf-ZA\n\nar-AE\n\nar-SA\n\ncy-GB\n\nda-DK\n\nde-CH\n\nde-DE\n\nen-AB\n\nen-AU\n\nen-GB\n\nen-IE\n\nen-IN\n\nen-US\n\nen-WL\n\nes-ES\n\nes-US\n\nfa-IR\n\nfr-CA\n\nfr-FR\n\nga-IE\n\ngd-GB\n\nhe-IL\n\nhi-IN\n\nid-ID\n\nit-IT\n\nja-JP\n\nko-KR\n\nms-MY\n\nnl-NL\n\npt-BR\n\npt-PT\n\nru-RU\n\nta-IN\n\nte-IN\n\ntr-TR\n\nzh-CN\n\nzh-TW\n\nth-TH\n\nen-ZA\n\nen-NZ\n\n--media-sample-rate-hertz (integer)\n\nThe sample rate, in Hertz, of the audio track in the input media file.\n\nIf you do not specify the media sample rate, Amazon Transcribe determines the sample rate. If you specify the sample rate, it must match the sample rate detected by Amazon Transcribe. In most cases, you should leave the MediaSampleRateHertz field blank and let Amazon Transcribe determine the sample rate.\n\n--media-format (string)\n\nThe format of the input media file.\n\nPossible values:\n\nmp3\n\nmp4\n\nwav\n\nflac\n\nogg\n\namr\n\nwebm\n\n--media (structure)\n\nAn object that describes the input media for a transcription job.\n\nMediaFileUri -> (string)\n\nThe S3 object location of the input media file. The URI must be in the same region as the API endpoint that you are calling. The general form is:\n\nFor example:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nRedactedMediaFileUri -> (string)\n\nThe S3 object location for your redacted output media file. This is only supported for call analytics jobs.\n\nShorthand Syntax:\n\nMediaFileUri=string,RedactedMediaFileUri=string\n\n\nJSON Syntax:\n\n{\n  \"MediaFileUri\": \"string\",\n  \"RedactedMediaFileUri\": \"string\"\n}\n\n\n--output-bucket-name (string)\n\nThe location where the transcription is stored.\n\nIf you set the OutputBucketName , Amazon Transcribe puts the transcript in the specified S3 bucket. When you call the GetTranscriptionJob operation, the operation returns this location in the TranscriptFileUri field. If you enable content redaction, the redacted transcript appears in RedactedTranscriptFileUri . If you enable content redaction and choose to output an unredacted transcript, that transcript’s location still appears in the TranscriptFileUri . The S3 bucket must have permissions that allow Amazon Transcribe to put files in the bucket. For more information, see Permissions Required for IAM User Roles .\n\nYou can specify an Amazon Web Services Key Management Service (KMS) key to encrypt the output of your transcription using the OutputEncryptionKMSKeyId parameter. If you don’t specify a KMS key, Amazon Transcribe uses the default Amazon S3 key for server-side encryption of transcripts that are placed in your S3 bucket.\n\nIf you don’t set the OutputBucketName , Amazon Transcribe generates a pre-signed URL, a shareable URL that provides secure access to your transcription, and returns it in the TranscriptFileUri field. Use this URL to download the transcription.\n\n--output-key (string)\n\nYou can specify a location in an Amazon S3 bucket to store the output of your transcription job.\n\nIf you don’t specify an output key, Amazon Transcribe stores the output of your transcription job in the Amazon S3 bucket you specified. By default, the object key is “your-transcription-job-name.json”.\n\nYou can use output keys to specify the Amazon S3 prefix and file name of the transcription output. For example, specifying the Amazon S3 prefix, “folder1/folder2/”, as an output key would lead to the output being stored as “folder1/folder2/your-transcription-job-name.json”. If you specify “my-other-job-name.json” as the output key, the object key is changed to “my-other-job-name.json”. You can use an output key to change both the prefix and the file name, for example “folder/my-other-job-name.json”.\n\nIf you specify an output key, you must also specify an S3 bucket in the OutputBucketName parameter.\n\n--output-encryption-kms-key-id (string)\n\nThe Amazon Resource Name (ARN) of the Amazon Web Services Key Management Service (KMS) key used to encrypt the output of the transcription job. The user calling the StartTranscriptionJob operation must have permission to use the specified KMS key.\n\nYou can use either of the following to identify a KMS key in the current account:\n\nKMS Key ID: “1234abcd-12ab-34cd-56ef-1234567890ab”\n\nKMS Key Alias: “alias/ExampleAlias”\n\nYou can use either of the following to identify a KMS key in the current account or another account:\n\nAmazon Resource Name (ARN) of a KMS Key: “arn:aws:kms:region:account ID:key/1234abcd-12ab-34cd-56ef-1234567890ab”\n\nARN of a KMS Key Alias: “arn:aws:kms:region:account ID:alias/ExampleAlias”\n\nIf you don’t specify an encryption key, the output of the transcription job is encrypted with the default Amazon S3 key (SSE-S3).\n\nIf you specify a KMS key to encrypt your output, you must also specify an output location in the OutputBucketName parameter.\n\n--kms-encryption-context (map)\n\nA map of plain text, non-secret key:value pairs, known as encryption context pairs, that provide an added layer of security for your data.\n\nkey -> (string)\n\nvalue -> (string)\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--settings (structure)\n\nA Settings object that provides optional settings for a transcription job.\n\nVocabularyName -> (string)\n\nThe name of a vocabulary to use when processing the transcription job.\n\nShowSpeakerLabels -> (boolean)\n\nDetermines whether the transcription job uses speaker recognition to identify different speakers in the input audio. Speaker recognition labels individual speakers in the audio file. If you set the ShowSpeakerLabels field to true, you must also set the maximum number of speaker labels MaxSpeakerLabels field.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException .\n\nMaxSpeakerLabels -> (integer)\n\nThe maximum number of speakers to identify in the input audio. If there are more speakers in the audio than this number, multiple speakers are identified as a single speaker. If you specify the MaxSpeakerLabels field, you must set the ShowSpeakerLabels field to true.\n\nChannelIdentification -> (boolean)\n\nInstructs Amazon Transcribe to process each audio channel separately and then merge the transcription output of each channel into a single transcription.\n\nAmazon Transcribe also produces a transcription of each item detected on an audio channel, including the start time and end time of the item and alternative transcriptions of the item including the confidence that Amazon Transcribe has in the transcription.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException .\n\nShowAlternatives -> (boolean)\n\nDetermines whether the transcription contains alternative transcriptions. If you set the ShowAlternatives field to true, you must also set the maximum number of alternatives to return in the MaxAlternatives field.\n\nMaxAlternatives -> (integer)\n\nThe number of alternative transcriptions that the service should return. If you specify the MaxAlternatives field, you must set the ShowAlternatives field to true.\n\nVocabularyFilterName -> (string)\n\nThe name of the vocabulary filter to use when transcribing the audio. The filter that you specify must have the same language code as the transcription job.\n\nVocabularyFilterMethod -> (string)\n\nSet to mask to remove filtered text from the transcript and replace it with three asterisks (“***”) as placeholder text. Set to remove to remove filtered text from the transcript without using placeholder text. Set to tag to mark the word in the transcription output that matches the vocabulary filter. When you set the filter method to tag , the words matching your vocabulary filter are not masked or removed.\n\nShorthand Syntax:\n\nVocabularyName=string,ShowSpeakerLabels=boolean,MaxSpeakerLabels=integer,ChannelIdentification=boolean,ShowAlternatives=boolean,MaxAlternatives=integer,VocabularyFilterName=string,VocabularyFilterMethod=string\n\n\nJSON Syntax:\n\n{\n  \"VocabularyName\": \"string\",\n  \"ShowSpeakerLabels\": true|false,\n  \"MaxSpeakerLabels\": integer,\n  \"ChannelIdentification\": true|false,\n  \"ShowAlternatives\": true|false,\n  \"MaxAlternatives\": integer,\n  \"VocabularyFilterName\": \"string\",\n  \"VocabularyFilterMethod\": \"remove\"|\"mask\"|\"tag\"\n}\n\n\n--model-settings (structure)\n\nChoose the custom language model you use for your transcription job in this parameter.\n\nLanguageModelName -> (string)\n\nThe name of your custom language model.\n\nShorthand Syntax:\n\nLanguageModelName=string\n\n\nJSON Syntax:\n\n{\n  \"LanguageModelName\": \"string\"\n}\n\n\n--job-execution-settings (structure)\n\nProvides information about how a transcription job is executed. Use this field to indicate that the job can be queued for deferred execution if the concurrency limit is reached and there are no slots available to immediately run the job.\n\nAllowDeferredExecution -> (boolean)\n\nIndicates whether a job should be queued by Amazon Transcribe when the concurrent execution limit is exceeded. When the AllowDeferredExecution field is true, jobs are queued and executed when the number of executing jobs falls below the concurrent execution limit. If the field is false, Amazon Transcribe returns a LimitExceededException exception.\n\nNote that job queuing is enabled by default for call analytics jobs.\n\nIf you specify the AllowDeferredExecution field, you must specify the DataAccessRoleArn field.\n\nDataAccessRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of a role that has access to the S3 bucket that contains the input files. Amazon Transcribe assumes this role to read queued media files. If you have specified an output S3 bucket for the transcription results, this role should have access to the output bucket as well.\n\nIf you specify the AllowDeferredExecution field, you must specify the DataAccessRoleArn field.\n\nShorthand Syntax:\n\nAllowDeferredExecution=boolean,DataAccessRoleArn=string\n\n\nJSON Syntax:\n\n{\n  \"AllowDeferredExecution\": true|false,\n  \"DataAccessRoleArn\": \"string\"\n}\n\n\n--content-redaction (structure)\n\nAn object that contains the request parameters for content redaction.\n\nRedactionType -> (string)\n\nRequest parameter that defines the entities to be redacted. The only accepted value is PII .\n\nRedactionOutput -> (string)\n\nThe output transcript file stored in either the default S3 bucket or in a bucket you specify.\n\nWhen you choose redacted Amazon Transcribe outputs only the redacted transcript.\n\nWhen you choose redacted_and_unredacted Amazon Transcribe outputs both the redacted and unredacted transcripts.\n\nShorthand Syntax:\n\nRedactionType=string,RedactionOutput=string\n\n\nJSON Syntax:\n\n{\n  \"RedactionType\": \"PII\",\n  \"RedactionOutput\": \"redacted\"|\"redacted_and_unredacted\"\n}\n\n\n--identify-language | --no-identify-language (boolean)\n\nSet this field to true to enable automatic language identification. Automatic language identification is disabled by default. You receive a BadRequestException error if you enter a value for a LanguageCode .\n\n--language-options (list)\n\nAn object containing a list of languages that might be present in your collection of audio files. Automatic language identification chooses a language that best matches the source audio from that list.\n\nTo transcribe speech in Modern Standard Arabic (ar-SA), your audio or video file must be encoded at a sample rate of 16,000 Hz or higher.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\nWhere valid values are:\n  af-ZA\n  ar-AE\n  ar-SA\n  cy-GB\n  da-DK\n  de-CH\n  de-DE\n  en-AB\n  en-AU\n  en-GB\n  en-IE\n  en-IN\n  en-US\n  en-WL\n  es-ES\n  es-US\n  fa-IR\n  fr-CA\n  fr-FR\n  ga-IE\n  gd-GB\n  he-IL\n  hi-IN\n  id-ID\n  it-IT\n  ja-JP\n  ko-KR\n  ms-MY\n  nl-NL\n  pt-BR\n  pt-PT\n  ru-RU\n  ta-IN\n  te-IN\n  tr-TR\n  zh-CN\n  zh-TW\n  th-TH\n  en-ZA\n  en-NZ\n\n\n--subtitles (structure)\n\nAdd subtitles to your batch transcription job.\n\nFormats -> (list)\n\nSpecify the output format for your subtitle file.\n\n(string)\n\nShorthand Syntax:\n\nFormats=string,string\n\n\nJSON Syntax:\n\n{\n  \"Formats\": [\"vtt\"|\"srt\", ...]\n}\n\n\n--tags (list)\n\nAdd tags to an Amazon Transcribe transcription job.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.\n\nShorthand Syntax:\n\nKey=string,Value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Key\": \"string\",\n    \"Value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nTranscriptionJob -> (structure)\n\nAn object containing details of the asynchronous transcription job.\n\nTranscriptionJobName -> (string)\n\nThe name of the transcription job.\n\nTranscriptionJobStatus -> (string)\n\nThe status of the transcription job.\n\nLanguageCode -> (string)\n\nThe language code for the input speech.\n\nMediaSampleRateHertz -> (integer)\n\nThe sample rate, in Hertz, of the audio track in the input media file.\n\nMediaFormat -> (string)\n\nThe format of the input media file.\n\nMedia -> (structure)\n\nAn object that describes the input media for the transcription job.\n\nMediaFileUri -> (string)\n\nThe S3 object location of the input media file. The URI must be in the same region as the API endpoint that you are calling. The general form is:\n\nFor example:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nRedactedMediaFileUri -> (string)\n\nThe S3 object location for your redacted output media file. This is only supported for call analytics jobs.\n\nTranscript -> (structure)\n\nAn object that describes the output of the transcription job.\n\nTranscriptFileUri -> (string)\n\nThe S3 object location of the transcript.\n\nUse this URI to access the transcript. If you specified an S3 bucket in the OutputBucketName field when you created the job, this is the URI of that bucket. If you chose to store the transcript in Amazon Transcribe, this is a shareable URL that provides secure access to that location.\n\nRedactedTranscriptFileUri -> (string)\n\nThe S3 object location of the redacted transcript.\n\nUse this URI to access the redacted transcript. If you specified an S3 bucket in the OutputBucketName field when you created the job, this is the URI of that bucket. If you chose to store the transcript in Amazon Transcribe, this is a shareable URL that provides secure access to that location.\n\nStartTime -> (timestamp)\n\nA timestamp that shows when the job started processing.\n\nCreationTime -> (timestamp)\n\nA timestamp that shows when the job was created.\n\nCompletionTime -> (timestamp)\n\nA timestamp that shows when the job completed.\n\nFailureReason -> (string)\n\nIf the TranscriptionJobStatus field is FAILED , this field contains information about why the job failed.\n\nThe FailureReason field can contain one of the following values:\n\nUnsupported media format - The media format specified in the MediaFormat field of the request isn’t valid. See the description of the MediaFormat field for a list of valid values.\n\nThe media format provided does not match the detected media format - The media format of the audio file doesn’t match the format specified in the MediaFormat field in the request. Check the media format of your media file and make sure that the two values match.\n\nInvalid sample rate for audio file - The sample rate specified in the MediaSampleRateHertz of the request isn’t valid. The sample rate must be between 8,000 and 48,000 Hertz.\n\nThe sample rate provided does not match the detected sample rate - The sample rate in the audio file doesn’t match the sample rate specified in the MediaSampleRateHertz field in the request. Check the sample rate of your media file and make sure that the two values match.\n\nInvalid file size: file size too large - The size of your audio file is larger than Amazon Transcribe can process. For more information, see Limits in the Amazon Transcribe Developer Guide .\n\nInvalid number of channels: number of channels too large - Your audio contains more channels than Amazon Transcribe is configured to process. To request additional channels, see Amazon Transcribe Limits in the Amazon Web Services General Reference .\n\nSettings -> (structure)\n\nOptional settings for the transcription job. Use these settings to turn on speaker recognition, to set the maximum number of speakers that should be identified and to specify a custom vocabulary to use when processing the transcription job.\n\nVocabularyName -> (string)\n\nThe name of a vocabulary to use when processing the transcription job.\n\nShowSpeakerLabels -> (boolean)\n\nDetermines whether the transcription job uses speaker recognition to identify different speakers in the input audio. Speaker recognition labels individual speakers in the audio file. If you set the ShowSpeakerLabels field to true, you must also set the maximum number of speaker labels MaxSpeakerLabels field.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException .\n\nMaxSpeakerLabels -> (integer)\n\nThe maximum number of speakers to identify in the input audio. If there are more speakers in the audio than this number, multiple speakers are identified as a single speaker. If you specify the MaxSpeakerLabels field, you must set the ShowSpeakerLabels field to true.\n\nChannelIdentification -> (boolean)\n\nInstructs Amazon Transcribe to process each audio channel separately and then merge the transcription output of each channel into a single transcription.\n\nAmazon Transcribe also produces a transcription of each item detected on an audio channel, including the start time and end time of the item and alternative transcriptions of the item including the confidence that Amazon Transcribe has in the transcription.\n\nYou can’t set both ShowSpeakerLabels and ChannelIdentification in the same request. If you set both, your request returns a BadRequestException .\n\nShowAlternatives -> (boolean)\n\nDetermines whether the transcription contains alternative transcriptions. If you set the ShowAlternatives field to true, you must also set the maximum number of alternatives to return in the MaxAlternatives field.\n\nMaxAlternatives -> (integer)\n\nThe number of alternative transcriptions that the service should return. If you specify the MaxAlternatives field, you must set the ShowAlternatives field to true.\n\nVocabularyFilterName -> (string)\n\nThe name of the vocabulary filter to use when transcribing the audio. The filter that you specify must have the same language code as the transcription job.\n\nVocabularyFilterMethod -> (string)\n\nSet to mask to remove filtered text from the transcript and replace it with three asterisks (“***”) as placeholder text. Set to remove to remove filtered text from the transcript without using placeholder text. Set to tag to mark the word in the transcription output that matches the vocabulary filter. When you set the filter method to tag , the words matching your vocabulary filter are not masked or removed.\n\nModelSettings -> (structure)\n\nAn object containing the details of your custom language model.\n\nLanguageModelName -> (string)\n\nThe name of your custom language model.\n\nJobExecutionSettings -> (structure)\n\nProvides information about how a transcription job is executed.\n\nAllowDeferredExecution -> (boolean)\n\nIndicates whether a job should be queued by Amazon Transcribe when the concurrent execution limit is exceeded. When the AllowDeferredExecution field is true, jobs are queued and executed when the number of executing jobs falls below the concurrent execution limit. If the field is false, Amazon Transcribe returns a LimitExceededException exception.\n\nNote that job queuing is enabled by default for call analytics jobs.\n\nIf you specify the AllowDeferredExecution field, you must specify the DataAccessRoleArn field.\n\nDataAccessRoleArn -> (string)\n\nThe Amazon Resource Name (ARN) of a role that has access to the S3 bucket that contains the input files. Amazon Transcribe assumes this role to read queued media files. If you have specified an output S3 bucket for the transcription results, this role should have access to the output bucket as well.\n\nIf you specify the AllowDeferredExecution field, you must specify the DataAccessRoleArn field.\n\nContentRedaction -> (structure)\n\nAn object that describes content redaction settings for the transcription job.\n\nRedactionType -> (string)\n\nRequest parameter that defines the entities to be redacted. The only accepted value is PII .\n\nRedactionOutput -> (string)\n\nThe output transcript file stored in either the default S3 bucket or in a bucket you specify.\n\nWhen you choose redacted Amazon Transcribe outputs only the redacted transcript.\n\nWhen you choose redacted_and_unredacted Amazon Transcribe outputs both the redacted and unredacted transcripts.\n\nIdentifyLanguage -> (boolean)\n\nA value that shows if automatic language identification was enabled for a transcription job.\n\nLanguageOptions -> (list)\n\nAn object that shows the optional array of languages inputted for transcription jobs with automatic language identification enabled.\n\n(string)\n\nIdentifiedLanguageScore -> (float)\n\nA value between zero and one that Amazon Transcribe assigned to the language that it identified in the source audio. Larger values indicate that Amazon Transcribe has higher confidence in the language it identified.\n\nTags -> (list)\n\nA key:value pair assigned to a given transcription job.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.\n\nSubtitles -> (structure)\n\nGenerate subtitles for your batch transcription job.\n\nFormats -> (list)\n\nSpecify the output format for your subtitle file; if you select both SRT and VTT formats, two output files are genereated.\n\n(string)\n\nSubtitleFileUris -> (list)\n\nChoose the output location for your subtitle file. This location must be an S3 bucket.\n\n(string)",
      "command_examples": "Examples\n\nExample 1: To transcribe an audio file\n\nThe following start-transcription-job example transcribes your audio file.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://myfile.json\n\n\nContents of myfile.json:\n\n{\n    \"TranscriptionJobName\": \"cli-simple-transcription-job\",\n    \"LanguageCode\": \"the-language-of-your-transcription-job\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n    }\n}\n\n\nFor more information, see Getting Started (AWS Command Line Interface) in the Amazon Transcribe Developer Guide.\n\nExample 2: To transcribe a multi-channel audio file\n\nThe following start-transcription-job example transcribes your multi-channel audio file.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://mysecondfile.json\n\n\nContents of mysecondfile.json:\n\n{\n    \"TranscriptionJobName\": \"cli-channelid-job\",\n    \"LanguageCode\": \"the-language-of-your-transcription-job\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n    },\n    \"Settings\":{\n        \"ChannelIdentification\":true\n    }\n}\n\n\nOutput:\n\n{\n    \"TranscriptionJob\": {\n        \"TranscriptionJobName\": \"cli-channelid-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"the-language-of-your-transcription-job\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n        },\n        \"StartTime\": \"2020-09-17T16:07:56.817000+00:00\",\n        \"CreationTime\": \"2020-09-17T16:07:56.784000+00:00\",\n        \"Settings\": {\n            \"ChannelIdentification\": true\n        }\n    }\n}\n\n\nFor more information, see Transcribing Multi-Channel Audio in the Amazon Transcribe Developer Guide.\n\nExample 3: To transcribe an audio file and identify the different speakers\n\nThe following start-transcription-job example transcribes your audio file and identifies the speakers in the transcription output.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://mythirdfile.json\n\n\nContents of mythirdfile.json:\n\n{\n    \"TranscriptionJobName\": \"cli-speakerid-job\",\n    \"LanguageCode\": \"the-language-of-your-transcription-job\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n    },\n    \"Settings\":{\n    \"ShowSpeakerLabels\": true,\n    \"MaxSpeakerLabels\": 2\n    }\n}\n\n\nOutput:\n\n{\n    \"TranscriptionJob\": {\n        \"TranscriptionJobName\": \"cli-speakerid-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"the-language-of-your-transcription-job\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n        },\n        \"StartTime\": \"2020-09-17T16:22:59.696000+00:00\",\n        \"CreationTime\": \"2020-09-17T16:22:59.676000+00:00\",\n        \"Settings\": {\n            \"ShowSpeakerLabels\": true,\n            \"MaxSpeakerLabels\": 2\n        }\n    }\n}\n\n\nFor more information, see Identifying Speakers in the Amazon Transcribe Developer Guide.\n\nExample 4: To transcribe an audio file and mask any unwanted words in the transcription output\n\nThe following start-transcription-job example transcribes your audio file and uses a vocabulary filter you’ve previously created to mask any unwanted words.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://myfourthfile.json\n\n\nContents of myfourthfile.json:\n\n{\n    \"TranscriptionJobName\": \"cli-filter-mask-job\",\n    \"LanguageCode\": \"the-language-of-your-transcription-job\",\n    \"Media\": {\n          \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n    },\n    \"Settings\":{\n        \"VocabularyFilterName\": \"your-vocabulary-filter\",\n        \"VocabularyFilterMethod\": \"mask\"\n    }\n}\n\n\nOutput:\n\n{\n    \"TranscriptionJob\": {\n        \"TranscriptionJobName\": \"cli-filter-mask-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"the-language-of-your-transcription-job\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://Amazon-S3-Prefix/your-media-file.file-extension\"\n        },\n        \"StartTime\": \"2020-09-18T16:36:18.568000+00:00\",\n        \"CreationTime\": \"2020-09-18T16:36:18.547000+00:00\",\n        \"Settings\": {\n            \"VocabularyFilterName\": \"your-vocabulary-filter\",\n            \"VocabularyFilterMethod\": \"mask\"\n        }\n    }\n}\n\n\nFor more information, see Filtering Transcriptions in the Amazon Transcribe Developer Guide.\n\nExample 5: To transcribe an audio file and remove any unwanted words in the transcription output\n\nThe following start-transcription-job example transcribes your audio file and uses a vocabulary filter you’ve previously created to mask any unwanted words.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://myfifthfile.json\n\n\nContents of myfifthfile.json:\n\n{\n    \"TranscriptionJobName\": \"cli-filter-remove-job\",\n    \"LanguageCode\": \"the-language-of-your-transcription-job\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n    },\n    \"Settings\":{\n        \"VocabularyFilterName\": \"your-vocabulary-filter\",\n        \"VocabularyFilterMethod\": \"remove\"\n    }\n}\n\n\nOutput:\n\n{\n    \"TranscriptionJob\": {\n        \"TranscriptionJobName\": \"cli-filter-remove-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"the-language-of-your-transcription-job\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n        },\n        \"StartTime\": \"2020-09-18T16:36:18.568000+00:00\",\n        \"CreationTime\": \"2020-09-18T16:36:18.547000+00:00\",\n        \"Settings\": {\n            \"VocabularyFilterName\": \"your-vocabulary-filter\",\n            \"VocabularyFilterMethod\": \"remove\"\n        }\n    }\n}\n\n\nFor more information, see Filtering Transcriptions in the Amazon Transcribe Developer Guide.\n\nExample 6: To transcribe an audio file with increased accuracy using a custom vocabulary\n\nThe following start-transcription-job example transcribes your audio file and uses a vocabulary filter you’ve previously created to mask any unwanted words.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://mysixthfile.json\n\n\nContents of mysixthfile.json:\n\n{\n    \"TranscriptionJobName\": \"cli-vocab-job\",\n    \"LanguageCode\": \"the-language-of-your-transcription-job\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n    },\n    \"Settings\":{\n        \"VocabularyName\": \"your-vocabulary\"\n    }\n}\n\n\nOutput:\n\n{\n    \"TranscriptionJob\": {\n        \"TranscriptionJobName\": \"cli-vocab-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"the-language-of-your-transcription-job\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n        },\n        \"StartTime\": \"2020-09-18T16:36:18.568000+00:00\",\n        \"CreationTime\": \"2020-09-18T16:36:18.547000+00:00\",\n        \"Settings\": {\n            \"VocabularyName\": \"your-vocabulary\"\n        }\n    }\n}\n\n\nFor more information, see Filtering Transcriptions in the Amazon Transcribe Developer Guide.\n\nExample 7: To identify the language of an audio file and transcribe it\n\nThe following start-transcription-job example transcribes your audio file and uses a vocabulary filter you’ve previously created to mask any unwanted words.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://myseventhfile.json\n\n\nContents of myseventhfile.json:\n\n{\n    \"TranscriptionJobName\": \"cli-identify-language-transcription-job\",\n    \"IdentifyLanguage\": true,\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n    }\n}\n\n\nOutput:\n\n{\n    \"TranscriptionJob\": {\n        \"TranscriptionJobName\": \"cli-identify-language-transcription-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension\"\n        },\n        \"StartTime\": \"2020-09-18T22:27:23.970000+00:00\",\n        \"CreationTime\": \"2020-09-18T22:27:23.948000+00:00\",\n        \"IdentifyLanguage\": true\n    }\n}\n\n\nFor more information, see Identifying the Language in the Amazon Transcribe Developer Guide.\n\nExample 8: To transcribe an audio file with personally identifiable information redacted\n\nThe following start-transcription-job example transcribes your audio file and redacts any personally identifiable information in the transcription output.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://myeighthfile.json\n\n\nContents of myeigthfile.json:\n\n{\n    \"TranscriptionJobName\": \"cli-redaction-job\",\n    \"LanguageCode\": \"language-code\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://Amazon-S3-Prefix/your-media-file.file-extension\"\n    },\n    \"ContentRedaction\": {\n        \"RedactionOutput\":\"redacted\",\n        \"RedactionType\":\"PII\"\n    }\n}\n\n\nOutput:\n\n{\n    \"TranscriptionJob\": {\n        \"TranscriptionJobName\": \"cli-redaction-job\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"language-code\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://Amazon-S3-Prefix/your-media-file.file-extension\"\n        },\n        \"StartTime\": \"2020-09-25T23:49:13.195000+00:00\",\n        \"CreationTime\": \"2020-09-25T23:49:13.176000+00:00\",\n        \"ContentRedaction\": {\n            \"RedactionType\": \"PII\",\n            \"RedactionOutput\": \"redacted\"\n        }\n    }\n}\n\n\nFor more information, see Automatic Content Redaction in the Amazon Transcribe Developer Guide.\n\nExample 9: To generate a transcript with personally identifiable information (PII) redacted and an unredacted transcript\n\nThe following start-transcription-job example generates two transcrptions of your audio file, one with the personally identifiable information redacted, and the other without any redactions.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://myninthfile.json\n\n\nContents of myninthfile.json:\n\n{\n    \"TranscriptionJobName\": \"cli-redaction-job-with-unredacted-transcript\",\n    \"LanguageCode\": \"language-code\",\n    \"Media\": {\n          \"MediaFileUri\": \"s3://Amazon-S3-Prefix/your-media-file.file-extension\"\n        },\n    \"ContentRedaction\": {\n        \"RedactionOutput\":\"redacted_and_unredacted\",\n        \"RedactionType\":\"PII\"\n    }\n}\n\n\nOutput:\n\n{\n    \"TranscriptionJob\": {\n        \"TranscriptionJobName\": \"cli-redaction-job-with-unredacted-transcript\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"language-code\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://Amazon-S3-Prefix/your-media-file.file-extension\"\n        },\n        \"StartTime\": \"2020-09-25T23:59:47.677000+00:00\",\n        \"CreationTime\": \"2020-09-25T23:59:47.653000+00:00\",\n        \"ContentRedaction\": {\n            \"RedactionType\": \"PII\",\n            \"RedactionOutput\": \"redacted_and_unredacted\"\n        }\n    }\n}\n\n\nFor more information, see Automatic Content Redaction in the Amazon Transcribe Developer Guide.\n\nExample 10: To use a custom language model you’ve previously created to transcribe an audio file.\n\nThe following start-transcription-job example transcribes your audio file with a custom language model you’ve previously created.\n\naws transcribe start-transcription-job \\\n    --cli-input-json file://mytenthfile.json\n\n\nContents of mytenthfile.json:\n\n{\n    \"TranscriptionJobName\": \"cli-clm-2-job-1\",\n    \"LanguageCode\": \"language-code\",\n    \"Media\": {\n        \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.file-extension\"\n    },\n    \"ModelSettings\": {\n        \"LanguageModelName\":\"cli-clm-2\"\n    }\n}\n\n\nOutput:\n\n{\n    \"TranscriptionJob\": {\n        \"TranscriptionJobName\": \"cli-clm-2-job-1\",\n        \"TranscriptionJobStatus\": \"IN_PROGRESS\",\n        \"LanguageCode\": \"language-code\",\n        \"Media\": {\n            \"MediaFileUri\": \"s3://DOC-EXAMPLE-BUCKET/your-audio-file.file-extension\"\n        },\n        \"StartTime\": \"2020-09-28T17:56:01.835000+00:00\",\n        \"CreationTime\": \"2020-09-28T17:56:01.801000+00:00\",\n        \"ModelSettings\": {\n            \"LanguageModelName\": \"cli-clm-2\"\n        }\n    }\n}\n\n\nFor more information, see Improving Domain-Specific Transcription Accuracy with Custom Language Models in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "tag-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/tag-resource.html",
      "command_description": "Description\n\nTags a Amazon Transcribe resource with the given list of tags.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  tag-resource\n--resource-arn <value>\n--tags <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "--tags <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe Amazon Resource Name (ARN) of the Amazon Transcribe resource you want to tag.\n\n--tags (list)\n\nThe tags you are assigning to a given Amazon Transcribe resource.\n\n(structure)\n\nA key:value pair that adds metadata to a resource used by Amazon Transcribe. For example, a tag with the key:value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by your organization’s sales department.\n\nKey -> (string)\n\nThe first part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the key is ‘Department’.\n\nValue -> (string)\n\nThe second part of a key:value pair that forms a tag associated with a given resource. For example, in the tag ‘Department’:’Sales’, the value is ‘Sales’.\n\nShorthand Syntax:\n\nKey=string,Value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"Key\": \"string\",\n    \"Value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "untag-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/untag-resource.html",
      "command_description": "Description\n\nRemoves specified tags from a specified Amazon Transcribe resource.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  untag-resource\n--resource-arn <value>\n--tag-keys <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "--tag-keys <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe Amazon Resource Name (ARN) of the Amazon Transcribe resource you want to remove tags from.\n\n--tag-keys (list)\n\nA list of tag keys you want to remove from a specified Amazon Transcribe resource.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone"
    },
    {
      "command_name": "update-call-analytics-category",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/update-call-analytics-category.html",
      "command_description": "Description\n\nUpdates the call analytics category with new values. The UpdateCallAnalyticsCategory operation overwrites all of the existing information with the values that you provide in the request.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-call-analytics-category\n--category-name <value>\n--rules <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--category-name <value>",
        "--rules <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--category-name (string)\n\nThe name of the analytics category to update. The name is case sensitive. If you try to update a call analytics category with the same name as a previous category you will receive a ConflictException error.\n\n--rules (list)\n\nThe rules used for the updated analytics category. The rules that you provide in this field replace the ones that are currently being used.\n\n(structure)\n\nA condition in the call between the customer and the agent that you want to filter for.\n\nNonTalkTimeFilter -> (structure)\n\nA condition for a time period when neither the customer nor the agent was talking.\n\nThreshold -> (long)\n\nThe duration of the period when neither the customer nor agent was talking.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when no one is talking. For example, you could specify a time period between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was silence. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period when people were talking.\n\nInterruptionFilter -> (structure)\n\nA condition for a time period when either the customer or agent was interrupting the other person.\n\nThreshold -> (long)\n\nThe duration of the interruption.\n\nParticipantRole -> (string)\n\nIndicates whether the caller or customer was interrupting.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when you’d want to find the interruption. For example, you could search for an interruption between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was a interruption. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period where there was no interruption.\n\nTranscriptFilter -> (structure)\n\nA condition that catches particular words or phrases based on a exact match. For example, if you set the phrase “I want to speak to the manager”, only that exact phrase will be returned.\n\nTranscriptFilterType -> (string)\n\nMatches the phrase to the transcription output in a word for word fashion. For example, if you specify the phrase “I want to speak to the manager.” Amazon Transcribe attempts to match that specific phrase to the transcription.\n\nAbsoluteTimeRange -> (structure)\n\nA time range, set in seconds, between two points in the call.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where you would like to apply a filter. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nDetermines whether the customer or the agent is speaking the phrases that you’ve specified.\n\nNegate -> (boolean)\n\nIf TRUE , the rule that you specify is applied to everything except for the phrases that you specify.\n\nTargets -> (list)\n\nThe phrases that you’re specifying for the transcript filter to match.\n\n(string)\n\nSentimentFilter -> (structure)\n\nA condition that is applied to a particular customer sentiment.\n\nSentiments -> (list)\n\nAn array that enables you to specify sentiments for the customer or agent. You can specify one or more values.\n\n(string)\n\nAbsoluteTimeRange -> (structure)\n\nThe time range, measured in seconds, of the sentiment.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nThe time range, set in percentages, that correspond to proportion of the call.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nA value that determines whether the sentiment belongs to the customer or the agent.\n\nNegate -> (boolean)\n\nSet to TRUE to look for sentiments that weren’t specified in the request.\n\nShorthand Syntax:\n\nNonTalkTimeFilter={Threshold=long,AbsoluteTimeRange={StartTime=long,EndTime=long,First=long,Last=long},RelativeTimeRange={StartPercentage=integer,EndPercentage=integer,First=integer,Last=integer},Negate=boolean},InterruptionFilter={Threshold=long,ParticipantRole=string,AbsoluteTimeRange={StartTime=long,EndTime=long,First=long,Last=long},RelativeTimeRange={StartPercentage=integer,EndPercentage=integer,First=integer,Last=integer},Negate=boolean},TranscriptFilter={TranscriptFilterType=string,AbsoluteTimeRange={StartTime=long,EndTime=long,First=long,Last=long},RelativeTimeRange={StartPercentage=integer,EndPercentage=integer,First=integer,Last=integer},ParticipantRole=string,Negate=boolean,Targets=[string,string]},SentimentFilter={Sentiments=[string,string],AbsoluteTimeRange={StartTime=long,EndTime=long,First=long,Last=long},RelativeTimeRange={StartPercentage=integer,EndPercentage=integer,First=integer,Last=integer},ParticipantRole=string,Negate=boolean} ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"NonTalkTimeFilter\": {\n      \"Threshold\": long,\n      \"AbsoluteTimeRange\": {\n        \"StartTime\": long,\n        \"EndTime\": long,\n        \"First\": long,\n        \"Last\": long\n      },\n      \"RelativeTimeRange\": {\n        \"StartPercentage\": integer,\n        \"EndPercentage\": integer,\n        \"First\": integer,\n        \"Last\": integer\n      },\n      \"Negate\": true|false\n    },\n    \"InterruptionFilter\": {\n      \"Threshold\": long,\n      \"ParticipantRole\": \"AGENT\"|\"CUSTOMER\",\n      \"AbsoluteTimeRange\": {\n        \"StartTime\": long,\n        \"EndTime\": long,\n        \"First\": long,\n        \"Last\": long\n      },\n      \"RelativeTimeRange\": {\n        \"StartPercentage\": integer,\n        \"EndPercentage\": integer,\n        \"First\": integer,\n        \"Last\": integer\n      },\n      \"Negate\": true|false\n    },\n    \"TranscriptFilter\": {\n      \"TranscriptFilterType\": \"EXACT\",\n      \"AbsoluteTimeRange\": {\n        \"StartTime\": long,\n        \"EndTime\": long,\n        \"First\": long,\n        \"Last\": long\n      },\n      \"RelativeTimeRange\": {\n        \"StartPercentage\": integer,\n        \"EndPercentage\": integer,\n        \"First\": integer,\n        \"Last\": integer\n      },\n      \"ParticipantRole\": \"AGENT\"|\"CUSTOMER\",\n      \"Negate\": true|false,\n      \"Targets\": [\"string\", ...]\n    },\n    \"SentimentFilter\": {\n      \"Sentiments\": [\"POSITIVE\"|\"NEGATIVE\"|\"NEUTRAL\"|\"MIXED\", ...],\n      \"AbsoluteTimeRange\": {\n        \"StartTime\": long,\n        \"EndTime\": long,\n        \"First\": long,\n        \"Last\": long\n      },\n      \"RelativeTimeRange\": {\n        \"StartPercentage\": integer,\n        \"EndPercentage\": integer,\n        \"First\": integer,\n        \"Last\": integer\n      },\n      \"ParticipantRole\": \"AGENT\"|\"CUSTOMER\",\n      \"Negate\": true|false\n    }\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nCategoryProperties -> (structure)\n\nThe attributes describing the analytics category. You can see information such as the rules that you’ve used to update the category and when the category was originally created.\n\nCategoryName -> (string)\n\nThe name of the call analytics category.\n\nRules -> (list)\n\nThe rules used to create a call analytics category.\n\n(structure)\n\nA condition in the call between the customer and the agent that you want to filter for.\n\nNonTalkTimeFilter -> (structure)\n\nA condition for a time period when neither the customer nor the agent was talking.\n\nThreshold -> (long)\n\nThe duration of the period when neither the customer nor agent was talking.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when no one is talking. For example, you could specify a time period between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was silence. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period when people were talking.\n\nInterruptionFilter -> (structure)\n\nA condition for a time period when either the customer or agent was interrupting the other person.\n\nThreshold -> (long)\n\nThe duration of the interruption.\n\nParticipantRole -> (string)\n\nIndicates whether the caller or customer was interrupting.\n\nAbsoluteTimeRange -> (structure)\n\nAn object you can use to specify a time range (in milliseconds) for when you’d want to find the interruption. For example, you could search for an interruption between the 30,000 millisecond mark and the 45,000 millisecond mark. You could also specify the time period as the first 15,000 milliseconds or the last 15,000 milliseconds.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where there was a interruption. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nNegate -> (boolean)\n\nSet to TRUE to look for a time period where there was no interruption.\n\nTranscriptFilter -> (structure)\n\nA condition that catches particular words or phrases based on a exact match. For example, if you set the phrase “I want to speak to the manager”, only that exact phrase will be returned.\n\nTranscriptFilterType -> (string)\n\nMatches the phrase to the transcription output in a word for word fashion. For example, if you specify the phrase “I want to speak to the manager.” Amazon Transcribe attempts to match that specific phrase to the transcription.\n\nAbsoluteTimeRange -> (structure)\n\nA time range, set in seconds, between two points in the call.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nAn object that allows percentages to specify the proportion of the call where you would like to apply a filter. For example, you can specify the first half of the call. You can also specify the period of time between halfway through to three-quarters of the way through the call. Because the length of conversation can vary between calls, you can apply relative time ranges across all calls.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nDetermines whether the customer or the agent is speaking the phrases that you’ve specified.\n\nNegate -> (boolean)\n\nIf TRUE , the rule that you specify is applied to everything except for the phrases that you specify.\n\nTargets -> (list)\n\nThe phrases that you’re specifying for the transcript filter to match.\n\n(string)\n\nSentimentFilter -> (structure)\n\nA condition that is applied to a particular customer sentiment.\n\nSentiments -> (list)\n\nAn array that enables you to specify sentiments for the customer or agent. You can specify one or more values.\n\n(string)\n\nAbsoluteTimeRange -> (structure)\n\nThe time range, measured in seconds, of the sentiment.\n\nStartTime -> (long)\n\nA value that indicates the beginning of the time range in seconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nEndTime -> (long)\n\nA value that indicates the end of the time range in milliseconds. To set absolute time range, you must specify a start time and an end time. For example, if you specify the following values:\n\nStartTime - 10000\n\nEndtime - 50000\n\nThe time range is set between 10,000 milliseconds and 50,000 milliseconds into the call.\n\nFirst -> (long)\n\nA time range from the beginning of the call to the value that you’ve specified. For example, if you specify 100000, the time range is set to the first 100,000 milliseconds of the call.\n\nLast -> (long)\n\nA time range from the value that you’ve specified to the end of the call. For example, if you specify 100000, the time range is set to the last 100,000 milliseconds of the call.\n\nRelativeTimeRange -> (structure)\n\nThe time range, set in percentages, that correspond to proportion of the call.\n\nStartPercentage -> (integer)\n\nA value that indicates the percentage of the beginning of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nEndPercentage -> (integer)\n\nA value that indicates the percentage of the end of the time range. To set a relative time range, you must specify a start percentage and an end percentage. For example, if you specify the following values:\n\nStartPercentage - 10\n\nEndPercentage - 50\n\nThis looks at the time range starting from 10% of the way into the call to 50% of the way through the call. For a call that lasts 100,000 milliseconds, this example range would apply from the 10,000 millisecond mark to the 50,000 millisecond mark.\n\nFirst -> (integer)\n\nA range that takes the portion of the call up to the time in milliseconds set by the value that you’ve specified. For example, if you specify 120000 , the time range is set for the first 120,000 milliseconds of the call.\n\nLast -> (integer)\n\nA range that takes the portion of the call from the time in milliseconds set by the value that you’ve specified to the end of the call. For example, if you specify 120000 , the time range is set for the last 120,000 milliseconds of the call.\n\nParticipantRole -> (string)\n\nA value that determines whether the sentiment belongs to the customer or the agent.\n\nNegate -> (boolean)\n\nSet to TRUE to look for sentiments that weren’t specified in the request.\n\nCreateTime -> (timestamp)\n\nA timestamp that shows when the call analytics category was created.\n\nLastUpdateTime -> (timestamp)\n\nA timestamp that shows when the call analytics category was most recently updated."
    },
    {
      "command_name": "update-medical-vocabulary",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/update-medical-vocabulary.html",
      "command_description": "Description\n\nUpdates a vocabulary with new values that you provide in a different text file from the one you used to create the vocabulary. The UpdateMedicalVocabulary operation overwrites all of the existing information with the values that you provide in the request.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-medical-vocabulary\n--vocabulary-name <value>\n--language-code <value>\n[--vocabulary-file-uri <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-name <value>",
        "--language-code <value>",
        "[--vocabulary-file-uri <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-name (string)\n\nThe name of the vocabulary to update. The name is case sensitive. If you try to update a vocabulary with the same name as a vocabulary you’ve already made, you get a ConflictException error.\n\n--language-code (string)\n\nThe language code of the language used for the entries in the updated vocabulary. US English (en-US) is the only valid language code in Amazon Transcribe Medical.\n\nPossible values:\n\naf-ZA\n\nar-AE\n\nar-SA\n\ncy-GB\n\nda-DK\n\nde-CH\n\nde-DE\n\nen-AB\n\nen-AU\n\nen-GB\n\nen-IE\n\nen-IN\n\nen-US\n\nen-WL\n\nes-ES\n\nes-US\n\nfa-IR\n\nfr-CA\n\nfr-FR\n\nga-IE\n\ngd-GB\n\nhe-IL\n\nhi-IN\n\nid-ID\n\nit-IT\n\nja-JP\n\nko-KR\n\nms-MY\n\nnl-NL\n\npt-BR\n\npt-PT\n\nru-RU\n\nta-IN\n\nte-IN\n\ntr-TR\n\nzh-CN\n\nzh-TW\n\nth-TH\n\nen-ZA\n\nen-NZ\n\n--vocabulary-file-uri (string)\n\nThe location in Amazon S3 of the text file that contains your custom vocabulary. The URI must be in the same Amazon Web Services Region as the resource that you are calling. The following is the format for a URI:\n\nhttps://s3.<aws-region>.amazonaws.com/<bucket-name>/<keyprefix>/<objectkey>\n\nFor example:\n\nhttps://s3.us-east-1.amazonaws.com/AWSDOC-EXAMPLE-BUCKET/vocab.txt\n\nFor more information about Amazon S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nFor more information about custom vocabularies in Amazon Transcribe Medical, see Medical Custom Vocabularies .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nVocabularyName -> (string)\n\nThe name of the updated vocabulary.\n\nLanguageCode -> (string)\n\nThe language code for the language of the text file used to update the custom vocabulary. US English (en-US) is the only language supported in Amazon Transcribe Medical.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the vocabulary was updated.\n\nVocabularyState -> (string)\n\nThe processing state of the update to the vocabulary. When the VocabularyState field is READY , the vocabulary is ready to be used in a StartMedicalTranscriptionJob request.",
      "command_examples": "Examples\n\nTo update a medical custom vocabulary with new terms.\n\nThe following update-medical-vocabulary example replaces the terms used in a medical custom vocabulary with the new ones. Prerequisite: to replace the terms in a medical custom vocabulary, you need a file with new terms.\n\naws transcribe update-medical-vocabulary \\\n    --vocabulary-file-uri s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix/medical-custom-vocabulary.txt \\\n    --vocabulary-name medical-custom-vocabulary \\\n    --language-code language\n\n\nOutput:\n\n{\n    \"VocabularyName\": \"medical-custom-vocabulary\",\n    \"LanguageCode\": \"en-US\",\n    \"VocabularyState\": \"PENDING\"\n}\n\n\nFor more information, see Medical Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "update-vocabulary",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/update-vocabulary.html",
      "command_description": "Description\n\nUpdates an existing vocabulary with new values. The UpdateVocabulary operation overwrites all of the existing information with the values that you provide in the request.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-vocabulary\n--vocabulary-name <value>\n--language-code <value>\n[--phrases <value>]\n[--vocabulary-file-uri <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-name <value>",
        "--language-code <value>",
        "[--phrases <value>]",
        "[--vocabulary-file-uri <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-name (string)\n\nThe name of the vocabulary to update. The name is case sensitive. If you try to update a vocabulary with the same name as a previous vocabulary you will receive a ConflictException error.\n\n--language-code (string)\n\nThe language code of the vocabulary entries. For a list of languages and their corresponding language codes, see transcribe-whatis .\n\nPossible values:\n\naf-ZA\n\nar-AE\n\nar-SA\n\ncy-GB\n\nda-DK\n\nde-CH\n\nde-DE\n\nen-AB\n\nen-AU\n\nen-GB\n\nen-IE\n\nen-IN\n\nen-US\n\nen-WL\n\nes-ES\n\nes-US\n\nfa-IR\n\nfr-CA\n\nfr-FR\n\nga-IE\n\ngd-GB\n\nhe-IL\n\nhi-IN\n\nid-ID\n\nit-IT\n\nja-JP\n\nko-KR\n\nms-MY\n\nnl-NL\n\npt-BR\n\npt-PT\n\nru-RU\n\nta-IN\n\nte-IN\n\ntr-TR\n\nzh-CN\n\nzh-TW\n\nth-TH\n\nen-ZA\n\nen-NZ\n\n--phrases (list)\n\nAn array of strings containing the vocabulary entries.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--vocabulary-file-uri (string)\n\nThe S3 location of the text file that contains the definition of the custom vocabulary. The URI must be in the same region as the API endpoint that you are calling. The general form is\n\nFor example:\n\nFor more information about S3 object names, see Object Keys in the Amazon S3 Developer Guide .\n\nFor more information about custom vocabularies, see Custom Vocabularies .\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nVocabularyName -> (string)\n\nThe name of the vocabulary that was updated.\n\nLanguageCode -> (string)\n\nThe language code of the vocabulary entries.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the vocabulary was updated.\n\nVocabularyState -> (string)\n\nThe processing state of the vocabulary. When the VocabularyState field contains READY the vocabulary is ready to be used in a StartTranscriptionJob request.",
      "command_examples": "Examples\n\nTo update a custom vocabulary with new terms.\n\nThe following update-vocabulary example overwrites the terms used to create a custom vocabulary with the new ones that you provide. Prerequisite: to replace the terms in a custom vocabulary, you need a file with new terms.\n\naws transcribe update-vocabulary \\\n    --vocabulary-file-uri s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix/custom-vocabulary.txt \\\n    --vocabulary-name custom-vocabulary \\\n    --language-code language-code\n\n\nOutput:\n\n{\n    \"VocabularyName\": \"custom-vocabulary\",\n    \"LanguageCode\": \"language\",\n    \"VocabularyState\": \"PENDING\"\n}\n\n\nFor more information, see Custom Vocabularies in the Amazon Transcribe Developer Guide."
    },
    {
      "command_name": "update-vocabulary-filter",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/transcribe/update-vocabulary-filter.html",
      "command_description": "Description\n\nUpdates a vocabulary filter with a new list of filtered words.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-vocabulary-filter\n--vocabulary-filter-name <value>\n[--words <value>]\n[--vocabulary-filter-file-uri <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--vocabulary-filter-name <value>",
        "[--words <value>]",
        "[--vocabulary-filter-file-uri <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--vocabulary-filter-name (string)\n\nThe name of the vocabulary filter to update. If you try to update a vocabulary filter with the same name as another vocabulary filter, you get a ConflictException error.\n\n--words (list)\n\nThe words to use in the vocabulary filter. Only use characters from the character set defined for custom vocabularies. For a list of character sets, see Character Sets for Custom Vocabularies .\n\nIf you provide a list of words in the Words parameter, you can’t use the VocabularyFilterFileUri parameter.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--vocabulary-filter-file-uri (string)\n\nThe Amazon S3 location of a text file used as input to create the vocabulary filter. Only use characters from the character set defined for custom vocabularies. For a list of character sets, see Character Sets for Custom Vocabularies .\n\nThe specified file must be less than 50 KB of UTF-8 characters.\n\nIf you provide the location of a list of words in the VocabularyFilterFileUri parameter, you can’t use the Words parameter.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nVocabularyFilterName -> (string)\n\nThe name of the updated vocabulary filter.\n\nLanguageCode -> (string)\n\nThe language code of the words in the vocabulary filter.\n\nLastModifiedTime -> (timestamp)\n\nThe date and time that the vocabulary filter was updated.",
      "command_examples": "Examples\n\nTo replace the words in a vocabulary filter\n\nThe following update-vocabulary-filter example replaces the words in a vocabulary filter with new ones. Prerequisite: To update a vocabulary filter with the new words, you must have those words saved as a text file.\n\naws transcribe update-vocabulary-filter \\\n    --vocabulary-filter-file-uri s3://DOC-EXAMPLE-BUCKET/Amazon-S3-Prefix/your-text-file-to-update-your-vocabulary-filter.txt \\\n    --vocabulary-filter-name vocabulary-filter-name\n\n\nOutput:\n\n{\n    \"VocabularyFilterName\": \"vocabulary-filter-name\",\n    \"LanguageCode\": \"language-code\",\n    \"LastModifiedTime\": \"2020-09-23T18:40:35.139000+00:00\"\n}\n\n\nFor more information, see Filtering Unwanted Words in the Amazon Transcribe Developer Guide."
    }
  ],
  "service_description": "Description\n\nOperations and objects for transcribing speech to text."
}