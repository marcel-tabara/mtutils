{
  "service_name": "iotanalytics",
  "service_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/index.html",
  "service_commands": [
    {
      "command_name": "batch-put-message",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/batch-put-message.html",
      "command_description": "Description\n\nSends messages to a channel.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  batch-put-message\n--channel-name <value>\n--messages <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-name <value>",
        "--messages <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-name (string)\n\nThe name of the channel where the messages are sent.\n\n--messages (list)\n\nThe list of messages to be sent. Each message has the format: { “messageId”: “string”, “payload”: “string”}.\n\nThe field names of message payloads (data) that you send to IoT Analytics:\n\nMust contain only alphanumeric characters and undescores (_). No other special characters are allowed.\n\nMust begin with an alphabetic character or single underscore (_).\n\nCannot contain hyphens (-).\n\nIn regular expression terms: “^[A-Za-z_]([A-Za-z0-9]*|[A-Za-z0-9][A-Za-z0-9_]*)$”.\n\nCannot be more than 255 characters.\n\nAre case insensitive. (Fields named foo and FOO in the same payload are considered duplicates.)\n\nFor example, {“temp_01”: 29} or {“_temp_01”: 29} are valid, but {“temp-01”: 29}, {“01_temp”: 29} or {“__temp_01”: 29} are invalid in message payloads.\n\n(structure)\n\nInformation about a message.\n\nmessageId -> (string)\n\nThe ID you want to assign to the message. Each messageId must be unique within each batch sent.\n\npayload -> (blob)\n\nThe payload of the message. This can be a JSON string or a base64-encoded string representing binary data, in which case you must decode it by means of a pipeline activity.\n\nShorthand Syntax:\n\nmessageId=string,payload=blob ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"messageId\": \"string\",\n    \"payload\": blob\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nbatchPutMessageErrorEntries -> (list)\n\nA list of any errors encountered when sending the messages to the channel.\n\n(structure)\n\nContains informations about errors.\n\nmessageId -> (string)\n\nThe ID of the message that caused the error. See the value corresponding to the messageId key in the message object.\n\nerrorCode -> (string)\n\nThe code associated with the error.\n\nerrorMessage -> (string)\n\nThe message associated with the error.",
      "command_examples": "Examples\n\nTo send a message to a channel\n\nThe following batch-put-message example sends a message to the specified channel.\n\naws iotanalytics batch-put-message \\\n    --cli-input-json file://batch-put-message.json\n\n\nContents of batch-put-message.json:\n\n{\n    \"channelName\": \"mychannel\",\n    \"messages\": [\n        {\n            \"messageId\": \"0001\",\n            \"payload\": \"eyAidGVtcGVyYXR1cmUiOiAyMCB9\"\n        }\n    ]\n}\n\n\nOutput:\n\n{\n    \"batchPutMessageErrorEntries\": []\n}\n\n\nFor more information, see BatchPutMessage in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "cancel-pipeline-reprocessing",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/cancel-pipeline-reprocessing.html",
      "command_description": "Description\n\nCancels the reprocessing of data through the pipeline.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  cancel-pipeline-reprocessing\n--pipeline-name <value>\n--reprocessing-id <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--pipeline-name <value>",
        "--reprocessing-id <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--pipeline-name (string)\n\nThe name of pipeline for which data reprocessing is canceled.\n\n--reprocessing-id (string)\n\nThe ID of the reprocessing task (returned by StartPipelineReprocessing ).\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo cancel the reprocessing of data through a pipeline\n\nThe following cancel-pipeline-reprocessing example cancels the reprocessing of data through the specified pipeline.\n\naws iotanalytics cancel-pipeline-reprocessing \\\n    --pipeline-name mypipeline \\\n    --reprocessing-id \"6ad2764f-fb13-4de3-b101-4e74af03b043\"\n\n\nThis command produces no output.\n\nFor more information, see CancelPipelineReprocessing in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "create-channel",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/create-channel.html",
      "command_description": "Description\n\nUsed to create a channel. A channel collects data from an MQTT topic and archives the raw, unprocessed messages before publishing the data to a pipeline.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-channel\n--channel-name <value>\n[--channel-storage <value>]\n[--retention-period <value>]\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-name <value>",
        "[--channel-storage <value>]",
        "[--retention-period <value>]",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-name (string)\n\nThe name of the channel.\n\n--channel-storage (structure)\n\nWhere channel data is stored. You can choose one of serviceManagedS3 or customerManagedS3 storage. If not specified, the default is serviceManagedS3 . You can’t change this storage option after the channel is created.\n\nserviceManagedS3 -> (structure)\n\nUsed to store channel data in an S3 bucket managed by IoT Analytics. You can’t change the choice of S3 storage after the data store is created.\n\ncustomerManagedS3 -> (structure)\n\nUsed to store channel data in an S3 bucket that you manage. If customer managed storage is selected, the retentionPeriod parameter is ignored. You can’t change the choice of S3 storage after the data store is created.\n\nbucket -> (string)\n\nThe name of the S3 bucket in which channel data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the channel data objects. Each object in an S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 resources.\n\nShorthand Syntax:\n\nserviceManagedS3={},customerManagedS3={bucket=string,keyPrefix=string,roleArn=string}\n\n\nJSON Syntax:\n\n{\n  \"serviceManagedS3\": {\n\n  },\n  \"customerManagedS3\": {\n    \"bucket\": \"string\",\n    \"keyPrefix\": \"string\",\n    \"roleArn\": \"string\"\n  }\n}\n\n\n--retention-period (structure)\n\nHow long, in days, message data is kept for the channel. When customerManagedS3 storage is selected, this parameter is ignored.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.\n\nShorthand Syntax:\n\nunlimited=boolean,numberOfDays=integer\n\n\nJSON Syntax:\n\n{\n  \"unlimited\": true|false,\n  \"numberOfDays\": integer\n}\n\n\n--tags (list)\n\nMetadata which can be used to manage the channel.\n\n(structure)\n\nA set of key-value pairs that are used to manage the resource.\n\nkey -> (string)\n\nThe tag’s key.\n\nvalue -> (string)\n\nThe tag’s value.\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nchannelName -> (string)\n\nThe name of the channel.\n\nchannelArn -> (string)\n\nThe ARN of the channel.\n\nretentionPeriod -> (structure)\n\nHow long, in days, message data is kept for the channel.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.",
      "command_examples": "Examples\n\nTo create a channel\n\nThe following create-channel example creates a channel with the specified configuration. A channel collects data from an MQTT topic and archives the raw, unprocessed messages before publishing the data to a pipeline.\n\naws iotanalytics create-channel \\\n    --cli-input-json file://create-channel.json\n\n\nContents of create-channel.json:\n\n{\n    \"channelName\": \"mychannel\",\n    \"retentionPeriod\": {\n        \"unlimited\": true\n    },\n    \"tags\": [\n        {\n            \"key\": \"Environment\",\n            \"value\": \"Production\"\n        }\n    ]\n}\n\n\nOutput:\n\n{\n    \"channelArn\": \"arn:aws:iotanalytics:us-west-2:123456789012:channel/mychannel\",\n    \"channelName\": \"mychannel\",\n    \"retentionPeriod\": {\n        \"unlimited\": true\n    }\n}\n\n\nFor more information, see CreateChannel in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "create-dataset",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/create-dataset.html",
      "command_description": "Description\n\nUsed to create a dataset. A dataset stores data retrieved from a data store by applying a queryAction (a SQL query) or a containerAction (executing a containerized application). This operation creates the skeleton of a dataset. The dataset can be populated manually by calling CreateDatasetContent or automatically according to a trigger you specify.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-dataset\n--dataset-name <value>\n--actions <value>\n[--triggers <value>]\n[--content-delivery-rules <value>]\n[--retention-period <value>]\n[--versioning-configuration <value>]\n[--tags <value>]\n[--late-data-rules <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--dataset-name <value>",
        "--actions <value>",
        "[--triggers <value>]",
        "[--content-delivery-rules <value>]",
        "[--retention-period <value>]",
        "[--versioning-configuration <value>]",
        "[--tags <value>]",
        "[--late-data-rules <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--dataset-name (string)\n\nThe name of the dataset.\n\n--actions (list)\n\nA list of actions that create the dataset contents.\n\n(structure)\n\nA DatasetAction object that specifies how dataset contents are automatically created.\n\nactionName -> (string)\n\nThe name of the dataset action by which dataset contents are automatically created.\n\nqueryAction -> (structure)\n\nAn SqlQueryDatasetAction object that uses an SQL query to automatically create dataset contents.\n\nsqlQuery -> (string)\n\nA SQL query string.\n\nfilters -> (list)\n\nPrefilters applied to message data.\n\n(structure)\n\nInformation that is used to filter message data, to segregate it according to the timeframe in which it arrives.\n\ndeltaTime -> (structure)\n\nUsed to limit data to that which has arrived since the last execution of the action.\n\noffsetSeconds -> (integer)\n\nThe number of seconds of estimated in-flight lag time of message data. When you create dataset contents using message data from a specified timeframe, some message data might still be in flight when processing begins, and so do not arrive in time to be processed. Use this field to make allowances for the in flight time of your message data, so that data not processed from a previous timeframe is included with the next timeframe. Otherwise, missed message data would be excluded from processing during the next timeframe too, because its timestamp places it within the previous timeframe.\n\ntimeExpression -> (string)\n\nAn expression by which the time of the message data might be determined. This can be the name of a timestamp field or a SQL expression that is used to derive the time the message data was generated.\n\ncontainerAction -> (structure)\n\nInformation that allows the system to run a containerized application to create the dataset contents. The application must be in a Docker container along with any required support libraries.\n\nimage -> (string)\n\nThe ARN of the Docker container stored in your account. The Docker container contains an application and required support libraries and is used to generate dataset contents.\n\nexecutionRoleArn -> (string)\n\nThe ARN of the role that gives permission to the system to access required resources to run the containerAction . This includes, at minimum, permission to retrieve the dataset contents that are the input to the containerized application.\n\nresourceConfiguration -> (structure)\n\nConfiguration of the resource that executes the containerAction .\n\ncomputeType -> (string)\n\nThe type of the compute resource used to execute the containerAction . Possible values are: ACU_1 (vCPU=4, memory=16 GiB) or ACU_2 (vCPU=8, memory=32 GiB).\n\nvolumeSizeInGB -> (integer)\n\nThe size, in GB, of the persistent storage available to the resource instance used to execute the containerAction (min: 1, max: 50).\n\nvariables -> (list)\n\nThe values of variables used in the context of the execution of the containerized application (basically, parameters passed to the application). Each variable must have a name and a value given by one of stringValue , datasetContentVersionValue , or outputFileUriValue .\n\n(structure)\n\nAn instance of a variable to be passed to the containerAction execution. Each variable must have a name and a value given by one of stringValue , datasetContentVersionValue , or outputFileUriValue .\n\nname -> (string)\n\nThe name of the variable.\n\nstringValue -> (string)\n\nThe value of the variable as a string.\n\ndoubleValue -> (double)\n\nThe value of the variable as a double (numeric).\n\ndatasetContentVersionValue -> (structure)\n\nThe value of the variable as a structure that specifies a dataset content version.\n\ndatasetName -> (string)\n\nThe name of the dataset whose latest contents are used as input to the notebook or application.\n\noutputFileUriValue -> (structure)\n\nThe value of the variable as a structure that specifies an output file URI.\n\nfileName -> (string)\n\nThe URI of the location where dataset contents are stored, usually the URI of a file in an S3 bucket.\n\nJSON Syntax:\n\n[\n  {\n    \"actionName\": \"string\",\n    \"queryAction\": {\n      \"sqlQuery\": \"string\",\n      \"filters\": [\n        {\n          \"deltaTime\": {\n            \"offsetSeconds\": integer,\n            \"timeExpression\": \"string\"\n          }\n        }\n        ...\n      ]\n    },\n    \"containerAction\": {\n      \"image\": \"string\",\n      \"executionRoleArn\": \"string\",\n      \"resourceConfiguration\": {\n        \"computeType\": \"ACU_1\"|\"ACU_2\",\n        \"volumeSizeInGB\": integer\n      },\n      \"variables\": [\n        {\n          \"name\": \"string\",\n          \"stringValue\": \"string\",\n          \"doubleValue\": double,\n          \"datasetContentVersionValue\": {\n            \"datasetName\": \"string\"\n          },\n          \"outputFileUriValue\": {\n            \"fileName\": \"string\"\n          }\n        }\n        ...\n      ]\n    }\n  }\n  ...\n]\n\n\n--triggers (list)\n\nA list of triggers. A trigger causes dataset contents to be populated at a specified time interval or when another dataset’s contents are created. The list of triggers can be empty or contain up to five DataSetTrigger objects.\n\n(structure)\n\nThe DatasetTrigger that specifies when the dataset is automatically updated.\n\nschedule -> (structure)\n\nThe Schedule when the trigger is initiated.\n\nexpression -> (string)\n\nThe expression that defines when to trigger an update. For more information, see Schedule Expressions for Rules in the Amazon CloudWatch Events User Guide .\n\ndataset -> (structure)\n\nThe dataset whose content creation triggers the creation of this dataset’s contents.\n\nname -> (string)\n\nThe name of the dataset whose content generation triggers the new dataset content generation.\n\nShorthand Syntax:\n\nschedule={expression=string},dataset={name=string} ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"schedule\": {\n      \"expression\": \"string\"\n    },\n    \"dataset\": {\n      \"name\": \"string\"\n    }\n  }\n  ...\n]\n\n\n--content-delivery-rules (list)\n\nWhen dataset contents are created, they are delivered to destinations specified here.\n\n(structure)\n\nWhen dataset contents are created, they are delivered to destination specified here.\n\nentryName -> (string)\n\nThe name of the dataset content delivery rules entry.\n\ndestination -> (structure)\n\nThe destination to which dataset contents are delivered.\n\niotEventsDestinationConfiguration -> (structure)\n\nConfiguration information for delivery of dataset contents to IoT Events.\n\ninputName -> (string)\n\nThe name of the IoT Events input to which dataset contents are delivered.\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to deliver dataset contents to an IoT Events input.\n\ns3DestinationConfiguration -> (structure)\n\nConfiguration information for delivery of dataset contents to Amazon S3.\n\nbucket -> (string)\n\nThe name of the S3 bucket to which dataset contents are delivered.\n\nkey -> (string)\n\nThe key of the dataset contents object in an S3 bucket. Each object has a key that is a unique identifier. Each object has exactly one key.\n\nYou can create a unique key with the following options:\n\nUse !{iotanalytics:scheduleTime} to insert the time of a scheduled SQL query run.\n\nUse !{iotanalytics:versionId} to insert a unique hash that identifies a dataset content.\n\nUse !{iotanalytics:creationTime} to insert the creation time of a dataset content.\n\nThe following example creates a unique key for a CSV file: dataset/mydataset/!{iotanalytics:scheduleTime}/!{iotanalytics:versionId}.csv\n\nNote\n\nIf you don’t use !{iotanalytics:versionId} to specify the key, you might get duplicate keys. For example, you might have two dataset contents with the same scheduleTime but different versionId s. This means that one dataset content overwrites the other.\n\nglueConfiguration -> (structure)\n\nConfiguration information for coordination with Glue, a fully managed extract, transform and load (ETL) service.\n\ntableName -> (string)\n\nThe name of the table in your Glue Data Catalog that is used to perform the ETL operations. An Glue Data Catalog table contains partitioned data and descriptions of data sources and targets.\n\ndatabaseName -> (string)\n\nThe name of the database in your Glue Data Catalog in which the table is located. An Glue Data Catalog database contains metadata tables.\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 and Glue resources.\n\nJSON Syntax:\n\n[\n  {\n    \"entryName\": \"string\",\n    \"destination\": {\n      \"iotEventsDestinationConfiguration\": {\n        \"inputName\": \"string\",\n        \"roleArn\": \"string\"\n      },\n      \"s3DestinationConfiguration\": {\n        \"bucket\": \"string\",\n        \"key\": \"string\",\n        \"glueConfiguration\": {\n          \"tableName\": \"string\",\n          \"databaseName\": \"string\"\n        },\n        \"roleArn\": \"string\"\n      }\n    }\n  }\n  ...\n]\n\n\n--retention-period (structure)\n\nOptional. How long, in days, versions of dataset contents are kept for the dataset. If not specified or set to null , versions of dataset contents are retained for at most 90 days. The number of versions of dataset contents retained is determined by the versioningConfiguration parameter. For more information, see Keeping Multiple Versions of IoT Analytics datasets in the IoT Analytics User Guide .\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.\n\nShorthand Syntax:\n\nunlimited=boolean,numberOfDays=integer\n\n\nJSON Syntax:\n\n{\n  \"unlimited\": true|false,\n  \"numberOfDays\": integer\n}\n\n\n--versioning-configuration (structure)\n\nOptional. How many versions of dataset contents are kept. If not specified or set to null, only the latest version plus the latest succeeded version (if they are different) are kept for the time period specified by the retentionPeriod parameter. For more information, see Keeping Multiple Versions of IoT Analytics datasets in the IoT Analytics User Guide .\n\nunlimited -> (boolean)\n\nIf true, unlimited versions of dataset contents are kept.\n\nmaxVersions -> (integer)\n\nHow many versions of dataset contents are kept. The unlimited parameter must be false .\n\nShorthand Syntax:\n\nunlimited=boolean,maxVersions=integer\n\n\nJSON Syntax:\n\n{\n  \"unlimited\": true|false,\n  \"maxVersions\": integer\n}\n\n\n--tags (list)\n\nMetadata which can be used to manage the dataset.\n\n(structure)\n\nA set of key-value pairs that are used to manage the resource.\n\nkey -> (string)\n\nThe tag’s key.\n\nvalue -> (string)\n\nThe tag’s value.\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--late-data-rules (list)\n\nA list of data rules that send notifications to CloudWatch, when data arrives late. To specify lateDataRules , the dataset must use a DeltaTimer filter.\n\n(structure)\n\nA structure that contains the name and configuration information of a late data rule.\n\nruleName -> (string)\n\nThe name of the late data rule.\n\nruleConfiguration -> (structure)\n\nThe information needed to configure the late data rule.\n\ndeltaTimeSessionWindowConfiguration -> (structure)\n\nThe information needed to configure a delta time session window.\n\ntimeoutInMinutes -> (integer)\n\nA time interval. You can use timeoutInMinutes so that IoT Analytics can batch up late data notifications that have been generated since the last execution. IoT Analytics sends one batch of notifications to Amazon CloudWatch Events at one time.\n\nFor more information about how to write a timestamp expression, see Date and Time Functions and Operators , in the Presto 0.172 Documentation .\n\nShorthand Syntax:\n\nruleName=string,ruleConfiguration={deltaTimeSessionWindowConfiguration={timeoutInMinutes=integer}} ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"ruleName\": \"string\",\n    \"ruleConfiguration\": {\n      \"deltaTimeSessionWindowConfiguration\": {\n        \"timeoutInMinutes\": integer\n      }\n    }\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ndatasetName -> (string)\n\nThe name of the dataset.\n\ndatasetArn -> (string)\n\nThe ARN of the dataset.\n\nretentionPeriod -> (structure)\n\nHow long, in days, dataset contents are kept for the dataset.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.",
      "command_examples": "Examples\n\nTo create a dataset\n\nThe following create-dataset example creates a dataset. A dataset stores data retrieved from a data store by applying a queryAction (a SQL query) or a containerAction (executing a containerized application). This operation creates the skeleton of a dataset. You can populate the dataset manually by calling CreateDatasetContent or automatically according to a trigger you specify.\n\naws iotanalytics create-dataset \\\n    --cli-input-json file://create-dataset.json\n\n\nContents of create-dataset.json:\n\n{\n    \"datasetName\": \"mydataset\",\n    \"actions\": [\n        {\n            \"actionName\": \"myDatasetAction\",\n            \"queryAction\": {\n                \"sqlQuery\": \"SELECT * FROM mydatastore\"\n            }\n        }\n    ],\n    \"retentionPeriod\": {\n        \"unlimited\": true\n    },\n    \"tags\": [\n        {\n            \"key\": \"Environment\",\n            \"value\": \"Production\"\n        }\n    ]\n}\n\n\nOutput:\n\n{\n    \"datasetName\": \"mydataset\",\n    \"retentionPeriod\": {\n        \"unlimited\": true\n    },\n    \"datasetArn\": \"arn:aws:iotanalytics:us-west-2:123456789012:dataset/mydataset\"\n}\n\n\nFor more information, see CreateDataset in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "create-dataset-content",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/create-dataset-content.html",
      "command_description": "Description\n\nCreates the content of a dataset by applying a queryAction (a SQL query) or a containerAction (executing a containerized application).\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-dataset-content\n--dataset-name <value>\n[--version-id <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--dataset-name <value>",
        "[--version-id <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--dataset-name (string)\n\nThe name of the dataset.\n\n--version-id (string)\n\nThe version ID of the dataset content. To specify versionId for a dataset content, the dataset must use a DeltaTimer filter.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nversionId -> (string)\n\nThe version ID of the dataset contents that are being created.",
      "command_examples": "Examples\n\nTo create the content of a dataset\n\nThe following create-dataset-content example creates the content of the specified dataset by applying a queryAction (an SQL query) or a containerAction (executing a containerized application).\n\naws iotanalytics create-dataset-content \\\n    --dataset-name mydataset\n\n\nOutput:\n\n{\n    \"versionId\": \"d494b416-9850-4670-b885-ca22f1e89d62\"\n}\n\n\nFor more information, see CreateDatasetContent in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "create-datastore",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/create-datastore.html",
      "command_description": "Description\n\nCreates a data store, which is a repository for messages.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-datastore\n--datastore-name <value>\n[--datastore-storage <value>]\n[--retention-period <value>]\n[--tags <value>]\n[--file-format-configuration <value>]\n[--datastore-partitions <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--datastore-name <value>",
        "[--datastore-storage <value>]",
        "[--retention-period <value>]",
        "[--tags <value>]",
        "[--file-format-configuration <value>]",
        "[--datastore-partitions <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--datastore-name (string)\n\nThe name of the data store.\n\n--datastore-storage (structure)\n\nWhere data in a data store is stored.. You can choose serviceManagedS3 storage, customerManagedS3 storage, or iotSiteWiseMultiLayerStorage storage. The default is serviceManagedS3 . You can’t change the choice of Amazon S3 storage after your data store is created.\n\nserviceManagedS3 -> (structure)\n\nUsed to store data in an Amazon S3 bucket managed by IoT Analytics. You can’t change the choice of Amazon S3 storage after your data store is created.\n\ncustomerManagedS3 -> (structure)\n\nS3-customer-managed; When you choose customer-managed storage, the retentionPeriod parameter is ignored. You can’t change the choice of Amazon S3 storage after your data store is created.\n\nbucket -> (string)\n\nThe name of the Amazon S3 bucket where your data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the data store data objects. Each object in an Amazon S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 resources.\n\niotSiteWiseMultiLayerStorage -> (structure)\n\nUsed to store data used by IoT SiteWise in an Amazon S3 bucket that you manage. You can’t change the choice of Amazon S3 storage after your data store is created.\n\ncustomerManagedS3Storage -> (structure)\n\nUsed to store data used by IoT SiteWise in an Amazon S3 bucket that you manage.\n\nbucket -> (string)\n\nThe name of the Amazon S3 bucket where your data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the data store data objects. Each object in an Amazon S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\nShorthand Syntax:\n\nserviceManagedS3={},customerManagedS3={bucket=string,keyPrefix=string,roleArn=string},iotSiteWiseMultiLayerStorage={customerManagedS3Storage={bucket=string,keyPrefix=string}}\n\n\nJSON Syntax:\n\n{\n  \"serviceManagedS3\": {\n\n  },\n  \"customerManagedS3\": {\n    \"bucket\": \"string\",\n    \"keyPrefix\": \"string\",\n    \"roleArn\": \"string\"\n  },\n  \"iotSiteWiseMultiLayerStorage\": {\n    \"customerManagedS3Storage\": {\n      \"bucket\": \"string\",\n      \"keyPrefix\": \"string\"\n    }\n  }\n}\n\n\n--retention-period (structure)\n\nHow long, in days, message data is kept for the data store. When customerManagedS3 storage is selected, this parameter is ignored.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.\n\nShorthand Syntax:\n\nunlimited=boolean,numberOfDays=integer\n\n\nJSON Syntax:\n\n{\n  \"unlimited\": true|false,\n  \"numberOfDays\": integer\n}\n\n\n--tags (list)\n\nMetadata which can be used to manage the data store.\n\n(structure)\n\nA set of key-value pairs that are used to manage the resource.\n\nkey -> (string)\n\nThe tag’s key.\n\nvalue -> (string)\n\nThe tag’s value.\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--file-format-configuration (structure)\n\nContains the configuration information of file formats. IoT Analytics data stores support JSON and Parquet .\n\nThe default file format is JSON. You can specify only one format.\n\nYou can’t change the file format after you create the data store.\n\njsonConfiguration -> (structure)\n\nContains the configuration information of the JSON format.\n\nparquetConfiguration -> (structure)\n\nContains the configuration information of the Parquet format.\n\nschemaDefinition -> (structure)\n\nInformation needed to define a schema.\n\ncolumns -> (list)\n\nSpecifies one or more columns that store your data.\n\nEach schema can have up to 100 columns. Each column can have up to 100 nested types.\n\n(structure)\n\nContains information about a column that stores your data.\n\nname -> (string)\n\nThe name of the column.\n\ntype -> (string)\n\nThe type of data. For more information about the supported data types, see Common data types in the Glue Developer Guide .\n\nJSON Syntax:\n\n{\n  \"jsonConfiguration\": {\n\n  },\n  \"parquetConfiguration\": {\n    \"schemaDefinition\": {\n      \"columns\": [\n        {\n          \"name\": \"string\",\n          \"type\": \"string\"\n        }\n        ...\n      ]\n    }\n  }\n}\n\n\n--datastore-partitions (structure)\n\nContains information about the partition dimensions in a data store.\n\npartitions -> (list)\n\nA list of partition dimensions in a data store.\n\n(structure)\n\nA single dimension to partition a data store. The dimension must be an AttributePartition or a TimestampPartition .\n\nattributePartition -> (structure)\n\nA partition dimension defined by an attributeName .\n\nattributeName -> (string)\n\nThe name of the attribute that defines a partition dimension.\n\ntimestampPartition -> (structure)\n\nA partition dimension defined by a timestamp attribute.\n\nattributeName -> (string)\n\nThe attribute name of the partition defined by a timestamp.\n\ntimestampFormat -> (string)\n\nThe timestamp format of a partition defined by a timestamp. The default format is seconds since epoch (January 1, 1970 at midnight UTC time).\n\nJSON Syntax:\n\n{\n  \"partitions\": [\n    {\n      \"attributePartition\": {\n        \"attributeName\": \"string\"\n      },\n      \"timestampPartition\": {\n        \"attributeName\": \"string\",\n        \"timestampFormat\": \"string\"\n      }\n    }\n    ...\n  ]\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ndatastoreName -> (string)\n\nThe name of the data store.\n\ndatastoreArn -> (string)\n\nThe ARN of the data store.\n\nretentionPeriod -> (structure)\n\nHow long, in days, message data is kept for the data store.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.",
      "command_examples": "Examples\n\nTo create a data store\n\nThe following create-datastore example creates a data store, which is a repository for messages.\n\naws iotanalytics create-datastore \\\n    --cli-input-json file://create-datastore.json\n\n\nContents of create-datastore.json:\n\n{\n    \"datastoreName\": \"mydatastore\",\n    \"retentionPeriod\": {\n        \"numberOfDays\": 90\n    },\n    \"tags\": [\n        {\n            \"key\": \"Environment\",\n            \"value\": \"Production\"\n        }\n    ]\n}\n\n\nOutput:\n\n{\n    \"datastoreName\": \"mydatastore\",\n    \"datastoreArn\": \"arn:aws:iotanalytics:us-west-2:123456789012:datastore/mydatastore\",\n    \"retentionPeriod\": {\n        \"numberOfDays\": 90,\n        \"unlimited\": false\n    }\n}\n\n\nFor more information, see CreateDatastore in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "create-pipeline",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/create-pipeline.html",
      "command_description": "Description\n\nCreates a pipeline. A pipeline consumes messages from a channel and allows you to process the messages before storing them in a data store. You must specify both a channel and a datastore activity and, optionally, as many as 23 additional activities in the pipelineActivities array.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  create-pipeline\n--pipeline-name <value>\n--pipeline-activities <value>\n[--tags <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--pipeline-name <value>",
        "--pipeline-activities <value>",
        "[--tags <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--pipeline-name (string)\n\nThe name of the pipeline.\n\n--pipeline-activities (list)\n\nA list of PipelineActivity objects. Activities perform transformations on your messages, such as removing, renaming or adding message attributes; filtering messages based on attribute values; invoking your Lambda unctions on messages for advanced processing; or performing mathematical transformations to normalize device data.\n\nThe list can be 2-25 PipelineActivity objects and must contain both a channel and a datastore activity. Each entry in the list must contain only one activity. For example:\n\npipelineActivities = [ { \"channel\": { ... } }, { \"lambda\": { ... } }, ... ]\n\n(structure)\n\nAn activity that performs a transformation on a message.\n\nchannel -> (structure)\n\nDetermines the source of the messages to be processed.\n\nname -> (string)\n\nThe name of the channel activity.\n\nchannelName -> (string)\n\nThe name of the channel from which the messages are processed.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nlambda -> (structure)\n\nRuns a Lambda function to modify the message.\n\nname -> (string)\n\nThe name of the lambda activity.\n\nlambdaName -> (string)\n\nThe name of the Lambda function that is run on the message.\n\nbatchSize -> (integer)\n\nThe number of messages passed to the Lambda function for processing.\n\nThe Lambda function must be able to process all of these messages within five minutes, which is the maximum timeout duration for Lambda functions.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndatastore -> (structure)\n\nSpecifies where to store the processed message data.\n\nname -> (string)\n\nThe name of the datastore activity.\n\ndatastoreName -> (string)\n\nThe name of the data store where processed messages are stored.\n\naddAttributes -> (structure)\n\nAdds other attributes based on existing attributes in the message.\n\nname -> (string)\n\nThe name of the addAttributes activity.\n\nattributes -> (map)\n\nA list of 1-50 AttributeNameMapping objects that map an existing attribute to a new attribute.\n\nNote\n\nThe existing attributes remain in the message, so if you want to remove the originals, use RemoveAttributeActivity .\n\nkey -> (string)\n\nvalue -> (string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nremoveAttributes -> (structure)\n\nRemoves attributes from a message.\n\nname -> (string)\n\nThe name of the removeAttributes activity.\n\nattributes -> (list)\n\nA list of 1-50 attributes to remove from the message.\n\n(string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nselectAttributes -> (structure)\n\nUsed to create a new message using only the specified attributes from the original message.\n\nname -> (string)\n\nThe name of the selectAttributes activity.\n\nattributes -> (list)\n\nA list of the attributes to select from the message.\n\n(string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nfilter -> (structure)\n\nFilters a message based on its attributes.\n\nname -> (string)\n\nThe name of the filter activity.\n\nfilter -> (string)\n\nAn expression that looks like a SQL WHERE clause that must return a Boolean value. Messages that satisfy the condition are passed to the next activity.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nmath -> (structure)\n\nComputes an arithmetic expression using the message’s attributes and adds it to the message.\n\nname -> (string)\n\nThe name of the math activity.\n\nattribute -> (string)\n\nThe name of the attribute that contains the result of the math operation.\n\nmath -> (string)\n\nAn expression that uses one or more existing attributes and must return an integer value.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndeviceRegistryEnrich -> (structure)\n\nAdds data from the IoT device registry to your message.\n\nname -> (string)\n\nThe name of the deviceRegistryEnrich activity.\n\nattribute -> (string)\n\nThe name of the attribute that is added to the message.\n\nthingName -> (string)\n\nThe name of the IoT device whose registry information is added to the message.\n\nroleArn -> (string)\n\nThe ARN of the role that allows access to the device’s registry information.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndeviceShadowEnrich -> (structure)\n\nAdds information from the IoT Device Shadow service to a message.\n\nname -> (string)\n\nThe name of the deviceShadowEnrich activity.\n\nattribute -> (string)\n\nThe name of the attribute that is added to the message.\n\nthingName -> (string)\n\nThe name of the IoT device whose shadow information is added to the message.\n\nroleArn -> (string)\n\nThe ARN of the role that allows access to the device’s shadow.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nShorthand Syntax:\n\nchannel={name=string,channelName=string,next=string},lambda={name=string,lambdaName=string,batchSize=integer,next=string},datastore={name=string,datastoreName=string},addAttributes={name=string,attributes={KeyName1=string,KeyName2=string},next=string},removeAttributes={name=string,attributes=[string,string],next=string},selectAttributes={name=string,attributes=[string,string],next=string},filter={name=string,filter=string,next=string},math={name=string,attribute=string,math=string,next=string},deviceRegistryEnrich={name=string,attribute=string,thingName=string,roleArn=string,next=string},deviceShadowEnrich={name=string,attribute=string,thingName=string,roleArn=string,next=string} ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"channel\": {\n      \"name\": \"string\",\n      \"channelName\": \"string\",\n      \"next\": \"string\"\n    },\n    \"lambda\": {\n      \"name\": \"string\",\n      \"lambdaName\": \"string\",\n      \"batchSize\": integer,\n      \"next\": \"string\"\n    },\n    \"datastore\": {\n      \"name\": \"string\",\n      \"datastoreName\": \"string\"\n    },\n    \"addAttributes\": {\n      \"name\": \"string\",\n      \"attributes\": {\"string\": \"string\"\n        ...},\n      \"next\": \"string\"\n    },\n    \"removeAttributes\": {\n      \"name\": \"string\",\n      \"attributes\": [\"string\", ...],\n      \"next\": \"string\"\n    },\n    \"selectAttributes\": {\n      \"name\": \"string\",\n      \"attributes\": [\"string\", ...],\n      \"next\": \"string\"\n    },\n    \"filter\": {\n      \"name\": \"string\",\n      \"filter\": \"string\",\n      \"next\": \"string\"\n    },\n    \"math\": {\n      \"name\": \"string\",\n      \"attribute\": \"string\",\n      \"math\": \"string\",\n      \"next\": \"string\"\n    },\n    \"deviceRegistryEnrich\": {\n      \"name\": \"string\",\n      \"attribute\": \"string\",\n      \"thingName\": \"string\",\n      \"roleArn\": \"string\",\n      \"next\": \"string\"\n    },\n    \"deviceShadowEnrich\": {\n      \"name\": \"string\",\n      \"attribute\": \"string\",\n      \"thingName\": \"string\",\n      \"roleArn\": \"string\",\n      \"next\": \"string\"\n    }\n  }\n  ...\n]\n\n\n--tags (list)\n\nMetadata which can be used to manage the pipeline.\n\n(structure)\n\nA set of key-value pairs that are used to manage the resource.\n\nkey -> (string)\n\nThe tag’s key.\n\nvalue -> (string)\n\nThe tag’s value.\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\npipelineName -> (string)\n\nThe name of the pipeline.\n\npipelineArn -> (string)\n\nThe ARN of the pipeline.",
      "command_examples": "Examples\n\nCreate an IoT Analytics Pipeline\n\nThe following create-pipeline example creates a pipeline. A pipeline consumes messages from a channel and allows you to process the messages before storing them in a data store. You must specify both a channel and a data store activity and, optionally, as many as 23 additional activities in the pipelineActivities array.\n\naws iotanalytics create-pipeline \\\n    --cli-input-json file://create-pipeline.json\n\n\nContents of create-pipeline.json:\n\n{\n    \"pipelineName\": \"mypipeline\",\n    \"pipelineActivities\": [\n        {\n            \"channel\": {\n                \"name\": \"myChannelActivity\",\n                \"channelName\": \"mychannel\",\n                \"next\": \"myMathActivity\"\n            }\n        },\n        {\n            \"datastore\": {\n                \"name\": \"myDatastoreActivity\",\n                \"datastoreName\": \"mydatastore\"\n            }\n        },\n        {\n            \"math\": {\n                \"name\": \"myMathActivity\",\n                \"math\": \"((temp - 32) * 5.0) / 9.0\",\n                \"attribute\": \"tempC\",\n                \"next\": \"myDatastoreActivity\"\n            }\n        }\n    ],\n    \"tags\": [\n        {\n            \"key\": \"Environment\",\n            \"value\": \"Beta\"\n        }\n    ]\n}\n\n\nOutput:\n\n{\n    \"pipelineArn\": \"arn:aws:iotanalytics:us-west-2:123456789012:pipeline/mypipeline\",\n    \"pipelineName\": \"mypipeline\"\n}\n\n\nFor more information, see CreatePipeline in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "delete-channel",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/delete-channel.html",
      "command_description": "Description\n\nDeletes the specified channel.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-channel\n--channel-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-name (string)\n\nThe name of the channel to delete.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nDelete an IoT Analytics Channel\n\nThe following delete-channel example deletes the specified channel.\n\naws iotanalytics delete-channel \\\n    --channel-name mychannel\n\n\nThis command produces no output.\n\nFor more information, see DeleteChannel in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "delete-dataset",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/delete-dataset.html",
      "command_description": "Description\n\nDeletes the specified dataset.\n\nYou do not have to delete the content of the dataset before you perform this operation.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-dataset\n--dataset-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--dataset-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--dataset-name (string)\n\nThe name of the dataset to delete.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo delete a dataset\n\nThe following delete-dataset example deletes the specified dataset. You don’t have to delete the content of the dataset before you perform this operation.\n\naws iotanalytics delete-dataset \\\n    --dataset-name mydataset\n\n\nThis command produces no output.\n\nFor more information, see DeleteDataset in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "delete-dataset-content",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/delete-dataset-content.html",
      "command_description": "Description\n\nDeletes the content of the specified dataset.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-dataset-content\n--dataset-name <value>\n[--version-id <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--dataset-name <value>",
        "[--version-id <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--dataset-name (string)\n\nThe name of the dataset whose content is deleted.\n\n--version-id (string)\n\nThe version of the dataset whose content is deleted. You can also use the strings “$LATEST” or “$LATEST_SUCCEEDED” to delete the latest or latest successfully completed data set. If not specified, “$LATEST_SUCCEEDED” is the default.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo delete dataset content\n\nThe following delete-dataset-content example deletes the content of the specified dataset.\n\naws iotanalytics delete-dataset-content \\\n    --dataset-name mydataset\n\n\nThis command produces no output.\n\nFor more information, see DeleteDatasetContent in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "delete-datastore",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/delete-datastore.html",
      "command_description": "Description\n\nDeletes the specified data store.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-datastore\n--datastore-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--datastore-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--datastore-name (string)\n\nThe name of the data store to delete.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo delete a data store\n\nThe following delete-datastore example deletes the specified data store.\n\naws iotanalytics delete-datastore \\\n    --datastore-name mydatastore\n\n\nThis command produces no output.\n\nFor more information, see DeleteDatastore in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "delete-pipeline",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/delete-pipeline.html",
      "command_description": "Description\n\nDeletes the specified pipeline.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  delete-pipeline\n--pipeline-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--pipeline-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--pipeline-name (string)\n\nThe name of the pipeline to delete.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo delete a pipeline\n\nThe following delete-pipeline example deletes the specified pipeline.\n\naws iotanalytics delete-pipeline \\\n    --pipeline-name mypipeline\n\n\nThis command produces no output.\n\nFor more information, see DeletePipeline in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "describe-channel",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/describe-channel.html",
      "command_description": "Description\n\nRetrieves information about a channel.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-channel\n--channel-name <value>\n[--include-statistics | --no-include-statistics]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-name <value>",
        "[--include-statistics | --no-include-statistics]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-name (string)\n\nThe name of the channel whose information is retrieved.\n\n--include-statistics | --no-include-statistics (boolean)\n\nIf true, additional statistical information about the channel is included in the response. This feature can’t be used with a channel whose S3 storage is customer-managed.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nchannel -> (structure)\n\nAn object that contains information about the channel.\n\nname -> (string)\n\nThe name of the channel.\n\nstorage -> (structure)\n\nWhere channel data is stored. You can choose one of serviceManagedS3 or customerManagedS3 storage. If not specified, the default is serviceManagedS3 . You can’t change this storage option after the channel is created.\n\nserviceManagedS3 -> (structure)\n\nUsed to store channel data in an S3 bucket managed by IoT Analytics. You can’t change the choice of S3 storage after the data store is created.\n\ncustomerManagedS3 -> (structure)\n\nUsed to store channel data in an S3 bucket that you manage. If customer managed storage is selected, the retentionPeriod parameter is ignored. You can’t change the choice of S3 storage after the data store is created.\n\nbucket -> (string)\n\nThe name of the S3 bucket in which channel data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the channel data objects. Each object in an S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 resources.\n\narn -> (string)\n\nThe ARN of the channel.\n\nstatus -> (string)\n\nThe status of the channel.\n\nretentionPeriod -> (structure)\n\nHow long, in days, message data is kept for the channel.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.\n\ncreationTime -> (timestamp)\n\nWhen the channel was created.\n\nlastUpdateTime -> (timestamp)\n\nWhen the channel was last updated.\n\nlastMessageArrivalTime -> (timestamp)\n\nThe last time when a new message arrived in the channel.\n\nIoT Analytics updates this value at most once per minute for one channel. Hence, the lastMessageArrivalTime value is an approximation.\n\nThis feature only applies to messages that arrived in the data store after October 23, 2020.\n\nstatistics -> (structure)\n\nStatistics about the channel. Included if the includeStatistics parameter is set to true in the request.\n\nsize -> (structure)\n\nThe estimated size of the channel.\n\nestimatedSizeInBytes -> (double)\n\nThe estimated size of the resource, in bytes.\n\nestimatedOn -> (timestamp)\n\nThe time when the estimate of the size of the resource was made.",
      "command_examples": "Examples\n\nTo retrieve information about a channel\n\nThe following describe-channel example displays details, including statistics, for the specified channel.\n\naws iotanalytics describe-channel \\\n    --channel-name mychannel \\\n    --include-statistics\n\n\nOutput:\n\n{\n    \"statistics\": {\n        \"size\": {\n            \"estimatedSizeInBytes\": 402.0,\n            \"estimatedOn\": 1561504380.0\n        }\n    },\n    \"channel\": {\n        \"status\": \"ACTIVE\",\n        \"name\": \"mychannel\",\n        \"lastUpdateTime\": 1557860351.001,\n        \"creationTime\": 1557860351.001,\n        \"retentionPeriod\": {\n            \"unlimited\": true\n        },\n        \"arn\": \"arn:aws:iotanalytics:us-west-2:123456789012:channel/mychannel\"\n    }\n}\n\n\nFor more information, see DescribeChannel in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "describe-dataset",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/describe-dataset.html",
      "command_description": "Description\n\nRetrieves information about a dataset.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-dataset\n--dataset-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--dataset-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--dataset-name (string)\n\nThe name of the dataset whose information is retrieved.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ndataset -> (structure)\n\nAn object that contains information about the dataset.\n\nname -> (string)\n\nThe name of the dataset.\n\narn -> (string)\n\nThe ARN of the dataset.\n\nactions -> (list)\n\nThe DatasetAction objects that automatically create the dataset contents.\n\n(structure)\n\nA DatasetAction object that specifies how dataset contents are automatically created.\n\nactionName -> (string)\n\nThe name of the dataset action by which dataset contents are automatically created.\n\nqueryAction -> (structure)\n\nAn SqlQueryDatasetAction object that uses an SQL query to automatically create dataset contents.\n\nsqlQuery -> (string)\n\nA SQL query string.\n\nfilters -> (list)\n\nPrefilters applied to message data.\n\n(structure)\n\nInformation that is used to filter message data, to segregate it according to the timeframe in which it arrives.\n\ndeltaTime -> (structure)\n\nUsed to limit data to that which has arrived since the last execution of the action.\n\noffsetSeconds -> (integer)\n\nThe number of seconds of estimated in-flight lag time of message data. When you create dataset contents using message data from a specified timeframe, some message data might still be in flight when processing begins, and so do not arrive in time to be processed. Use this field to make allowances for the in flight time of your message data, so that data not processed from a previous timeframe is included with the next timeframe. Otherwise, missed message data would be excluded from processing during the next timeframe too, because its timestamp places it within the previous timeframe.\n\ntimeExpression -> (string)\n\nAn expression by which the time of the message data might be determined. This can be the name of a timestamp field or a SQL expression that is used to derive the time the message data was generated.\n\ncontainerAction -> (structure)\n\nInformation that allows the system to run a containerized application to create the dataset contents. The application must be in a Docker container along with any required support libraries.\n\nimage -> (string)\n\nThe ARN of the Docker container stored in your account. The Docker container contains an application and required support libraries and is used to generate dataset contents.\n\nexecutionRoleArn -> (string)\n\nThe ARN of the role that gives permission to the system to access required resources to run the containerAction . This includes, at minimum, permission to retrieve the dataset contents that are the input to the containerized application.\n\nresourceConfiguration -> (structure)\n\nConfiguration of the resource that executes the containerAction .\n\ncomputeType -> (string)\n\nThe type of the compute resource used to execute the containerAction . Possible values are: ACU_1 (vCPU=4, memory=16 GiB) or ACU_2 (vCPU=8, memory=32 GiB).\n\nvolumeSizeInGB -> (integer)\n\nThe size, in GB, of the persistent storage available to the resource instance used to execute the containerAction (min: 1, max: 50).\n\nvariables -> (list)\n\nThe values of variables used in the context of the execution of the containerized application (basically, parameters passed to the application). Each variable must have a name and a value given by one of stringValue , datasetContentVersionValue , or outputFileUriValue .\n\n(structure)\n\nAn instance of a variable to be passed to the containerAction execution. Each variable must have a name and a value given by one of stringValue , datasetContentVersionValue , or outputFileUriValue .\n\nname -> (string)\n\nThe name of the variable.\n\nstringValue -> (string)\n\nThe value of the variable as a string.\n\ndoubleValue -> (double)\n\nThe value of the variable as a double (numeric).\n\ndatasetContentVersionValue -> (structure)\n\nThe value of the variable as a structure that specifies a dataset content version.\n\ndatasetName -> (string)\n\nThe name of the dataset whose latest contents are used as input to the notebook or application.\n\noutputFileUriValue -> (structure)\n\nThe value of the variable as a structure that specifies an output file URI.\n\nfileName -> (string)\n\nThe URI of the location where dataset contents are stored, usually the URI of a file in an S3 bucket.\n\ntriggers -> (list)\n\nThe DatasetTrigger objects that specify when the dataset is automatically updated.\n\n(structure)\n\nThe DatasetTrigger that specifies when the dataset is automatically updated.\n\nschedule -> (structure)\n\nThe Schedule when the trigger is initiated.\n\nexpression -> (string)\n\nThe expression that defines when to trigger an update. For more information, see Schedule Expressions for Rules in the Amazon CloudWatch Events User Guide .\n\ndataset -> (structure)\n\nThe dataset whose content creation triggers the creation of this dataset’s contents.\n\nname -> (string)\n\nThe name of the dataset whose content generation triggers the new dataset content generation.\n\ncontentDeliveryRules -> (list)\n\nWhen dataset contents are created they are delivered to destinations specified here.\n\n(structure)\n\nWhen dataset contents are created, they are delivered to destination specified here.\n\nentryName -> (string)\n\nThe name of the dataset content delivery rules entry.\n\ndestination -> (structure)\n\nThe destination to which dataset contents are delivered.\n\niotEventsDestinationConfiguration -> (structure)\n\nConfiguration information for delivery of dataset contents to IoT Events.\n\ninputName -> (string)\n\nThe name of the IoT Events input to which dataset contents are delivered.\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to deliver dataset contents to an IoT Events input.\n\ns3DestinationConfiguration -> (structure)\n\nConfiguration information for delivery of dataset contents to Amazon S3.\n\nbucket -> (string)\n\nThe name of the S3 bucket to which dataset contents are delivered.\n\nkey -> (string)\n\nThe key of the dataset contents object in an S3 bucket. Each object has a key that is a unique identifier. Each object has exactly one key.\n\nYou can create a unique key with the following options:\n\nUse !{iotanalytics:scheduleTime} to insert the time of a scheduled SQL query run.\n\nUse !{iotanalytics:versionId} to insert a unique hash that identifies a dataset content.\n\nUse !{iotanalytics:creationTime} to insert the creation time of a dataset content.\n\nThe following example creates a unique key for a CSV file: dataset/mydataset/!{iotanalytics:scheduleTime}/!{iotanalytics:versionId}.csv\n\nNote\n\nIf you don’t use !{iotanalytics:versionId} to specify the key, you might get duplicate keys. For example, you might have two dataset contents with the same scheduleTime but different versionId s. This means that one dataset content overwrites the other.\n\nglueConfiguration -> (structure)\n\nConfiguration information for coordination with Glue, a fully managed extract, transform and load (ETL) service.\n\ntableName -> (string)\n\nThe name of the table in your Glue Data Catalog that is used to perform the ETL operations. An Glue Data Catalog table contains partitioned data and descriptions of data sources and targets.\n\ndatabaseName -> (string)\n\nThe name of the database in your Glue Data Catalog in which the table is located. An Glue Data Catalog database contains metadata tables.\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 and Glue resources.\n\nstatus -> (string)\n\nThe status of the dataset.\n\ncreationTime -> (timestamp)\n\nWhen the dataset was created.\n\nlastUpdateTime -> (timestamp)\n\nThe last time the dataset was updated.\n\nretentionPeriod -> (structure)\n\nOptional. How long, in days, message data is kept for the dataset.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.\n\nversioningConfiguration -> (structure)\n\nOptional. How many versions of dataset contents are kept. If not specified or set to null, only the latest version plus the latest succeeded version (if they are different) are kept for the time period specified by the retentionPeriod parameter. For more information, see Keeping Multiple Versions of IoT Analytics datasets in the IoT Analytics User Guide .\n\nunlimited -> (boolean)\n\nIf true, unlimited versions of dataset contents are kept.\n\nmaxVersions -> (integer)\n\nHow many versions of dataset contents are kept. The unlimited parameter must be false .\n\nlateDataRules -> (list)\n\nA list of data rules that send notifications to CloudWatch, when data arrives late. To specify lateDataRules , the dataset must use a DeltaTimer filter.\n\n(structure)\n\nA structure that contains the name and configuration information of a late data rule.\n\nruleName -> (string)\n\nThe name of the late data rule.\n\nruleConfiguration -> (structure)\n\nThe information needed to configure the late data rule.\n\ndeltaTimeSessionWindowConfiguration -> (structure)\n\nThe information needed to configure a delta time session window.\n\ntimeoutInMinutes -> (integer)\n\nA time interval. You can use timeoutInMinutes so that IoT Analytics can batch up late data notifications that have been generated since the last execution. IoT Analytics sends one batch of notifications to Amazon CloudWatch Events at one time.\n\nFor more information about how to write a timestamp expression, see Date and Time Functions and Operators , in the Presto 0.172 Documentation .",
      "command_examples": "Examples\n\nTo retrieve information about a dataset\n\nThe following describe-dataset example displays details for the specified dataset.\n\naws iotanalytics describe-dataset \\\n    --dataset-name mydataset\n\n\nOutput:\n\n{\n    \"dataset\": {\n        \"status\": \"ACTIVE\",\n        \"contentDeliveryRules\": [],\n        \"name\": \"mydataset\",\n        \"lastUpdateTime\": 1557859240.658,\n        \"triggers\": [],\n        \"creationTime\": 1557859240.658,\n        \"actions\": [\n            {\n                \"actionName\": \"query_32\",\n                \"queryAction\": {\n                    \"sqlQuery\": \"SELECT * FROM mydatastore\",\n                    \"filters\": []\n                }\n            }\n        ],\n        \"retentionPeriod\": {\n            \"numberOfDays\": 90,\n            \"unlimited\": false\n        },\n        \"arn\": \"arn:aws:iotanalytics:us-west-2:123456789012:dataset/mydataset\"\n    }\n}\n\n\nFor more information, see DescribeDataset in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "describe-datastore",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/describe-datastore.html",
      "command_description": "Description\n\nRetrieves information about a data store.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-datastore\n--datastore-name <value>\n[--include-statistics | --no-include-statistics]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--datastore-name <value>",
        "[--include-statistics | --no-include-statistics]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--datastore-name (string)\n\nThe name of the data store\n\n--include-statistics | --no-include-statistics (boolean)\n\nIf true, additional statistical information about the data store is included in the response. This feature can’t be used with a data store whose S3 storage is customer-managed.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ndatastore -> (structure)\n\nInformation about the data store.\n\nname -> (string)\n\nThe name of the data store.\n\nstorage -> (structure)\n\nWhere data in a data store is stored.. You can choose serviceManagedS3 storage, customerManagedS3 storage, or iotSiteWiseMultiLayerStorage storage. The default is serviceManagedS3 . You can’t change the choice of Amazon S3 storage after your data store is created.\n\nserviceManagedS3 -> (structure)\n\nUsed to store data in an Amazon S3 bucket managed by IoT Analytics. You can’t change the choice of Amazon S3 storage after your data store is created.\n\ncustomerManagedS3 -> (structure)\n\nS3-customer-managed; When you choose customer-managed storage, the retentionPeriod parameter is ignored. You can’t change the choice of Amazon S3 storage after your data store is created.\n\nbucket -> (string)\n\nThe name of the Amazon S3 bucket where your data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the data store data objects. Each object in an Amazon S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 resources.\n\niotSiteWiseMultiLayerStorage -> (structure)\n\nUsed to store data used by IoT SiteWise in an Amazon S3 bucket that you manage. You can’t change the choice of Amazon S3 storage after your data store is created.\n\ncustomerManagedS3Storage -> (structure)\n\nUsed to store data used by IoT SiteWise in an Amazon S3 bucket that you manage.\n\nbucket -> (string)\n\nThe name of the Amazon S3 bucket where your data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the data store data objects. Each object in an Amazon S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\narn -> (string)\n\nThe ARN of the data store.\n\nstatus -> (string)\n\nThe status of a data store:\n\nCREATING\n\nThe data store is being created.\n\nACTIVE\n\nThe data store has been created and can be used.\n\nDELETING\n\nThe data store is being deleted.\n\nretentionPeriod -> (structure)\n\nHow long, in days, message data is kept for the data store. When customerManagedS3 storage is selected, this parameter is ignored.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.\n\ncreationTime -> (timestamp)\n\nWhen the data store was created.\n\nlastUpdateTime -> (timestamp)\n\nThe last time the data store was updated.\n\nlastMessageArrivalTime -> (timestamp)\n\nThe last time when a new message arrived in the data store.\n\nIoT Analytics updates this value at most once per minute for Amazon Simple Storage Service one data store. Hence, the lastMessageArrivalTime value is an approximation.\n\nThis feature only applies to messages that arrived in the data store after October 23, 2020.\n\nfileFormatConfiguration -> (structure)\n\nContains the configuration information of file formats. IoT Analytics data stores support JSON and Parquet .\n\nThe default file format is JSON. You can specify only one format.\n\nYou can’t change the file format after you create the data store.\n\njsonConfiguration -> (structure)\n\nContains the configuration information of the JSON format.\n\nparquetConfiguration -> (structure)\n\nContains the configuration information of the Parquet format.\n\nschemaDefinition -> (structure)\n\nInformation needed to define a schema.\n\ncolumns -> (list)\n\nSpecifies one or more columns that store your data.\n\nEach schema can have up to 100 columns. Each column can have up to 100 nested types.\n\n(structure)\n\nContains information about a column that stores your data.\n\nname -> (string)\n\nThe name of the column.\n\ntype -> (string)\n\nThe type of data. For more information about the supported data types, see Common data types in the Glue Developer Guide .\n\ndatastorePartitions -> (structure)\n\nContains information about the partition dimensions in a data store.\n\npartitions -> (list)\n\nA list of partition dimensions in a data store.\n\n(structure)\n\nA single dimension to partition a data store. The dimension must be an AttributePartition or a TimestampPartition .\n\nattributePartition -> (structure)\n\nA partition dimension defined by an attributeName .\n\nattributeName -> (string)\n\nThe name of the attribute that defines a partition dimension.\n\ntimestampPartition -> (structure)\n\nA partition dimension defined by a timestamp attribute.\n\nattributeName -> (string)\n\nThe attribute name of the partition defined by a timestamp.\n\ntimestampFormat -> (string)\n\nThe timestamp format of a partition defined by a timestamp. The default format is seconds since epoch (January 1, 1970 at midnight UTC time).\n\nstatistics -> (structure)\n\nAdditional statistical information about the data store. Included if the includeStatistics parameter is set to true in the request.\n\nsize -> (structure)\n\nThe estimated size of the data store.\n\nestimatedSizeInBytes -> (double)\n\nThe estimated size of the resource, in bytes.\n\nestimatedOn -> (timestamp)\n\nThe time when the estimate of the size of the resource was made.",
      "command_examples": "Examples\n\nTo retrieve information about a data store\n\nThe following describe-datastore example displays details, including statistics, for the specified data store.\n\naws iotanalytics describe-datastore \\\n    --datastore-name mydatastore \\\n    --include-statistics\n\n\nOutput:\n\n{\n    \"datastore\": {\n        \"status\": \"ACTIVE\",\n        \"name\": \"mydatastore\",\n        \"lastUpdateTime\": 1557858971.02,\n        \"creationTime\": 1557858971.02,\n        \"retentionPeriod\": {\n            \"unlimited\": true\n        },\n        \"arn\": \"arn:aws:iotanalytics:us-west-2:123456789012:datastore/mydatastore\"\n    },\n    \"statistics\": {\n        \"size\": {\n            \"estimatedSizeInBytes\": 397.0,\n            \"estimatedOn\": 1561592040.0\n        }\n    }\n}\n\n\nFor more information, see DescribeDatastore in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "describe-logging-options",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/describe-logging-options.html",
      "command_description": "Description\n\nRetrieves the current settings of the IoT Analytics logging options.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-logging-options\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nloggingOptions -> (structure)\n\nThe current settings of the IoT Analytics logging options.\n\nroleArn -> (string)\n\nThe ARN of the role that grants permission to IoT Analytics to perform logging.\n\nlevel -> (string)\n\nThe logging level. Currently, only ERROR is supported.\n\nenabled -> (boolean)\n\nIf true, logging is enabled for IoT Analytics.",
      "command_examples": "Examples\n\nTo retrieve the current logging options\n\nThe following describe-logging-options example displays the current AWS IoT Analytics logging options.\n\naws iotanalytics describe-logging-options\n\n\nThis command produces no output. Output:\n\n{\n    \"loggingOptions\": {\n        \"roleArn\": \"arn:aws:iam::123456789012:role/service-role/myIoTAnalyticsRole\",\n        \"enabled\": true,\n        \"level\": \"ERROR\"\n    }\n}\n\n\nFor more information, see DescribeLoggingOptions in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "describe-pipeline",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/describe-pipeline.html",
      "command_description": "Description\n\nRetrieves information about a pipeline.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  describe-pipeline\n--pipeline-name <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--pipeline-name <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--pipeline-name (string)\n\nThe name of the pipeline whose information is retrieved.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\npipeline -> (structure)\n\nA Pipeline object that contains information about the pipeline.\n\nname -> (string)\n\nThe name of the pipeline.\n\narn -> (string)\n\nThe ARN of the pipeline.\n\nactivities -> (list)\n\nThe activities that perform transformations on the messages.\n\n(structure)\n\nAn activity that performs a transformation on a message.\n\nchannel -> (structure)\n\nDetermines the source of the messages to be processed.\n\nname -> (string)\n\nThe name of the channel activity.\n\nchannelName -> (string)\n\nThe name of the channel from which the messages are processed.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nlambda -> (structure)\n\nRuns a Lambda function to modify the message.\n\nname -> (string)\n\nThe name of the lambda activity.\n\nlambdaName -> (string)\n\nThe name of the Lambda function that is run on the message.\n\nbatchSize -> (integer)\n\nThe number of messages passed to the Lambda function for processing.\n\nThe Lambda function must be able to process all of these messages within five minutes, which is the maximum timeout duration for Lambda functions.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndatastore -> (structure)\n\nSpecifies where to store the processed message data.\n\nname -> (string)\n\nThe name of the datastore activity.\n\ndatastoreName -> (string)\n\nThe name of the data store where processed messages are stored.\n\naddAttributes -> (structure)\n\nAdds other attributes based on existing attributes in the message.\n\nname -> (string)\n\nThe name of the addAttributes activity.\n\nattributes -> (map)\n\nA list of 1-50 AttributeNameMapping objects that map an existing attribute to a new attribute.\n\nNote\n\nThe existing attributes remain in the message, so if you want to remove the originals, use RemoveAttributeActivity .\n\nkey -> (string)\n\nvalue -> (string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nremoveAttributes -> (structure)\n\nRemoves attributes from a message.\n\nname -> (string)\n\nThe name of the removeAttributes activity.\n\nattributes -> (list)\n\nA list of 1-50 attributes to remove from the message.\n\n(string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nselectAttributes -> (structure)\n\nUsed to create a new message using only the specified attributes from the original message.\n\nname -> (string)\n\nThe name of the selectAttributes activity.\n\nattributes -> (list)\n\nA list of the attributes to select from the message.\n\n(string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nfilter -> (structure)\n\nFilters a message based on its attributes.\n\nname -> (string)\n\nThe name of the filter activity.\n\nfilter -> (string)\n\nAn expression that looks like a SQL WHERE clause that must return a Boolean value. Messages that satisfy the condition are passed to the next activity.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nmath -> (structure)\n\nComputes an arithmetic expression using the message’s attributes and adds it to the message.\n\nname -> (string)\n\nThe name of the math activity.\n\nattribute -> (string)\n\nThe name of the attribute that contains the result of the math operation.\n\nmath -> (string)\n\nAn expression that uses one or more existing attributes and must return an integer value.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndeviceRegistryEnrich -> (structure)\n\nAdds data from the IoT device registry to your message.\n\nname -> (string)\n\nThe name of the deviceRegistryEnrich activity.\n\nattribute -> (string)\n\nThe name of the attribute that is added to the message.\n\nthingName -> (string)\n\nThe name of the IoT device whose registry information is added to the message.\n\nroleArn -> (string)\n\nThe ARN of the role that allows access to the device’s registry information.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndeviceShadowEnrich -> (structure)\n\nAdds information from the IoT Device Shadow service to a message.\n\nname -> (string)\n\nThe name of the deviceShadowEnrich activity.\n\nattribute -> (string)\n\nThe name of the attribute that is added to the message.\n\nthingName -> (string)\n\nThe name of the IoT device whose shadow information is added to the message.\n\nroleArn -> (string)\n\nThe ARN of the role that allows access to the device’s shadow.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nreprocessingSummaries -> (list)\n\nA summary of information about the pipeline reprocessing.\n\n(structure)\n\nInformation about pipeline reprocessing.\n\nid -> (string)\n\nThe reprocessingId returned by StartPipelineReprocessing .\n\nstatus -> (string)\n\nThe status of the pipeline reprocessing.\n\ncreationTime -> (timestamp)\n\nThe time the pipeline reprocessing was created.\n\ncreationTime -> (timestamp)\n\nWhen the pipeline was created.\n\nlastUpdateTime -> (timestamp)\n\nThe last time the pipeline was updated.",
      "command_examples": "Examples\n\nTo retrieve information about a pipeline\n\nThe following describe-pipeline example displays details for the specified pipeline.\n\naws iotanalytics describe-pipeline \\\n    --pipeline-name mypipeline\n\n\nOutput:\n\n{\n    \"pipeline\": {\n        \"activities\": [\n            {\n                \"channel\": {\n                    \"channelName\": \"mychannel\",\n                    \"name\": \"mychannel_28\",\n                    \"next\": \"mydatastore_29\"\n                }\n            },\n            {\n                \"datastore\": {\n                    \"datastoreName\": \"mydatastore\",\n                    \"name\": \"mydatastore_29\"\n                }\n            }\n        ],\n        \"name\": \"mypipeline\",\n        \"lastUpdateTime\": 1561676362.515,\n        \"creationTime\": 1557859124.432,\n        \"reprocessingSummaries\": [\n            {\n                \"status\": \"SUCCEEDED\",\n                \"creationTime\": 1561676362.189,\n                \"id\": \"6ad2764f-fb13-4de3-b101-4e74af03b043\"\n            }\n        ],\n        \"arn\": \"arn:aws:iotanalytics:us-west-2:123456789012:pipeline/mypipeline\"\n    }\n}\n\n\nFor more information, see DescribePipeline in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "get-dataset-content",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/get-dataset-content.html",
      "command_description": "Description\n\nRetrieves the contents of a dataset as presigned URIs.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  get-dataset-content\n--dataset-name <value>\n[--version-id <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--dataset-name <value>",
        "[--version-id <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--dataset-name (string)\n\nThe name of the dataset whose contents are retrieved.\n\n--version-id (string)\n\nThe version of the dataset whose contents are retrieved. You can also use the strings “$LATEST” or “$LATEST_SUCCEEDED” to retrieve the contents of the latest or latest successfully completed dataset. If not specified, “$LATEST_SUCCEEDED” is the default.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nentries -> (list)\n\nA list of DatasetEntry objects.\n\n(structure)\n\nThe reference to a dataset entry.\n\nentryName -> (string)\n\nThe name of the dataset item.\n\ndataURI -> (string)\n\nThe presigned URI of the dataset item.\n\ntimestamp -> (timestamp)\n\nThe time when the request was made.\n\nstatus -> (structure)\n\nThe status of the dataset content.\n\nstate -> (string)\n\nThe state of the dataset contents. Can be one of READY, CREATING, SUCCEEDED, or FAILED.\n\nreason -> (string)\n\nThe reason the dataset contents are in this state.",
      "command_examples": "Examples\n\nTo retrieve the contents of a dataset\n\nThe following get-dataset-content example retrieves the contents of a dataset as presigned URIs.\n\naws iotanalytics get-dataset-content --dataset-name mydataset\n\n\nOutput:\n\n{\n    \"status\": {\n        \"state\": \"SUCCEEDED\"\n    },\n    \"timestamp\": 1557863215.995,\n    \"entries\": [\n        {\n            \"dataURI\": \"https://aws-radiant-dataset-12345678-1234-1234-1234-123456789012.s3.us-west-2.amazonaws.com/results/12345678-e8b3-46ba-b2dd-efe8d86cf385.csv?X-Amz-Security-Token=...-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20190628T173437Z&X-Amz-SignedHeaders=host&X-Amz-Expires=7200&X-Amz-Credential=...F20190628%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=...\"\n        }\n    ]\n}\n\n\nFor more information, see GetDatasetContent in the guide."
    },
    {
      "command_name": "list-channels",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/list-channels.html",
      "command_description": "Description\n\nRetrieves a list of channels.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-channels is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: channelSummaries",
      "command_synopsis": "Synopsis\n  list-channels\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nchannelSummaries -> (list)\n\nA list of ChannelSummary objects.\n\n(structure)\n\nA summary of information about a channel.\n\nchannelName -> (string)\n\nThe name of the channel.\n\nchannelStorage -> (structure)\n\nWhere channel data is stored.\n\nserviceManagedS3 -> (structure)\n\nUsed to store channel data in an S3 bucket managed by IoT Analytics.\n\ncustomerManagedS3 -> (structure)\n\nUsed to store channel data in an S3 bucket that you manage.\n\nbucket -> (string)\n\nThe name of the S3 bucket in which channel data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the channel data objects. Each object in an S3 bucket has a key that is its unique identifier within the bucket (each object in a bucket has exactly one key). The prefix must end with a forward slash (/).\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 resources.\n\nstatus -> (string)\n\nThe status of the channel.\n\ncreationTime -> (timestamp)\n\nWhen the channel was created.\n\nlastUpdateTime -> (timestamp)\n\nThe last time the channel was updated.\n\nlastMessageArrivalTime -> (timestamp)\n\nThe last time when a new message arrived in the channel.\n\nIoT Analytics updates this value at most once per minute for one channel. Hence, the lastMessageArrivalTime value is an approximation.\n\nThis feature only applies to messages that arrived in the data store after October 23, 2020.\n\nnextToken -> (string)\n\nThe token to retrieve the next set of results, or null if there are no more results.",
      "command_examples": "Examples\n\nTo retrieve a list of channels\n\nThe following list-channels example displays summary information for the available channels.\n\naws iotanalytics list-channels\n\n\nOutput:\n\n{\n    \"channelSummaries\": [\n        {\n            \"status\": \"ACTIVE\",\n            \"channelName\": \"mychannel\",\n            \"creationTime\": 1557860351.001,\n            \"lastUpdateTime\": 1557860351.001\n        }\n    ]\n}\n\n\nFor more information, see ListChannels in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "list-dataset-contents",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/list-dataset-contents.html",
      "command_description": "Description\n\nLists information about dataset contents that have been created.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-dataset-contents is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: datasetContentSummaries",
      "command_synopsis": "Synopsis\n  list-dataset-contents\n--dataset-name <value>\n[--scheduled-on-or-after <value>]\n[--scheduled-before <value>]\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--dataset-name <value>",
        "[--scheduled-on-or-after <value>]",
        "[--scheduled-before <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--dataset-name (string)\n\nThe name of the dataset whose contents information you want to list.\n\n--scheduled-on-or-after (timestamp)\n\nA filter to limit results to those dataset contents whose creation is scheduled on or after the given time. See the field triggers.schedule in the CreateDataset request. (timestamp)\n\n--scheduled-before (timestamp)\n\nA filter to limit results to those dataset contents whose creation is scheduled before the given time. See the field triggers.schedule in the CreateDataset request. (timestamp)\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ndatasetContentSummaries -> (list)\n\nSummary information about dataset contents that have been created.\n\n(structure)\n\nSummary information about dataset contents.\n\nversion -> (string)\n\nThe version of the dataset contents.\n\nstatus -> (structure)\n\nThe status of the dataset contents.\n\nstate -> (string)\n\nThe state of the dataset contents. Can be one of READY, CREATING, SUCCEEDED, or FAILED.\n\nreason -> (string)\n\nThe reason the dataset contents are in this state.\n\ncreationTime -> (timestamp)\n\nThe actual time the creation of the dataset contents was started.\n\nscheduleTime -> (timestamp)\n\nThe time the creation of the dataset contents was scheduled to start.\n\ncompletionTime -> (timestamp)\n\nThe time the dataset content status was updated to SUCCEEDED or FAILED.\n\nnextToken -> (string)\n\nThe token to retrieve the next set of results, or null if there are no more results.",
      "command_examples": "Examples\n\nTo list information about dataset contents\n\nThe following list-dataset-contents example lists information about dataset contents that have been created.\n\naws iotanalytics list-dataset-contents \\\n    --dataset-name mydataset\n\n\nOutput:\n\n{\n    \"datasetContentSummaries\": [\n        {\n            \"status\": {\n                \"state\": \"SUCCEEDED\"\n            },\n            \"scheduleTime\": 1557863215.995,\n            \"version\": \"b10ea2a9-66c1-4d99-8d1f-518113b738d0\",\n            \"creationTime\": 1557863215.995\n        }\n    ]\n}\n\n\nFor more information, see ListDatasetContents in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "list-datasets",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/list-datasets.html",
      "command_description": "Description\n\nRetrieves information about datasets.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-datasets is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: datasetSummaries",
      "command_synopsis": "Synopsis\n  list-datasets\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ndatasetSummaries -> (list)\n\nA list of DatasetSummary objects.\n\n(structure)\n\nA summary of information about a dataset.\n\ndatasetName -> (string)\n\nThe name of the dataset.\n\nstatus -> (string)\n\nThe status of the dataset.\n\ncreationTime -> (timestamp)\n\nThe time the dataset was created.\n\nlastUpdateTime -> (timestamp)\n\nThe last time the dataset was updated.\n\ntriggers -> (list)\n\nA list of triggers. A trigger causes dataset content to be populated at a specified time interval or when another dataset is populated. The list of triggers can be empty or contain up to five DataSetTrigger objects\n\n(structure)\n\nThe DatasetTrigger that specifies when the dataset is automatically updated.\n\nschedule -> (structure)\n\nThe Schedule when the trigger is initiated.\n\nexpression -> (string)\n\nThe expression that defines when to trigger an update. For more information, see Schedule Expressions for Rules in the Amazon CloudWatch Events User Guide .\n\ndataset -> (structure)\n\nThe dataset whose content creation triggers the creation of this dataset’s contents.\n\nname -> (string)\n\nThe name of the dataset whose content generation triggers the new dataset content generation.\n\nactions -> (list)\n\nA list of DataActionSummary objects.\n\n(structure)\n\nInformation about the action that automatically creates the dataset’s contents.\n\nactionName -> (string)\n\nThe name of the action that automatically creates the dataset’s contents.\n\nactionType -> (string)\n\nThe type of action by which the dataset’s contents are automatically created.\n\nnextToken -> (string)\n\nThe token to retrieve the next set of results, or null if there are no more results.",
      "command_examples": "Examples\n\nTo retrieve information about datasets\n\nThe following list-datasets example lists summary information about available datasets.\n\naws iotanalytics list-datasets\n\n\nOutput:\n\n{\n    \"datasetSummaries\": [\n        {\n            \"status\": \"ACTIVE\",\n            \"datasetName\": \"mydataset\",\n            \"lastUpdateTime\": 1557859240.658,\n            \"triggers\": [],\n            \"creationTime\": 1557859240.658,\n            \"actions\": [\n                {\n                    \"actionName\": \"query_32\",\n                    \"actionType\": \"QUERY\"\n                }\n            ]\n        }\n    ]\n}\n\n\nFor more information, see ListDatasets in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "list-datastores",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/list-datastores.html",
      "command_description": "Description\n\nRetrieves a list of data stores.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-datastores is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: datastoreSummaries",
      "command_synopsis": "Synopsis\n  list-datastores\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ndatastoreSummaries -> (list)\n\nA list of DatastoreSummary objects.\n\n(structure)\n\nA summary of information about a data store.\n\ndatastoreName -> (string)\n\nThe name of the data store.\n\ndatastoreStorage -> (structure)\n\nWhere data in a data store is stored.\n\nserviceManagedS3 -> (structure)\n\nUsed to store data in an Amazon S3 bucket managed by IoT Analytics.\n\ncustomerManagedS3 -> (structure)\n\nUsed to store data in an Amazon S3 bucket managed by IoT Analytics.\n\nbucket -> (string)\n\nThe name of the Amazon S3 bucket where your data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the data store data objects. Each object in an Amazon S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 resources.\n\niotSiteWiseMultiLayerStorage -> (structure)\n\nUsed to store data used by IoT SiteWise in an Amazon S3 bucket that you manage.\n\ncustomerManagedS3Storage -> (structure)\n\nUsed to store data used by IoT SiteWise in an Amazon S3 bucket that you manage.\n\nbucket -> (string)\n\nThe name of the Amazon S3 bucket where your data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the data store data objects. Each object in an Amazon S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\nstatus -> (string)\n\nThe status of the data store.\n\ncreationTime -> (timestamp)\n\nWhen the data store was created.\n\nlastUpdateTime -> (timestamp)\n\nThe last time the data store was updated.\n\nlastMessageArrivalTime -> (timestamp)\n\nThe last time when a new message arrived in the data store.\n\nIoT Analytics updates this value at most once per minute for Amazon Simple Storage Service one data store. Hence, the lastMessageArrivalTime value is an approximation.\n\nThis feature only applies to messages that arrived in the data store after October 23, 2020.\n\nfileFormatType -> (string)\n\nThe file format of the data in the data store.\n\ndatastorePartitions -> (structure)\n\nContains information about the partition dimensions in a data store.\n\npartitions -> (list)\n\nA list of partition dimensions in a data store.\n\n(structure)\n\nA single dimension to partition a data store. The dimension must be an AttributePartition or a TimestampPartition .\n\nattributePartition -> (structure)\n\nA partition dimension defined by an attributeName .\n\nattributeName -> (string)\n\nThe name of the attribute that defines a partition dimension.\n\ntimestampPartition -> (structure)\n\nA partition dimension defined by a timestamp attribute.\n\nattributeName -> (string)\n\nThe attribute name of the partition defined by a timestamp.\n\ntimestampFormat -> (string)\n\nThe timestamp format of a partition defined by a timestamp. The default format is seconds since epoch (January 1, 1970 at midnight UTC time).\n\nnextToken -> (string)\n\nThe token to retrieve the next set of results, or null if there are no more results.",
      "command_examples": "Examples\n\nTo retrieve a list of data stores\n\nThe following list-datastores example displays summary information about the available data stores.\n\naws iotanalytics list-datastores\n\n\nOutput:\n\n{\n    \"datastoreSummaries\": [\n        {\n            \"status\": \"ACTIVE\",\n            \"datastoreName\": \"mydatastore\",\n            \"creationTime\": 1557858971.02,\n            \"lastUpdateTime\": 1557858971.02\n        }\n    ]\n}\n\n\nFor more information, see ListDatastores in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "list-pipelines",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/list-pipelines.html",
      "command_description": "Description\n\nRetrieves a list of pipelines.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.\n\nlist-pipelines is a paginated operation. Multiple API calls may be issued in order to retrieve the entire data set of results. You can disable pagination by providing the --no-paginate argument. When using --output text and the --query argument on a paginated response, the --query argument must extract data from the results of the following query expressions: pipelineSummaries",
      "command_synopsis": "Synopsis\n  list-pipelines\n[--cli-input-json | --cli-input-yaml]\n[--starting-token <value>]\n[--page-size <value>]\n[--max-items <value>]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "[--cli-input-json | --cli-input-yaml]",
        "[--starting-token <value>]",
        "[--page-size <value>]",
        "[--max-items <value>]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--starting-token (string)\n\nA token to specify where to start paginating. This is the NextToken from a previously truncated response.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--page-size (integer)\n\nThe size of each page to get in the AWS service call. This does not affect the number of items returned in the command’s output. Setting a smaller page size results in more calls to the AWS service, retrieving fewer items in each call. This can help prevent the AWS service calls from timing out.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--max-items (integer)\n\nThe total number of items to return in the command’s output. If the total number of items available is more than the value specified, a NextToken is provided in the command’s output. To resume pagination, provide the NextToken value in the starting-token argument of a subsequent command. Do not use the NextToken response element directly outside of the AWS CLI.\n\nFor usage examples, see Pagination in the AWS Command Line Interface User Guide .\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\npipelineSummaries -> (list)\n\nA list of PipelineSummary objects.\n\n(structure)\n\nA summary of information about a pipeline.\n\npipelineName -> (string)\n\nThe name of the pipeline.\n\nreprocessingSummaries -> (list)\n\nA summary of information about the pipeline reprocessing.\n\n(structure)\n\nInformation about pipeline reprocessing.\n\nid -> (string)\n\nThe reprocessingId returned by StartPipelineReprocessing .\n\nstatus -> (string)\n\nThe status of the pipeline reprocessing.\n\ncreationTime -> (timestamp)\n\nThe time the pipeline reprocessing was created.\n\ncreationTime -> (timestamp)\n\nWhen the pipeline was created.\n\nlastUpdateTime -> (timestamp)\n\nWhen the pipeline was last updated.\n\nnextToken -> (string)\n\nThe token to retrieve the next set of results, or null if there are no more results.",
      "command_examples": "Examples\n\nTo retrieve a list of pipelines\n\nThe following list-pipelines example displays a list of available pipelines.\n\naws iotanalytics list-pipelines\n\n\nOutput:\n\n{\n    \"pipelineSummaries\": [\n        {\n            \"pipelineName\": \"mypipeline\",\n            \"creationTime\": 1557859124.432,\n            \"lastUpdateTime\": 1557859124.432,\n            \"reprocessingSummaries\": []\n        }\n    ]\n}\n\n\nFor more information, see ListPipelines in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "list-tags-for-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/list-tags-for-resource.html",
      "command_description": "Description\n\nLists the tags (metadata) that you have assigned to the resource.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  list-tags-for-resource\n--resource-arn <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe ARN of the resource whose tags you want to list.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\ntags -> (list)\n\nThe tags (metadata) that you have assigned to the resource.\n\n(structure)\n\nA set of key-value pairs that are used to manage the resource.\n\nkey -> (string)\n\nThe tag’s key.\n\nvalue -> (string)\n\nThe tag’s value.",
      "command_examples": "Examples\n\nTo list tags for a resource\n\nThe following list-tags-for-resource example Lists the tags that you have attached to the specified resource.\n\naws iotanalytics list-tags-for-resource \\\n    --resource-arn \"arn:aws:iotanalytics:us-west-2:123456789012:channel/mychannel\"\n\n\nOutput:\n\n{\n    \"tags\": [\n        {\n            \"value\": \"bar\",\n            \"key\": \"foo\"\n        }\n    ]\n}\n\n\nFor more information, see ListTagsForResource in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "put-logging-options",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/put-logging-options.html",
      "command_description": "Description\n\nSets or updates the IoT Analytics logging options.\n\nIf you update the value of any loggingOptions field, it takes up to one minute for the change to take effect. Also, if you change the policy attached to the role you specified in the roleArn field (for example, to correct an invalid policy), it takes up to five minutes for that change to take effect.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  put-logging-options\n--logging-options <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--logging-options <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--logging-options (structure)\n\nThe new values of the IoT Analytics logging options.\n\nroleArn -> (string)\n\nThe ARN of the role that grants permission to IoT Analytics to perform logging.\n\nlevel -> (string)\n\nThe logging level. Currently, only ERROR is supported.\n\nenabled -> (boolean)\n\nIf true, logging is enabled for IoT Analytics.\n\nShorthand Syntax:\n\nroleArn=string,level=string,enabled=boolean\n\n\nJSON Syntax:\n\n{\n  \"roleArn\": \"string\",\n  \"level\": \"ERROR\",\n  \"enabled\": true|false\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo set or update logging options\n\nThe following put-logging-options example sets or updates the AWS IoT Analytics logging options. If you update the value of any loggingOptions field, it can take up to one minute for the change to take effect. Also, if you change the policy attached to the role you specified in the “roleArn” field (for example, to correct an invalid policy) it can take up to five minutes for that change to take effect.\n\naws iotanalytics put-logging-options \\\n    --cli-input-json file://put-logging-options.json\n\n\nContents of put-logging-options.json:\n\n{\n    \"loggingOptions\": {\n        \"roleArn\": \"arn:aws:iam::123456789012:role/service-role/myIoTAnalyticsRole\",\n        \"level\": \"ERROR\",\n        \"enabled\": true\n    }\n}\n\n\nThis command produces no output.\n\nFor more information, see PutLoggingOptions in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "run-pipeline-activity",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/run-pipeline-activity.html",
      "command_description": "Description\n\nSimulates the results of running a pipeline activity on a message payload.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  run-pipeline-activity\n--pipeline-activity <value>\n--payloads <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--pipeline-activity <value>",
        "--payloads <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--pipeline-activity (structure)\n\nThe pipeline activity that is run. This must not be a channel activity or a data store activity because these activities are used in a pipeline only to load the original message and to store the (possibly) transformed message. If a Lambda activity is specified, only short-running Lambda functions (those with a timeout of less than 30 seconds or less) can be used.\n\nchannel -> (structure)\n\nDetermines the source of the messages to be processed.\n\nname -> (string)\n\nThe name of the channel activity.\n\nchannelName -> (string)\n\nThe name of the channel from which the messages are processed.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nlambda -> (structure)\n\nRuns a Lambda function to modify the message.\n\nname -> (string)\n\nThe name of the lambda activity.\n\nlambdaName -> (string)\n\nThe name of the Lambda function that is run on the message.\n\nbatchSize -> (integer)\n\nThe number of messages passed to the Lambda function for processing.\n\nThe Lambda function must be able to process all of these messages within five minutes, which is the maximum timeout duration for Lambda functions.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndatastore -> (structure)\n\nSpecifies where to store the processed message data.\n\nname -> (string)\n\nThe name of the datastore activity.\n\ndatastoreName -> (string)\n\nThe name of the data store where processed messages are stored.\n\naddAttributes -> (structure)\n\nAdds other attributes based on existing attributes in the message.\n\nname -> (string)\n\nThe name of the addAttributes activity.\n\nattributes -> (map)\n\nA list of 1-50 AttributeNameMapping objects that map an existing attribute to a new attribute.\n\nNote\n\nThe existing attributes remain in the message, so if you want to remove the originals, use RemoveAttributeActivity .\n\nkey -> (string)\n\nvalue -> (string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nremoveAttributes -> (structure)\n\nRemoves attributes from a message.\n\nname -> (string)\n\nThe name of the removeAttributes activity.\n\nattributes -> (list)\n\nA list of 1-50 attributes to remove from the message.\n\n(string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nselectAttributes -> (structure)\n\nUsed to create a new message using only the specified attributes from the original message.\n\nname -> (string)\n\nThe name of the selectAttributes activity.\n\nattributes -> (list)\n\nA list of the attributes to select from the message.\n\n(string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nfilter -> (structure)\n\nFilters a message based on its attributes.\n\nname -> (string)\n\nThe name of the filter activity.\n\nfilter -> (string)\n\nAn expression that looks like a SQL WHERE clause that must return a Boolean value. Messages that satisfy the condition are passed to the next activity.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nmath -> (structure)\n\nComputes an arithmetic expression using the message’s attributes and adds it to the message.\n\nname -> (string)\n\nThe name of the math activity.\n\nattribute -> (string)\n\nThe name of the attribute that contains the result of the math operation.\n\nmath -> (string)\n\nAn expression that uses one or more existing attributes and must return an integer value.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndeviceRegistryEnrich -> (structure)\n\nAdds data from the IoT device registry to your message.\n\nname -> (string)\n\nThe name of the deviceRegistryEnrich activity.\n\nattribute -> (string)\n\nThe name of the attribute that is added to the message.\n\nthingName -> (string)\n\nThe name of the IoT device whose registry information is added to the message.\n\nroleArn -> (string)\n\nThe ARN of the role that allows access to the device’s registry information.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndeviceShadowEnrich -> (structure)\n\nAdds information from the IoT Device Shadow service to a message.\n\nname -> (string)\n\nThe name of the deviceShadowEnrich activity.\n\nattribute -> (string)\n\nThe name of the attribute that is added to the message.\n\nthingName -> (string)\n\nThe name of the IoT device whose shadow information is added to the message.\n\nroleArn -> (string)\n\nThe ARN of the role that allows access to the device’s shadow.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nShorthand Syntax:\n\nchannel={name=string,channelName=string,next=string},lambda={name=string,lambdaName=string,batchSize=integer,next=string},datastore={name=string,datastoreName=string},addAttributes={name=string,attributes={KeyName1=string,KeyName2=string},next=string},removeAttributes={name=string,attributes=[string,string],next=string},selectAttributes={name=string,attributes=[string,string],next=string},filter={name=string,filter=string,next=string},math={name=string,attribute=string,math=string,next=string},deviceRegistryEnrich={name=string,attribute=string,thingName=string,roleArn=string,next=string},deviceShadowEnrich={name=string,attribute=string,thingName=string,roleArn=string,next=string}\n\n\nJSON Syntax:\n\n{\n  \"channel\": {\n    \"name\": \"string\",\n    \"channelName\": \"string\",\n    \"next\": \"string\"\n  },\n  \"lambda\": {\n    \"name\": \"string\",\n    \"lambdaName\": \"string\",\n    \"batchSize\": integer,\n    \"next\": \"string\"\n  },\n  \"datastore\": {\n    \"name\": \"string\",\n    \"datastoreName\": \"string\"\n  },\n  \"addAttributes\": {\n    \"name\": \"string\",\n    \"attributes\": {\"string\": \"string\"\n      ...},\n    \"next\": \"string\"\n  },\n  \"removeAttributes\": {\n    \"name\": \"string\",\n    \"attributes\": [\"string\", ...],\n    \"next\": \"string\"\n  },\n  \"selectAttributes\": {\n    \"name\": \"string\",\n    \"attributes\": [\"string\", ...],\n    \"next\": \"string\"\n  },\n  \"filter\": {\n    \"name\": \"string\",\n    \"filter\": \"string\",\n    \"next\": \"string\"\n  },\n  \"math\": {\n    \"name\": \"string\",\n    \"attribute\": \"string\",\n    \"math\": \"string\",\n    \"next\": \"string\"\n  },\n  \"deviceRegistryEnrich\": {\n    \"name\": \"string\",\n    \"attribute\": \"string\",\n    \"thingName\": \"string\",\n    \"roleArn\": \"string\",\n    \"next\": \"string\"\n  },\n  \"deviceShadowEnrich\": {\n    \"name\": \"string\",\n    \"attribute\": \"string\",\n    \"thingName\": \"string\",\n    \"roleArn\": \"string\",\n    \"next\": \"string\"\n  }\n}\n\n\n--payloads (list)\n\nThe sample message payloads on which the pipeline activity is run.\n\n(blob)\n\nSyntax:\n\nblob blob ...\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\npayloads -> (list)\n\nThe enriched or transformed sample message payloads as base64-encoded strings. (The results of running the pipeline activity on each input sample message payload, encoded in base64.)\n\n(blob)\n\nlogResult -> (string)\n\nIn case the pipeline activity fails, the log message that is generated.",
      "command_examples": "Examples\n\nTo simulate a pipeline activity\n\nThe following run-pipeline-activity example simulates the results of running a pipeline activity on a message payload.\n\naws iotanalytics run-pipeline-activity \\\n    --cli-binary-format raw-in-base64-out \\\n    --pipeline-activity file://maths.json \\\n    --payloads file://payloads.json\n\n\nContents of maths.json:\n\n{\n    \"math\": {\n        \"name\": \"MyMathActivity\",\n        \"math\": \"((temp - 32) * 5.0) / 9.0\",\n        \"attribute\": \"tempC\"\n    }\n}\n\n\nContents of payloads.json:\n\n[\n    \"{\\\"humidity\\\": 52, \\\"temp\\\": 68 }\",\n    \"{\\\"humidity\\\": 52, \\\"temp\\\": 32 }\"\n]\n\n\nOutput:\n\n{\n    \"logResult\": \"\",\n    \"payloads\": [\n        \"eyJodW1pZGl0eSI6NTIsInRlbXAiOjY4LCJ0ZW1wQyI6MjB9\",\n        \"eyJodW1pZGl0eSI6NTIsInRlbXAiOjMyLCJ0ZW1wQyI6MH0=\"\n    ]\n}\n\n\nFor more information, see RunPipelineActivity in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "sample-channel-data",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/sample-channel-data.html",
      "command_description": "Description\n\nRetrieves a sample of messages from the specified channel ingested during the specified timeframe. Up to 10 messages can be retrieved.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  sample-channel-data\n--channel-name <value>\n[--max-messages <value>]\n[--start-time <value>]\n[--end-time <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-name <value>",
        "[--max-messages <value>]",
        "[--start-time <value>]",
        "[--end-time <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-name (string)\n\nThe name of the channel whose message samples are retrieved.\n\n--max-messages (integer)\n\nThe number of sample messages to be retrieved. The limit is 10. The default is also 10.\n\n--start-time (timestamp)\n\nThe start of the time window from which sample messages are retrieved.\n\n--end-time (timestamp)\n\nThe end of the time window from which sample messages are retrieved.\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\npayloads -> (list)\n\nThe list of message samples. Each sample message is returned as a base64-encoded string.\n\n(blob)",
      "command_examples": "Examples\n\nTo retrieve sample messages from a channel\n\nThe following sample-channel-data example retrieves a sample of messages from the specified channel ingested during the specified timeframe. You can retrieve up to 10 messages.\n\naws iotanalytics sample-channel-data \\\n    --channel-name mychannel\n\n\nOutput:\n\n{\n    \"payloads\": [\n        \"eyAidGVtcGVyYXR1cmUiOiAyMCB9\",\n        \"eyAiZm9vIjogImJhciIgfQ==\"\n    ]\n}\n\n\nFor more information, see SampleChannelData in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "start-pipeline-reprocessing",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/start-pipeline-reprocessing.html",
      "command_description": "Description\n\nStarts the reprocessing of raw message data through the pipeline.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  start-pipeline-reprocessing\n--pipeline-name <value>\n[--start-time <value>]\n[--end-time <value>]\n[--channel-messages <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--pipeline-name <value>",
        "[--start-time <value>]",
        "[--end-time <value>]",
        "[--channel-messages <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--pipeline-name (string)\n\nThe name of the pipeline on which to start reprocessing.\n\n--start-time (timestamp)\n\nThe start time (inclusive) of raw message data that is reprocessed.\n\nIf you specify a value for the startTime parameter, you must not use the channelMessages object.\n\n--end-time (timestamp)\n\nThe end time (exclusive) of raw message data that is reprocessed.\n\nIf you specify a value for the endTime parameter, you must not use the channelMessages object.\n\n--channel-messages (structure)\n\nSpecifies one or more sets of channel messages that you want to reprocess.\n\nIf you use the channelMessages object, you must not specify a value for startTime and endTime .\n\ns3Paths -> (list)\n\nSpecifies one or more keys that identify the Amazon Simple Storage Service (Amazon S3) objects that save your channel messages.\n\nYou must use the full path for the key.\n\nExample path: channel/mychannel/__dt=2020-02-29 00:00:00/1582940490000_1582940520000_123456789012_mychannel_0_2118.0.json.gz\n\n(string)\n\nShorthand Syntax:\n\ns3Paths=string,string\n\n\nJSON Syntax:\n\n{\n  \"s3Paths\": [\"string\", ...]\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nreprocessingId -> (string)\n\nThe ID of the pipeline reprocessing activity that was started.",
      "command_examples": "Examples\n\nTo start pipeline reprocessing\n\nThe following start-pipeline-reprocessing example starts the reprocessing of raw message data through the specified pipeline.\n\naws iotanalytics start-pipeline-reprocessing \\\n    --pipeline-name mypipeline\n\n\nOutput:\n\n{\n    \"reprocessingId\": \"6ad2764f-fb13-4de3-b101-4e74af03b043\"\n}\n\n\nFor more information, see StartPipelineReprocessing in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "tag-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/tag-resource.html",
      "command_description": "Description\n\nAdds to or modifies the tags of the given resource. Tags are metadata that can be used to manage a resource.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  tag-resource\n--resource-arn <value>\n--tags <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "--tags <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe ARN of the resource whose tags you want to modify.\n\n--tags (list)\n\nThe new or modified tags for the resource.\n\n(structure)\n\nA set of key-value pairs that are used to manage the resource.\n\nkey -> (string)\n\nThe tag’s key.\n\nvalue -> (string)\n\nThe tag’s value.\n\nShorthand Syntax:\n\nkey=string,value=string ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"key\": \"string\",\n    \"value\": \"string\"\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo add or modify tags for a resource\n\nThe following tag-resource example adds to or modifies the tags attached to the specified resource.\n\naws iotanalytics tag-resource \\\n    --resource-arn \"arn:aws:iotanalytics:us-west-2:123456789012:channel/mychannel\" \\\n    --tags \"[{\\\"key\\\": \\\"Environment\\\", \\\"value\\\": \\\"Production\\\"}]\"\n\n\nThis command produces no output.\n\nFor more information, see TagResource in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "untag-resource",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/untag-resource.html",
      "command_description": "Description\n\nRemoves the given tags (metadata) from the resource.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  untag-resource\n--resource-arn <value>\n--tag-keys <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--resource-arn <value>",
        "--tag-keys <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--resource-arn (string)\n\nThe ARN of the resource whose tags you want to remove.\n\n--tag-keys (list)\n\nThe keys of those tags which you want to remove.\n\n(string)\n\nSyntax:\n\n\"string\" \"string\" ...\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo remove tags from a resource\n\nThe following untag-resource example removes the tags with the specified key names from the specified resource.\n\naws iotanalytics untag-resource \\\n    --resource-arn \"arn:aws:iotanalytics:us-west-2:123456789012:channel/mychannel\" \\\n    --tag-keys \"[\\\"Environment\\\"]\"\n\n\nThis command produces no output.\n\nFor more information, see `UntagResource <https://docs.aws.amazon.com/iotanalytics/latest/APIReference/API_UntagResource.html >`__ in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "update-channel",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/update-channel.html",
      "command_description": "Description\n\nUsed to update the settings of a channel.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-channel\n--channel-name <value>\n[--channel-storage <value>]\n[--retention-period <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--channel-name <value>",
        "[--channel-storage <value>]",
        "[--retention-period <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--channel-name (string)\n\nThe name of the channel to be updated.\n\n--channel-storage (structure)\n\nWhere channel data is stored. You can choose one of serviceManagedS3 or customerManagedS3 storage. If not specified, the default is serviceManagedS3 . You can’t change this storage option after the channel is created.\n\nserviceManagedS3 -> (structure)\n\nUsed to store channel data in an S3 bucket managed by IoT Analytics. You can’t change the choice of S3 storage after the data store is created.\n\ncustomerManagedS3 -> (structure)\n\nUsed to store channel data in an S3 bucket that you manage. If customer managed storage is selected, the retentionPeriod parameter is ignored. You can’t change the choice of S3 storage after the data store is created.\n\nbucket -> (string)\n\nThe name of the S3 bucket in which channel data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the channel data objects. Each object in an S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 resources.\n\nShorthand Syntax:\n\nserviceManagedS3={},customerManagedS3={bucket=string,keyPrefix=string,roleArn=string}\n\n\nJSON Syntax:\n\n{\n  \"serviceManagedS3\": {\n\n  },\n  \"customerManagedS3\": {\n    \"bucket\": \"string\",\n    \"keyPrefix\": \"string\",\n    \"roleArn\": \"string\"\n  }\n}\n\n\n--retention-period (structure)\n\nHow long, in days, message data is kept for the channel. The retention period can’t be updated if the channel’s Amazon S3 storage is customer-managed.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.\n\nShorthand Syntax:\n\nunlimited=boolean,numberOfDays=integer\n\n\nJSON Syntax:\n\n{\n  \"unlimited\": true|false,\n  \"numberOfDays\": integer\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo modify a channel\n\nThe following update-channel example modifies the settings for the specified channel.\n\naws iotanalytics update-channel \\\n    --cli-input-json file://update-channel.json\n\n\nContents of update-channel.json:\n\n{\n    \"channelName\": \"mychannel\",\n    \"retentionPeriod\": {\n        \"numberOfDays\": 92\n    }\n}\n\n\nThis command produces no output.\n\nFor more information, see UpdateChannel in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "update-dataset",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/update-dataset.html",
      "command_description": "Description\n\nUpdates the settings of a dataset.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-dataset\n--dataset-name <value>\n--actions <value>\n[--triggers <value>]\n[--content-delivery-rules <value>]\n[--retention-period <value>]\n[--versioning-configuration <value>]\n[--late-data-rules <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--dataset-name <value>",
        "--actions <value>",
        "[--triggers <value>]",
        "[--content-delivery-rules <value>]",
        "[--retention-period <value>]",
        "[--versioning-configuration <value>]",
        "[--late-data-rules <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--dataset-name (string)\n\nThe name of the dataset to update.\n\n--actions (list)\n\nA list of DatasetAction objects.\n\n(structure)\n\nA DatasetAction object that specifies how dataset contents are automatically created.\n\nactionName -> (string)\n\nThe name of the dataset action by which dataset contents are automatically created.\n\nqueryAction -> (structure)\n\nAn SqlQueryDatasetAction object that uses an SQL query to automatically create dataset contents.\n\nsqlQuery -> (string)\n\nA SQL query string.\n\nfilters -> (list)\n\nPrefilters applied to message data.\n\n(structure)\n\nInformation that is used to filter message data, to segregate it according to the timeframe in which it arrives.\n\ndeltaTime -> (structure)\n\nUsed to limit data to that which has arrived since the last execution of the action.\n\noffsetSeconds -> (integer)\n\nThe number of seconds of estimated in-flight lag time of message data. When you create dataset contents using message data from a specified timeframe, some message data might still be in flight when processing begins, and so do not arrive in time to be processed. Use this field to make allowances for the in flight time of your message data, so that data not processed from a previous timeframe is included with the next timeframe. Otherwise, missed message data would be excluded from processing during the next timeframe too, because its timestamp places it within the previous timeframe.\n\ntimeExpression -> (string)\n\nAn expression by which the time of the message data might be determined. This can be the name of a timestamp field or a SQL expression that is used to derive the time the message data was generated.\n\ncontainerAction -> (structure)\n\nInformation that allows the system to run a containerized application to create the dataset contents. The application must be in a Docker container along with any required support libraries.\n\nimage -> (string)\n\nThe ARN of the Docker container stored in your account. The Docker container contains an application and required support libraries and is used to generate dataset contents.\n\nexecutionRoleArn -> (string)\n\nThe ARN of the role that gives permission to the system to access required resources to run the containerAction . This includes, at minimum, permission to retrieve the dataset contents that are the input to the containerized application.\n\nresourceConfiguration -> (structure)\n\nConfiguration of the resource that executes the containerAction .\n\ncomputeType -> (string)\n\nThe type of the compute resource used to execute the containerAction . Possible values are: ACU_1 (vCPU=4, memory=16 GiB) or ACU_2 (vCPU=8, memory=32 GiB).\n\nvolumeSizeInGB -> (integer)\n\nThe size, in GB, of the persistent storage available to the resource instance used to execute the containerAction (min: 1, max: 50).\n\nvariables -> (list)\n\nThe values of variables used in the context of the execution of the containerized application (basically, parameters passed to the application). Each variable must have a name and a value given by one of stringValue , datasetContentVersionValue , or outputFileUriValue .\n\n(structure)\n\nAn instance of a variable to be passed to the containerAction execution. Each variable must have a name and a value given by one of stringValue , datasetContentVersionValue , or outputFileUriValue .\n\nname -> (string)\n\nThe name of the variable.\n\nstringValue -> (string)\n\nThe value of the variable as a string.\n\ndoubleValue -> (double)\n\nThe value of the variable as a double (numeric).\n\ndatasetContentVersionValue -> (structure)\n\nThe value of the variable as a structure that specifies a dataset content version.\n\ndatasetName -> (string)\n\nThe name of the dataset whose latest contents are used as input to the notebook or application.\n\noutputFileUriValue -> (structure)\n\nThe value of the variable as a structure that specifies an output file URI.\n\nfileName -> (string)\n\nThe URI of the location where dataset contents are stored, usually the URI of a file in an S3 bucket.\n\nJSON Syntax:\n\n[\n  {\n    \"actionName\": \"string\",\n    \"queryAction\": {\n      \"sqlQuery\": \"string\",\n      \"filters\": [\n        {\n          \"deltaTime\": {\n            \"offsetSeconds\": integer,\n            \"timeExpression\": \"string\"\n          }\n        }\n        ...\n      ]\n    },\n    \"containerAction\": {\n      \"image\": \"string\",\n      \"executionRoleArn\": \"string\",\n      \"resourceConfiguration\": {\n        \"computeType\": \"ACU_1\"|\"ACU_2\",\n        \"volumeSizeInGB\": integer\n      },\n      \"variables\": [\n        {\n          \"name\": \"string\",\n          \"stringValue\": \"string\",\n          \"doubleValue\": double,\n          \"datasetContentVersionValue\": {\n            \"datasetName\": \"string\"\n          },\n          \"outputFileUriValue\": {\n            \"fileName\": \"string\"\n          }\n        }\n        ...\n      ]\n    }\n  }\n  ...\n]\n\n\n--triggers (list)\n\nA list of DatasetTrigger objects. The list can be empty or can contain up to five DatasetTrigger objects.\n\n(structure)\n\nThe DatasetTrigger that specifies when the dataset is automatically updated.\n\nschedule -> (structure)\n\nThe Schedule when the trigger is initiated.\n\nexpression -> (string)\n\nThe expression that defines when to trigger an update. For more information, see Schedule Expressions for Rules in the Amazon CloudWatch Events User Guide .\n\ndataset -> (structure)\n\nThe dataset whose content creation triggers the creation of this dataset’s contents.\n\nname -> (string)\n\nThe name of the dataset whose content generation triggers the new dataset content generation.\n\nShorthand Syntax:\n\nschedule={expression=string},dataset={name=string} ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"schedule\": {\n      \"expression\": \"string\"\n    },\n    \"dataset\": {\n      \"name\": \"string\"\n    }\n  }\n  ...\n]\n\n\n--content-delivery-rules (list)\n\nWhen dataset contents are created, they are delivered to destinations specified here.\n\n(structure)\n\nWhen dataset contents are created, they are delivered to destination specified here.\n\nentryName -> (string)\n\nThe name of the dataset content delivery rules entry.\n\ndestination -> (structure)\n\nThe destination to which dataset contents are delivered.\n\niotEventsDestinationConfiguration -> (structure)\n\nConfiguration information for delivery of dataset contents to IoT Events.\n\ninputName -> (string)\n\nThe name of the IoT Events input to which dataset contents are delivered.\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to deliver dataset contents to an IoT Events input.\n\ns3DestinationConfiguration -> (structure)\n\nConfiguration information for delivery of dataset contents to Amazon S3.\n\nbucket -> (string)\n\nThe name of the S3 bucket to which dataset contents are delivered.\n\nkey -> (string)\n\nThe key of the dataset contents object in an S3 bucket. Each object has a key that is a unique identifier. Each object has exactly one key.\n\nYou can create a unique key with the following options:\n\nUse !{iotanalytics:scheduleTime} to insert the time of a scheduled SQL query run.\n\nUse !{iotanalytics:versionId} to insert a unique hash that identifies a dataset content.\n\nUse !{iotanalytics:creationTime} to insert the creation time of a dataset content.\n\nThe following example creates a unique key for a CSV file: dataset/mydataset/!{iotanalytics:scheduleTime}/!{iotanalytics:versionId}.csv\n\nNote\n\nIf you don’t use !{iotanalytics:versionId} to specify the key, you might get duplicate keys. For example, you might have two dataset contents with the same scheduleTime but different versionId s. This means that one dataset content overwrites the other.\n\nglueConfiguration -> (structure)\n\nConfiguration information for coordination with Glue, a fully managed extract, transform and load (ETL) service.\n\ntableName -> (string)\n\nThe name of the table in your Glue Data Catalog that is used to perform the ETL operations. An Glue Data Catalog table contains partitioned data and descriptions of data sources and targets.\n\ndatabaseName -> (string)\n\nThe name of the database in your Glue Data Catalog in which the table is located. An Glue Data Catalog database contains metadata tables.\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 and Glue resources.\n\nJSON Syntax:\n\n[\n  {\n    \"entryName\": \"string\",\n    \"destination\": {\n      \"iotEventsDestinationConfiguration\": {\n        \"inputName\": \"string\",\n        \"roleArn\": \"string\"\n      },\n      \"s3DestinationConfiguration\": {\n        \"bucket\": \"string\",\n        \"key\": \"string\",\n        \"glueConfiguration\": {\n          \"tableName\": \"string\",\n          \"databaseName\": \"string\"\n        },\n        \"roleArn\": \"string\"\n      }\n    }\n  }\n  ...\n]\n\n\n--retention-period (structure)\n\nHow long, in days, dataset contents are kept for the dataset.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.\n\nShorthand Syntax:\n\nunlimited=boolean,numberOfDays=integer\n\n\nJSON Syntax:\n\n{\n  \"unlimited\": true|false,\n  \"numberOfDays\": integer\n}\n\n\n--versioning-configuration (structure)\n\nOptional. How many versions of dataset contents are kept. If not specified or set to null, only the latest version plus the latest succeeded version (if they are different) are kept for the time period specified by the retentionPeriod parameter. For more information, see Keeping Multiple Versions of IoT Analytics datasets in the IoT Analytics User Guide .\n\nunlimited -> (boolean)\n\nIf true, unlimited versions of dataset contents are kept.\n\nmaxVersions -> (integer)\n\nHow many versions of dataset contents are kept. The unlimited parameter must be false .\n\nShorthand Syntax:\n\nunlimited=boolean,maxVersions=integer\n\n\nJSON Syntax:\n\n{\n  \"unlimited\": true|false,\n  \"maxVersions\": integer\n}\n\n\n--late-data-rules (list)\n\nA list of data rules that send notifications to CloudWatch, when data arrives late. To specify lateDataRules , the dataset must use a DeltaTimer filter.\n\n(structure)\n\nA structure that contains the name and configuration information of a late data rule.\n\nruleName -> (string)\n\nThe name of the late data rule.\n\nruleConfiguration -> (structure)\n\nThe information needed to configure the late data rule.\n\ndeltaTimeSessionWindowConfiguration -> (structure)\n\nThe information needed to configure a delta time session window.\n\ntimeoutInMinutes -> (integer)\n\nA time interval. You can use timeoutInMinutes so that IoT Analytics can batch up late data notifications that have been generated since the last execution. IoT Analytics sends one batch of notifications to Amazon CloudWatch Events at one time.\n\nFor more information about how to write a timestamp expression, see Date and Time Functions and Operators , in the Presto 0.172 Documentation .\n\nShorthand Syntax:\n\nruleName=string,ruleConfiguration={deltaTimeSessionWindowConfiguration={timeoutInMinutes=integer}} ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"ruleName\": \"string\",\n    \"ruleConfiguration\": {\n      \"deltaTimeSessionWindowConfiguration\": {\n        \"timeoutInMinutes\": integer\n      }\n    }\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo update a dataset\n\nThe following update-dataset example modifies the settings of the specified dataset.\n\naws iotanalytics update-dataset \\\n    --cli-input-json file://update-dataset.json\n\n\nContents of update-dataset.json:\n\n{\n    \"datasetName\": \"mydataset\",\n    \"actions\": [\n        {\n            \"actionName\": \"myDatasetUpdateAction\",\n            \"queryAction\": {\n                \"sqlQuery\": \"SELECT * FROM mydatastore\"\n            }\n        }\n    ],\n    \"retentionPeriod\": {\n        \"numberOfDays\": 92\n    }\n}\n\n\nThis command produces no output.\n\nFor more information, see `UpdateDataset <https://docs.aws.amazon.com/iotanalytics/latest/APIReference/API_UpdateDataset.html >`__ in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "update-datastore",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/update-datastore.html",
      "command_description": "Description\n\nUsed to update the settings of a data store.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-datastore\n--datastore-name <value>\n[--retention-period <value>]\n[--datastore-storage <value>]\n[--file-format-configuration <value>]\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--datastore-name <value>",
        "[--retention-period <value>]",
        "[--datastore-storage <value>]",
        "[--file-format-configuration <value>]",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--datastore-name (string)\n\nThe name of the data store to be updated.\n\n--retention-period (structure)\n\nHow long, in days, message data is kept for the data store. The retention period can’t be updated if the data store’s Amazon S3 storage is customer-managed.\n\nunlimited -> (boolean)\n\nIf true, message data is kept indefinitely.\n\nnumberOfDays -> (integer)\n\nThe number of days that message data is kept. The unlimited parameter must be false.\n\nShorthand Syntax:\n\nunlimited=boolean,numberOfDays=integer\n\n\nJSON Syntax:\n\n{\n  \"unlimited\": true|false,\n  \"numberOfDays\": integer\n}\n\n\n--datastore-storage (structure)\n\nWhere data in a data store is stored.. You can choose serviceManagedS3 storage, customerManagedS3 storage, or iotSiteWiseMultiLayerStorage storage. The default is serviceManagedS3 . You can’t change the choice of Amazon S3 storage after your data store is created.\n\nserviceManagedS3 -> (structure)\n\nUsed to store data in an Amazon S3 bucket managed by IoT Analytics. You can’t change the choice of Amazon S3 storage after your data store is created.\n\ncustomerManagedS3 -> (structure)\n\nS3-customer-managed; When you choose customer-managed storage, the retentionPeriod parameter is ignored. You can’t change the choice of Amazon S3 storage after your data store is created.\n\nbucket -> (string)\n\nThe name of the Amazon S3 bucket where your data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the data store data objects. Each object in an Amazon S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\nroleArn -> (string)\n\nThe ARN of the role that grants IoT Analytics permission to interact with your Amazon S3 resources.\n\niotSiteWiseMultiLayerStorage -> (structure)\n\nUsed to store data used by IoT SiteWise in an Amazon S3 bucket that you manage. You can’t change the choice of Amazon S3 storage after your data store is created.\n\ncustomerManagedS3Storage -> (structure)\n\nUsed to store data used by IoT SiteWise in an Amazon S3 bucket that you manage.\n\nbucket -> (string)\n\nThe name of the Amazon S3 bucket where your data is stored.\n\nkeyPrefix -> (string)\n\n(Optional) The prefix used to create the keys of the data store data objects. Each object in an Amazon S3 bucket has a key that is its unique identifier in the bucket. Each object in a bucket has exactly one key. The prefix must end with a forward slash (/).\n\nShorthand Syntax:\n\nserviceManagedS3={},customerManagedS3={bucket=string,keyPrefix=string,roleArn=string},iotSiteWiseMultiLayerStorage={customerManagedS3Storage={bucket=string,keyPrefix=string}}\n\n\nJSON Syntax:\n\n{\n  \"serviceManagedS3\": {\n\n  },\n  \"customerManagedS3\": {\n    \"bucket\": \"string\",\n    \"keyPrefix\": \"string\",\n    \"roleArn\": \"string\"\n  },\n  \"iotSiteWiseMultiLayerStorage\": {\n    \"customerManagedS3Storage\": {\n      \"bucket\": \"string\",\n      \"keyPrefix\": \"string\"\n    }\n  }\n}\n\n\n--file-format-configuration (structure)\n\nContains the configuration information of file formats. IoT Analytics data stores support JSON and Parquet .\n\nThe default file format is JSON. You can specify only one format.\n\nYou can’t change the file format after you create the data store.\n\njsonConfiguration -> (structure)\n\nContains the configuration information of the JSON format.\n\nparquetConfiguration -> (structure)\n\nContains the configuration information of the Parquet format.\n\nschemaDefinition -> (structure)\n\nInformation needed to define a schema.\n\ncolumns -> (list)\n\nSpecifies one or more columns that store your data.\n\nEach schema can have up to 100 columns. Each column can have up to 100 nested types.\n\n(structure)\n\nContains information about a column that stores your data.\n\nname -> (string)\n\nThe name of the column.\n\ntype -> (string)\n\nThe type of data. For more information about the supported data types, see Common data types in the Glue Developer Guide .\n\nJSON Syntax:\n\n{\n  \"jsonConfiguration\": {\n\n  },\n  \"parquetConfiguration\": {\n    \"schemaDefinition\": {\n      \"columns\": [\n        {\n          \"name\": \"string\",\n          \"type\": \"string\"\n        }\n        ...\n      ]\n    }\n  }\n}\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo update a data store\n\nThe following update-datastore example modifies the settings of the specified data store.\n\naws iotanalytics update-datastore \\\n    --cli-input-json file://update-datastore.json\n\n\nContents of update-datastore.json:\n\n{\n    \"datastoreName\": \"mydatastore\",\n    \"retentionPeriod\": {\n        \"numberOfDays\": 93\n    }\n}\n\n\nThis command produces no output.\n\nFor more information, see UpdateDatastore in the AWS IoT Analytics API Reference."
    },
    {
      "command_name": "update-pipeline",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iotanalytics/update-pipeline.html",
      "command_description": "Description\n\nUpdates the settings of a pipeline. You must specify both a channel and a datastore activity and, optionally, as many as 23 additional activities in the pipelineActivities array.\n\nSee also: AWS API Documentation\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  update-pipeline\n--pipeline-name <value>\n--pipeline-activities <value>\n[--cli-input-json | --cli-input-yaml]\n[--generate-cli-skeleton <value>]\n",
      "command_options": [
        "--pipeline-name <value>",
        "--pipeline-activities <value>",
        "[--cli-input-json | --cli-input-yaml]",
        "[--generate-cli-skeleton <value>]"
      ],
      "command_options_description": "Options\n\n--pipeline-name (string)\n\nThe name of the pipeline to update.\n\n--pipeline-activities (list)\n\nA list of PipelineActivity objects. Activities perform transformations on your messages, such as removing, renaming or adding message attributes; filtering messages based on attribute values; invoking your Lambda functions on messages for advanced processing; or performing mathematical transformations to normalize device data.\n\nThe list can be 2-25 PipelineActivity objects and must contain both a channel and a datastore activity. Each entry in the list must contain only one activity. For example:\n\npipelineActivities = [ { \"channel\": { ... } }, { \"lambda\": { ... } }, ... ]\n\n(structure)\n\nAn activity that performs a transformation on a message.\n\nchannel -> (structure)\n\nDetermines the source of the messages to be processed.\n\nname -> (string)\n\nThe name of the channel activity.\n\nchannelName -> (string)\n\nThe name of the channel from which the messages are processed.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nlambda -> (structure)\n\nRuns a Lambda function to modify the message.\n\nname -> (string)\n\nThe name of the lambda activity.\n\nlambdaName -> (string)\n\nThe name of the Lambda function that is run on the message.\n\nbatchSize -> (integer)\n\nThe number of messages passed to the Lambda function for processing.\n\nThe Lambda function must be able to process all of these messages within five minutes, which is the maximum timeout duration for Lambda functions.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndatastore -> (structure)\n\nSpecifies where to store the processed message data.\n\nname -> (string)\n\nThe name of the datastore activity.\n\ndatastoreName -> (string)\n\nThe name of the data store where processed messages are stored.\n\naddAttributes -> (structure)\n\nAdds other attributes based on existing attributes in the message.\n\nname -> (string)\n\nThe name of the addAttributes activity.\n\nattributes -> (map)\n\nA list of 1-50 AttributeNameMapping objects that map an existing attribute to a new attribute.\n\nNote\n\nThe existing attributes remain in the message, so if you want to remove the originals, use RemoveAttributeActivity .\n\nkey -> (string)\n\nvalue -> (string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nremoveAttributes -> (structure)\n\nRemoves attributes from a message.\n\nname -> (string)\n\nThe name of the removeAttributes activity.\n\nattributes -> (list)\n\nA list of 1-50 attributes to remove from the message.\n\n(string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nselectAttributes -> (structure)\n\nUsed to create a new message using only the specified attributes from the original message.\n\nname -> (string)\n\nThe name of the selectAttributes activity.\n\nattributes -> (list)\n\nA list of the attributes to select from the message.\n\n(string)\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nfilter -> (structure)\n\nFilters a message based on its attributes.\n\nname -> (string)\n\nThe name of the filter activity.\n\nfilter -> (string)\n\nAn expression that looks like a SQL WHERE clause that must return a Boolean value. Messages that satisfy the condition are passed to the next activity.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nmath -> (structure)\n\nComputes an arithmetic expression using the message’s attributes and adds it to the message.\n\nname -> (string)\n\nThe name of the math activity.\n\nattribute -> (string)\n\nThe name of the attribute that contains the result of the math operation.\n\nmath -> (string)\n\nAn expression that uses one or more existing attributes and must return an integer value.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndeviceRegistryEnrich -> (structure)\n\nAdds data from the IoT device registry to your message.\n\nname -> (string)\n\nThe name of the deviceRegistryEnrich activity.\n\nattribute -> (string)\n\nThe name of the attribute that is added to the message.\n\nthingName -> (string)\n\nThe name of the IoT device whose registry information is added to the message.\n\nroleArn -> (string)\n\nThe ARN of the role that allows access to the device’s registry information.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\ndeviceShadowEnrich -> (structure)\n\nAdds information from the IoT Device Shadow service to a message.\n\nname -> (string)\n\nThe name of the deviceShadowEnrich activity.\n\nattribute -> (string)\n\nThe name of the attribute that is added to the message.\n\nthingName -> (string)\n\nThe name of the IoT device whose shadow information is added to the message.\n\nroleArn -> (string)\n\nThe ARN of the role that allows access to the device’s shadow.\n\nnext -> (string)\n\nThe next activity in the pipeline.\n\nShorthand Syntax:\n\nchannel={name=string,channelName=string,next=string},lambda={name=string,lambdaName=string,batchSize=integer,next=string},datastore={name=string,datastoreName=string},addAttributes={name=string,attributes={KeyName1=string,KeyName2=string},next=string},removeAttributes={name=string,attributes=[string,string],next=string},selectAttributes={name=string,attributes=[string,string],next=string},filter={name=string,filter=string,next=string},math={name=string,attribute=string,math=string,next=string},deviceRegistryEnrich={name=string,attribute=string,thingName=string,roleArn=string,next=string},deviceShadowEnrich={name=string,attribute=string,thingName=string,roleArn=string,next=string} ...\n\n\nJSON Syntax:\n\n[\n  {\n    \"channel\": {\n      \"name\": \"string\",\n      \"channelName\": \"string\",\n      \"next\": \"string\"\n    },\n    \"lambda\": {\n      \"name\": \"string\",\n      \"lambdaName\": \"string\",\n      \"batchSize\": integer,\n      \"next\": \"string\"\n    },\n    \"datastore\": {\n      \"name\": \"string\",\n      \"datastoreName\": \"string\"\n    },\n    \"addAttributes\": {\n      \"name\": \"string\",\n      \"attributes\": {\"string\": \"string\"\n        ...},\n      \"next\": \"string\"\n    },\n    \"removeAttributes\": {\n      \"name\": \"string\",\n      \"attributes\": [\"string\", ...],\n      \"next\": \"string\"\n    },\n    \"selectAttributes\": {\n      \"name\": \"string\",\n      \"attributes\": [\"string\", ...],\n      \"next\": \"string\"\n    },\n    \"filter\": {\n      \"name\": \"string\",\n      \"filter\": \"string\",\n      \"next\": \"string\"\n    },\n    \"math\": {\n      \"name\": \"string\",\n      \"attribute\": \"string\",\n      \"math\": \"string\",\n      \"next\": \"string\"\n    },\n    \"deviceRegistryEnrich\": {\n      \"name\": \"string\",\n      \"attribute\": \"string\",\n      \"thingName\": \"string\",\n      \"roleArn\": \"string\",\n      \"next\": \"string\"\n    },\n    \"deviceShadowEnrich\": {\n      \"name\": \"string\",\n      \"attribute\": \"string\",\n      \"thingName\": \"string\",\n      \"roleArn\": \"string\",\n      \"next\": \"string\"\n    }\n  }\n  ...\n]\n\n\n--cli-input-json | --cli-input-yaml (string) Reads arguments from the JSON string provided. The JSON string follows the format provided by --generate-cli-skeleton. If other arguments are provided on the command line, those values will override the JSON-provided values. It is not possible to pass arbitrary binary values using a JSON-provided value as the string will be taken literally. This may not be specified along with --cli-input-yaml.\n\n--generate-cli-skeleton (string) Prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value input, prints a sample input JSON that can be used as an argument for --cli-input-json. Similarly, if provided yaml-input it will print a sample input YAML that can be used with --cli-input-yaml. If provided with the value output, it validates the command inputs and returns a sample output JSON for that command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_output": "Output\n\nNone",
      "command_examples": "Examples\n\nTo update a pipeline\n\nThe following update-pipeline example modifies the settings of the specified pipeline. You must specify both a channel and a data store activity and, optionally, as many as 23 additional activities, in the pipelineActivities array.\n\naws iotanalytics update-pipeline \\\n    --cli-input-json file://update-pipeline.json\n\n\nContents of update-pipeline.json:\n\n{\n    \"pipelineName\": \"mypipeline\",\n    \"pipelineActivities\": [\n        {\n            \"channel\": {\n                \"name\": \"myChannelActivity\",\n                \"channelName\": \"mychannel\",\n                \"next\": \"myMathActivity\"\n            }\n        },\n        {\n            \"datastore\": {\n                \"name\": \"myDatastoreActivity\",\n                \"datastoreName\": \"mydatastore\"\n            }\n        },\n        {\n            \"math\": {\n                \"name\": \"myMathActivity\",\n                \"math\": \"(((temp - 32) * 5.0) / 9.0) + 273.15\",\n                \"attribute\": \"tempK\",\n                \"next\": \"myDatastoreActivity\"\n            }\n        }\n    ]\n}\n\n\nThis command produces no output.\n\nFor more information, see UpdatePipeline in the AWS IoT Analytics API Reference."
    }
  ],
  "service_description": "Description\n\nIoT Analytics allows you to collect large amounts of device data, process messages, and store them. You can then query the data and run sophisticated analytics on it. IoT Analytics enables advanced data exploration through integration with Jupyter Notebooks and data visualization through integration with Amazon QuickSight.\n\nTraditional analytics and business intelligence tools are designed to process structured data. IoT data often comes from devices that record noisy processes (such as temperature, motion, or sound). As a result the data from these devices can have significant gaps, corrupted messages, and false readings that must be cleaned up before analysis can occur. Also, IoT data is often only meaningful in the context of other data from external sources.\n\nIoT Analytics automates the steps required to analyze data from IoT devices. IoT Analytics filters, transforms, and enriches IoT data before storing it in a time-series data store for analysis. You can set up the service to collect only the data you need from your devices, apply mathematical transforms to process the data, and enrich the data with device-specific metadata such as device type and location before storing it. Then, you can analyze your data by running queries using the built-in SQL query engine, or perform more complex analytics and machine learning inference. IoT Analytics includes pre-built models for common IoT use cases so you can answer questions like which devices are about to fail or which customers are at risk of abandoning their wearable devices."
}