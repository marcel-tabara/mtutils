{
  "service_name": "s3",
  "service_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/index.html",
  "service_commands": [
    {
      "command_name": "cp",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/cp.html",
      "command_description": "Description\n\nCopies a local file or S3 object to another location locally or in S3.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  cp\n<LocalPath> <S3Uri> or <S3Uri> <LocalPath> or <S3Uri> <S3Uri>\n[--dryrun]\n[--quiet]\n[--include <value>]\n[--exclude <value>]\n[--acl <value>]\n[--follow-symlinks | --no-follow-symlinks]\n[--no-guess-mime-type]\n[--sse <value>]\n[--sse-c <value>]\n[--sse-c-key <value>]\n[--sse-kms-key-id <value>]\n[--sse-c-copy-source <value>]\n[--sse-c-copy-source-key <value>]\n[--storage-class <value>]\n[--grants <value> [<value>...]]\n[--website-redirect <value>]\n[--content-type <value>]\n[--cache-control <value>]\n[--content-disposition <value>]\n[--content-encoding <value>]\n[--content-language <value>]\n[--expires <value>]\n[--source-region <value>]\n[--only-show-errors]\n[--no-progress]\n[--page-size <value>]\n[--ignore-glacier-warnings]\n[--force-glacier-transfer]\n[--request-payer <value>]\n[--metadata <value>]\n[--copy-props <value>]\n[--metadata-directive <value>]\n[--expected-size <value>]\n[--recursive]\n",
      "command_options": [
        "<LocalPath> <S3Uri> or <S3Uri> <LocalPath> or <S3Uri> <S3Uri>",
        "[--dryrun]",
        "[--quiet]",
        "[--include <value>]",
        "[--exclude <value>]",
        "[--acl <value>]",
        "[--follow-symlinks | --no-follow-symlinks]",
        "[--no-guess-mime-type]",
        "[--sse <value>]",
        "[--sse-c <value>]",
        "[--sse-c-key <value>]",
        "[--sse-kms-key-id <value>]",
        "[--sse-c-copy-source <value>]",
        "[--sse-c-copy-source-key <value>]",
        "[--storage-class <value>]",
        "[--grants <value> [<value>...]]",
        "[--website-redirect <value>]",
        "[--content-type <value>]",
        "[--cache-control <value>]",
        "[--content-disposition <value>]",
        "[--content-encoding <value>]",
        "[--content-language <value>]",
        "[--expires <value>]",
        "[--source-region <value>]",
        "[--only-show-errors]",
        "[--no-progress]",
        "[--page-size <value>]",
        "[--ignore-glacier-warnings]",
        "[--force-glacier-transfer]",
        "[--request-payer <value>]",
        "[--metadata <value>]",
        "[--copy-props <value>]",
        "[--metadata-directive <value>]",
        "[--expected-size <value>]",
        "[--recursive]"
      ],
      "command_options_description": "Options\n\npaths (string)\n\n--dryrun (boolean) Displays the operations that would be performed using the specified command without actually running them.\n\n--quiet (boolean) Does not display the operations performed from the specified command.\n\n--include (string) Don’t exclude files or objects in the command that match the specified pattern. See Use of Exclude and Include Filters for details.\n\n--exclude (string) Exclude all files or objects from the command that matches the specified pattern.\n\n--acl (string) Sets the ACL for the object when the command is performed. If you use this parameter you must have the “s3:PutObjectAcl” permission included in the list of actions for your IAM policy. Only accepts values of private, public-read, public-read-write, authenticated-read, aws-exec-read, bucket-owner-read, bucket-owner-full-control and log-delivery-write. See Canned ACL for details\n\n--follow-symlinks | --no-follow-symlinks (boolean) Symbolic links are followed only when uploading to S3 from the local filesystem. Note that S3 does not support symbolic links, so the contents of the link target are uploaded under the name of the link. When neither --follow-symlinks nor --no-follow-symlinks is specified, the default is to follow symlinks.\n\n--no-guess-mime-type (boolean) Do not try to guess the mime type for uploaded files. By default the mime type of a file is guessed when it is uploaded.\n\n--sse (string) Specifies server-side encryption of the object in S3. Valid values are AES256 and aws:kms. If the parameter is specified but no value is provided, AES256 is used.\n\n--sse-c (string) Specifies server-side encryption using customer provided keys of the the object in S3. AES256 is the only valid value. If the parameter is specified but no value is provided, AES256 is used. If you provide this value, --sse-c-key must be specified as well.\n\n--sse-c-key (blob) The customer-provided encryption key to use to server-side encrypt the object in S3. If you provide this value, --sse-c must be specified as well. The key provided should not be base64 encoded.\n\n--sse-kms-key-id (string) The customer-managed AWS Key Management Service (KMS) key ID that should be used to server-side encrypt the object in S3. You should only provide this parameter if you are using a customer managed customer master key (CMK) and not the AWS managed KMS CMK.\n\n--sse-c-copy-source (string) This parameter should only be specified when copying an S3 object that was encrypted server-side with a customer-provided key. It specifies the algorithm to use when decrypting the source object. AES256 is the only valid value. If the parameter is specified but no value is provided, AES256 is used. If you provide this value, --sse-c-copy-source-key must be specified as well.\n\n--sse-c-copy-source-key (blob) This parameter should only be specified when copying an S3 object that was encrypted server-side with a customer-provided key. Specifies the customer-provided encryption key for Amazon S3 to use to decrypt the source object. The encryption key provided must be one that was used when the source object was created. If you provide this value, --sse-c-copy-source be specified as well. The key provided should not be base64 encoded.\n\n--storage-class (string) The type of storage to use for the object. Valid choices are: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE. Defaults to ‘STANDARD’\n\n--grants (string)\n\nGrant specific permissions to individual users or groups. You can supply a list of grants of the form\n\n--grants Permission=Grantee_Type=Grantee_ID [Permission=Grantee_Type=Grantee_ID ...]\n\n\nTo specify the same permission type for multiple grantees, specify the permission as such as\n\n--grants Permission=Grantee_Type=Grantee_ID,Grantee_Type=Grantee_ID,...\n\n\nEach value contains the following elements:\n\nPermission - Specifies the granted permissions, and can be set to read, readacl, writeacl, or full.\n\nGrantee_Type - Specifies how the grantee is to be identified, and can be set to uri or id.\n\nGrantee_ID - Specifies the grantee based on Grantee_Type. The Grantee_ID value can be one of:\n\nuri - The group’s URI. For more information, see Who Is a Grantee?\n\nid - The account’s canonical ID\n\nFor more information on Amazon S3 access control, see Access Control\n\n--website-redirect (string) If the bucket is configured as a website, redirects requests for this object to another object in the same bucket or to an external URL. Amazon S3 stores the value of this header in the object metadata.\n\n--content-type (string) Specify an explicit content type for this operation. This value overrides any guessed mime types.\n\n--cache-control (string) Specifies caching behavior along the request/reply chain.\n\n--content-disposition (string) Specifies presentational information for the object.\n\n--content-encoding (string) Specifies what content encodings have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n--content-language (string) The language the content is in.\n\n--expires (string) The date and time at which the object is no longer cacheable.\n\n--source-region (string) When transferring objects from an s3 bucket to an s3 bucket, this specifies the region of the source bucket. Note the region specified by --region or through configuration of the CLI refers to the region of the destination bucket. If --source-region is not specified the region of the source will be the same as the region of the destination bucket.\n\n--only-show-errors (boolean) Only errors and warnings are displayed. All other output is suppressed.\n\n--no-progress (boolean) File transfer progress is not displayed. This flag is only applied when the quiet and only-show-errors flags are not provided.\n\n--page-size (integer) The number of results to return in each response to a list operation. The default value is 1000 (the maximum allowed). Using a lower value may help if an operation times out.\n\n--ignore-glacier-warnings (boolean) Turns off glacier warnings. Warnings about an operation that cannot be performed because it involves copying, downloading, or moving a glacier object will no longer be printed to standard error and will no longer cause the return code of the command to be 2.\n\n--force-glacier-transfer (boolean) Forces a transfer request on all Glacier objects in a sync or recursive copy.\n\n--request-payer (string) Confirms that the requester knows that they will be charged for the request. Bucket owners need not specify this parameter in their requests. Documentation on downloading objects from requester pays buckets can be found at http://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html\n\n--metadata (map) A map of metadata to store with the objects in S3. This will be applied to every object which is part of this request. In a sync, this means that files which haven’t changed won’t receive the new metadata. key -> (string)\n\nvalue -> (string)\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--copy-props (string) Determines which properties are copied from the source S3 object. This parameter only applies for S3 to S3 copies. Valid values are:\n\nnone - Do not copy any of the properties from the source S3 object.\n\nmetadata-directive - Copies the following properties from the source S3 object: content-type, content-language, content-encoding, content-disposition, cache-control, --expires, and metadata\n\ndefault - The default value. Copies tags and properties covered under the metadata-directive value from the source S3 object.\n\nIn order to copy the appropriate properties for multipart copies, some of the options may require additional API calls if a multipart copy is involved. Specifically:\n\nmetadata-directive may require additional HeadObject API calls.\n\ndefault may require additional HeadObject, GetObjectTagging, and PutObjectTagging API calls. Note this list of API calls may grow in the future in order to ensure multipart copies preserve the exact properties a CopyObject API call would preserve.\n\nIf you want to guarantee no additional API calls are made other than than the ones needed to perform the actual copy, set this option to none.\n\n--metadata-directive (string) Sets the x-amz-metadata-directive header for CopyObject operations. It is recommended to use the --copy-props parameter instead to control copying of metadata properties. If --metadata-directive is set, the --copy-props parameter will be disabled and will have no affect on the transfer.\n\n--expected-size (string) This argument specifies the expected size of a stream in terms of bytes. Note that this argument is needed only when a stream is being uploaded to s3 and the size is larger than 50GB. Failure to include this argument under these conditions may result in a failed upload due to too many parts in upload.\n\n--recursive (boolean) Command is performed on all files or objects under the specified directory or prefix.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_examples": "Examples\n\nCopying a local file to S3\n\nThe following cp command copies a single file to a specified bucket and key:\n\naws s3 cp test.txt s3://mybucket/test2.txt\n\n\nOutput:\n\nupload: test.txt to s3://mybucket/test2.txt\n\n\nCopying a local file to S3 with an expiration date\n\nThe following cp command copies a single file to a specified bucket and key that expires at the specified ISO 8601 timestamp:\n\naws s3 cp test.txt s3://mybucket/test2.txt --expires 2014-10-01T20:30:00Z\n\n\nOutput:\n\nupload: test.txt to s3://mybucket/test2.txt\n\n\nCopying a file from S3 to S3\n\nThe following cp command copies a single s3 object to a specified bucket and key:\n\naws s3 cp s3://mybucket/test.txt s3://mybucket/test2.txt\n\n\nOutput:\n\ncopy: s3://mybucket/test.txt to s3://mybucket/test2.txt\n\n\nCopying an S3 object to a local file\n\nThe following cp command copies a single object to a specified file locally:\n\naws s3 cp s3://mybucket/test.txt test2.txt\n\n\nOutput:\n\ndownload: s3://mybucket/test.txt to test2.txt\n\n\nCopying an S3 object from one bucket to another\n\nThe following cp command copies a single object to a specified bucket while retaining its original name:\n\naws s3 cp s3://mybucket/test.txt s3://mybucket2/\n\n\nOutput:\n\ncopy: s3://mybucket/test.txt to s3://mybucket2/test.txt\n\n\nRecursively copying S3 objects to a local directory\n\nWhen passed with the parameter --recursive, the following cp command recursively copies all objects under a specified prefix and bucket to a specified directory. In this example, the bucket mybucket has the objects test1.txt and test2.txt:\n\naws s3 cp s3://mybucket . --recursive\n\n\nOutput:\n\ndownload: s3://mybucket/test1.txt to test1.txt\ndownload: s3://mybucket/test2.txt to test2.txt\n\n\nRecursively copying local files to S3\n\nWhen passed with the parameter --recursive, the following cp command recursively copies all files under a specified directory to a specified bucket and prefix while excluding some files by using an --exclude parameter. In this example, the directory myDir has the files test1.txt and test2.jpg:\n\naws s3 cp myDir s3://mybucket/ --recursive --exclude \"*.jpg\"\n\n\nOutput:\n\nupload: myDir/test1.txt to s3://mybucket/test1.txt\n\n\nRecursively copying S3 objects to another bucket\n\nWhen passed with the parameter --recursive, the following cp command recursively copies all objects under a specified bucket to another bucket while excluding some objects by using an --exclude parameter. In this example, the bucket mybucket has the objects test1.txt and another/test1.txt:\n\naws s3 cp s3://mybucket/ s3://mybucket2/ --recursive --exclude \"another/*\"\n\n\nOutput:\n\ncopy: s3://mybucket/test1.txt to s3://mybucket2/test1.txt\n\n\nYou can combine --exclude and --include options to copy only objects that match a pattern, excluding all others:\n\naws s3 cp s3://mybucket/logs/ s3://mybucket2/logs/ --recursive --exclude \"*\" --include \"*.log\"\n\n\nOutput:\n\ncopy: s3://mybucket/logs/test/test.log to s3://mybucket2/logs/test/test.log\ncopy: s3://mybucket/logs/test3.log to s3://mybucket2/logs/test3.log\n\n\nSetting the Access Control List (ACL) while copying an S3 object\n\nThe following cp command copies a single object to a specified bucket and key while setting the ACL to public-read-write:\n\naws s3 cp s3://mybucket/test.txt s3://mybucket/test2.txt --acl public-read-write\n\n\nOutput:\n\ncopy: s3://mybucket/test.txt to s3://mybucket/test2.txt\n\n\nNote that if you’re using the --acl option, ensure that any associated IAM policies include the \"s3:PutObjectAcl\" action:\n\naws iam get-user-policy --user-name myuser --policy-name mypolicy\n\n\nOutput:\n\n{\n    \"UserName\": \"myuser\",\n    \"PolicyName\": \"mypolicy\",\n    \"PolicyDocument\": {\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Action\": [\n                    \"s3:PutObject\",\n                    \"s3:PutObjectAcl\"\n                ],\n                \"Resource\": [\n                    \"arn:aws:s3:::mybucket/*\"\n                ],\n                \"Effect\": \"Allow\",\n                \"Sid\": \"Stmt1234567891234\"\n            }\n        ]\n    }\n}\n\n\nGranting permissions for an S3 object\n\nThe following cp command illustrates the use of the --grants option to grant read access to all users and full control to a specific user identified by their URI:\n\naws s3 cp file.txt s3://mybucket/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=uri=79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be\n\n\nOutput:\n\nupload: file.txt to s3://mybucket/file.txt\n\n\nUploading a local file stream to S3\n\nWarning\n\nPowerShell may alter the encoding of or add a CRLF to piped input.\n\nThe following cp command uploads a local file stream from standard input to a specified bucket and key:\n\naws s3 cp - s3://mybucket/stream.txt\n\n\nUploading a local file stream that is larger than 50GB to S3\n\nThe following cp command uploads a 51GB local file stream from standard input to a specified bucket and key. The --expected-size option must be provided, or the upload may fail when it reaches the default part limit of 10,000:\n\naws s3 cp - s3://mybucket/stream.txt --expected-size 54760833024\n\n\nDownloading an S3 object as a local file stream\n\nWarning\n\nPowerShell may alter the encoding of or add a CRLF to piped or redirected output.\n\nThe following cp command downloads an S3 object locally as a stream to standard output. Downloading as a stream is not currently compatible with the --recursive parameter:\n\naws s3 cp s3://mybucket/stream.txt -\n\n\nUploading to an S3 access point\n\nThe following cp command uploads a single file (mydoc.txt) to the access point (myaccesspoint) at the key (mykey):\n\naws s3 cp mydoc.txt s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mykey\n\n\nOutput:\n\nupload: mydoc.txt to s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mykey\n\n\nDownloading from an S3 access point\n\nThe following cp command downloads a single object (mykey) from the access point (myaccesspoint) to the local file (mydoc.txt):\n\naws s3 cp s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mykey mydoc.txt\n\n\nOutput:\n\ndownload: s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mykey to mydoc.txt\n"
    },
    {
      "command_name": "ls",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/ls.html",
      "command_description": "Description\n\nList S3 objects and common prefixes under a prefix or all S3 buckets. Note that the –output and –no-paginate arguments are ignored for this command.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  ls\n<S3Uri> or NONE\n[--recursive]\n[--page-size <value>]\n[--human-readable]\n[--summarize]\n[--request-payer <value>]\n",
      "command_options": [
        "<S3Uri> or NONE",
        "[--recursive]",
        "[--page-size <value>]",
        "[--human-readable]",
        "[--summarize]",
        "[--request-payer <value>]"
      ],
      "command_options_description": "Options\n\npaths (string)\n\n--recursive (boolean) Command is performed on all files or objects under the specified directory or prefix.\n\n--page-size (integer) The number of results to return in each response to a list operation. The default value is 1000 (the maximum allowed). Using a lower value may help if an operation times out.\n\n--human-readable (boolean) Displays file sizes in human readable format.\n\n--summarize (boolean) Displays summary information (number of objects, total size).\n\n--request-payer (string) Confirms that the requester knows that they will be charged for the request. Bucket owners need not specify this parameter in their requests. Documentation on downloading objects from requester pays buckets can be found at http://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_examples": "Examples\n\nExample 1: Listing all user owned buckets\n\nThe following ls command lists all of the bucket owned by the user. In this example, the user owns the buckets mybucket and mybucket2. The timestamp is the date the bucket was created, shown in your machine’s time zone. This date can change when making changes to your bucket, such as editing its bucket policy. Note if s3:// is used for the path argument <S3Uri>, it will list all of the buckets as well:\n\naws s3 ls\n\n\nOutput:\n\n2013-07-11 17:08:50 mybucket\n2013-07-24 14:55:44 mybucket2\n\n\nExample 2: Listing all prefixes and objects in a bucket\n\nThe following ls command lists objects and common prefixes under a specified bucket and prefix. In this example, the user owns the bucket mybucket with the objects test.txt and somePrefix/test.txt. The LastWriteTime and Length are arbitrary. Note that since the ls command has no interaction with the local filesystem, the s3:// URI scheme is not required to resolve ambiguity and may be omitted:\n\naws s3 ls s3://mybucket\n\n\nOutput:\n\n                           PRE somePrefix/\n2013-07-25 17:06:27         88 test.txt\n\n\nExample 3: Listing all prefixes and objects in a specific bucket and prefix\n\nThe following ls command lists objects and common prefixes under a specified bucket and prefix. However, there are no objects nor common prefixes under the specified bucket and prefix:\n\naws s3 ls s3://mybucket/noExistPrefix\n\n\nOutput:\n\nNone\n\n\nExample 4: Recursively listing all prefixes and objects in a bucket\n\nThe following ls command will recursively list objects in a bucket. Rather than showing PRE dirname/ in the output, all the content in a bucket will be listed in order:\n\naws s3 ls s3://mybucket --recursive\n\n\nOutput:\n\n2013-09-02 21:37:53         10 a.txt\n2013-09-02 21:37:53    2863288 foo.zip\n2013-09-02 21:32:57         23 foo/bar/.baz/a\n2013-09-02 21:32:58         41 foo/bar/.baz/b\n2013-09-02 21:32:57        281 foo/bar/.baz/c\n2013-09-02 21:32:57         73 foo/bar/.baz/d\n2013-09-02 21:32:57        452 foo/bar/.baz/e\n2013-09-02 21:32:57        896 foo/bar/.baz/hooks/bar\n2013-09-02 21:32:57        189 foo/bar/.baz/hooks/foo\n2013-09-02 21:32:57        398 z.txt\n\n\nExample 5: Summarizing all prefixes and objects in a bucket\n\nThe following ls command demonstrates the same command using the –human-readable and –summarize options. –human-readable displays file size in Bytes/MiB/KiB/GiB/TiB/PiB/EiB. –summarize displays the total number of objects and total size at the end of the result listing:\n\naws s3 ls s3://mybucket --recursive --human-readable --summarize\n\n\nOutput:\n\n2013-09-02 21:37:53   10 Bytes a.txt\n2013-09-02 21:37:53  2.9 MiB foo.zip\n2013-09-02 21:32:57   23 Bytes foo/bar/.baz/a\n2013-09-02 21:32:58   41 Bytes foo/bar/.baz/b\n2013-09-02 21:32:57  281 Bytes foo/bar/.baz/c\n2013-09-02 21:32:57   73 Bytes foo/bar/.baz/d\n2013-09-02 21:32:57  452 Bytes foo/bar/.baz/e\n2013-09-02 21:32:57  896 Bytes foo/bar/.baz/hooks/bar\n2013-09-02 21:32:57  189 Bytes foo/bar/.baz/hooks/foo\n2013-09-02 21:32:57  398 Bytes z.txt\n\nTotal Objects: 10\n   Total Size: 2.9 MiB\n\n\nExample 6: Listing from an S3 access point\n\nThe following ls command list objects from access point (myaccesspoint):\n\naws s3 ls s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/\n\n\nOutput:\n\n                           PRE somePrefix/\n2013-07-25 17:06:27         88 test.txt\n"
    },
    {
      "command_name": "mb",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/mb.html",
      "command_description": "Description\n\nCreates an S3 bucket.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  mb\n<S3Uri>\n",
      "command_options": [
        "<S3Uri>"
      ],
      "command_options_description": "Options\n\npath (string)\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_examples": "Examples\n\nThe following mb command creates a bucket. In this example, the user makes the bucket mybucket. The bucket is created in the region specified in the user’s configuration file:\n\naws s3 mb s3://mybucket\n\n\nOutput:\n\nmake_bucket: s3://mybucket\n\n\nThe following mb command creates a bucket in a region specified by the --region parameter. In this example, the user makes the bucket mybucket in the region us-west-1:\n\naws s3 mb s3://mybucket --region us-west-1\n\n\nOutput:\n\nmake_bucket: s3://mybucket\n"
    },
    {
      "command_name": "mv",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/mv.html",
      "command_description": "Description\n\nMoves a local file or S3 object to another location locally or in S3.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  mv\n<LocalPath> <S3Uri> or <S3Uri> <LocalPath> or <S3Uri> <S3Uri>\n[--dryrun]\n[--quiet]\n[--include <value>]\n[--exclude <value>]\n[--acl <value>]\n[--follow-symlinks | --no-follow-symlinks]\n[--no-guess-mime-type]\n[--sse <value>]\n[--sse-c <value>]\n[--sse-c-key <value>]\n[--sse-kms-key-id <value>]\n[--sse-c-copy-source <value>]\n[--sse-c-copy-source-key <value>]\n[--storage-class <value>]\n[--grants <value> [<value>...]]\n[--website-redirect <value>]\n[--content-type <value>]\n[--cache-control <value>]\n[--content-disposition <value>]\n[--content-encoding <value>]\n[--content-language <value>]\n[--expires <value>]\n[--source-region <value>]\n[--only-show-errors]\n[--no-progress]\n[--page-size <value>]\n[--ignore-glacier-warnings]\n[--force-glacier-transfer]\n[--request-payer <value>]\n[--metadata <value>]\n[--copy-props <value>]\n[--metadata-directive <value>]\n[--recursive]\n",
      "command_options": [
        "<LocalPath> <S3Uri> or <S3Uri> <LocalPath> or <S3Uri> <S3Uri>",
        "[--dryrun]",
        "[--quiet]",
        "[--include <value>]",
        "[--exclude <value>]",
        "[--acl <value>]",
        "[--follow-symlinks | --no-follow-symlinks]",
        "[--no-guess-mime-type]",
        "[--sse <value>]",
        "[--sse-c <value>]",
        "[--sse-c-key <value>]",
        "[--sse-kms-key-id <value>]",
        "[--sse-c-copy-source <value>]",
        "[--sse-c-copy-source-key <value>]",
        "[--storage-class <value>]",
        "[--grants <value> [<value>...]]",
        "[--website-redirect <value>]",
        "[--content-type <value>]",
        "[--cache-control <value>]",
        "[--content-disposition <value>]",
        "[--content-encoding <value>]",
        "[--content-language <value>]",
        "[--expires <value>]",
        "[--source-region <value>]",
        "[--only-show-errors]",
        "[--no-progress]",
        "[--page-size <value>]",
        "[--ignore-glacier-warnings]",
        "[--force-glacier-transfer]",
        "[--request-payer <value>]",
        "[--metadata <value>]",
        "[--copy-props <value>]",
        "[--metadata-directive <value>]",
        "[--recursive]"
      ],
      "command_options_description": "Options\n\npaths (string)\n\n--dryrun (boolean) Displays the operations that would be performed using the specified command without actually running them.\n\n--quiet (boolean) Does not display the operations performed from the specified command.\n\n--include (string) Don’t exclude files or objects in the command that match the specified pattern. See Use of Exclude and Include Filters for details.\n\n--exclude (string) Exclude all files or objects from the command that matches the specified pattern.\n\n--acl (string) Sets the ACL for the object when the command is performed. If you use this parameter you must have the “s3:PutObjectAcl” permission included in the list of actions for your IAM policy. Only accepts values of private, public-read, public-read-write, authenticated-read, aws-exec-read, bucket-owner-read, bucket-owner-full-control and log-delivery-write. See Canned ACL for details\n\n--follow-symlinks | --no-follow-symlinks (boolean) Symbolic links are followed only when uploading to S3 from the local filesystem. Note that S3 does not support symbolic links, so the contents of the link target are uploaded under the name of the link. When neither --follow-symlinks nor --no-follow-symlinks is specified, the default is to follow symlinks.\n\n--no-guess-mime-type (boolean) Do not try to guess the mime type for uploaded files. By default the mime type of a file is guessed when it is uploaded.\n\n--sse (string) Specifies server-side encryption of the object in S3. Valid values are AES256 and aws:kms. If the parameter is specified but no value is provided, AES256 is used.\n\n--sse-c (string) Specifies server-side encryption using customer provided keys of the the object in S3. AES256 is the only valid value. If the parameter is specified but no value is provided, AES256 is used. If you provide this value, --sse-c-key must be specified as well.\n\n--sse-c-key (blob) The customer-provided encryption key to use to server-side encrypt the object in S3. If you provide this value, --sse-c must be specified as well. The key provided should not be base64 encoded.\n\n--sse-kms-key-id (string) The customer-managed AWS Key Management Service (KMS) key ID that should be used to server-side encrypt the object in S3. You should only provide this parameter if you are using a customer managed customer master key (CMK) and not the AWS managed KMS CMK.\n\n--sse-c-copy-source (string) This parameter should only be specified when copying an S3 object that was encrypted server-side with a customer-provided key. It specifies the algorithm to use when decrypting the source object. AES256 is the only valid value. If the parameter is specified but no value is provided, AES256 is used. If you provide this value, --sse-c-copy-source-key must be specified as well.\n\n--sse-c-copy-source-key (blob) This parameter should only be specified when copying an S3 object that was encrypted server-side with a customer-provided key. Specifies the customer-provided encryption key for Amazon S3 to use to decrypt the source object. The encryption key provided must be one that was used when the source object was created. If you provide this value, --sse-c-copy-source be specified as well. The key provided should not be base64 encoded.\n\n--storage-class (string) The type of storage to use for the object. Valid choices are: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE. Defaults to ‘STANDARD’\n\n--grants (string)\n\nGrant specific permissions to individual users or groups. You can supply a list of grants of the form\n\n--grants Permission=Grantee_Type=Grantee_ID [Permission=Grantee_Type=Grantee_ID ...]\n\n\nTo specify the same permission type for multiple grantees, specify the permission as such as\n\n--grants Permission=Grantee_Type=Grantee_ID,Grantee_Type=Grantee_ID,...\n\n\nEach value contains the following elements:\n\nPermission - Specifies the granted permissions, and can be set to read, readacl, writeacl, or full.\n\nGrantee_Type - Specifies how the grantee is to be identified, and can be set to uri or id.\n\nGrantee_ID - Specifies the grantee based on Grantee_Type. The Grantee_ID value can be one of:\n\nuri - The group’s URI. For more information, see Who Is a Grantee?\n\nid - The account’s canonical ID\n\nFor more information on Amazon S3 access control, see Access Control\n\n--website-redirect (string) If the bucket is configured as a website, redirects requests for this object to another object in the same bucket or to an external URL. Amazon S3 stores the value of this header in the object metadata.\n\n--content-type (string) Specify an explicit content type for this operation. This value overrides any guessed mime types.\n\n--cache-control (string) Specifies caching behavior along the request/reply chain.\n\n--content-disposition (string) Specifies presentational information for the object.\n\n--content-encoding (string) Specifies what content encodings have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n--content-language (string) The language the content is in.\n\n--expires (string) The date and time at which the object is no longer cacheable.\n\n--source-region (string) When transferring objects from an s3 bucket to an s3 bucket, this specifies the region of the source bucket. Note the region specified by --region or through configuration of the CLI refers to the region of the destination bucket. If --source-region is not specified the region of the source will be the same as the region of the destination bucket.\n\n--only-show-errors (boolean) Only errors and warnings are displayed. All other output is suppressed.\n\n--no-progress (boolean) File transfer progress is not displayed. This flag is only applied when the quiet and only-show-errors flags are not provided.\n\n--page-size (integer) The number of results to return in each response to a list operation. The default value is 1000 (the maximum allowed). Using a lower value may help if an operation times out.\n\n--ignore-glacier-warnings (boolean) Turns off glacier warnings. Warnings about an operation that cannot be performed because it involves copying, downloading, or moving a glacier object will no longer be printed to standard error and will no longer cause the return code of the command to be 2.\n\n--force-glacier-transfer (boolean) Forces a transfer request on all Glacier objects in a sync or recursive copy.\n\n--request-payer (string) Confirms that the requester knows that they will be charged for the request. Bucket owners need not specify this parameter in their requests. Documentation on downloading objects from requester pays buckets can be found at http://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html\n\n--metadata (map) A map of metadata to store with the objects in S3. This will be applied to every object which is part of this request. In a sync, this means that files which haven’t changed won’t receive the new metadata. key -> (string)\n\nvalue -> (string)\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--copy-props (string) Determines which properties are copied from the source S3 object. This parameter only applies for S3 to S3 copies. Valid values are:\n\nnone - Do not copy any of the properties from the source S3 object.\n\nmetadata-directive - Copies the following properties from the source S3 object: content-type, content-language, content-encoding, content-disposition, cache-control, --expires, and metadata\n\ndefault - The default value. Copies tags and properties covered under the metadata-directive value from the source S3 object.\n\nIn order to copy the appropriate properties for multipart copies, some of the options may require additional API calls if a multipart copy is involved. Specifically:\n\nmetadata-directive may require additional HeadObject API calls.\n\ndefault may require additional HeadObject, GetObjectTagging, and PutObjectTagging API calls. Note this list of API calls may grow in the future in order to ensure multipart copies preserve the exact properties a CopyObject API call would preserve.\n\nIf you want to guarantee no additional API calls are made other than than the ones needed to perform the actual copy, set this option to none.\n\n--metadata-directive (string) Sets the x-amz-metadata-directive header for CopyObject operations. It is recommended to use the --copy-props parameter instead to control copying of metadata properties. If --metadata-directive is set, the --copy-props parameter will be disabled and will have no affect on the transfer.\n\n--recursive (boolean) Command is performed on all files or objects under the specified directory or prefix.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_examples": "Examples\n\nThe following mv command moves a single file to a specified bucket and key:\n\naws s3 mv test.txt s3://mybucket/test2.txt\n\n\nOutput:\n\nmove: test.txt to s3://mybucket/test2.txt\n\n\nThe following mv command moves a single s3 object to a specified bucket and key:\n\naws s3 mv s3://mybucket/test.txt s3://mybucket/test2.txt\n\n\nOutput:\n\nmove: s3://mybucket/test.txt to s3://mybucket/test2.txt\n\n\nThe following mv command moves a single object to a specified file locally:\n\naws s3 mv s3://mybucket/test.txt test2.txt\n\n\nOutput:\n\nmove: s3://mybucket/test.txt to test2.txt\n\n\nThe following mv command moves a single object to a specified bucket while retaining its original name:\n\naws s3 mv s3://mybucket/test.txt s3://mybucket2/\n\n\nOutput:\n\nmove: s3://mybucket/test.txt to s3://mybucket2/test.txt\n\n\nWhen passed with the parameter --recursive, the following mv command recursively moves all objects under a specified prefix and bucket to a specified directory. In this example, the bucket mybucket has the objects test1.txt and test2.txt:\n\naws s3 mv s3://mybucket . --recursive\n\n\nOutput:\n\nmove: s3://mybucket/test1.txt to test1.txt\nmove: s3://mybucket/test2.txt to test2.txt\n\n\nWhen passed with the parameter --recursive, the following mv command recursively moves all files under a specified directory to a specified bucket and prefix while excluding some files by using an --exclude parameter. In this example, the directory myDir has the files test1.txt and test2.jpg:\n\naws s3 mv myDir s3://mybucket/ --recursive --exclude \"*.jpg\"\n\n\nOutput:\n\nmove: myDir/test1.txt to s3://mybucket2/test1.txt\n\n\nWhen passed with the parameter --recursive, the following mv command recursively moves all objects under a specified bucket to another bucket while excluding some objects by using an --exclude parameter. In this example, the bucket mybucket has the objects test1.txt and another/test1.txt:\n\naws s3 mv s3://mybucket/ s3://mybucket2/ --recursive --exclude \"mybucket/another/*\"\n\n\nOutput:\n\nmove: s3://mybucket/test1.txt to s3://mybucket2/test1.txt\n\n\nThe following mv command moves a single object to a specified bucket and key while setting the ACL to public-read-write:\n\naws s3 mv s3://mybucket/test.txt s3://mybucket/test2.txt --acl public-read-write\n\n\nOutput:\n\nmove: s3://mybucket/test.txt to s3://mybucket/test2.txt\n\n\nThe following mv command illustrates the use of the --grants option to grant read access to all users and full control to a specific user identified by their email address:\n\naws s3 mv file.txt s3://mybucket/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=emailaddress=user@example.com\n\n\nOutput:\n\nmove: file.txt to s3://mybucket/file.txt\n\n\nMoving a file to an S3 access point\n\nThe following mv command moves a single file (mydoc.txt) to the access point (myaccesspoint) at the key (mykey):\n\naws s3 mv mydoc.txt s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mykey\n\n\nOutput:\n\nmove: mydoc.txt to s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mykey\n"
    },
    {
      "command_name": "presign",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/presign.html",
      "command_description": "Description\n\nGenerate a pre-signed URL for an Amazon S3 object. This allows anyone who receives the pre-signed URL to retrieve the S3 object with an HTTP GET request. All presigned URL’s now use sigv4 so the region needs to be configured explicitly.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  presign\n<S3Uri>\n[--expires-in <value>]\n",
      "command_options": [
        "<S3Uri>",
        "[--expires-in <value>]"
      ],
      "command_options_description": "Options\n\npath (string)\n\n--expires-in (integer) Number of seconds until the pre-signed URL expires. Default is 3600 seconds. Maximum is 604800 seconds.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_examples": "Examples\n\nTo create a pre-signed URL with the default one hour lifetime that links to an object in an S3 bucket\n\nThe following presign command generates a pre-signed URL for a specified bucket and key that is valid for one hour:\n\naws s3 presign s3://awsexamplebucket/test2.txt\n\n\nOutput:\n\nhttps://awsexamplebucket.s3.amazonaws.com/test2.txt?AWSAccessKeyId=AKIAEXAMPLEACCESSKEY&Signature=EXHCcBe%EXAMPLEKnz3r8O0AgEXAMPLE&Expires=1555531131\n\n\nTo create a pre-signed URL with a custom lifetime that links to an object in an S3 bucket\n\nThe following presign command generates a pre-signed URL for a specified bucket and key that is valid for one week:\n\naws s3 presign s3://awsexamplebucket/test2.txt --expires-in 604800\n\n\nOutput:\n\nhttps://examplebucket.s3.amazonaws.com/test2.txt?AWSAccessKeyId=AKIAEXAMPLEACCESSKEY&Signature=EXHCcBe%EXAMPLEKnz3r8O0AgEXAMPLE&Expires=1556132848\n\n\nFor more information, see Share an Object with Others in the S3 Developer Guide guide."
    },
    {
      "command_name": "rb",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/rb.html",
      "command_description": "Description\n\nDeletes an empty S3 bucket. A bucket must be completely empty of objects and versioned objects before it can be deleted. However, the --force parameter can be used to delete the non-versioned objects in the bucket before the bucket is deleted.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  rb\n<S3Uri>\n[--force]\n",
      "command_options": [
        "<S3Uri>",
        "[--force]"
      ],
      "command_options_description": "Options\n\npath (string)\n\n--force (boolean) Deletes all objects in the bucket including the bucket itself. Note that versioned objects will not be deleted in this process which would cause the bucket deletion to fail because the bucket would not be empty. To delete versioned objects use the s3api delete-object command with the --version-id parameter.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_examples": "Examples\n\nThe following rb command removes a bucket. In this example, the user’s bucket is mybucket. Note that the bucket must be empty in order to remove:\n\naws s3 rb s3://mybucket\n\n\nOutput:\n\nremove_bucket: mybucket\n\n\nThe following rb command uses the --force parameter to first remove all of the objects in the bucket and then remove the bucket itself. In this example, the user’s bucket is mybucket and the objects in mybucket are test1.txt and test2.txt:\n\naws s3 rb s3://mybucket --force\n\n\nOutput:\n\ndelete: s3://mybucket/test1.txt\ndelete: s3://mybucket/test2.txt\nremove_bucket: mybucket\n"
    },
    {
      "command_name": "rm",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/rm.html",
      "command_description": "Description\n\nDeletes an S3 object.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  rm\n<S3Uri>\n[--dryrun]\n[--quiet]\n[--recursive]\n[--request-payer <value>]\n[--include <value>]\n[--exclude <value>]\n[--only-show-errors]\n[--page-size <value>]\n",
      "command_options": [
        "<S3Uri>",
        "[--dryrun]",
        "[--quiet]",
        "[--recursive]",
        "[--request-payer <value>]",
        "[--include <value>]",
        "[--exclude <value>]",
        "[--only-show-errors]",
        "[--page-size <value>]"
      ],
      "command_options_description": "Options\n\npaths (string)\n\n--dryrun (boolean) Displays the operations that would be performed using the specified command without actually running them.\n\n--quiet (boolean) Does not display the operations performed from the specified command.\n\n--recursive (boolean) Command is performed on all files or objects under the specified directory or prefix.\n\n--request-payer (string) Confirms that the requester knows that they will be charged for the request. Bucket owners need not specify this parameter in their requests. Documentation on downloading objects from requester pays buckets can be found at http://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html\n\n--include (string) Don’t exclude files or objects in the command that match the specified pattern. See Use of Exclude and Include Filters for details.\n\n--exclude (string) Exclude all files or objects from the command that matches the specified pattern.\n\n--only-show-errors (boolean) Only errors and warnings are displayed. All other output is suppressed.\n\n--page-size (integer) The number of results to return in each response to a list operation. The default value is 1000 (the maximum allowed). Using a lower value may help if an operation times out.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_examples": "Examples\n\nThe following rm command deletes a single s3 object:\n\naws s3 rm s3://mybucket/test2.txt\n\n\nOutput:\n\ndelete: s3://mybucket/test2.txt\n\n\nThe following rm command recursively deletes all objects under a specified bucket and prefix when passed with the parameter --recursive. In this example, the bucket mybucket contains the objects test1.txt and test2.txt:\n\naws s3 rm s3://mybucket --recursive\n\n\nOutput:\n\ndelete: s3://mybucket/test1.txt\ndelete: s3://mybucket/test2.txt\n\n\nThe following rm command recursively deletes all objects under a specified bucket and prefix when passed with the parameter --recursive while excluding some objects by using an --exclude parameter. In this example, the bucket mybucket has the objects test1.txt and test2.jpg:\n\naws s3 rm s3://mybucket/ --recursive --exclude \"*.jpg\"\n\n\nOutput:\n\ndelete: s3://mybucket/test1.txt\n\n\nThe following rm command recursively deletes all objects under a specified bucket and prefix when passed with the parameter --recursive while excluding all objects under a particular prefix by using an --exclude parameter. In this example, the bucket mybucket has the objects test1.txt and another/test.txt:\n\naws s3 rm s3://mybucket/ --recursive --exclude \"another/*\"\n\n\nOutput:\n\ndelete: s3://mybucket/test1.txt\n\n\nDeleting an object from an S3 access point\n\nThe following rm command deletes a single object (mykey) from the access point (myaccesspoint):\n\naws s3 rm s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mykey\n\n\nOutput:\n\ndelete: s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mykey\n"
    },
    {
      "command_name": "sync",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/sync.html",
      "command_description": "Description\n\nSyncs directories and S3 prefixes. Recursively copies new and updated files from the source directory to the destination. Only creates folders in the destination if they contain one or more files.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  sync\n<LocalPath> <S3Uri> or <S3Uri> <LocalPath> or <S3Uri> <S3Uri>\n[--dryrun]\n[--quiet]\n[--include <value>]\n[--exclude <value>]\n[--acl <value>]\n[--follow-symlinks | --no-follow-symlinks]\n[--no-guess-mime-type]\n[--sse <value>]\n[--sse-c <value>]\n[--sse-c-key <value>]\n[--sse-kms-key-id <value>]\n[--sse-c-copy-source <value>]\n[--sse-c-copy-source-key <value>]\n[--storage-class <value>]\n[--grants <value> [<value>...]]\n[--website-redirect <value>]\n[--content-type <value>]\n[--cache-control <value>]\n[--content-disposition <value>]\n[--content-encoding <value>]\n[--content-language <value>]\n[--expires <value>]\n[--source-region <value>]\n[--only-show-errors]\n[--no-progress]\n[--page-size <value>]\n[--ignore-glacier-warnings]\n[--force-glacier-transfer]\n[--request-payer <value>]\n[--metadata <value>]\n[--copy-props <value>]\n[--metadata-directive <value>]\n[--size-only]\n[--exact-timestamps]\n[--delete]\n",
      "command_options": [
        "<LocalPath> <S3Uri> or <S3Uri> <LocalPath> or <S3Uri> <S3Uri>",
        "[--dryrun]",
        "[--quiet]",
        "[--include <value>]",
        "[--exclude <value>]",
        "[--acl <value>]",
        "[--follow-symlinks | --no-follow-symlinks]",
        "[--no-guess-mime-type]",
        "[--sse <value>]",
        "[--sse-c <value>]",
        "[--sse-c-key <value>]",
        "[--sse-kms-key-id <value>]",
        "[--sse-c-copy-source <value>]",
        "[--sse-c-copy-source-key <value>]",
        "[--storage-class <value>]",
        "[--grants <value> [<value>...]]",
        "[--website-redirect <value>]",
        "[--content-type <value>]",
        "[--cache-control <value>]",
        "[--content-disposition <value>]",
        "[--content-encoding <value>]",
        "[--content-language <value>]",
        "[--expires <value>]",
        "[--source-region <value>]",
        "[--only-show-errors]",
        "[--no-progress]",
        "[--page-size <value>]",
        "[--ignore-glacier-warnings]",
        "[--force-glacier-transfer]",
        "[--request-payer <value>]",
        "[--metadata <value>]",
        "[--copy-props <value>]",
        "[--metadata-directive <value>]",
        "[--size-only]",
        "[--exact-timestamps]",
        "[--delete]"
      ],
      "command_options_description": "Options\n\npaths (string)\n\n--dryrun (boolean) Displays the operations that would be performed using the specified command without actually running them.\n\n--quiet (boolean) Does not display the operations performed from the specified command.\n\n--include (string) Don’t exclude files or objects in the command that match the specified pattern. See Use of Exclude and Include Filters for details.\n\n--exclude (string) Exclude all files or objects from the command that matches the specified pattern.\n\n--acl (string) Sets the ACL for the object when the command is performed. If you use this parameter you must have the “s3:PutObjectAcl” permission included in the list of actions for your IAM policy. Only accepts values of private, public-read, public-read-write, authenticated-read, aws-exec-read, bucket-owner-read, bucket-owner-full-control and log-delivery-write. See Canned ACL for details\n\n--follow-symlinks | --no-follow-symlinks (boolean) Symbolic links are followed only when uploading to S3 from the local filesystem. Note that S3 does not support symbolic links, so the contents of the link target are uploaded under the name of the link. When neither --follow-symlinks nor --no-follow-symlinks is specified, the default is to follow symlinks.\n\n--no-guess-mime-type (boolean) Do not try to guess the mime type for uploaded files. By default the mime type of a file is guessed when it is uploaded.\n\n--sse (string) Specifies server-side encryption of the object in S3. Valid values are AES256 and aws:kms. If the parameter is specified but no value is provided, AES256 is used.\n\n--sse-c (string) Specifies server-side encryption using customer provided keys of the the object in S3. AES256 is the only valid value. If the parameter is specified but no value is provided, AES256 is used. If you provide this value, --sse-c-key must be specified as well.\n\n--sse-c-key (blob) The customer-provided encryption key to use to server-side encrypt the object in S3. If you provide this value, --sse-c must be specified as well. The key provided should not be base64 encoded.\n\n--sse-kms-key-id (string) The customer-managed AWS Key Management Service (KMS) key ID that should be used to server-side encrypt the object in S3. You should only provide this parameter if you are using a customer managed customer master key (CMK) and not the AWS managed KMS CMK.\n\n--sse-c-copy-source (string) This parameter should only be specified when copying an S3 object that was encrypted server-side with a customer-provided key. It specifies the algorithm to use when decrypting the source object. AES256 is the only valid value. If the parameter is specified but no value is provided, AES256 is used. If you provide this value, --sse-c-copy-source-key must be specified as well.\n\n--sse-c-copy-source-key (blob) This parameter should only be specified when copying an S3 object that was encrypted server-side with a customer-provided key. Specifies the customer-provided encryption key for Amazon S3 to use to decrypt the source object. The encryption key provided must be one that was used when the source object was created. If you provide this value, --sse-c-copy-source be specified as well. The key provided should not be base64 encoded.\n\n--storage-class (string) The type of storage to use for the object. Valid choices are: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE. Defaults to ‘STANDARD’\n\n--grants (string)\n\nGrant specific permissions to individual users or groups. You can supply a list of grants of the form\n\n--grants Permission=Grantee_Type=Grantee_ID [Permission=Grantee_Type=Grantee_ID ...]\n\n\nTo specify the same permission type for multiple grantees, specify the permission as such as\n\n--grants Permission=Grantee_Type=Grantee_ID,Grantee_Type=Grantee_ID,...\n\n\nEach value contains the following elements:\n\nPermission - Specifies the granted permissions, and can be set to read, readacl, writeacl, or full.\n\nGrantee_Type - Specifies how the grantee is to be identified, and can be set to uri or id.\n\nGrantee_ID - Specifies the grantee based on Grantee_Type. The Grantee_ID value can be one of:\n\nuri - The group’s URI. For more information, see Who Is a Grantee?\n\nid - The account’s canonical ID\n\nFor more information on Amazon S3 access control, see Access Control\n\n--website-redirect (string) If the bucket is configured as a website, redirects requests for this object to another object in the same bucket or to an external URL. Amazon S3 stores the value of this header in the object metadata.\n\n--content-type (string) Specify an explicit content type for this operation. This value overrides any guessed mime types.\n\n--cache-control (string) Specifies caching behavior along the request/reply chain.\n\n--content-disposition (string) Specifies presentational information for the object.\n\n--content-encoding (string) Specifies what content encodings have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n--content-language (string) The language the content is in.\n\n--expires (string) The date and time at which the object is no longer cacheable.\n\n--source-region (string) When transferring objects from an s3 bucket to an s3 bucket, this specifies the region of the source bucket. Note the region specified by --region or through configuration of the CLI refers to the region of the destination bucket. If --source-region is not specified the region of the source will be the same as the region of the destination bucket.\n\n--only-show-errors (boolean) Only errors and warnings are displayed. All other output is suppressed.\n\n--no-progress (boolean) File transfer progress is not displayed. This flag is only applied when the quiet and only-show-errors flags are not provided.\n\n--page-size (integer) The number of results to return in each response to a list operation. The default value is 1000 (the maximum allowed). Using a lower value may help if an operation times out.\n\n--ignore-glacier-warnings (boolean) Turns off glacier warnings. Warnings about an operation that cannot be performed because it involves copying, downloading, or moving a glacier object will no longer be printed to standard error and will no longer cause the return code of the command to be 2.\n\n--force-glacier-transfer (boolean) Forces a transfer request on all Glacier objects in a sync or recursive copy.\n\n--request-payer (string) Confirms that the requester knows that they will be charged for the request. Bucket owners need not specify this parameter in their requests. Documentation on downloading objects from requester pays buckets can be found at http://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html\n\n--metadata (map) A map of metadata to store with the objects in S3. This will be applied to every object which is part of this request. In a sync, this means that files which haven’t changed won’t receive the new metadata. key -> (string)\n\nvalue -> (string)\n\nShorthand Syntax:\n\nKeyName1=string,KeyName2=string\n\n\nJSON Syntax:\n\n{\"string\": \"string\"\n  ...}\n\n\n--copy-props (string) Determines which properties are copied from the source S3 object. This parameter only applies for S3 to S3 copies. Valid values are:\n\nnone - Do not copy any of the properties from the source S3 object.\n\nmetadata-directive - Copies the following properties from the source S3 object: content-type, content-language, content-encoding, content-disposition, cache-control, --expires, and metadata\n\ndefault - The default value. Copies tags and properties covered under the metadata-directive value from the source S3 object.\n\nIn order to copy the appropriate properties for multipart copies, some of the options may require additional API calls if a multipart copy is involved. Specifically:\n\nmetadata-directive may require additional HeadObject API calls.\n\ndefault may require additional HeadObject, GetObjectTagging, and PutObjectTagging API calls. Note this list of API calls may grow in the future in order to ensure multipart copies preserve the exact properties a CopyObject API call would preserve.\n\nIf you want to guarantee no additional API calls are made other than than the ones needed to perform the actual copy, set this option to none.\n\n--metadata-directive (string) Sets the x-amz-metadata-directive header for CopyObject operations. It is recommended to use the --copy-props parameter instead to control copying of metadata properties. If --metadata-directive is set, the --copy-props parameter will be disabled and will have no affect on the transfer.\n\n--size-only (boolean) Makes the size of each key the only criteria used to decide whether to sync from source to destination.\n\n--exact-timestamps (boolean) When syncing from S3 to local, same-sized items will be ignored only when the timestamps match exactly. The default behavior is to ignore same-sized items unless the local version is newer than the S3 version.\n\n--delete (boolean) Files that exist in the destination but not in the source are deleted during sync.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_examples": "Examples\n\nThe following sync command syncs objects under a specified prefix and bucket to files in a local directory by uploading the local files to s3. A local file will require uploading if the size of the local file is different than the size of the s3 object, the last modified time of the local file is newer than the last modified time of the s3 object, or the local file does not exist under the specified bucket and prefix. In this example, the user syncs the bucket mybucket to the local current directory. The local current directory contains the files test.txt and test2.txt. The bucket mybucket contains no objects:\n\naws s3 sync . s3://mybucket\n\n\nOutput:\n\nupload: test.txt to s3://mybucket/test.txt\nupload: test2.txt to s3://mybucket/test2.txt\n\n\nThe following sync command syncs objects under a specified prefix and bucket to objects under another specified prefix and bucket by copying s3 objects. A s3 object will require copying if the sizes of the two s3 objects differ, the last modified time of the source is newer than the last modified time of the destination, or the s3 object does not exist under the specified bucket and prefix destination. In this example, the user syncs the bucket mybucket to the bucket mybucket2. The bucket mybucket contains the objects test.txt and test2.txt. The bucket mybucket2 contains no objects:\n\naws s3 sync s3://mybucket s3://mybucket2\n\n\nOutput:\n\ncopy: s3://mybucket/test.txt to s3://mybucket2/test.txt\ncopy: s3://mybucket/test2.txt to s3://mybucket2/test2.txt\n\n\nThe following sync command syncs files in a local directory to objects under a specified prefix and bucket by downloading s3 objects. A s3 object will require downloading if the size of the s3 object differs from the size of the local file, the last modified time of the s3 object is newer than the last modified time of the local file, or the s3 object does not exist in the local directory. Take note that when objects are downloaded from s3, the last modified time of the local file is changed to the last modified time of the s3 object. In this example, the user syncs the current local directory to the bucket mybucket. The bucket mybucket contains the objects test.txt and test2.txt. The current local directory has no files:\n\naws s3 sync s3://mybucket .\n\n\nOutput:\n\ndownload: s3://mybucket/test.txt to test.txt\ndownload: s3://mybucket/test2.txt to test2.txt\n\n\nThe following sync command syncs objects under a specified prefix and bucket to files in a local directory by uploading the local files to s3. Because the --delete parameter flag is thrown, any files existing under the specified prefix and bucket but not existing in the local directory will be deleted. In this example, the user syncs the bucket mybucket to the local current directory. The local current directory contains the files test.txt and test2.txt. The bucket mybucket contains the object test3.txt:\n\naws s3 sync . s3://mybucket --delete\n\n\nOutput:\n\nupload: test.txt to s3://mybucket/test.txt\nupload: test2.txt to s3://mybucket/test2.txt\ndelete: s3://mybucket/test3.txt\n\n\nThe following sync command syncs objects under a specified prefix and bucket to files in a local directory by uploading the local files to s3. Because the --exclude parameter flag is thrown, all files matching the pattern existing both in s3 and locally will be excluded from the sync. In this example, the user syncs the bucket mybucket to the local current directory. The local current directory contains the files test.jpg and test2.txt. The bucket mybucket contains the object test.jpg of a different size than the local test.jpg:\n\naws s3 sync . s3://mybucket --exclude \"*.jpg\"\n\n\nOutput:\n\nupload: test2.txt to s3://mybucket/test2.txt\n\n\nThe following sync command syncs files under a local directory to objects under a specified prefix and bucket by downloading s3 objects. This example uses the --exclude parameter flag to exclude a specified directory and s3 prefix from the sync command. In this example, the user syncs the local current directory to the bucket mybucket. The local current directory contains the files test.txt and another/test2.txt. The bucket mybucket contains the objects another/test5.txt and test1.txt:\n\naws s3 sync s3://mybucket/ . --exclude \"*another/*\"\n\n\nOutput:\n\ndownload: s3://mybucket/test1.txt to test1.txt\n\n\nThe following sync command syncs files between two buckets in different regions:\n\naws s3 sync s3://my-us-west-2-bucket s3://my-us-east-1-bucket --source-region us-west-2 --region us-east-1\n\n\nSync to an S3 access point\n\nThe following sync command syncs the current directory to the access point (myaccesspoint):\n\naws s3 sync . s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/\n\n\nOutput:\n\nupload: test.txt to s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/test.txt\nupload: test2.txt to s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/test2.txt\n"
    },
    {
      "command_name": "website",
      "command_url": "https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/website.html",
      "command_description": "Description\n\nSet the website configuration for a bucket.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_synopsis": "Synopsis\n  website\n<S3Uri>\n[--index-document <value>]\n[--error-document <value>]\n",
      "command_options": [
        "<S3Uri>",
        "[--index-document <value>]",
        "[--error-document <value>]"
      ],
      "command_options_description": "Options\n\npaths (string)\n\n--index-document (string) A suffix that is appended to a request that is for a directory on the website endpoint (e.g. if the suffix is index.html and you make a request to samplebucket/images/ the data that is returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character.\n\n--error-document (string) The object key name to use when a 4XX class error occurs.\n\nSee ‘aws help’ for descriptions of global parameters.",
      "command_examples": "Examples\n\nThe following command configures a bucket named my-bucket as a static website:\n\naws s3 website s3://my-bucket/ --index-document index.html --error-document error.html\n\n\nThe index document option specifies the file in my-bucket that visitors will be directed to when they navigate to the website URL. In this case, the bucket is in the us-west-2 region, so the site would appear at http://my-bucket.s3-website-us-west-2.amazonaws.com.\n\nAll files in the bucket that appear on the static site must be configured to allow visitors to open them. File permissions are configured separately from the bucket website configuration. For information on hosting a static website in Amazon S3, see Hosting a Static Website in the Amazon Simple Storage Service Developer Guide."
    }
  ],
  "service_description": "Description\n\nThis section explains prominent concepts and notations in the set of high-level S3 commands provided.\n\nPath Argument Type\n\nWhenever using a command, at least one path argument must be specified. There are two types of path arguments: LocalPath and S3Uri.\n\nLocalPath: represents the path of a local file or directory. It can be written as an absolute path or relative path.\n\nS3Uri: represents the location of a S3 object, prefix, or bucket. This must be written in the form s3://mybucket/mykey where mybucket is the specified S3 bucket, mykey is the specified S3 key. The path argument must begin with s3:// in order to denote that the path argument refers to a S3 object. Note that prefixes are separated by forward slashes. For example, if the S3 object myobject had the prefix myprefix, the S3 key would be myprefix/myobject, and if the object was in the bucket mybucket, the S3Uri would be s3://mybucket/myprefix/myobject.\n\nS3Uri also supports S3 access points. To specify an access point, this value must be of the form s3://<access-point-arn>/<key>. For example if the access point myaccesspoint to be used has the ARN: arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint and the object being accessed has the key mykey, then the S3URI used must be: s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mykey. Similar to bucket names, you can also use prefixes with access point ARNs for the S3Uri. For example: s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/myprefix/\n\nThe higher level s3 commands do not support access point object ARNs. For example, if the following was specified: s3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/object/mykey the S3URI will resolve to the object key object/mykey\n\nOrder of Path Arguments\n\nEvery command takes one or two positional path arguments. The first path argument represents the source, which is the local file/directory or S3 object/prefix/bucket that is being referenced. If there is a second path argument, it represents the destination, which is the local file/directory or S3 object/prefix/bucket that is being operated on. Commands with only one path argument do not have a destination because the operation is being performed only on the source.\n\nSingle Local File and S3 Object Operations\n\nSome commands perform operations only on single files and S3 objects. The following commands are single file/object operations if no --recursive flag is provided.\n\ncp\n\nmv\n\nrm\n\nFor this type of operation, the first path argument, the source, must exist and be a local file or S3 object. The second path argument, the destination, can be the name of a local file, local directory, S3 object, S3 prefix, or S3 bucket.\n\nThe destination is indicated as a local directory, S3 prefix, or S3 bucket if it ends with a forward slash or back slash. The use of slash depends on the path argument type. If the path argument is a LocalPath, the type of slash is the separator used by the operating system. If the path is a S3Uri, the forward slash must always be used. If a slash is at the end of the destination, the destination file or object will adopt the name of the source file or object. Otherwise, if there is no slash at the end, the file or object will be saved under the name provided. See examples in cp and mv to illustrate this description.\n\nDirectory and S3 Prefix Operations\n\nSome commands only perform operations on the contents of a local directory or S3 prefix/bucket. Adding or omitting a forward slash or back slash to the end of any path argument, depending on its type, does not affect the results of the operation. The following commands will always result in a directory or S3 prefix/bucket operation:\n\nsync\n\nmb\n\nrb\n\nls\n\nUse of Exclude and Include Filters\n\nCurrently, there is no support for the use of UNIX style wildcards in a command’s path arguments. However, most commands have --exclude \"<value>\" and --include \"<value>\" parameters that can achieve the desired result. These parameters perform pattern matching to either exclude or include a particular file or object. The following pattern symbols are supported.\n\n*: Matches everything\n\n?: Matches any single character\n\n[sequence]: Matches any character in sequence\n\n[!sequence]: Matches any character not in sequence\n\nAny number of these parameters can be passed to a command. You can do this by providing an --exclude or --include argument multiple times, e.g. --include \"*.txt\" --include \"*.png\". When there are multiple filters, the rule is the filters that appear later in the command take precedence over filters that appear earlier in the command. For example, if the filter parameters passed to the command were\n\n--exclude \"*\" --include \"*.txt\"\n\n\nAll files will be excluded from the command except for files ending with .txt However, if the order of the filter parameters was changed to\n\n--include \"*.txt\" --exclude \"*\"\n\n\nAll files will be excluded from the command.\n\nEach filter is evaluated against the source directory. If the source location is a file instead of a directory, the directory containing the file is used as the source directory. For example, suppose you had the following directory structure:\n\n/tmp/foo/\n  .git/\n  |---config\n  |---description\n  foo.txt\n  bar.txt\n  baz.jpg\n\n\nIn the command aws s3 sync /tmp/foo s3://bucket/ the source directory is /tmp/foo. Any include/exclude filters will be evaluated with the source directory prepended. Below are several examples to demonstrate this.\n\nGiven the directory structure above and the command aws s3 cp /tmp/foo s3://bucket/ --recursive --exclude \".git/*\", the files .git/config and .git/description will be excluded from the files to upload because the exclude filter .git/* will have the source prepended to the filter. This means that:\n\n/tmp/foo/.git/* -> /tmp/foo/.git/config       (matches, should exclude)\n/tmp/foo/.git/* -> /tmp/foo/.git/description  (matches, should exclude)\n/tmp/foo/.git/* -> /tmp/foo/foo.txt  (does not match, should include)\n/tmp/foo/.git/* -> /tmp/foo/bar.txt  (does not match, should include)\n/tmp/foo/.git/* -> /tmp/foo/baz.jpg  (does not match, should include)\n\n\nThe command aws s3 cp /tmp/foo/ s3://bucket/ --recursive --exclude \"ba*\" will exclude /tmp/foo/bar.txt and /tmp/foo/baz.jpg:\n\n/tmp/foo/ba* -> /tmp/foo/.git/config      (does not match, should include)\n/tmp/foo/ba* -> /tmp/foo/.git/description (does not match, should include)\n/tmp/foo/ba* -> /tmp/foo/foo.txt          (does not match, should include)\n/tmp/foo/ba* -> /tmp/foo/bar.txt  (matches, should exclude)\n/tmp/foo/ba* -> /tmp/foo/baz.jpg  (matches, should exclude)\n\n\nNote that, by default, all files are included. This means that providing only an --include filter will not change what files are transferred. --include will only re-include files that have been excluded from an --exclude filter. If you only want to upload files with a particular extension, you need to first exclude all files, then re-include the files with the particular extension. This command will upload only files ending with .jpg:\n\naws s3 cp /tmp/foo/ s3://bucket/ --recursive --exclude \"*\" --include \"*.jpg\"\n\n\nIf you wanted to include both .jpg files as well as .txt files you can run:\n\naws s3 cp /tmp/foo/ s3://bucket/ --recursive \\\n    --exclude \"*\" --include \"*.jpg\" --include \"*.txt\"\n\n\nSee ‘aws help’ for descriptions of global parameters."
}